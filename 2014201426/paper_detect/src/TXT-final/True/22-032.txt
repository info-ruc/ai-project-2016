 
the assumption-based truth maintenance system  atms  is an important tool in ai. so far its wider use has been limited due to the enormous computational resources which it requires. we investigate the possibility of speeding it up by using a modest number of processors in parallel. we begin with a highly efficient sequential version written in c and then extend this version to allow parallel execution on the encore multimax  a 1 node shared-memory multiprocessor. we describe our experiences in implementing this shared-memory parallel version of the atms  present detailed results of its execution  and discuss the factors which limit the available speedup. 
1 	introduction 
the assumption-based truth maintenance system  atms  is an important tool in ai. it makes the task of designing a problem solver much easier  removing the need for the problem solver to maintain information concerning derivations which it makes. without an atms  the problem solver must implicitly record which of its assumptions it currently believes to be true and what these assumptions imply. when it wishes to change its assumption set  it must also recompute the set of items which are implied. with an atms  the problem solver explores the problem space  informing the atms of the assumptions it makes  the items which it wishes to reason about  and the derivations which it makes concerning these items. the atms keeps track of which items hold under any given assumption set  thus allowing the problem solver to freely change the set of assumptions which it currently believes. a number of problem solvers have been built which use the atms in a number of ai subfields. the atms provides a convenient level of abstraction  greatly simplifying the structure of the problem solver  filman  1 . 
   so far wider use of the atms has been limited due to the enormous computational resources which it requires. the atms is often the bottleneck in the problem solving process  often having greater computational requirements than the problem solver with which it is collaborating. we investigate the possibility of speeding up the atms by using a modest number of processors in parallel. we begin with a highly efficient c-based implementation of the atms based on the techniques described in  dekleer  1 . through a number of modifications to the basic sequential atms  we obtain moderate speedup on the three example problem solver trace files which we examine. 
   'this research is supported by darpa contract n1-k1. edward rothberg is also supported by an office of naval research graduate fellowship. anoop gupta is also supported by a faculty award from digital equipment corporation 
   the paper is organized as follows. section 1 presents background information about the atms and introduces related terminology. section 1 presents details of an efficient sequential implementation of the atms. section 1 presents the modifications to the sequential implementation which were necessary to allow parallel execution. section 1 presents the results of executing the basic parallel implementation. we discuss the bottlenecks encountered and introduce a number of modifications to the basic algorithm to deal with these bottlenecks. section 1 discusses related work  and section 1 presents the conclusions. 
1 	the atms 
the atms serves as a companion to a problem solver  acting as a sort of ''truth database . the problem solver feeds beliefs  contradictions  and implications to the atms. the atms keeps track of what is true under what assumption sets and why. in this section we illustrate how the atms is used and introduce the terminology with a brief example. the example problem that we solve is the 1-queens problem  the problem of finding placements for three queens on a 1 by 1 chessboard such that no queen can capture any other. 
   everything which the problem solver reasons about is assigned an atms node. in the 1-queens example we use 1 nodes  one for each of the 1 squares on the chessboard and one goal node to represent the solution. each chessboard node represents the placement of a queen on the corresponding chessboard square. some subset of the atms nodes are designated to be assumptions. these are nodes which are presumed to be true unless there is evidence to the contrary. in the example  the 1 nodes assigned to chessboard squares are the assumptions. we assume that a queen can be placed at each square of the board. every important derivation made by the problem solver is recorded as a justification: 
where x1. x1 are the antecedent nodes and 1  is the consequent node. in the example  the problem solver tells the atms that any set of three queens placed on the board constitutes a solution. thus  the justifications take the form: 
	position 1  position 1 positions 	=  	goal-node 
where position  is an assumption which corresponds to a queen being on a particular square on the chessboard. an atms environment is a set of assumptions. a node n holds in environment e if n can be derived from e using the current set of justifications. an environment is inconsistent  called nogood  if the distinguished node false holds in it. in the 1-queens example  we declare any set of assumptions in which the corresponding board positions contain a capturing pair to be nogood. the answer to the 1-queens problem is the set of all consistent environments in which the goal node holds. 
	rothberg and gupta 	1 
   in the atms  sets of environments play an important role in keeping track of the contexts under which a given node holds. they are used extremely frequently  and consequently we need a concise representation for a mem. in our representation  we can take advantage of the fact that if a node holds under environment e  then it also holds under any superset of e. also  any node holds under a nogood environment  so it is never necessary to keep track of nogoods in the set. we therefore represent a set s of environments by its smallest consistent members  a list of environments  e 1 . e 1 -     which we call a minimal environment list. this representation has the following properties: 
  minimality - no e1 is a subset of any other. 
  consistency - no e1 is nogood. 
the distinction between sets of environments and sets of assumptions presents a possible source of confusion. for example  consider the environments {a  b  and {a  b  c . clearly {a  b  c} is a superset of {a  b}. yet  the minimal environment list  {a  b  c}  represents a subset of the minimal environment list  {a  b} ; the second contains environments which do not have assumption c in them  while the first does not. please keep this potential source of confusion in mind when we discuss environment supersets and subsets in the remainder of this paper. 
   the problem solving process involves a dialogue between the problem solver and the atms  in which the atms receives a sequence of requests to create new nodes  new assumptions  new 
justifications  and to provide information on the environments in which nodes hold. this information can be easily provided if the atms maintains with each node n a set of environments  in minimal environment list form  called its label. in addition to its minimal environment list properties  each node's label has the following two properties: 
  label soundness - node n holds in every environment in the label set. 
  label completeness - every environment e in which n holds is a member of the label. 
1 	sequential implementation 
we now examine how the sequential atms is actually implemented  with emphasis on those aspects of the implementation which are relevant to parallel execution. since we will be computing the speedups of the parallel implementation based on the execution time of the sequential implementation  we must make sure that sequential version is as efficient as possible. 
1 the trace files 
we first present the results of executing three problem solver traces on our atms. these traces were generated by monitoring the interaction between an actual problem solver and an atms  and dumping the observed interaction into a trace file. the traces are: 
  qpe  from a problem solver created by ken forbus fforbus  1  which solves qualitative physics problems. 
  bug  a trace which led to a bug in some atms implemen-tation. 
  1-q  from a problem solver which solves the 1-queens prob-lem. this formulation of the n-queens problem differs somewhat from the one described earlier in this paper. 
table 1 provides information on the three traces. it also provides the runtimes for the three traces  both for the lisp-based atms implementation of dekleer  dekleer  1  and for our c-based implementation. we provide these numbers to demonstrate that we are basing our parallel program on an efficient sequential implementation. the time quoted for dekleer's atms is from execution on a texas instruments explorer i lisp machine. the time quoted 
1 	parallel and distributed processing 

for our implementation is from execution on a single processor of an encore multimax multiprocessor. the encore multimax is a 
1 node  shared-memory multiprocessor  with an ns 1  1 mips  microprocessor at each node. we also include the runtime on a more widely available machine  a dec decstation 1  for reference purposes. these times include all costs involved in processing the trace files from beginning to end  including the time spent processing the atms commands and the time spent reading the trace files from disk. 
1 	implementation overview 
the four basic operations which the atms makes available to the problem solver are: 
  create-node n - create a new node. 
  create-as sumption // - create a new assumption. 
  justify-node n by x 1 .x 1 .. - add a new justification. 
  node-query n - request the current label of node n. 
   the problem solver places a sequence of these commands on a queue it shares with the atms. the atms repeatedly removes available commands from this queue. given a command  it performs the requested action  restores node label soundness and consistency for all nodes in the inference graph  and is then ready to 
perform the next command. 
   of the four commands which the atms makes available to the problem solver  only justify-node consumes significant amounts of time. the create-node command takes very little time  since at the 
point at which the node is created it does not participate in any justifications. the create-assumption command also takes little time for the same reason. the node-query command is also computationally inexpensive because of the properties of label consistency  soundness  completeness  and minimality. in order to process a node-query command  the atms simply returns the current label of the appropriate node. 
   when a justify-node command arrives at the atms  the labels of the consequent node n and any nodes which depend on node n may no longer be complete. node n may now be derivable from a new set of assumptions not currently in node n 's label. its label must be updated  and any changes to node n's label must be propagated to the successors of node n. 
   a new justification can also cause new nogood environments to be discovered  potentially causing the node label of any node in the inference graph to become inconsistent. the simplest example of this would be a justification whose consequent is the false node. in order to restore node consistency  environments which become nogood must be removed from all node labels. 
   in order to handle propagation of node labels  the atms maintains an update request stack. any time a node label is changed. update requests are placed on the request stack  one for each justification which has the modified node as an antecedent. the first step in the processing of a new justification is to push an update request onto the request stack. the atms continues popping update requests off of the update stack  processing the requests  and potentially pushing more requests onto the stack until the stack is empty. this corresponds to a depth first propagation of labels. 
a single update request is processed as follows: 
  the set of consistent environments which derive the conse-quent using the new justification and the new label environments is computed. this set is the intersection of the new label environments of the one antecedent with the labels of the other antecedents of the justification. 
  if the consequent is the false node  then all of these environ-ments are recorded as nogood. 
  otherwise  the consequent node label is set equal to the union of the previous label and the new set of environments. 
  the changes to the consequent label  i.e. the set of environ-ments in the label which were not present in the previous label  are propagated to all nodes which depend on the consequent. 
1 	set operations on minimal environment lists 
adding a new justification requires a number of set operations on sets of environments  including set union and set intersection. the minimal environment list representation allows us to perform these operations quickly. given two environment sets  $ and 1  represented as  e 1   e1   and  f1. f1   respectively  we perform set operation on them as follows: 
   when we wish to add a new set of environments to the label of a node  we must take the set union of the existing label with the set of new environments. the set union of s and t  in minimal form is the concatenation of the minimal forms of s and 1   with all supersets removed. 
   when we wish to compute the effect of a justification on its consequent node  we must find the set intersection of all of the labels of the antecedent nodes. the set intersection of s and t is somewhat more involved than the set union. if all supersets of t  are in s and all supersets of f1 are in t   then all environments which are supersets of both e1..'  and f1  are in s' n t . the set of all supersets of both e1  and f1'-  is the set of all supersets of the union of e1 and f1  remember that environments are sets of assumptions . for example  the intersection of the supersets of { 1 b  with the supersets of { b . c} is the supersets of {a. b . c     which is the union of {.1. b  with { b. c'}. thus the intersection of s with t is the set of all supersets of the pairwise unions of e1  with e1. thus  in minimal environment hst form  this is the cross product of the minimal environment list forms of s and t  again with all supersets removed. 
1 data structures 
the efficiency of the atms is highly dependent on the data structures and algorithms used in the implementation. a straightforward atms implementation can literally take days to solve a problem which a more sophisticated implementation solves in a few minutes. we first present the major data structures used in our atms implementation. the data structures are simply laid out here with brief descriptions; the purpose of each individual field will be made clear in later sections. 
the environment data structure has the following fields:  1  
present a bit vector representing the set of assumptions present in the environment.  1  constituents: a list of all assumptions present in the environment.  1  size: the number of assumptions present.  1  contra: a flag indicating whether the environment is consistent.  1  where: a list of all nodes which contain this environment in their labels.  1  orthogonal: a bit vector representing the set of assumptions which  if added to the environment  would result in a nogood environment. 
   the node data structure has the following fields:  1  label the node's label.  1  assumption: a pointer to the node's assumption fields  if the node is an assumption.  1  consequences: a list of justifications in which the node is an antecedent. 
   the assumption data structure has the following fields  in addition to its node fields:  1  binary: a bit vector representing the set of all binary nogoods this assumption participates in. if bit j is set in the binary field of assumption    then the environment {i  j  is nogood.  1  nogoods: a table of all minimal nogood environments in which the assumption belongs  indexed by environment size. 
   the justification data structure has the following fields:  1  antecedents: a list of antecedent nodes.  1  consequent: the consequent node. 
1 	the environment database 
our atms maintains three data structures to keep track of environments encountered during a problem solver run  an environment hash table  a consistent table  and a minimal nogood  mng  table. the environment hash table holds all environments encountered so far  both consistent and nogood  indexed by a hash function. the consistent table holds all consistent environments  and is indexed by environment size  number of assumptions present in the environment . the mng table holds all minimal nogoods  the nogoods which are not subsumed by any other nogood  and is again indexed by environment size. each environment has a unique physical representation in memory. 
   we make two modifications to the simple mng table for efficiency. first  we handle unary and binary nogoods as special cases. the assumption data structure has a field entitled binary which keeps track of unary and binary nogoods. if bit j in the binary field of assumption i is set  then the environment { ..j } is nogood. similarly  if bit   is set  then {1} is nogood. the second modification involves the nogood field of the assumption data structure. any environment in the mng table is also kept in the nogoods table of each assumption in the environment. these two modifications allow the atms to find all minimal nogoods containing a given assumption extremely quickly. 
   the consistent and mng tables form what we call the environment database. the environment database  together with the environment hash table  make the following frequent operations extremely fast: 
  when searching for a particular environment  find its unique representation. 
  when checking an environment for consistency  find all min-imal nogoods smaller than that environment. 
  when adding a new nogood  find all consistent and nogood environments larger than that environment. 
   we represent an environment as a bit vector. a one in bit i of the vector indicates the presence of assumption 1 in the environment. this representation allows us to do subset testing  the most prevalent operation in the atms  by simply anding the bit vector of one environment with the complement of the bit vector of the other environment. the bit vector representation also allows fast hash function computation. 
1 	the cross product 
when we handle an update request  we need to compute the cross product of a number of minimal environment lists  as was described previously. assume we wish to take the cross product of n minimal environment lists l1  i1   /n  with l  being the incremental update. we do this by looping over each hst  creating m    the cross product of l1 through / . we begin with m1 - /1  and at each iteration we compute mi +1 = m1  x /i+1  where both m  and mi+1 are in minimal environment list form. we do this by collecting the unions of each environment e in m   with each environment f in 
/  + i  again with supersets removed 
   we can greatly decrease the amount of time it takes to compute mn by using the following two techniques. first  if some envi-
ronment e in m  is subsumed by some environment in the label of the consequent of the justification which we are updating  then 
	rothberg and gupta 	1 
clearly every environment in m   + i . . . mn which is generated from e will also be subsumed by this environment. any such e may therefore be discarded 
   second  consider taking the cross product of m   with /i+1. if some environment e in m  is subsumed by some f in 1i+1  then clearly e will be in mi+1. since all environments which would result from taking the union of e with some environment in /i+1 are supersets of e and since e is in mi+1  none of the resulting environments will be present in mi+1. we can therefore place any such e into mi+1  thus avoiding having to take the union of e with each environment in mi+1. 
   if we compute the cross product  using these two techniques  the result is a minimal environment list which represents the change to the label of the consequent node n. if the consequent is not the false node  we add each environment in our cross product to the label of node n. we must now restore minimality in the label by checking every environment previously in the label for subsumption against every environment just added to the label. we then propagate the cross product list  which represents the changes to the label of node n  to every justification which has node n as an antecedent. 
   if the consequent is the false node  then our cross product list is a set of environments which were previously consistent but have just become nogood. we add them to the mng table  and sweep through the consistent and mng tables looking for subsumed environments. if an environment in the consistent table is subsumed  it is removed from the table and from the labels of all nodes which contain it  found in the where field of the environment . if an environment in the mng table is subsumed  it is removed from the table. 
   computing the union of two environments is an extremely frequent and potentially extremely costly operation in the atms. the method of union computation which we use is an assumption by assumption method. that is  given two environments e  and e1  we compute the union by successively adding the assumptions in 
¡ê1 into e  computing an intermediate environment at every step. the result of a union is either a consistent environment ¡ê1  which is the union of e  with ¡ê1  or nogood'  indicating that the union of e1 with e1 is nogood. while this seems like a somewhat cumbersome way of computing the union  if we look at the amount of work done per union we see that in practice it is extremely effective. in qpe  bug  and 1-q  the average number of assumptions which must be added to e1 before the union is known are 1  
1  and 1  respectively. 
   while the exact details of the union computation are crucial to the efficiency of a sequential implementation  they are not essential to understanding the parallel modifications which follow. briefly  the orthogonal field of the environment and the binary field of the assumption  see section 1  allow the atms to quickly determine when adding an assumption to a particular environment will result in a nogood. if these quick tests fail  then the environment must be checked for its existence in the hash table  and if it doesn't exist it must be checked for consistency with the minimal nogoods. 
   this concludes our discussion of an efficient sequential implementation of the atms. as was discussed in section 1  our implementation is quite competitive with existing atms implementations. we use the sequential implementation which we have described as the basis of comparison for the parallel implementations which we describe in the remainder of this paper. 
1 	modifications for parallel implementation 
we now discuss the modifications which are necessary to allow the preceding algorithm to be executed in parallel on a modest number of processors. our goal is to exploit as much parallelism as possible  but we can not afford to introduce a large amount of redundant work in doing so. 
1 	parallel and distributed processing 
1 division of work 
the overall structure of our parallel atms is quite similar to the structure of the sequential atms. the atms and the problem solver run concurrently  sharing commands and data through a shared command queue. in order to allow a greater amount of parallelism  we no longer require that node labels be made sound and complete at the completion of each command. this requirement would necessitate the synchronization of all processors after each command  an operation which would greatly constrain our ability to distribute work among the processors. we now only require that labels be made sound and complete before a node-query command is answered. thus  node-query commands are now somewhat expensive  since they require a global synchronization. create-node and assume-node messages again require very little work to be done  and are dealt with quickly. justify-node again require by far the most computation time  and thus afford the most opportunity to distribute work. 
   in order to decrease contention for tasks  each processor has its own update request stack. when a processor completes a task  it first looks for a new task in it's own update request stack. if it is empty  then the processor checks the global command queue. if the next command on the command queue is a node-query  or if the command queue is empty  the processor becomes idle. when all processors are idle  one processor processes and removes the nodequery command  thus unblocking the problem solver and allowing the problem solving process to proceed. we call this program pl we later provide variations of this basic algorithm. 
1 	locks 
in our shared memory implementation  all the processors access the same data structures. we therefore need a number of mutualexclusion locks to control simultaneous access to shared data. we begin by using straightforward locking techniques  and later modify our approach based on the observed bottlenecks. 
   our atms implementation has a number of local structures  where access and modifications to these structures has little or no effect on other structures. these include the environment hash table buckets  the environments  and the atms nodes. we provide a lock for each one of these structures to enforce the following conditions: for hash table buckets  no two processors may access the same bucket at the same time. for environments  we enforce the conditions that no nogood environment may be added to a node's label and when an environment becomes nogood  it must be removed from the label of every node which contains it  and that only a single processor may change an environment from good to nogood. for nodes  we enforce the condition that no node label may be accessed by more than one processor at the same time. in order to decrease contention when processing justification updates  we copy the node label and work with the copy. since a typical atms application has thousands of each of these structures and for now we are using at most 1 processors  contention for these locks is usually not a problem. 
   in contrast to the relatively local structures which we have just discussed  the environment database is a very global structure. a single change could conceivably affect every environment in the environment database. we must be able to check a new environment for consistency against all nogoods encountered so far. we must also allow a new nogood to be added and all existing environments to be checked for consistency against this new nogood. since the atms spends much of its time creating new environments and checking them for consistency  we cannot tolerate a high latency on consistency checking. at the same time  however  most new environments which are encountered are nogood  so to avoid superfluous work we want a new nogood to be recorded as soon as possible. we initially used a single global lock to control access to both the consistent and mng tables. since the atms spends a substantial percentage of its time within this lock  1% for 

the three traces   this global locking approach appears somewhat suspect. 
1 results 
we now present the results of executing the three problem solver traces on our parallel atms. note that because node-query information was not required when the traces were originally generated  these traces do not record this command the absence of this command does not affect the performance of the sequential atms significantly  since node-query commands take so little time to execute. in our parallel atms  however  the lack of these commands obviates the need for global synchronization. thus  the results we present here are optimistic  as the synchronization is done only at the completion of the entire trace. in applications where nodequery commands are frequent  one would expect less available parallelism. 
   the atms traces we examine seem to present abundant opportunities for parallelism. their inference graphs are extremely large  with thousands of justifications capable of being distributed among the processors  see table 1 . though the only limiting factor would appear to be the global lock on the consistent and mng tables  we observed speedups of only 1  1  and 1 for qpe  bug  and 1-q  respectively  when program 1 was executed on 1 processors. these were greatly below what one would expect  even given the global lock. the sequential atms spends 1%  1%  and 1% of its time within the lock for the three traces. if this were the only parallelism limitation  we would expect speedups of 1 or more. clearly  parallelism is being limited in some other way. 
   the most serious bottleneck appears to be processor idle time. when executed on 1 processors  the processors spend 1%  1%  and 1% of the total runtime  for qpe  bug  and 1-q  respectively  without a task to execute. we have a number of tasks of varying size to execute  and we wish to divide them among a number of processors so that each processor takes approximately the same amount of time to complete them. this near equal division of tasks is usually possible given a large number of tasks to distribute; the large number of tasks serve to smooth out the variations in grain size. however  two factors make this untrue in program pi. first  the variation in grain size is enormous. in the bug trace  for example  the processing of a single justification accounts for 1% of the run-time of the trace  see table 1 . second  as the trace progresses the size and complexity of the inference graph increases  thus making the amount of work involved in processing a justification increase. the combination of some extremely large grains with the tendency for the large grains to be towards the end of the trace combine to make it extremely likely that one processor will be stuck with a large grain while the other processors have nothing to work on. 
   in order to alleviate the grain size problem  we decrease the task size. instead of each problem solver issued command being a single task  we now consider each update request to be a task. in program pi  once the command queue becomes empty the processor simply quits. now  in program p1  an idle processor attempts to steal an update request from the update stacks of the other processors. in this way  work can be distributed among the processors even after the command queue has been emptied. comparing 

columns in table 1 we see that by decreasing the task size we have greatly increased the number of tasks and greatly reduced both the average and maximum task size. the net result of our modification  figure 1  is that the speedup is greatly increased from that of program pi  but it is still far from ideal. 
   another serious bottleneck in our parallel implementation is the environment database lock. in order to increase concurrency in the environment database  we introduce another variation on our basic algorithm. in programs pi and p1  only a single processor may access the database at one time. our modification  which we call modal access  allows a number of processors to access the table concurrently  while still maintaining the stringent consistency requirements of the environment database. 
   the problem in allowing concurrent access to the database comes from the potential simultaneous additions of a consistent environment and a nogood environment. in order to add the consistent environment to the database  we must know that it is not subsumed by any environment in the mng table. to add the nogood to the database  we must remove all environments which are subsumed by it from the consistent table. these requirements seem to place serious sequentiality constraints on modifications to the environment database. in order to avoid these constraints  we add a mode of access indicator. the three access modes are free mode  in which no processor is currently accessing the database; consistent mode  in which only consistent environments may be added to the database; and ng mode  in which only nogood environments may be added to the database. if a processor wishes to add a new consistent or nogood environment and finds the database in the wrong mode  it must wait until the conflicting access is complete. 
   we can modify the above slightly to increase concurrency. when new nogood environments are generated  they usually come in groups of more than one. we can therefore distribute the work of adding a list of new nogoods among a number of processors. new nogoods waiting to be added are placed on a global list. now when a processors wishes to add a consistent environment and finds the database in ng mode  instead of waiting for the mode to change  the processor pulls new nogood environments off of the global list and processes them. 
   figures 1 and 1 show the percentage of time each processor spends doing useful work as compared to the percentage spent waiting on locks and the percentage spent idle for two of the three traces executed with program p1. the numbers for the third trace are between those of the two presented. the speedups obtained from program p1  figure 1  are still far from ideal. while contention for the environment database is greatly reduced  it is still 
	rothberg and gupta 	1 
substantial. we also still have a substantial speedup reduction due 
to processor idle time. 
   note that the speedup obtained is not equal the product of the processor utilization and the number of processors used. this is due to several factors. first  our speedup numbers are obtained by dividing the parallel execution time by the execution time of the best sequential implementation. there are a number of overheads involved in the parallel implementation  such as environment list copying and redundant checks  which can reduce the speedup when compared to a sequential implementation without these overheads. second  the parallel atms does not necessarily do the same amount of work that the sequential atms does. for example  the parallel atms can process the justifications in a different order than the sequential atms. while the answer we arrive at is the same  the amount of propagation necessary to get to this answer may differ. third  there a number of hardware contention issues  including bus bandwidth and cache interactions  which can preclude linear speedups. we noticed a substantial degradation in speedup  as much as 1%  which could not be attributed to software issues and must therefore be caused by hardware contention. these issues are not reflected in the utilization graphs which we present. 
   we have yet to examine one possible cause of reduced speedup in the parallel implementation  redundant work. in the atms  it is difficult to establish a measure of how much  work  is being done. there are a number of routines which are called often and take large amounts of time  yet none dominates the others. one routine  subset testing  accounts for more of the runtime of the sequential atms than any other routine  and appears in many diverse places in the computation. it therefore appears to be a reasonably accurate measure of work. according to our subset measure of work  we observed that the parallel atms does between 1% and 1% of the work of the sequential atms for 1 or fewer processors. though the subset test numbers show interesting trends as the number of processors grows larger  the differences for less than 1 processors are not significant. 
1 	going to a still finer grain 
variation in grain size is still a problem in our implementation. furthermore  the problem would be much more severe if node-query commands were more frequent. one possible way to further decrease the grain size would be to split update requests into smaller pieces. in program p1  an update request contains a list of new environments which have been added to the label of an antecedent. in order to decrease the size of a single grain  we could split this list into many smaller lists. we could use a heuristic to determine approximating how long an update task will take. depending on the estimate  the list can be split so that other processors will not go idle while this task is executed. in the extreme  update requests can be split into single new antecedent environments. 
   performing updates with smaller lists of environments can generate a large amount of avoidable work  however. consider the cross product of   { a } . { b } . { c } . { d }   with   i }  if we simply perform the cross product  we get the fist  {1 } . if we split the list  {a}  { b } . {c'}. {d}  into two parts and perform separate cross products  however  we get  { a  d}  { b  d }  from the first part and  {d    from the second. now  instead of propagating a single list of length one to the successors of the consequent  a list of length two and a list of length one are propagated. 
   we can observe this situation in the bug trace file. the largest update task in the trace arises from a justification x1.x1 x1 x1 x1 = n. the update request comes from x i with a list of 1 new environments. nodes x1  x1  and x1 all have 1 environments in their labels  and node x 1 has 1 environment in its label. the resulting cross product environment list contains 1 environments  if the incoming new environment list of 1 environments is split into two environment lists of 1 environments each  one resulting cross product contains 1 environments and the other contains 

1. the net effect of splitting this single update request into two smaller requests is substantial. the sequential execution time for bug increases from around 1 seconds to 1 seconds  an increase of 1%. while we could have all processors working on a single update synchronize and combine their results before propagating them on  the added synchronization combined with the fact that the pieces of a split update are not necessarily smaller than the whole update combine to make such an action unwise. 
   due to the above reasons  our initial efforts to go to a smaller grain have not resulted in much success. in order to get significantly more speedup from some atms instances  we need to find a natural task grain which is smaller than that of an update request. unfortunately  no obvious alternative presents itself. 
1 related work 
while in this paper we have explored how atms parallelism can be exploited on a shared-memory multiprocessor  a related question is how it can be exploited on other types of parallel machine architectures. mike dixon and johan de kleer have proposed  dixon and dekleer  1  a massively parallel assumption-based truth maintenance system  which we refer to as the mpatms. this mpatms can utilize thousands of processors  thus potentialy making possible the extremely fast solution of large atms problems. for example  on the n-queens problem they achieve speedups of around 1 running on a 1k processor connection machine  hillis  1  over a sequential atms running on a symbolics lisp machine. 
   as dixon and dekleer discuss in the paper  their mpatms has a strong relation to chronological backtracking. specifically  the number of processors which execute a specific command in the mpatms is exactly equal to the number of times the command is executed by a sequential backtracker. in other words  the mpatms preforms the same amount of work as a sequential chronological backtracker  though  of course  the work is done in parallel. the problem  however  is that chronological backgracking is not the most efficient form of backtracking. more efficient techniques such as dependency directed backtracking exist. in fact  the atms was designed by dekleer as a means of dealing with the limitations inherent in backtracking. the atms avoids the main source of inefficiency in backtracking  the rederivation of previously derived conclusions. as an example of this efficiency  ken forbus  forbus  1  has developed a pair of problem solvers in the domain of qualitative physics. he finds that qpe  his atms based problem solver  is approximately 1 times faster than his backtracking based gizmo. 
   in the above context  while a 1-fold speedup for the n-queens problem appears promising  several factors must be considered. first  the symbolics lisp machine is a relatively slow machine. 
more modem machines offer many times the performance. second  the n-queens problem is one for which the atms offers no advantage over chronological backtracking. a backtracker will perform no redundant derivations when solving this problem. on problems which are less amenable to solution by chronological backtracking  we would expect substantially less speedup. thus  it remains to be seen whether this approach will offer significant speedups for atms problems from a wide range of domains. 
   work is also being done by hiroshi okuno on a parallel qlispbased atms lokuno  1 . 
1 	conclusions 
in this paper  we have presented the details of implementing both a sequential and a parallel atms. the results we obtained from executing the parallel implementation on an encore multimax allow us to draw a number of conclusions. 
  the traces we examined seemed to present abundant op-portunities for parallelism. they consisted of thousands 
of relatively independent tasks  seemingly capable of being distributed among a number of processors. however  this apparent abundance of parallelism proved to be somewhat elusive to exploit. 
  the obvious source of parallelism in the atms  the thousands of justifications  generated grains which varied enormously in size. in one trace  for example  a single justification accounted for 1% of the total runtime  making effective parallel distribution of grains impossible. in order to make grain sizes more uniform  we decreased the grain size by treating a single justification update as a task. we also introduced the notion of modal access to the environment database in order to alleviate the sequentiality constraints imposed by the global consistency requirements. 
  with these modifications  we were able to obtain speedups of between 1 and 1 using 1 processors for the three trace files which we examined. further speedups were limited by a number of factors  including still too large a variation in task grain size  processor contention for numerous mutualexclusion locks  and hardware contention issues. 
  although the parallelism is limited  by combining it with a highly efficient c-based implementation we have created an atms implementation which is significantly faster than currently available lisp-based implementations. 
  finally  despite significant efforts made by us  any attempts at increasing the available parallelism in the atms by reducing grain size resulted in an explosion in the amount of work done. this explosion of work is also present in the massively parallel approach to the atms. consequently  a major new insight is needed if we are to obtain significant speedup from parallel processing. 
   a more detailed version of this paper can be found in  rothberg and gupta  1 . 
acknowledgments 
we would like to thank johan dekleer and ken forbus for providing us with atms trace files. we would like to thank hiroshi okuno for his assistance in the initial stages of this research. 

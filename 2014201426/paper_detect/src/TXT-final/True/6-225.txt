 
to support more efficient video database management  this paper explores the concept of video association mining  with which the association patterns are characterized by sequentially associated video shots and their cluster information. given a continuous video sequence v  the video shot segmentation mechanism is first introduced to parse it into discrete shots. we then cluster shots into visually distinct groups and construct a shot cluster sequence by using the class label of each shot. an association mining scheme is designed to mine sequentially associated clusters from the sequence. those detected associations will convey valuable knowledge for video database management. the experimental results demonstrate the effectiveness of our design. 
1 introduction 
since the 1s  data mining has been a very active area for research and applications. many successful techniques have been implemented through academic research and industrial applications 
 agrawal and srikant  1  agrawal and srikant  1  wu  1   han and kamber  1 . however  these approaches deal with various databases  like transaction datasets  in which the relationship between data items is explicitly given. video and image databases are different from these databases. the most distinct feature of video and image databases is that the relationship between any two of their items cannot be explicitly  or precisely  figured out. this inherent complexity of the multimedia data has suggested that mining knowledge from multimedia materials is even harder than from general databases  zhu et al  
1  thuraisingham  1  zaiane  et al.  1 . generally  there are two types of video mining techniques:  1  special pattern detection  zhu et al  1   which detects some predefined special patterns; and  1  video clustering and classification  oh et al.   1  pan and faloutsos  1   which clusters and classifies video units into different categories. 
   different from these two types of video mining schemes  we address a new research area of video mining  video association mining  in this paper  where associations from video units are used to explore video knowledge. we will present a definition for video associations  and design a video association mining algorithm. as shown in fig. 1  we first segment a video sequence into shots and cluster shots into groups. then  we assemble the class information 
1 
of each shot to form a shot cluster sequence. we mine sequential associations from the sequence to find clusters with strong correlations and take strongly correlated clusters as video associations. 

fig. 1 some typical video scenes and video data transformation 
1 	video association mining 
generally  most videos from our daily life are edited by editors  where various kinds of shots are packed as scenes to convey video scenarios  as shown in fig. 1. there are two typical video scenes: 
 1  scenes that consist of visually similar shots  as demonstrated in fig. 1 a ; and  1  scenes that consist of visually distinct shots  as shown in fig. 1  b . in the first type of scenes  most video shots are visually similar. take fig. 1 a  as an example  if we denote each of the shots by  a   all shots form a sequence  aaaaaaa   and the self-coherence of  a  indicates an association of itself. we name this type of association as an intra-association  i.e.  all items in the association are the same. in the second type of scenes  sequential associations exist too. in fig.1 b   if we denote the actor by  a   the actress by  b  and the shot containing both of them by  c   all 
poster papers 
shots form a sequence  ababacab . the co-occurrence of  a  and  b  implies an association. we name this type of association as an inter-association  i.e.  items in the association are different. 
based on the above observations  wc define a video association 
as a sequential pattern with  for any  
where x  is a video item  see definition below   l denotes the length of the association. x' denotes the temporal order of x  indicates that x  happens before xj for an inter-
	and 	for 	an 	intra-association  
for simplicity  we use {x} as the abbre-
viation of an association. 
   due to the fact that the temporal information in a video sequence plays an important role in conveying the video content  we integrate traditional association measures {support and confidence  and video temporal information to evaluate video associations. 
some definitions are given as follows: 
  an item is a basic unit  which denotes a shot cluster. 
  given a shot cluster sequence  the temporal distance  td  between two items is the number of shots between them. e.g  given sequence  abdec   the temporal distance of  ab  is td ab =1  and for  ac  is td ac  =1. 
  an l-ltemassociation is a video association that consists of l sequential items. e.g.   abc  is a 1-itemassociation. 
  the l-itemset is an aggregation of all l-itemassociations  with each of its members being an l-ltemassociation. 
  given a temporal distance threshold  tdt  tdt=t  the temporal support {ts  of an association {x1...xl} is defined as the number of times that this association appears sequentially in the sequence. in addition  each time this association appears  the temporal distance between any two neighboring items of the association should be no more than t shots. that is  given any x  and  
  given tdt=t  the confidence of an association is defined as the ratio between the temporal support of {x} when tdt=t and the number of maximal possible occurrences of the association {x}. for an inter-association  the maximal possible occurrence of the association is determined by the number of occurrences of the item with the minimal support. its confidence is defined by eq. l . for an intra-association  all items are the same  the maximal possible occurrence of the association is determined by the support of the item and the association length  l   as defined by eq. 1   where  x  indicates the maximal integer which is not larger than x. 
 1  
 1  
  the l-litemset is an aggregation of all l-itemassociations that each of their temporal support is no less than a given threshold. 
1 	association mining algorithm 
our video mining algorithm consists of the following phases: 
1. transform phase. given video v  this step transforms v from continuous frames into a sequence dataset d. 
1. l-litemset phase. in this phase  we mine both intraassociations and inter-associations from d. we first find the litemset  and then use l-itemset and a user-specified threshold to find l-litcmset. we will iteratively execute this phase until no more non-empty l-litcmset can be found. 
1. collection & pruning phase. this phase prunes and selects valuable associations from all l-litemsets. 
   since phase 1 is quite obvious  we focus on phases 1 and 1. meanwhile  due to the fact that all items in intra-associations are the same  mining this type of associations is relatively easy  wc hereby introduce mechanisms on mining inter-associations only. 
   in the transform phase  we adopt some video processing techniques to segment a video sequence into shots  and execute shot clustering to explore relationships among shots. to detect video shots  we use our existing algorithm in  zhu et al.  1 . for the sake of simplicity  we select the 1th frame of each shot as its keyframe. after the shot segmentation  we adopt a modified split-andmerge clustering algorithm  horowitz and pavlidis  1  to cluster video shots into groups where visually similar shots are first merged into groups and the groups with large visual variances are split into two clusters. after shot clustering  each shot will receive a class label  we sequentially aggregate the class information of each shot by its original temporal order to form a shot cluster sequence d. as shown in fig. 1  each icon image denotes one shot and the letter below it indicates its class label  and the acquired shot cluster sequences are given in fig. 1  c . table 1 gives an example of the video association mining  where the first column presents the video shot cluster sequence. 
　　in the l-litcmset phase  we use the large itemset from the previous pass to generate the candidate itemset and then measure their temporal support by making a pass over the database a as shown in fig. 1. at the end of the pass  the support of each candidate is used to determine the l-litemset. the candidate generation is similar to the method in  agrawal and srikant  1 . it takes the set of all k-1 -itemassociations in lk-1 and all their items as input  and works as shown in fig. 1. take the 1-litemset l1 in the fourth column of table 1 as an example. if l1 is given as the input  we will get the itemset shown in the fifth column after the join. after pruning out sequences whose subsequences are not in l1  the sequences shown in the sixth column arc left. e.g.  {abdc} is pruned out because its subsequence {bdc} is not in l1. 
 1  
 1  
 1   
begin: 
 1  ik=new 	candidates generated from lk-1  see fig. 1 . 
 1  for each k-itemassociation in /k  we count its temporal support by considering the user's specification with tdt. 
 1  lk=candidates 	in ik with the minimum temporal support. 
end 
fig. 1 the l-litemset phase of the mining algorithm 
 1 . 	join the items of associations in lk-1 
 1 . 
 1 .  
fig. 1 candidate generation 
in fig. 1 and fig. 1  lk denotes the k-litemset and ik the k-itemset. 

poster papers 	1 

1 	experimental results and discussion 
traditional video database systems use video shots as the units to index and manage video data where the visual similarities among shots are used to construct the index structure. unfortunately  a single shot which is separated from its context has less capability to convey semantics; moreover  the index considering only visual similarities ignores the temporal information among shots. consequently  the constructed cluster nodes may contain shots that have considerable variances both in semantics and visual content and hereby do not make much sense to human perception. accordingly  a semantic video database management framework has been presented  zhu et al  1  where video semantic units  events  scenes or other scenario information  are used to construct a database index. to facilitate this goal  one of the most important tasks is to detect the video semantic units. in this section  our experimental results will demonstrate that the proposed video association mining technique could be used to explore semantic units for the management of video database systems. 
　　to evaluate the ability of video associations in addressing local event and scenario information and figure out the relationship between tdt and the mined associations  we set tdt with different values t  t=l. 1  1  1  1 and ＜＜  and assess the associations. for each acquired association  we scan the datasct to check whether all items in the association belong to the same scene each time when the association appears. we define the scene coverage  sc  of an association as the ratio between the frequency of the association's items belonging to the same scene and the frequency of the association's appearance. the higher the sc  the better the association addresses the scene and event information. on the other side  with an adopted temporal support  the smaller the tdt  the less is the number of mined associations. this indicates that the tdt also acts as a factor for pruning associations. we hereby define the pruning rate  pr  as the ratio between the number of associations when tdt is t  1  1  1  1  1  and 1. we have performed our experiments with 1 news videos and 1 medical videos  about 1 minutes   and the results arc given in table 1. 
　　table 1 demonstrates that when the tdt increases  the mined associations become worse in addressing the local scenario and event information. one reason for this declination is that the clustering process may cluster semantically unrelated shots into one group  and consequently  when evaluating the scene coverage  the items of an association would come from different events. however  with relatively small tdt values  this type of errors can be reduced  because items with a small temporal distance would more likely belong to one semantic unit. on the other hand  table 1 also indicates that the smaller the tdt  the less is the number of mined associations  but the better arc the mined associations in addressing event and scenario information. depending on the user's objectives of association mining  a balance between the number of associations and the sc is necessary to select a reasonable value for tdt. 
table l. video association mining results 

1 	conclusions 
to facilitate video database management  we have explored a new research area of video data mining. a video association mining algorithm has been proposed. given video v  we first transform it from sequential frames to a relational dataset by shot segmentation  clustering  and constructing a shot cluster sequence. the video mining scheme mines sequentially associated video items from this sequence. in addition to using the traditional association measures  we have integrated temporal features among video shots into the video association evaluation. the experimental results have demonstrated the ability of our mined associations in addressing semantic information for video database management. 
a c k n o w l e d g m e n t s 
this research has been supported by the u.s. army research laboratory and the u.s. army research office under grant number daad1-1. 

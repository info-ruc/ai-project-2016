
in this paper  we present a scheme based on feature mining and neuro-fuzzy inference system for detecting lsb matching steganography in grayscale images  which is a very challenging problem in steganalysis. four types of features are proposed  and a dynamic evolving neural fuzzy inference system  denfis  based feature selection is proposed  as well as the use of support vector machine recursive feature elimination  svm-rfe  to obtain better detection accuracy. in comparison with other well-known features  overall  our features perform the best. denfis outperforms some traditional learning classifiers. svm-rfe and denfis based feature selection outperform statistical significance based feature selection such as t-test. experimental results also indicate that it remains very challenging to steganalyze lsb matching steganography in grayscale images with high complexity.
1	introduction
steganalysis is the science and art of detecting the presence of hidden data in digital images  audios  videos and other media. in steganography or the hiding of secret data in digital media  the most common cover is digital images. to this date  many steganographical or embedding methods  such as lsb embedding  spread spectrum steganography  f1 algorithm and some other jpeg steganography  have been very successfully steganalyzed  fridrich etal.  1; ker  1a; fridrich et al. 1; harmsen and pearlman 1; choubassi and moulin 1; liu etal.  1a . several other embedding paradigms  include stochastic modulation  fridrich and goljan  1; moulin and briassouli  1  and lsb matching  sharp 1   however  are much more difficult to detect.

 support for this research was received from icasa  of
new mexico tech  and a dod iasp capacity building grant　the literature does provide a few detectors for lsb matching steganography. one of the first papers on detection of embedding by noise adding is the paper by harmsen and pearlman  harmsen and pearlman  1   wherein the measure of histogram characteristic function center of mass  hcfcom   is extracted and a bayesian multivariate classifier is applied. based on the contribution of harmsen and pearlman   ker  1b  proposes two novel ways of applying the hcf: calibrating the output using a down-sampled image and computing the adjacency histogram instead of the usual histogram. the best discriminators are adjacency hcfcom  a.hcfcom  and calibrated adjacency hcfcom  c.a.hcfcom  to improve the probability of detection for lsb matching in grayscale images. farid and lyu describe an approach to detecting hidden messages in images by using a wavelet-like decomposition to build high-order statistical models of natural images  lyu and farid  1 and 1 . fridrich et al.  propose a maximum likelihood  ml  estimator for estimating the number of embedding changes for non-adaptive ＼k embedding in images. based on the stego-signal estimation  holotyak et al.  present a blind steganalysis classifying on high order statistics of the estimation signal.
　unfortunately  the publications mentioned above did not fully address the issue of image complexity that is very important in evaluating the detection performance  though fridrich etal.  report that the ml estimator starts to fail to reliably estimate the message length once the variance of sample exceeds 1  indicating that the detection performance decreases with the increase in the image complexity .
　recently  the shape parameter of generalized gaussian distribution  ggd  in the wavelet domain is introduced by the authors to measure the image complexity in steganalysis  liu et al.  1b ; although the method proposed therein is successful in detecting lsb matching steganography in color images and outperforms other well-known methods  its performance is not so good in grayscale images  which is generally more difficult.
　on the other side  many steganalysis methods are based on feature mining and machine learning. in feature mining  besides feature extraction  another general problem is how to choose the good measures from the extracted features. avcibas et al.  propose a steganalysis using image quality metrics. in their method  they apply analysis of variance  anova  to feature selection  the higher the f statistic  the lower the p value  and the better the feature will be. essentially  the anova applied by avcibas etal. is significancebased feature selection like other statistics such as t-test  etc. but these statistics just consider the significance of individual feature  not the interaction of features. there has been little research that addresses in depth the feature selection problem with specific respect to steganalysis.
　in this paper  we propose four types of features and a dynamic evolving neural fuzzy inference system  kasabov and song  1; kasabov  1   denfis based feature selection to the steganalysis of lsb matching steganography in grayscale images. the four types of features consist of the shape parameter of ggd in the wavelet domain to measure the image complexity  the entropy and the high order statistics in the histogram of the nearest neighbors  and correlation features. we also adopt the well-known gene selection method of support vector machine recursive feature elimination  svmrfe   guyon etal.  1  for choosing good measures in steganalysis.
　comparing against other well-known methods in terms of steganalysis performance  our feature set  overall  performs the best. denfis outperforms some traditional learning classifiers. svm-rfe and denfis-based feature selection outperform statistical significance based feature selection such as t-test in steganalysis.
1	feature mining
1	image complexity
several papers  srivastava etal.  1; winkler  1; sharifi and leon-garcia  1  describe the statistical models of images such as probability models for images based on markov random field models  mrfs   gaussian mixture model  gmm  and ggd model in transform domains  such as dct  dft  or dwt.
　experiments show that a good probability density function  pdf  approximation for the marginal density of coefficients at a particular subband produced by various types of wavelet transforms may be achieved by adaptively varying two parameters of the ggd  sharifi and leon-garcia  1; moulin and liu  1   which is defined as
		 | |/x 	 1 
	px  ;   =	e
1/ 
where    z =1e t dt z t z 1	    1 is the gamma function.
here  models the width of the pdf peak  while  is inversely proportional to the decreasing rate of the peak;  is referred to as the scale parameter and  is called the shape parameter. the ggd model contains the gaussian and laplacian pdfs as special cases  using  = 1 and  =
1  respectively.
1 entropy and high order statistics of the histogram of the nearest neighbors there is evidence that adjacent pixels in ordinary images are highly correlated  huang and mumford  1; liu et al.  1a . consider the histogram of the nearest neighbors  denote the grayscale value at the point  i  j  as x  the grayscale value at the nearest point  i+1  j  in the horizontal direction as y  and the grayscale value at the nearest point  i  j+1  in the vertical direction as z. the variable h x y z  denotes the occurrence of the pair  x  y z   or the histogram of the nearest neighbors  nnh .
the entropy of nnh  nnh e  is calculated as follows:
	nnh e=log1 	 1 
where denotes the distribution density of the nnh.
the symbol h denotes the standard deviation of h.
the rthhigh order statistics of nnh is given as:
r
1 n1n1	h x  y z  1 n1n1h x  y z 
nnh hos r =n1 x=1 y=1 x=1	 	n1 x=1 y=1 z=1		 1 
                                                                 hr where n is the number of possible gray scales of the image  e.g.  for 1-bit grayscale image  n=1.
1	correlation features
the following three correlation features are extracted.
　1. the correlation between the least significant bitplane  lsbp  and the second least significant bit plane  lsbp1  and the autocorrelation in the lsbp: m1:m  1:n  denotes the binary bits of the lsbp and m1:m  1:n  denotes the binary bits of the lsbp1.
	covm m 	1 	1 	 1 
	c1 = cor m m 	1 	1  = 
	 m m1
where  m1 =varm 	1  	and  m1 =varm 	1  .
c k l   the autocorrelation of lsbp is defined as:
	ckl      = cor x x 	k 	l 	 1 
where xk =m1:m k n l x m k  1:   ;	l = 1  +1:ml  +1:  .n
　1. the autocorrelation in the image histogram: thehistogram probability density is denoted as  1  1 
1...n-1 . the histogram probability densities  he  ho  hl1  and hl1 are denoted as follows:
	he=  1  1  1...n-1   	ho=  1  1  1...n-1 ;
	hl1=  1  1  1...n-1-l  	hl1 =  l  l+1  l+1...n-1 .
　the autocorrelation coefficients c1 and ch l   where l is the lag distance  are defined as follows:
c1 =cor he ho  1 ch l =cor hl1 hl1  1 　1. the correlation in the difference between the imageand the denoised version: the original cover is denoted as f  the stego-image is denoted as f＞ d  ，  denotes some denoising function  the differences between the image and the denoised are:
ef =f-d f 
ef＞=f＞-d f＞ 
　generally  the statistics of efand ef＞ are different. the correlation features in the difference domain are extracted as follows. firstly  the test image is decomposed by wavelet transform. find the coefficients in hl  lh and hh subbands with the absolute value smaller than the threshold value  t  set these coefficients to zero  and reconstruct the image using the inverse wavelet transform on the updated wavelet coefficients. the reconstructed image is treated as denoised image. the difference between test image and reconstructed version is et  where tis the threshold value.
	c t kle  ;	    = cor e 	tk    etl   	 1 
where etk  =et 1:m k n l e  1:   ; tl  =e kt  +1:ml  +1:  .n the variables kand ldenote the lag distance.
1	neuro-fuzzy inference system based feature selection
neuro-fuzzy inference systems and evolving neuro-fuzzy inference systems are introduced in  kasabov  1 . the dynamic evolving neuro-fuzzy system  denfis  proposed by  kasabov and song  1  uses the takagisugeno type of fuzzy inference method  takagi and sugeno  1 .
　to improve the detection performance  based on our previous work  liu and sung  1   we propose a feature selection method based on the denfis supervised learning  described as follows:
　1. each individual feature is ranked in the order fromthe highest train accuracy to the lowest train accuracy with the use of denfis.
　1. the feature with the highest train accuracy is chosenas the first feature. after this step  the chosen feature set  f1  consists of the best feature  e1  corresponding to feature dimension one.
st
　1. the  n+1  feature set  fn+1={e1  e1  ...  en   en+1} is produced by adding en+1into the present n-dimensional feature set  fn= {e1 e1  ...  en} according to the following method: each feature ei i 1 ... n  outside of fn is added into fn; the classification accuracy of each feature set fn + {ei} is compared  the ec with the highest train accuracy is put into the set of candidates  c. the candidate set c generally includes multiple features  but only one feature will be chosen. the strategy is to measure the similarity of chosen features and each of the candidates. pearson's correlation between the candidate ec  ec  c and the element ei  ei  fn i=1...n  is calculated. to measure the similarity  the sum of the square of the correlation  sc  is defined as follows:
n
	sc ec  = cor e  e1  c	i 	 1 
i=1
where  ec  c ei  fn i=1...n . the ecwith the minimal value of sc ec  is chosen as en+1. we call this feature selection denfis-msc  for minimum of sc .
1	experiments
1	experimental setup
the original images in our experiments are 1 tiff raw format digital pictures from olympus c1. these images are 1-bit  1 pixels  lossless true color and never compressed. according to the method in  lyu and farid  1 and 1   we cropped the original images into 1 pixels in order to get rid of the low complexity parts of the images. the cropped color images are converted into grayscales and we hid data in these grayscales with different hiding ratio. lsb matching stego-images are produced. the hidden data in different covers are different. the hiding ratio is 1%.
1	feature extraction and comparison
the following features are extracted:
　1. shape parameter  of ggd of hh wavelet subband to measure image complexity  described in  1 .
　1. entropy of the histogram of the nearest neighbors nnh e  defined in  1 
　1. the high order statistics of the histogram of thenearest neighbors  nnh hos r  in  1 . ris set from 1 to 1  total 1 high order statistics.
　1. correlations features consist of c1 in  1   c k l  in  1   c1 in  1   ch l  in  1   and ce t;k l .
　we set the following lag distance to k and l in c k l  and get 1 features:
a. k= 1  l= 1  1  1  and 1; l= 1  k= 1  1  1  and 1.
b. k= 1  l= 1; k= 1  l=1; k=1  l= 1; k= 1 and l= 1.
c. k= 1  l=1; k=1  l=1.
　in  1   l is set to 1  1  1  and 1. in  1   we set the following lag distance to k and l in ce t;k l  and get following pairs: ce t; 1   ce t; 1   ce t;1   ce t; 1   ce t; 1   ce t; 1   and ce t;1 . tis set 1  1  1  1  1  1  1  1  and 1.
　henceforth  we use cf to denote the fourth type of correlation features; and use ehcc  for entropy  high order statistics  complexity  and correlation features  to denote types 1 to 1 features.
　to compare ehcc with other well-known features  the histogram characteristic function center of mass  hcfcom  features  harmsen and pearlman  1  are extracted because the hiding process of lsb matching steganography can be modeled in the context of additive noise. we extend hcfcom feature set to the high order moments. hcfhom stands for hcf center of mass high order moments; hcfhom r  denotes the rth order statistics. in our experiments  the hcfhom feature set consists of hcfcom and hcfhom r   r = 1  1  and 1 . based on harmsen and pearlman's work  ker  1b  proposed a.hcfcom and c.a.hcfcom. additionally  farid and lyu  1  1  described an approach to detecting hidden messages in images by building highorder moment statistics in multi-scale decomposition domain  we call the features homms   which consists of 1-dimension features in grayscale images.
1	detection performance on feature sets
to compare the detection performances on these feature sets with different classifiers  besides denfis  we apply the following classifiers to each feature sets. these classifiers are naive bayes classifier  nbc   support vector machines  svm   quadratic bayes normal classifier  qdc   nearest mean scaled classifier  nmsc   k-nearest neighbor classifier  knn  and adaboost that produces a classifier composed from a set of weak rules  vapnik  1; schlesinger and hlavac  1; heijden etal.  1; webb  1; schapire and singer  1; friedman etal. 1 .
　thirty experiments are done on each feature set using each classifier. training samples are chosen at random and the remaining samples are for test. the ratio of training samples to test samples is 1. the average classification accuracy is compared.
　table 1 compares the detection performances  mean values and standard deviations  on each feature set with the use of different classifiers. in each category of image complexity  the highest test accuracy is in bold. table 1 indicates that  regarding the classification accuracy of feature sets  on the average  ehcc performs best  followed by cf  homms performs worst; regarding the classification performance of classifiers  svm is the best; regarding image complexity  the test accuracy decreases while the image complexity increases. in the low complexity of    1  the highest test accuracy is 1%; in the high complexity of    1  the highest test accuracy is 1%. it shows that image complexity is an important factor to the detection performance. to obtain a higher detection performance  we combine
ehcc  hcfcom  homms  c.a. hcfcom  and a. hcfcom features  and apply three feature section methods  svm-rfe  guyon etal.  1   denfis-msc  and t-test  here we apply t-test instead of anova because cover samples and steganography samples are unpaired in each category of image complexity  to the features  and compare different classifiers and the three feature selections in the feature dimensions 1 to 1.
　fig. 1 compares the detection performance on the svm-rfe feature set with the use of denfis  svm  nbc  nmsc  and knn. it indicates that in the low image complexity  denfis and svm are the best; in the mediate and high image complexity  denfis is the best.
fig. 1 also shows that the detection performance decreases as the image complexity increases.
table 1. detection performances  mean value ＼ standard deviation  %  on the feature sets with the use of different classifiers. in different image complexity  the highest test accuracy is in bold.

　fig. 1 compares the three feature selections in the image complexity of    1 with the use of svm  denfis  and nmsc. it indicates that the feature selections svm-rfe and denfis-msc are better than t-test. furthermore  applying svm and denfis to svm-rfe and denfis-msc feature sets  the test accuracies are better than the highest value of table 1. due to the page limit  we don't list comparison of the feature selections in the high image complexity. our experiments also indicate that svm-rfe and denfismsc outperform t-test.

	 a 	   1	 b  1      1	 c  1      1

	 d  1      1	 e     1

fig. 1. comparison of the detection performance on svm-rfe feature set with the use of different classifiers.

fig. 1. comparison of feature selections denfis-msc  svm-rfe  and t-test in the image complexity of    1.1	conclusions
in this paper  we present a scheme of steganalysis of lsb matching steganography in grayscale images based on feature mining and neuro-fuzzy inference system. four types of features are extracted  a denfis-based feature selection is used  and svm-rfe is used as well to obtain better detection accuracy. in comparison with other features of hcfhom  homms  a.hcfcom  and c.a.hcfcom  overall  our features perform the best. denfis outperforms some traditional learning classifiers. svm-rfe and denfis based feature selection outperform statistical significance based feature selection such as t-test. experimental results also indicate that it is still very challenging for the steganalysis of lsb matching steganography in grayscale images with high complexity.


a prerequisite to efficient behavior by a multi-robot team is the ability to accurately perceive the environment. in this paper  we present an approach to deal with sensing uncertainty at the coordination level. specifically  robots attach information regarding features that caused the initiation of a course of action  to any coordination message for that activity. further information regarding such features  acquired by the team  are then combined and the expected utility of the started action is re-evaluated accordingly. experiments show that the approach allows to coordinate a large group of robots  addressing sensing uncertainty in a tractable way.
1 introduction
emerging large multi-robotteams hold great promise for revolutionizing the way some important  complex and dangerous tasks  such as disaster response1 and space exploration1are performed. such teams  consist of multiple  heterogeneous robots with imperfect sensors  which must act efficiently in the face of considerable uncertainty and time pressure. specifically  in many complex environments  robots have systematic sensor noise that leads individual robots to incorrect perception of the objects in the environment. this paper presents an approach that leverages multi-robot cooperation to overcome individual sensing limitations.
　dealing with sensing uncertainty is a key area of robot and agent research. a variety of techniques attempt to either reduce the uncertainty before deciding how to act  e.g.  bayesian filters  fox et al.  1   or explicitly deal with the uncertainty when choosing a course of action  e.g.  pomdps  theocharous et al.  1 . such approaches  require that each robot deals with its sensor noise on its own  thus failing to leverage any assistance the rest of the team might be able to supply. other work explicitly uses input from other members of the team to allow a more accurate picture of the environment to be created. for example  decpomdps have been used to devise a coordinated course of action  pynadath and tambe  1 . several approaches use cooperative perception to deal with perception limitation of the single robot  rosencratz et al.  1; dietl et al.  1; stroupe et al.  1 . the general idea of these approaches is to exchange sensor readings and aggregate them using different filtering techniques  e.g. kalman filters  dietl et al.  1; stroupe et al.  1  or particle filters  rosencratz et al.  1  .
　coordination in multi-robot systems has been successfully addressed using task assignment approaches  parker  1; werger and mataric  1; zlot et al.  1 . while task assignment has been deeply investigated in several scenarios and many different techniques have been proposed  little attention has been devoted to the impact that limited and noisy perception capabilities have on the task allocation process. in many applications  tasks to be allocated are created by the robots when particular features are extracted from the environment. such feature extraction process is subject to errors  which can greatly impact the overall task assignment process. cooperative perception techniques can be used to address this problem  however previous approaches to cooperative perception often require to exchange too many data among robots. a key reason for this is that  typically  each robot attempts to maintain an accurate model of the complete state when  in practice  only a small part of the overall state might be relevant to its activities.
　this paper presents an approach to deal with perception errors by exchanging information about observed features in a task assignment coordination framework. this approach comprises two key ideas  first  when a robot senses an event in the environment that might lead it to initiate a team activity  it immediately computes expected utility of action and inaction  given its confidence in its sensors. if the expected utility of acting is greater than that of not acting  it initiates the team activity. for example  if a team of robots is searching a sparsely occupied burning office building  any sensors suggesting the presence of a trapped civilian should immediately trigger a team response. over time  new information acquired by the team can impact the confidence in the occurrence of the event. at any point in time  if robots' confidence in the event drops sufficiently low  the team activity can be suspended. the idea of the approach is to balance the need for a rapid response in a time critical domain and the high costs of acting on incorrect sensor information.
　once a team activity has been initiated  messages are typically passed around the team to coordinate the activity. the second key idea to the proposed approach is to require that these communication messages include the event that led to the team activity being initiated. such information is considered as a justification for the team activity to be carried out. robots receiving such messages check whether they have any information that can impact confidence in the occurrence of the event. if so  the information are communicated to the robot initiating the action. this technique focuses the information gathering process on events that are important for team activities and  thus  prevents communication about irrelevant aspects of the state. notice that  in order to refute justifications  robots need to maintain a history of the areas they have observed so that they can report not seeing something at a particular location. in this way  uncertainty in robot perception is addressed at coordination level  focusing only on information which are relevant to robot mission and thus dramatically reducing the required communication overhead. to evaluate the effectiveness of the proposed approach  experiments were performed both in an abstract simulation environment and in a simulation framework based on player/stage1. the proposed approach was shown to perform almost as good as an approach that broadcasts every detected features to every other robots  while using orders of magnitude less communication bandwidth. unsurprisingly  the proposed approach did not perform as well when the environment was very sparse  because fewer robots had helpful information  or when the environment was very dynamic because information from other robots were soon out-of-date.
1 problem
this section formally describes the problem addressed by this paper. mobile robots r = {r1 ... rm}  with imperfect sensors  act in an environment with events.
the events are spread spatially across the environment. ei = true iff event i is observable at time t. the robots make observations oe +|    where oe+ corresponds to a positive reading for evente and oe  correspondsto a negativereading. the probability of a false positive reading is p oe+| e . notice that  false positive  or false negative  should be intended not as direct sensor readings  but as errors in the feature extraction process. the proposed binary model for robot observations is therefore well suited and general enough to represent such issues. moreover  such model can consider both errors due to systematic issues with sensors  and random errors of the feature extraction process.
　the prior probability of eti = true is written p eti  ★  1 . this is the probability an event occurs before robots acquire any observation. robot r estimate of eti = true  given acquired observation  is belr eti  ★  1 . the world changes dynamically according to p eti+1|eti  and p  eti+1| eti . the start time of an event to be t such that  eti 1 … eti and the end time of the event tfei to be t such that eti …  eti+1.
　when events occur  the robot team should take actions in response. the function ae t  ★ {1} returns 1 if the team is acting in response to event e at time t and returns 1 otherwise. informally  the team receives reward  α   for acting when an event is real  and costs for either not acting when the event is real  β1   or acting when it is not  β1 . formally  the problem for the team is to maximize:
		 1 
　to maximize expected utility  the team should act on ei only when:
       αbel eti    β1   bel eti     β1bel eti .	 1  1	example

figure 1: example of scenario where cooperative perception can enhance system performance
　figure 1 shows an example of the type of situation that cooperative teams of robots should avoid at low cost. unfilled hexagons show mobile robots performing search and rescue in an office-like environment. dotted lines indicate the paths the robots have taken through the environment. the filled hexagon is a robot that believes it sees an injured victim  indicated by the emoticon. it should consider initiating a joint activity to rescue the victim. however  there is not actually a victim at that location. since six other robots have recently passed that same location without sensing a victim the team should be able to quickly establish that the filled hexagon robot is experiencing a perception error and avoid the costs of the joint activity.
1 approach
the key idea to this approach is to use input from team mates to update confidence in reasons for acting  while starting actions on initial observations. the technical elements of the approach are: i  attach to coordination messages assumptions that justify a coordinated action; ii  add observations to coordination messages when relevant; iii  revise decisions to act based on observations attached from teammates to coordination messages.
　when a robot detects a new event  it performs an expected utility calculation to decide whether to act in response to that event  see equation 1 . if it decides to start a coordinated action  it attaches the justification for that coordinated action to the coordination messages. when a robot receives a coordination message  it evaluates whether it has relevant observations about that event. if it is the case  it will attach to the coordination message the relevant observations and it will send a cooperative perception message back to the robot that initiated the action. finally  when the robot that instantiated a coordinated action receives a cooperative perception message  it integrates all observations attached to the message and re-considers the expected utility  while continuing to perform the coordinated action. in particular  if robot r receives a cooperative perception message at time t related to the event  where   it will update belr eti  using the observations attached to the message. with the update belr eti  robot r will then re-evaluate the expected utility of continuing the activity.
world representation
　to support or refute observations performed by other team members  robots have to store their previous observations. in particular  their representation should include not only observed relevant features  but also in which parts of the environment they did not observe any relevant features. thus each robot maintains three main elements: i  a set of interesting points  ips ; ii  a representation of the observable space  os  iii  a set of positive observations  po . an interesting point is a portion of space where an event was detected at a given time step. each entry of the  ips  comprises: i  information characterizing the location to which the event is related  e.g.  x and y for a bi-dimensional representation ; ii  a numerical value  belief  representing the robot's estimates that the observation is correct.
　the os is dependent on the robot's sensors  but in general it is a representation of the portion of the environment that was observed by the robot's sensors at a given time step. the po is the set of relevant features that were detected at each time step. given an event ei detected by a robot r  robot r will perform the following operations to support or refute the event.
for each entry of the os history:
  if the portion of space related to ei is inside the current os and the corresponding po set contains an observation for that feature  attach the observation to the cooperative perception message  supporting the event detection .
  if the portion of space related to ei is inside the current os but the current po set does not contain any observation for that feature  create a negative observation and attach the observation to the cooperative perception message  refuting the event detection .
  if the portion of space related to ei is not inside the current os do nothing.

figure 1: supporting and refuting observations
　notice that  to relate observations to detected features  or events   the data association problem has to be solved  i.e. which feature is related to which observation . data association is a well known problem for robotic and tracking applications  see for example  hall and llinas  1  . several approaches have been used to address this problem  however  since our method is based on a feature-level representation  and the data association issue is not the main focus of our work  a distance threshold is adopted. other approaches to address the data association problem can be used; in fact  the decision process we described is general with respect to the chosen data association method.
　figure 1 provides a graphical representation of supporting and refuting observations  showing a robot with the current laser readings and the field of view of the camera. the os  in this case  is the intersection between the laser reading and the camera field of view. the point labeled as none in the figure is a point for which the robot cannot provide any information  because it can not observe that part of the environment.
bayesian update of robot knowledge
　in this work  the belief update of each robot is done using a bayes filter. specifically  a bayes filter is instantiated for each relevant detected event in the environment  equations 1 and 1 .
 1 
 1 
　since readings  obtained from team mates may be older than present time  they cannot be directly integrated using the filter equation  because  referring to a time step in the past  they should have influenced the robot's belief up to the present time. when a reading referring to a past time t is obtained the filter is reinitialized with a state
bel eti．  where. if the event location is not inside the ips a new interesting point is added to the ips. observations for the locations are generated using the po and the os. maintaining the history for os  po and ips for all the process has a cost in terms of memory that grows with time. to limit such cost  a valid time window t is used that goes from the current time tc back to tc   t. an appropriate time window can be chosen by considering the evolution model of the environment.
1 experiments and results
to evaluate the approach  we have tested our method both in an abstract simulationenvironmentand in a simulation framework based on player/stage. the former simulator has been used to test our method with a very large team of robots  1 team members . moreover  the behavior of our method has been tested under varying environmental conditions such as the world dynamism and the world size. the latter simulation environment allowed us to consider important issues such as sensor occlusion or message delay among team members. overall  the first experimental setting allows to test the general behaviorof the method  while the second set of experiments provides more accurate indications on specific robotic issues. two metrics were used to measure performance: the percentage of stopped actions out of the total number of actions incorrectly instantiated  percentage found  pfound on graphs  and the percentage of correctly stopped actions out of all the actions that were stopped  percentage good  pgood on graphs . in both cases  higher is better. notice that  the percentage good measure is related to the correctness of the approach while the percentage found measure is related to the completeness. these metrics are the key values underlying equation 1 and hence  with knowledge of the relative costs of action and inaction  allow for the computation of the team performance. in the experiments presented below  each robot initiates a coordinated action according to equation 1.
　the communication overhead is evaluated using two measures: i  number of messages exchanged at each time step by each robot; ii  size of the messages  in bytes  exchanged at each time step by each robot. we assume that the overhead of a broadcast message is higher than the overhead of a point to point message. in particular  we count a broadcast message as point to point message times the number of robots. while for a more precise analysis of the overhead one should consider the specific network used  this provides a general cost model for communication which is suitable for our level of analysis. in our experiments we used a task assignment algorithm based on token passing  scerri et al.  1 . tokens  representing tasks to be accomplished  get propagated through the team until a robot accepts the task. the algorithm has been chosen  because it requires a very low communication overhead and is thus well suited for our interest domain.
　the proposed approach  referred as sharerelinfo1 in the following  was compared to a benchmark strategy  called share all  where each robot shares all its observations with all other robots at each time step. clearly  this type of approach is infeasible for large teams  but it provides an upper bound on the performance that can be achieved by the cooperative perception process.
　experiments have been performed in a 1d office-like environment. to exchange information about features present in the environment  robots need to share a common reference framework. to simplify the experimental setting  we do not explicitly consider localization errors. as a matter of fact  standard localization techniques  fox et al.  1  can be used for our experimental scenario  and localization errors can be taken into account in the error model of the feature extraction process. each graph reports values averaged over 1 trials of the same experiment.
1 abstract simulator results
the abstract simulator captures key features of the environment  while being sufficiently abstract to test a wide range of parameters and configurations efficiently. the simulated robots have limited knowledge of the overall team state and can communicate only with a subset of the overall team. in each experiment there were 1 simulated robots  each with the same perception model.
　figure 1 shows that share all does perform better and the advantage increases as the world becomes more dynamic. however  for less dynamic environments sharerelinfo performs almost as well. for this team size  1 robots  the communication gain of sharerelinfo is approximately two orders of magnitude.

 1
 1.1.1.1.1.1.1.1 world change rate
figure 1: comparison between share all and sharerelinfo  varying world dynamics
　figure 1 shows performance as the size of the environment is varied  while keeping the number of robots and the sensor range constant. the performance decreases as the robot density becomes lower. this is because  when the density of robots decreases there will be less opportunity for mutual observations of same features  therefore less information for supporting or refuting observations can be provided.
1 player/stage results
in the player/stage experimental framework each robot is equipped with a laser range finder and a color camera. robot controllers are run as distributed processes over a network of pcs and messages are exchanged using the udp protocol. in this configuration  we can validate the coordination method with possible message loss and delay. objects of various colors are distributed over the map. the goal of the team is to detect objects and locate them in the map  figure 1 represents the reference experimental scenario .

figure 1: comparison among share all and sharerelinfo  varying world size

figure 1: reference experimental scenario
　the approach was tested in three different configurations  where the object and robot positions are different. specifically  the first configuration comprises one group of eight robots which observe the same group of objects. in this configuration the number of shared observations is very high. however  due to occlusions in the visual field the observations for each robot are not exactly the same. the second configuration includes two groups of robots. the first one is composed of eight robots which observe the same group of objects  the second group is composed of two robots which observe a group of other two objects. in this configuration the two groups of robots do not share any observations. finally  the third configuration  shown in figure 1  shows three groups of robots  in this case the number of shared observations among groups is very limited.
　figure 1 reports results obtained for the two methods in the three described configurations. figure 1 shows that the lower number of shared observation has a negative impact for both strategies and both measures. the completeness  pfound in graph  is more disadvantaged by the lower availability of shared observations than the correctness  pgood in graph . this can be explained by considering that  when there are fewer shared observations  there will be a lower chance that a robot will obtain enough information to stop an invalid action. on the other hand  once the relevant information has

figure 1: performance comparison among share all and
sharerelinfo in the tree different configurations
reached a robot  the chances to stop an invalid action remain almost constant.
　sharerelinfo achieves results which are very close to the share all strategy. as for completeness  the proposed method attains lower values and is more sensitive to the differences among configurations. this is due to the smaller amount of information that this method uses. in fact  when fewer observations are shared among robots  there is a lower chance that coordination messages reach robots that can provide relevant information to refute or support coordinated actions. however  the performance decrease is minimal while the gain in communication is very high  see below .
　as for correctness  sharerelinfo attains slightly better results than the share all strategy. this can be explained by considering how actions are created and stopped in the two policies. in the sharerelinfo a coordinated action can be stopped only when a message containing observations of a subset of the teammates is received and the computation of equation 1 indicates that the action should be stopped. in the share all strategy the policy to stop actions is different: each robot monitors  at each time step  the belief associated with features that originatedcorrespondingactions  and actions are stopped according to equation 1. in this way  if at some time step a subset of the robots experiences an error in the perception process for the same feature  the corresponding action will be stopped immediately. since the proposed approach integrates measures over time before stopping a coordinated action  it is less sensitive to this problem.
　figure 1 and 1 show that the proposed approach not only requires a lower number of messages  but ensures also a smaller communication overhead in terms of message size. since the communication overhead does not change significantly across the different configurations  we report results referred to one particular configuration  configuration 1 .
　the graphs show the number of messages and communication load for different world change rate. for this team size  1 robots  the communication gain is approximatively one order of magnitude. when the world change rate is lower  less coordinated actions will be instantiated. in such a situation  sharerelinfo requires a lower communication overhead  while the communication overhead for the share all strategy remains almost constant.
notice that  having a smaller communication overhead can

figure 1: communication comparison for different world change rate  number of messages 

figure 1: communication comparison for different world change rate  communication load 
be exploited to enhance the robustness of the system. for example  it could be possible to use a reliable communication protocol  e.g.  based on acknowledgment  to avoid or reduce message loss. moreover  the available bandwidth could be allocated to other processes to have a better coordination among team members  e.g.  to exchange the planned path to avoid collision or complex maneuvers .
1 conclusions
in this paper we proposed a novel approach to deal with distributed unreliable perception in dynamic environments. the approach enables robots to integrate previously made sensor readings to help refute incorrect sensing. the novelty of the proposed approach lies in dealing with perception errors at coordination level. this is achieved by introducing an abstract representation of the state and by sharing information driven by events.
　while obtained results refer to a simulated environment and thus deserve further investigation  this work is a first important step to explicitly consider uncertainty at the coordination level in a tractable way.
　addressing the problem of sensor inaccuracy at the coordination level provides several advantages: first of all the method is general and does not strictly depend on the tasks to be performed and on the types of sensors used. moreover  it uses an explicit representation of beliefs about the world  which is shared among team members. this could enable team members to reason about their states. for example  a very interesting issue for future work would be to analyze team member perception failures  based on coordinationmessages  and change the team coordination policy accordingly.
1 acknowledgment
alessandro farinelli is supported by the european office of aerospace research and development under grant number 1. the views and conclusions contained herein are those of the authors and should not be interpreted as necessarily representing the official policies or endorsements  either expressed or implied  of the european office of aerospace research and development.

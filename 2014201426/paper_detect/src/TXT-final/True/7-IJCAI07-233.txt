
a distributed constraint optimization problem  dcop  is a formalism that captures the rewards and costs of local interactions within a team of agents. because complete algorithms to solve dcops are unsuitable for some dynamic or anytime domains  researchers have explored incomplete dcop algorithms that result in locally optimal solutions. one type of categorization of such algorithms  and the solutions they produce  is koptimality; a k-optimal solution is one that cannot be improved by any deviation by k or fewer agents. this paper presents the first known guarantees on solution quality for k-optimal solutions. the guarantees are independent of the costs and rewards in the dcop  and once computed can be used for any dcop of a given constraint graph structure.
1	introduction
in a large class of multi-agent scenarios  a set of agents chooses a joint action as a combination of individual actions. often  the locality of agents' interactions means that the utility generated by each agent's action depends only on the actions of a subset of the other agents. in this case  the outcomes of possible joint actions can be compactly represented in cooperative domains by a distributed constraint optimization problem  dcop   modi et al.  1; zhang et al.  1a . a dcop can take the form of a graph in which each node is an agent and each edge denotes a subset of agents whose actions  taken together  incur costs or rewards to the agent team. applications of dcop include sensor networks  modi et al.  1   meeting scheduling  petcu and faltings  1  and robocup soccer  vlassis et al.  1 .
모globally optimal dcop algorithms can incur large computation or communication costs for domains where the number of agents is large or where time is limited. however  incomplete algorithms in which agents react on the basis of local knowledge of neighbors and constraint utilities can lead to a system that scales up easily and is more robust to dynamic environments. researchers have introduced k-optimal algorithms in which small groups of agents optimize based on their local constraints  resulting in a k-optimal dcop assignment  in which no subset of k or fewer agents can improve the overall solution. some examples include the 1optimal algorithms dba  yokoo and hirayama  1  and dsa  fitzpatrick and meertens  1  for distributed constraint satisfaction problems  discsps   which were later extended to dcops  zhang et al.  1a   as well as the 1optimal algorithms in  maheswaran et al.  1   in which optimization was done by agents acting in pairs. previous work has focused on upper bounds on the number of koptima in dcops  pearce et al.  1   as well as experimental analysis of k-optimal algorithms  zhang et al.  1a; maheswaran et al.  1 .
모unfortunately  the lack of theoretical guarantees on the quality of solutions obtained by k-optimal algorithms was a fundamental limitation; until now  we could not guarantee a lower bound on the quality of the solution obtained with respect to the quality of the global optimum. in this paper  we introduce such guarantees. these guarantees can help determine an appropriate k-optimal algorithm  or possibly an appropriate constraint graph structure  for agents to use in situations where the cost of coordination between agents must be weighed against the quality of the solution reached. if increasing the value of k will provide a large increase in guaranteed solution quality  it may be worth the extra computation or communication required to reach a higher k-optimal solution. for example  consider a team of autonomous underwater vehicles  auvs   zhang et al.  1b  that must quickly choose a joint action in order to observe some transitory underwater phenomenon. the combination of individual actions by nearby auvs may generate costs or rewards to the team  and the overall utility of the joint action is determined by their sum. if this problem were represented as a dcop  nearby auvs would share constraints in the graph  while far-away auvs would not. however  the actual rewards on these constraints may not be known until the auvs are deployed  and in addition  due to time constraints  an incomplete  k-optimal algorithm  rather than a complete algorithm  must be used to find a solution. in this case  worst-case quality guarantees for k-optimal solutions for a given k  that are independent of the actual costs and rewards in the dcop  are useful to help
1111rr
1
모모모모모모모figure 1: dcop example decide which algorithm to use. alternatively  the guarantees can help to choose between different auv formations  i. e. different constraint graphs.
모we present two distinct types of guarantees for k-optima. the first  in sections 1 and 1  is a lower bound on the quality of any k-optimum  expressed as a fraction of the quality of the optimal solution. the second  in section 1  is a lower bound on the proportion of all dcop assignments that a koptimum must dominate in terms of quality. this type is useful in approximating the difficulty of finding a better solution than a given k-optimum. for both  we provide general bounds that apply to all constraint graph structures  as well as tighter bounds made possible if the graph is known in advance.
1	dcop and k-optima
we consider a dcop in which each agent controls a variable to which it must assign a value. constraints exist on subsets of these variables; each constraint generates a cost or reward to the team based on the values assigned to each variable in the corresponding subset. although we assume in this paper that each agent controls a single variable  all results are valid for cases in which agents control more than one variable.
formally  a dcop is a set of variables  one per agent 
n := {1 ... n} and a set of domains a := {a1 ...  an}  where the ith variable takes value ai 뫍 ai. we denote the assignment of the multi-agent team by a =  a1 몫 몫 몫 an . valued constraints exist on various subsets s   n of these variables. a constraint on s is expressed as a reward function rs  a . this function represents the reward generated by the constraint on s when the agents take assignment a; costs are expressed as negative rewards. 붿 is the set of all such subsets s on which a constraint exists  and no s 뫍 붿 is a subset of any other s 뫍 붿. for convenience  we will refer to these subsets s as  constraints  and the functions rs  몫  as  constraint reward functions.  the solution quality for a particular complete assignment a is the sum of the rewards for that assignment from all constraints in the dcop: pearce et al.  1   ther adeviating group  = s 뫍붿 rs  a .between two
in
assignments  a and  a  was defined as d a a   := {i 뫍 n : ai  a i}  i.e. the set of variables whose values in  a differ from their values in a. the distance between two assignments was defined as d a a   := |d a a  | where | 몫 | denotes the size of the set. an assignment a is classified as a k-optimum if r a    r a   뫟 1  a  such that d a a   뫞 k. equivalently  at a k-optimum  no subset of k or fewer agents can improve the overall reward by choosing different values; every such subset is acting optimally given the values of the others.
example 1 figure 1 is a binary dcop in which agents choose values from {1}  with constraints s 1 = {1} and s 1 = {1} with rewards shown. the assignment a =  1 1  is 1-optimal because any single agent that deviates reduces the team reward. however   1 1  is not 1-optimal because if the group {1} deviated  making the assignment a  =  1 1   team reward would increase from 1 to 1. the globally optimal solution  a  =  1 1  is k-optimal for all k 뫍 {1 1}.
모in addition to categorizing local optima  k-optimality provides a natural classification for dcop algorithms. many algorithms are guaranteed to converge to k-optima  including dba  zhang et al.  1a   dsa  fitzpatrick and meertens  1   and coordinate ascent  vlassis et al.  1  for k = 1  and mgm-1 and sca-1  maheswaran et al.  1  for k = 1. globally optimal algorithms such as adopt  modi et al.  1   optapo  mailler and lesser  1  and dpop  petcu and faltings  1  converge to a k-optimum for k = n. 1 quality guarantees on k-optima
this section provides reward-independent guarantees on solution quality for any k-optimal dcop assignment. if we must choose a k-optimal algorithm for agents to use  it is useful to see how much reward will be gained or lost in the worst case by choosing a higher or lower value for k. we assume the actual costs and rewards on the dcop are not known a priori  otherwise the dcop could be solved centrally ahead of time . we provide a guarantee for a k-optimal solution as a fraction of the reward of the optimal solution  assuming that all rewards in the dcop are non-negative  the reward structure of any dcop can be normalized to one with all nonnegative rewards as long as no infinitely large costs exist .
proposition 1 for any dcop of n agents  with maximum constraint arity of m  where all constraint rewards are nonnegative  and where a  is the globally optimal solution  then  for any k-optimal assignment  a  where m 뫞 k   n 
m
	rm	r a  .	 1 

k nm
proof: by the definition of k-optimality  any assignment  a such that d a a   뫞 k must have reward r a   뫞 r a . we call this set of assignments a . now consider any non-null subset a    a . for any assignment  a 뫍 a   the constraints 붿 in the dcop can be divided into three discrete sets  given a and  a:
  붿1 a a     붿 such that  s 뫍 붿1 a a   s   d a a  .
  붿1 a a     붿 s.t.  s 뫍 붿1 a a   s 뫌 d a a   =  .
  붿1 a a     붿 s.t.  s 뫍 붿1 a a   s  붿1 a a   뫋 붿1 a a  .
모붿1 a a   contains the constraints that include only the variables in  a which have deviated from their values in a; 붿1 a a   contains the constraints that include only the variables in  a which have not deviated from a; and 붿1 a a   contains the constraints that include at least one of each. thus:
r a   = 1     rs  a   + 1     rs  a   + 1    rs  a  .
	s뫍붿 a a	s뫍붿 a a	s뫍붿 a a 
and  the sum of rewards of all assignments  a in a  is:
rs  a  
rs  a  .
since r a    r a     a  뫍 a  
	r a  뫟 a 뫍a  s뫍붿1 a a   rs  a  |+|a 뫍a  s뫍붿1 a a   rs  a  .	 1 
a 
모now  if the two numerator terms and the denominator can be expressed in terms of r a   and r a   then we have a bound on r a  in terms of r a  . to do this  we consider the particular a  which contains all assignments  a such that d a a   = k  and  a  뫍 a    a i 뫍 d a a   a i = a i . this means that exactly k variables in  a have deviated from their value in a  and these variables are taking the same values that they had in a .
there are d ak a   assignments  a 뫍 a . for every constraint
s 뫍 붿  there are exactlys 뫍 붿1 a a  . this is because there exists a uniqued ak a  |s  ||s | different assignments  a 뫍 a  for which a  뫍 a  for every subset of k variables in d a a  . if s   d a a    as stipulated by the definition of 붿1 a a    then there are d a a     |s | remaining variables from which k must
be chosen to completepossible assignments  a for which this is true. for all  d a a    and so there are  k a|s  for ||s |
all s 뫍 붿1 a a    rs  a   = rs  a    so a 뫍a  s 뫍붿1 a a   rs  a   = ssimilarly  for every constraint뫍붿  k | s 뫍 붿  there are d a a   |s |
d
different assignments  a 뫍 a  for which s 뫍 붿1 a a  . if s 뫌d a a   =    as stipulated by the definition of 붿1 a a    then there are d a a   |s | remaining variables from which k must be chosen to complete d a a    and so there are d a ak   |s | possible assignments  a for which this is true. for all  a  for all s 뫍 붿1 a a   rs  a   = rs  a   and  so a 뫍a  s 뫍붿1 a a   rs  a   = s 뫍붿  k rs  a  뫟 d a ak   mr a . d a a   |s |
therefore  from equation 1 

	d a a  	 a a  
r a  뫟k	d a	a  m	 a    k a  	d ak   
 which is minimized when d a a   = n  so equation 1 holds as a guarantee for a k-optimum in any dcop. it is possible that k   n   m; in this case we take n km to be 1. 
for binary dcops  m = 1   equation 1 simplifies to:
r.
the following example illustrates proposition 1:
example 1 consider a dcop with five variables numbered 1 to 1  with domains of {1}  fully connected with binary constraints between all variable pairs. suppose that a =  1 1 1  is a 1-optimum  and that a  =  1 1 1  is the global optimum. then d a a   = 1  and a contains  d ak a   = 1 assignments:  1 1 1    1 1 1    1 1 1    1 1 1    1 1 1    1 1 1    1 1 1    1 1 1    1 1 1    1 1 1 . whatever the values of the rewards are 
every constraint reward r 	1s}  aa    will equal r= r{1} a   fors  a a  =for 1 1 1 nk  1 = 1 
assignments in a  e.g. r{
 1 1 1   and  1 1 1   and similarly  every constraint reward rs  a  equals rs  a   for n k1 = 1 assignment in a. thus  
r.
모we now show that proposition 1 is tight  i.e. that there exist dcops with k-optima of quality equal to the bound.
proposition 1  n m k such that m 뫞 k   n  there exists some dcop with n variables  with maximum constraint arity m with a k-optimal assignment  a  such that  if a  is the globally optimal solution 
m
	rm m r a  .	 1 
n
k
proof: consider a fully-connected m-ary dcop where the domain of each variable contains at least two values {1} and every constraint rs contains the following reward function:
	  	   i 뫍 s ai = 1
rs  a  =            1   i 뫍 s ai = 1
	1	 otherwise
모the optimal solution a  is a i = 1   i. if a is defined such that ai = 1   i  then equation 1 is true. now we show that a is k-optimal. for any assignment  a  such that d a a   = k 
r a   = 붿1 a a   r a s   + s 붿1 a a   r a s   + s 붿1 a a r a s  .
	s뫍	뫍	뫍	  
	뫞  mk+ nm  knk nk n km	mknk k  m n k 	mm
= n! 뫅 n! n  k! mn  kk ! !  n n  mm  ! k !n   k ! m! k   m ! n   k !
	=	n!k! n   m   k !
m! k   m ! n! n   m   k !    n   k ! n   m ! 
	=  n	 n   m !k! n   m   k !
m  k   m ! n! n   m   k !    n   m ! n   k ! 
=  n n! nk  n nk  n m = r a  m  n  k  !    n   m ! k     k 
 
 because in a  each of the mn constraints in the dcop are producing the same reward. since this can be shown for d a a   = j    j such that 1 뫞 j 뫞 k a is k-optimal. 
1	graph-based quality guarantees
the guarantee for k-optima in section 1 applies to all possible dcop graph structures. however  knowledge of the structure of constraint graphs can be used to obtain tighter guarantees. this is done by again expressing the two numerator terms in equation 1 as multiples of r a   and r a . however  for a sparse graph  if a  is chosen as defined in proposition 1  there may be many assignments  a 뫍 a  that have few or no constraints s in 붿1 a a   because the variables in d a a   may not share any constraints. instead  exploiting the graph structure by choosing a smaller a  can lead to a tighter bound. we can take a  from proposition 1  i.e. a  which contains all  a such that d a a   = k and  a  뫍 a    a i 뫍 d a a   a i = a i . then  we restrict this a  further  so that  a  뫍 a   the variables in d a a   form a connected subgraph of the dcop graph  or hypergraph   meaning that any two variables in d a a   must be connected by some chain of constraints. this allows us to again transform equation 1 to express r a  in terms of r a  ; this new method can produce tighter guarantees for k-optima in sparse graphs. as an illustration  provably tight guarantees for binary dcops on ring graphs  each variable has two constraints  and star graphs  each variable has one constraint except the central variable  which has n   1  are given below.
proposition 1 for any binary dcop of n agents with a ring graph structure  where all constraint rewards are nonnegative  and a  is the globally optimal solution  then  for any k-optimal assignment  a  where k   n 
	r a  뫟 kk +  1r a  .	 1 
proof: returning to equation 1  |a | = n because d a a   could consist of any of the n connected subgraphs of k variables in a ring. for any constraint s 뫍 붿  there are k   1 assignments  a 뫍 a  for which s 뫍 붿1 a a   because there are k  1 connected subgraphs of k variables in a ring that contain
are n k 1 assignments  	     because s. therefore  a 	also  there
there are n   k   1 ways to choose s in a ring so that it does not include any variable in a given connected subgraph of k
variables. therefore 	a 뫍a 	s 뫍붿  a a   rs  a   =  n	k	1 r a .
so  from equation 1  		1	 	 
r a  뫟  k   1 r a   +n n   k   1 r a 
and therefore equation 1 holds. 
proposition 1 for any binary dcop of n agents with a star graph structure  where all constraint rewards are nonnegative  and a  is the globally optimal solution  then  for any k-optimal assignment  a  where k   n 
	r a  뫟 nk    1r a  .	 1 
proof: the proof is similar to the previous proof. in a star graph  there are nk  1 subgraphs of k variables  and therefore |a | = n 1. every constraint s 뫍 붿 includes the central variable and one other variable  and thus there arek 	n 1
                   k variables that contain s  and there-k  connected subgraphs of
fore a 뫍a  s 뫍붿1 as a   so that it does not include any variablers     . finally  there are no ways to choose
in a given connected subgraph of k variables.	therefore 

a 뫍a  s 뫍붿1 a a   rs  a   = 1r a . so  from equation 1 
n
	r a  뫟 k  	n
k
and therefore equation 1 holds. 
모tightness can be proven by constructing dcops on ring and chain graphs with the same rewards as in proposition 1; proofs are omitted for space. the bound for rings can also be applied to chains  since any chain can be expressed as a ring where all rewards on one constraint are zero.
모finally  bounds for dcops with arbitrary graphs and nonnegative constraint rewards can be found using a linearfractional program  lfp . this method gives a tight bound for any graph  since it instantiates the rewards for all constraints  but requires a globally optimal solution to the lfp  in contrast to the constant-time guarantees of equations 1  1 and 1. an lfp such as this is reducible to a linear program  lp   boyd and vandenberghe  1 . the objective is to minimize rr  aa    such that  a  뫍 a  r a    r a   뫟 1  given
a  as defined in proposition 1. note that r a   and r a  can be expressed as s 뫍붿 rs  a   and s 뫍붿 rs  a  . we can now transform the dcop so that every r a   can also be expressed in terms of sums of rs  a   and rs  a   without changing or invalidating the guarantee on r a . therefore  the lfp will contain only two variables for each s 뫍 붿  one for rs  a   and one for rs  a   where the domain of each one is the set of nonnegative real numbers. the transformation is to set all reward functions rs  몫  for all s 뫍 붿 to 1  except for two cases: when all variables i 뫍 s have the same value as in a   or when all i 뫍 s have the same value as in a. this has no effect on r a   or r a   because rs  a   and rs  a  will be unchanged for all s 뫍 붿. it also has no effect on the optimality of a  or the koptimality of a  since the only change is to reduce the global reward for assignments other than a  and a. thus  the tight lower bound on rr a   still applies to the original dcop.
1	domination analysis of k-optima
in this section we now provide a different type of guarantee: lower bounds on the proportion of all possible dcop assignments which any k-optimum must dominate in terms of solution quality. this proportion  called a domination ratio  provides a guide for how difficult it may be to find a solution of higher quality than a k-optimum; this metric is commonly used to evaluate heuristics for combinatorial optimization problems  gutin and yeo  1 .
모for example  suppose for some k  the solution quality guarantee from section 1 for any k-optimum was 1% of optimal  but  additionally  it was known that any k-optimum was guaranteed to dominate 1% of all possible assignments to the dcop. then  at most only 1% of the other assignments could be of higher quality  indicating that it would likely be computationally expensive to find a better assignment  either with a higher k algorithm  or by some other method  and so a koptimal algorithm should be used despite the low guarantee of 1% of the optimal solution quality. now suppose instead for the same problem  the k-optimum was guaranteed to dominate only 1% of all assignments. then it becomes more likely that a better solution could be found quickly  and so the k-optimal algorithm might not be recommended.
모to find the domination ratio  observe that any k-optimum a must be of the same or higher quality than all  a 뫍 a  as defined in proposition 1. so  the ratio is:
1 + |a |
	.	 1 
i뫍n |an|
 if the constraint graph is fully connected  or not known  and so must be assumed to be fully connected   and each variable has q values  then |a | = kj=1 nj q   1 j and i뫍n |an| = qn.
if the graph is known to be not fully connected  then the set
a  from equation 1 can be expanded to include assignments of distance greater than k from a  providing a stronger guarantee on the ratio of the assignment space that must be dominated by any k-optimum. specifically  if a is k-optimal  then any assignment where any number of disjoint subsets of size 뫞 k have deviated from a must be of the same or lower quality as a  as long as no constraint includes any two agents in different such subsets; this idea is illustrated below:
example 1 consider a binary dcop of five variables  numbered 1 to 1  with domains of two values  with unknown constraint graph. any 1-optimum must be of equal or greater quality than 1 +1+1 = 1% of all possible assignments  i.e. where 1  1  1  or 1 agents have deviated.
모now  suppose the graph is known to be a chain with variables ordered by number. since a deviation by either the variables {1} or {1} cannot increase global reward  and no constraint exists across these subsets  then neither can a deviation by {1 1}  even though four variables are deviating. the same applies to {1 1} and {1 1}  since both are made up of subsets of three or fewer variables that do not share constraints. so  a 1-optimum is now of equal or greater quality than 1 +1+1+ 1 = 1% of all assignments. 
모an improved guarantee can be found by enumerating the set a  of assignments  a with equal or lower reward than a; this set is expanded due to the dcop graph structure as in the above example. the following proposition makes this possible; we introduce new notation for it: if we define n different subsets of agents as di for i = 1...n  we use dm = 뫋mi=1di  i.e. dm is the union of the first m subsets. the proof is by induction over each subset di for i = 1...n.
proposition 1 let a be some k-optimal assignment. let a n be another assignment for which d a a n  can be expressed as dn = 뫋ni=1di where:
   di  |di| 뫞 k.  subsets contain k or fewer agents 
   di  dj  di 뫌 dj =  .  subsets are disjoint 
   di  dj i 뫍 di  j 뫍 dj such that i  j 뫍 s  for any s 뫍 붿.
모모 no constraint exists between agents in different subsets  then  r a  뫟 r a n .
proof:
모base case: if n = 1 then dn = d1 and r a  뫟 r a n  by definition of k-optimality.
모inductive step: r a  뫟 r a n 1    r a  뫟 r a n . the set of all agents can be divided into the set of agents in dn 1  the set of agents in dn  and the set of agents not in dn. also  by inductive hypothesis  r a  뫟 r a n 1 . therefore 
rrs  a 
rs  a n 1 
rewards from agents outsideso s 뫍붿:s 뫌dn	  because thea and  an 1.
모let a be an assignment such that  dn = d a n 1 a n . because a is k-optimal  r ; therefore 
rrs  a 
rs .
and so	s  because the
rewards from agents outside	dn are the same for a and a.
	we also know that	s 뫍붿:s 뫌d =  rs  a  = s
because the rewards from agents outside	n	dn are the same for뫍붿:s 뫌dn=  rs  a n 
a and  an; therefore 
rrs  a n 
rs  a n 
 because the rewards from dn 1 are the same for  an 1 and  an  and the rewards from dn are the same for a and  an. therefore  r a  뫟 r a n . 
1	experimental results
while the main thrust of this paper is on theoretical guarantees for k-optima  this section gives an illustration of the guarantees in action  and how they are affected by constraint graph structure. figures 1a  1b  and 1c show quality guarantees for binary dcops with fully connected graphs  ring graphs  and star graphs  calculated directly from equations 1  1 and 1. figure 1d shows quality guarantees for binary-tree dcops  obtained using the lfp from section 1. the x-axis plots the value chosen for k  and the y-axis plots the lower bound for koptima as a percentage of the optimal solution quality for systems of 1  1  1  and 1 agents. these results show how the worst-case benefit of increasing k varies depending on graph structure. for example  in a five-agent dcop  a 1-optimum is guaranteed to be 1% of optimal whether the graph is a star or a ring. however  moving to k = 1 means that worst-case solution quality will improve to 1% for a star  but only to 1% for a ring. for fully connected graphs  the benefit of increasing k goes up as k increases; whereas for stars it stays constant  and for chains it decreases  except for when k = n. results for binary trees are mixed.
모figure 1 shows the domination ratio guarantees for koptima from section 1  for dcops where variables have do-

figure 1: quality guarantees for k-optima with respect to the global optimum for dcops of various graph structures.

figure 1: domination ratio guarantees for k-optima for various graph structures.
mains of two values. this figure  when considered with figure 1  provides insight into the difficulty of finding a solution of higher quality than a k-optimum. for example  a 1optimum in a fully connected graph of 1 agents  figure 1a  is only guaranteed to be 1% of optimal; however this 1optimum is guaranteed to be of higher quality than 1% of all possible assignments to that dcop  figure 1a   which suggests that finding a better solution may be difficult. in contrast  a 1-optimum in a ring of 1 agents  figure 1b  has the same guarantee of 1% of optimal solution  but this 1optimum is only guaranteed to be of higher quality than 1% of all possible assignments  which suggests that finding a better solution may be easier.
1	related work and conclusion
this paper contains the first guarantees on solution quality for k-optimal dcop assignments. the performance of any local dcop algorithms can now be compared in terms of worst case guaranteed solution quality  either on a particular constraint graph  or over all possible graphs. in addition  since the guarantees are reward-independent  they can be used for any dcop of a given graph structure  once computed.
모in  pearce et al.  1   upper bounds on the number of possible k-optima that could exist in a given dcop graph were presented. the work in this paper focuses instead on lower bounds on solution quality for k-optima for a given dcop graph. this paper provides a complement to the experimental analysis of local optima  1-optima  arising from the execution of incomplete dcop algorithms  zhang et al.  1a; maheswaran et al.  1 . however  in this paper  the emphasis is on the worst case rather than the average case.
모the results in this paper can help illuminate the relationship between local and global optimality in many types of multi-agent systems  e. g. networked distributed pomdps  nair et al.  1 . all results in this paper also apply to centralized constraint reasoning. however  examining properties of solutions that arise from coordinated value changes of small groups of variables is especially useful in distributed settings  given the computational and communication expense of large-scale coordination.

 
many researchers have noted the importance of combining inductive and analytical learning  yet we still lack combined learning methods that are effective in practice. we present here a learning method that combines explanation-based learning from a previously learned approximate domain theory  together with inductive learning from observations. this method  called explanation-based neural network learning  ebnn   is based on a neural network representation of domain knowledge. explanations are constructed by chaining together inferences from multiple neural networks. in contrast with symbolic approaches to explanation-based learning which extract weakest preconditions from the explanation  ebnn extracts the derivatives of the target concept with respect to the training example features. these derivatives summarize the dependencies within the explanation  and are used to bias the inductive learning of the target concept. experimental results on a simulated robot control task show that ebnn requires significantly fewer training examples than standard inductive learning. furthermore  the method is shown to be robust to errors in the domain theory  operating effectively over a broad spectrum from very strong to very weak domain theories. 
1 	the problem 
analytical learning methods such as explanation-based learning  ebl   dejong and mooney  1    mitchell et a/.  1  use prior knowledge to explain and then gener-
alize from observed training data. while such methods may dramatically reduce the number of training examples needed for successful generalization  in their pure 
1
　　this research was done while the first author was with carnegie mellon university. 
     this research was sponsored in part by the avionics lab  wright research and development center  aeronautical systems division  afsc   u. s. air force  wrightpatterson afb  oh 1 under contract f1c-1  arpa order no. 1. the views and conclusions contained in this document are those of the authors and should not be interpreted as representing the official policies  either expressed or implied  of the u.s. government. 
machine learning 
network learning and d learning 
tom m. mitchell school of computer science carnegie mellon university pittsburgh  pa 1 e-mail: mitchell cs.cmu.edu 
figure 1: combining inductive and analytical learning: in the ideal case  a learning system deals with all levels of domain theories  i.e.  it is robust with respect to severe errors therein. it operates purely inductively if no domain theory is available or the domain theory is random  and purely analytically if the domain theory is perfect. 
form they require correct and complete prior knowledge of the domain. in contrast  inductive learning methods require no such prior knowledge  but rely instead 
on many more training examples to guide generalization  together with some syntactic inductive bias. one of the major open problems in machine learning is to combine analytical and inductive learning in order to gain the benefits of both approaches: reduced requirement for training data  and robustness with respect to poor prior knowledge. 
　figure 1 illustrates the spectrum of domain theories over which a general learning system should be able to operate. at present  we have inductive learning methods that operate well at the leftmost point on the spectrum  in which no domain theory is available. we also have explanation-based methods that operate well on the right  under certain assumptions about the character of potential errors in the domain knowledge . we seek a single unified method  which is 
  robust with respect to severe errors in the domain theory  i.e.  it should operate across the entire spectrum. in particular  if no domain theory is available  or one that is even worse than random   we desire that the system learns as well as a purely inductive system. at the other extreme  if perfect knowledge is available  the system should perform comparably to current explanation-based methods. 
  general  i.e.  it should be able to employ background domain knowledge that it has previously learned from scratch  as well as knowledge provided by the designer. in particular  we are interested in methods that can operate under a broad variety of domain theory errors  such as those typical of inductively learned dofigure 1: episode: starting with the initial state s1  the action sequence a1  a 1  ...  a n - 1 was observed to produce the final state sn  a goal state. the domain knowledge represented by neural networks can be used to explain how the observed state-action sequence resulted in achieving the goal. ebnn extracts slopes of the target function  i.e.  the partial derivatives of the goal feature of the final state with respect to all features of the initial state  from this explanation. 
main knowledge. we are also interested in interleaving learning of the domain theory and the target concept. 
  noise tolerant  i.e.  it should be able to learn from noisy data. noise may be present both in the features that describe instances  and in the given training classifications. 
1 	the e b n n learning algorithm 
ebnn is an explanation-based learning method utilizing neural network representations that seeks to achieve the above three properties. in ebnn  the domain theory is represented by a collection of artificial neural networks. the target function to be learned is represented separately  either by an additional neural network or by an alternative representation for real-valued functions  e.g.  a nearest neighbor scheme . as in symbolic ebl  ebnn uses its domain theory to guide learning of the target function by explaining and analyzing each observed training example of the target function in terms of the domain theory. the domain theory itself may be learned from scratch using backpropagation  rumelhart et a/.  1  or some other neural network learning procedure  either before or during learning of the target function. 
1 	neural network domain theories 
to illustrate ebnn  consider an agent  perhaps a robot  which must learn a strategy for choosing which of its actions to apply in any given state in order to achieve its goal. consider  for example  the episode shown in figure 1. starting with an initial state s1  the sequence of actions a1  a 1  ...  a n - 1 is observed to produce the goal state sn. the learning task in this case is to acquire the concept  the class of states  s  for which the action a will lead eventually to a goal state.  the target function in this case is a function from states and actions to  1   i.e.  a 1 indicates that executing this action in this state leads to the goal . once learned  this evaluation function allows the agent to select actions that achieve its goal  as in  watkins  1    barto et a/.  1 . 
1 	explaining and analyzing observed episodes 
one could apply standard explanation-based learning methods to this problem  provided the agent initially possessed a perfect domain theory describing the effects of its actions on the world state. instead  we consider the case where the robot has only an approximate  previously learned theory of the effects of its actions. this domain theory is represented by a collection of neural networks  one for each action. the network characterising action ai takes as input the description of an arbitrary state  and produces as output a description of the predicted resulting state  i.e.  each network represents the same information typically represented by symbolic precondition-postcondition action descriptions . ebnn applies these action model networks to explain and learn from each observed episode in which it achieves its goal. more precisely  ebnn applies the following three-step process to each observed episode: 
1. explain: an explanation is a post-facto prediction of the observed episode using the domain knowledge. explanations are constructed by using the neural network domain theory to post-facto predict  and thus explain  how action a1 applied at state s  led to the observed state s1  how a1 led to s1  and so on. note that predicted states usually deviate from the observed ones since inductively learned domain theories are only approximately correct. 
1. analyze: the role of the explanation is to elucidate how achieving the final goal depends on the various features of the observed initial state  s1. in symbolic ebl  this dependence is used to extract the weakest precondition under which the same explanation would have produced the same outcome. since ebnn represents its domain theory by neural networks  it is difficult to extract weakest preconditions. however  since neural networks are real-valued differentiable functions  ebnn uses the dependencies in the explanation to extract the derivatives  i.e.  slopes  of the final goal feature with respect to each feature of the initial state  s1. more specifically  ebnn examines the specific chain of neural net activations and weights in the explanation to analytically extract these derivatives. 
to see how this is done  consider the last state-action pair  s n -iion-i  shown in figure 1  which led to the goal state sn. neural networks represent differentiable functions. using the last step of the explanation for this episode  the slopes of the goal features of the predicted final state 1n with respect to sn-1 and an-1 can be extracted by computing the derivative of the neural network function. these slopes describe the dependence of the final state sn on the previous state sn-1 and action a n - 1 . in particular  they measure how infinitesimally small changes applied to sn-1 or an-1 will change the final state sn. the extraction of slopes can be chained back through the entire episode by applying the chain rule of differentiation to the multiple explanation steps. the result of this analysis is the set of derivatives  slopes  of the target concept  goal state  with respect to each state-action pair in the observed episode. as stated above  these slopes measure the dependence of the target concept on each of the features of the states and actions in the observed episode. state features believed  by the domain theory  to be 
	thrun and mitchell 	1 

irrelevant to achieving the final goal will have partial derivatives of zero  whereas large slope values indicate the presence of strongly relevant features. 
1. refine: the slopes extracted from the explanation  along with the observed training example itself  are used to refine the learner's description of the target function. the target function in ebnn is represented by a separate neural network  or any other representation appropriate for approximating real-valued functions from sample values and sample slopes . this target function is incrementally updated with each new training example  both inductively and analytically  to iteratively approximate the true target function. in the episode from our example  each state-action pair in the episode   si ai  is observed to lead to the goal state and thus becomes a training example for inductively and analytically refining the target network. the inductive component of learning corresponds to updating the target network to produce the target output value  e.g.  1 if the example leads to achieving the goal . inductive learning is crucial for compensating for errors in the domain theory. the analytical component of learning corresponds to updating the network to fit the target output slopes  extracted analytically from the explanation. as shown in figure 1  these slopes influence the learned network by overriding the default bias of interpolating between observed points. therefore the analytical component in ebnn enables more correct generalization from less training data  if slopes are sufficiently accurate. in the case that the target function is represented by a neural network  the backpropagation algorithm can be extended to fit slopes as well as values  as may be found in  simard et a/.  1 . 
to summarize  the target function is iteratively approximated by updating it  a  inductively  to fit the empirically observed training values of the target function  and  b  analytically  to fit the analytically derived training slopes obtained by explaining the observed example in terms of a previously learned domain theory. 
1 	accommodating imperfect domain theories 
since the domain theory is learned inductively from training instances1  its accuracy might be arbitrarily 
　　1 this process of inductively learning the domain theory is not to be confused with learning the target function. 
machine learning 
figure 1: a. the simulated robot world  b. the squared generalization error of the domain theory networks decreases monotonically as the amount of training data increases. these nine alternative domain theories were used in the experiments. 
poor  resulting in arbitrarily poor explanations and extracted slopes. how can the learner avoid the damaging effects of such incorrect slopes arising from a poor domain theory  
　ebnn reduces the undesired influence of incorrect domain theory predictions by estimating the accuracy of the extracted slopes  based on the fit between the observed sequence of states and those predicted by the explanation  the underlying assumption  prediction errors measure slope errors  is called lob* . more specifically  
each time the domain theory is used for post-facto predicting a state sk+1 its prediction sk+1 may deviate from the observed state sk+1observe. we define the 1-step prediction accuracy at state sk  denoted by c1  i   as 1 minus the normalized prediction error: 

   for a given episode we define the n-step accuracy cn i  as the product of the 1-step accuracies in the next n steps. the n-step accuracy  which measures the accuracy of the extracted slopes n steps away from the end of the episode  possesses three desirable properties: a. it is 1 if the learned domain theory is perfectly correct  b. it decreases monotonically as the length of the chain of inferences increases  and c. it is bounded below by 1. the n-step accuracy is used to determine the ratio by which the analytical and inductive components are weighted when learning the target function. if an observation is n steps away from the end of the episode  the analytically derived training information  slopes  is weighted by the n-step accuracy times the weight of the inductive component  values . although the experimental results reported in section 1 are promising  the generality of this approach is an open question  due to the assumption lob*. 
1 	experimental results 
ebnn was evaluated in a simulated robot navigation domain. the world and the action space are depicted in figure 1a. the learning task is to find an evaluation function q for which the greedy policy navigates the agent to its goal location  circle  from arbitrary starting locations  while avoiding collisions with the walls or the 

obstacle  square . states are described by the local view of the agent  in terms of distances and angles to the center of the goal and to the center of the obstacle. note that the world is deterministic in these experiments  and there is no sensor noise. 
　in order to allow exploration of the robot environment and to compensate for the necessary non-optimal action choices  we applied ebnn to watkins'qi-learning  watkins  1  together with sutton's temporal difference learning td  sutton  1   with  = 1 and a reward discount = 1 1. each discrete action was modeled in the domain theory by a separate neural network. we used neural network backpropagation learning for learning action models. the evaluation functions q were approximated by an instance-based local approximation technique  modeling q separately for each action. in this instance-based technique  each training instance together with its slopes was explicitly memorized. given a new point as a query  generalization was achieved by fitting a local second order polynomial over the three nearest neighbors in the instance memory. this polynomial fit both the values and the slopes. in our initial experiments  this instance-based technique was found to outperform neural networks for representing the target functions. 
　experiment 1:  what is the impact of the analytical component of ebnn  given a strong domain theory   in the first experiment  we initially allowed the agent to train each of the action modeling networks that form its domain theory using 1 randomly generated training examples. this results in a fairly accurate  but 
still imperfect  domain theory. figure 1 shows results of applying ebnn using this pre-learned domain theory  compared to using just the inductive learning component alone. in this figure  the performance was measured on an independent test set of 1 initial locations. both techniques exhibit asymptotically the same performance and learn the desired control function successfully. how-
　　1  we will omit the somewhat lengthy details here  since they are not essential for the understanding of ebnn. see  mitchell and thrun  1b  for a detailed description. 
figure 1: how does domain knowledge improve generalization  a. averaged results for ebnn domain theories of differing accuracies  pre-trained with from 1 to 1 training examples for each action model network. in contrast  the bold gray line reflects the learning curve for pure inductive learning  i.e.  q-learning and td a . b. same experiments  but without weighting the analytical component of ebnn by its accuracy  illustrating the importance of lob*. all curves are averaged over 1 runs and are also locally windowaveraged. the performance  vertical axis  is measured on an independent test set of starting positions. 
ever  there is a significant reduction in the number of training episodes needed by ebnn in order to reach the same level of performance as inductive learning  i.e.  the ebnn learning curve is steeper  indicating more correct generalization from the same data . 
　experiment 1:  how does ebnn degrade with progressively weaker domain theories   we repeated experiment 1 using weaker domain theories  trained with 1  1  1  1  1  1  1  1  and 1 training examples per action network  c.f. figure 1b . figure 1a shows clearly that  1  ebnn outperforms purely inductive learning at all accuracy levels  and  1  the more accurate the domain theory  the steeper the learning curve. thus  ebnn in this experiment degrades gracefully to the performance of a pure inductive system as the accuracy of the domain theory decreases. 
　experiment 1:  how important is the heuristic lob* for the graceful degradation of ebnn   we then repeated experiment 1 without weighting the slopes relative to their observed accuracy. figure 1b shows the results. for high-quality domain theories  the learning curves are not affected. as the quality of the domain theory decreases  however  the learning speed of ebnn without lob* is significantly worse than pure inductive 
	thrun and mitchell 	1 

learning. this result justifies lob* and illustrates its importance in ebnn. 
1 	related work 
recent research has produced a variety of proposals for combining inductive and analytical learning methods  e.g.  see the workshop of combining inductive and analytical learning  machine learning workshop  1    though none of these achieves a final solution to the problem. indeed  as research in this area matures we may find that multiple approaches are needed  depending on the type of representations used for the domain theory and target function  e.g.  first order domain theories versus prepositional  or discrete-valued target functions versus real-valued . approaches differ in the types of domain theory imperfections they can accommodate  the representations they use for the domain theory and the target concept  and the particular mechanisms by which they combine inductive and analytical components. mechanisms for combining induction and analysis can be grouped roughly into three categories: 
  analytical  then inductive. here  each training example is first generalized analytically  and inductive methods are then applied to the results. for example  hirsh's ivsm  hirsh  1  applies explanationbased generalization to each training example  then combines the results from different examples using an inductive method based on version spaces. in some systems  it is the explanations over which induction is applied  e.g.   dietterich and flann  1    kedarcabelli  1  . in others  inductive methods are applied to the remaining unexplained features to catch relevant features that may have been missed by the domain theory  e.g.   mooney and ourston  1  . 
  inductive  then analytical. lebowitz  lebowitz  1  has suggested an approach in which statistical regularities are first found from a large set of data. these empirical regularities  e.g.   midwest congressman typically vote in favor of farm subsidies   are then explained  e.g.   midwest states contain many farmers     congressmen typically vote to help their voters   in order to further refine them and guide the search for variants on this regularity. 
  interleave inductive and analytical processes. some systems interleave inductive and analytical steps. for example  bergadano and giordana  bergadano and giordana  1  construct the explanation not for one example  but simultaneously considering all available examples. systems such as vanlehn's  vanlehn  1   hall's  hall  1   and pazzani's  pazzani  1  learn by inductively filling in the gaps in incomplete explanations. others such as widmer  widmer  1  and mahadevan  mahadevan  1  use abstracted domain knowledge such as determinations  russell  1  to form abstract explanations  and then to specialize the domain theory based on the observed example. oursten and mooney propose a system that inductively refines an initial domain theory based on noisy training data  ourston and mooney  1  using ids' quinlan  1  as the 
machine learning 
inductive component. like ebnn  their system is able to deal with a whole spectrum of domain theories  from weak to strong. rosenbloom and aasman  rosenbloom and aasman  1  and miller and laird  miller and laird  1  have demonstrated that induction can be achieved with purely analytical learning mechanisms by inserting appropriate  inductive rules  into the domain theory. 
the ebnn method presented here falls into the first of these categories: each example is explained to extract general information  and the results of these explanations are then combined. however  ebnn differs significantly from previous explanation-based approaches in that it is based on neural network representations for both the domain theory and the target concept. this leads to two useful properties. first  it enables the use of standard inductive methods for learning the domain theory from noisy data  e.g.  it can use backpropagation  rumelhart et a/.  1   or ebnn itself . second  it provides a natural method for incrementally refining the learned target concept based both on observed training examples  the inductive component  and on information extracted from explanations  the analytical component . 
　researchers working on neural network learning methods have also noted the importance of using prior knowledge to learn more complex functions from less training data. for example  simard and colleagues  simard et a/.  1  have shown that network training algorithms 
can be developed that fit certain types of user-provided constraints on the target function. they developed a system for recognizing visual objects  constraining the network output to be invariant to translation of the object within the image. the key difference between this work and ebnn is that in simard's work the designer must embed his own knowledge into a task-specific learning algorithm  whereas ebnn is a task-independent method that learns and then uses its own prior  learned  knowledge to constrain subsequent learning. 
   others  such as shavlik and towell  shavlik and towell  1   fu  fu  1  and mahoney and mooney  mahoney and mooney  1  have proposed methods that use explicitly represented domain knowledge to bias neural network learning by initializing the network to reflect this prior knowledge. in their methods  a symbolic domain theory is used to define a neural network  both its topology and weights  so that it infers exactly the same example classifications as the given domain theory. this network is then refined inductively using backpropagation. ebnn differs from this approach in that  1  ebnn constructs a distinct explanation for each observed example  rather than  compiling  the domain theory in one shot into a neural network   1  ebnn uses a selflearned domain theory represented by neural networks  rather than a user-provided domain theory represented by symbolic rules   1  because it uses the domain theory to explain each example  ebnn can use available data to refine both the domain theory and target concept  with domain theory improvements having a direct effect on subsequent analytical steps. 

1 	discussion 
this paper presents a learning method  ebnn  which combines inductive and analytical learning. an inductively learned approximate domain theory is used to guide learning a separate target function  by a combined inductive and analytical process. the domain theory in ebnn is represented by a collection of learned neural networks  e.g.  one to model each action in our robotic example . the target function  e.g.  the state-action evaluation function in our example  may be represented by any approximator for real-valued functions that can 
fit both training values and training slopes of the target function. fitting the observed training values provides a purely inductive component for learning the target function  whereas fitting the slopes extracted from explanations provides the analytical component. ebnn is demonstrated to learn the target function better from fewer examples  when compared against purely inductive learning  and to degrade gracefully as the quality of the domain theory decreases. the lob* heuristic appears effective as a means for decreasing the contribution of the analytical component for those training examples for which the domain theory produces poor explanations. 
　ebnn at least partially fulfills all three of the requirements discussed in section 1  i.e.  it is robust  general  and in part noise tolerant. it is robust to errors in the domain theory  because inaccurate slopes resulting from inaccurate domain knowledge are identified and their effect reduced  via the n-step accuracy estimate  and because the inductive learning component competes with the analytical learning component. it is general  since no a priori domain knowledge is required to initialize the system-it can learn the necessary domain theory inductively. furthermore  it is noise tolerant to the extent that neural networks are capable of dealing with noisy training data. 
　while these first results suggest ebnn is a promising learning method  there are a number of significant issues that warrant further research: 
  in contrast to many other approaches to ebl which utilize first-order predicate logic to represent domain knowledge  the ebnn domain theory expressed by neural networks is propositional. 
  the capability of ebnn in stochastic domains is un-clear  since the lob* heuristic for weighting the analytical component of learning relies on the observed prediction error of the deterministic predictions of the domain theory. 
  derivatives  or slopes  represent only one kind of knowledge that can be analytically extracted from explanations. it would be interesting to extract other forms of knowledge as well  to further accelerate learning. 
  there are several fundamental differences between ebnn and explanation-based approaches that utilize symbolic representations. for example  representing the target function by a single neural network  instead of a collection of learned rules  leads to different scaling problems. when learning collections of rules  the learner can encounter a slowdown in overall performance arising from the rising cost of matching an increasing number of learned rules. if the target function is instead represented by a single neural network  there is no corresponding slowdown as learning proceeds. however  a different scaling issue arises: the correctness of the single-network approximation to the target function might degrade when learning very complex target functions. see  mitchell and thrun  1a  for a detailed discussion of these issues. 
  in ebnn  the complete domain theory is learned from scratch. if a priori domain knowledge is available  it will be interesting to study the correspondence and the interaction between learned and pre-given domain theories. 
acknowledgment 
we thank ryusuke masuoka for his invaluable help in refining the ebnn algorithm and code. jude shavlik and paul rosenbloom and the cmu robot learning group have contributed useful ideas during discussions of the correspondence between symbolic and neural network ebl methods. we thank lonnie chrisman and rich goodwin for comments on earlier drafts of this paper. 

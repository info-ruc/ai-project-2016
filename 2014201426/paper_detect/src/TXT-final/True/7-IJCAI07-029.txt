
many interesting tractable problems are identified under the model of constraint satisfaction problems. these problems are usually solved by forcing a certain level of local consistency. in this paper  for the class of connected row convex constraints  we propose a novel algorithm which is based on the ideas of variable elimination and efficient composition of row convex and connected constraints. compared with the existing work including randomized algorithms  the new algorithm has better worst case time and space complexity.
1 introduction
constraint satisfaction techniques have found wide applications in combinatorial optimisation  scheduling  configuration  and many other areas. however  constraint satisfaction problems  csp  are np-hard in general. one active research area is to identify tractable csp problems and find efficient algorithms for them.
모an interesting class of row convex constraints was identified by van beek and dechter  1 . it is known that if a problem of row convex constraints is path consistent  it is tractable to find a solution for this problem. however  when the problem is not path consistent  path consistency enforcing might not lead to global consistency due to the possibility that the row convexity of some constraints is destroyed. deville et al.  1  restrict row convexity to connected row convexity  crc . in fact  the scene labeling problem and constraint based grammar examples given in  van beek and dechter  1  are crc constraints. one can find a solution of crc constraints by enforcing path consistency. deville et al. also provide an algorithm more efficient than the general path consistency algorithm by making use of certain properties of row convexity. the algorithm has a worst case time complexity of o n1  with space complexity of o n1d  where n is the number of variables  d the maximum domain size. recently  kumar  1  has proposed a randomized algorithm for crc constraints with time complexity of o 붺n1  and space complexity o ed   personal communication  where e is the number of constraints and 붺 the maximum degree of the constraint graph.
모in this paper  making use of the row convexity and connectedness of constraints  we propose a new algorithm to solve crc constraints with time complexity of o n1d + ed1  where  is the elimination degree of the triangulated graph of the given problem. we observe that the satisfiability of crc constraints is preserved when a variable is eliminated with proper modification of the constraints on the neighbors of the eliminated variable. the new algorithm simply eliminates the variables one by one until it reaches a special problem with only one variable.
모a key operation in the elimination algorithm is to compose two constraints. the properties of connectedness and row convexity of the constraints make it possible to get a fast composition algorithm with time complexity of o d .
모in this paper  we present the elimination algorithm after the preliminaries on crc constraints. the methods to compute composition of row convex and connected constraints are then proposed. we examine the elimination algorithm on problems with sparse constraint graphs before we conclude the paper.
1 preliminaries
a binary constraint satisfaction problem  csp  is a triple
 v d c  where v is a finite set of variables  d ={dx | x 뫍 v and dx is the finite domain of x}  and c is a finite set of binary constraints over the variables of v . as usual  we assume there is only one constraint on a pair of variables. we use n  e  and d to denote the number of variables  the number of constraints  and the maximum domain size of a csp problem. we use i j ... and x y ... to denote variables in this paper. the constraint graph of a problem  v d c  is a graph with vertices v and edges e = {{i j} | cij 뫍 c}. a csp is satisfiable if there is an assignment of values to variables such that all constraints are satisfied.
모assume there is a total ordering on each domain of d. when necessary  we introduce head and tail for each variable domain such that head  tail respectively  is smaller  larger respectively  than any other value of the domain. functions succ u di   u 뫍 di 뫋 {head}  and pred u di   u 뫍 di 뫋 {tail}  denote respectively the successor and predecessor of u in the current domain di뫋 {head  tail}. the domain di is omitted when it is clear from the context.
모given a constraint cij and a value a 뫍 di  the extension set cij a  is {b 뫍 dj |  a b  뫍 cij}. cij a  is also called the image of a with respect to cij. clearly cij head  = cij tail  =  . standard operations of intersection and composition can be applied to constraints. the composition of cix and cxj is denoted by cxj   cix. it is convenient to use a boolean matrix to represent a constraint cij. the rows and columns are ordered by the ordering of the values of di and dj.
모a constraint cij is arc consistent  ac  if every value of di has a support in dj and every value of dj has a support in di. a csp problem is arc consistent if all its constraints are arc consistent. a path x ... y of a constraint graph is consistent if for any assignments x = a and y = b such that  a b  뫍 cxy  there is an assignment for each of other variables in the path such that all constraints over the path are satisfied by the assignments. a constraint graph is path consistent if every path of the graph is consistent. a csp is path consistent if the completion of its constraint graph is path consistent. a csp is partially path consistent if its constraint graph is path consistent  bliek and sam-haroud  1 .
모a constraint cij is row convex if there exists a total ordering on dj such that the 1's are consecutive in each row of the matrix of cij. the reduced form of a constraint cij  denoted by c ij  is obtained by removing from di  and dj respectively  those values whose image with respect to cij  cji respectively  is empty. for a row convex constraint cij  the image of a 뫍 di can be represented as an interval  u v  where u is the first and v is the last value of dj such that  a u   a v  뫍 cij. a row convex constraint cij is connected if the images  a b  and  of any two consecutive rows  and columns respectively  of cij are not empty and satisfy
 a b 뫌   pred  succ.
note that  for our purposes  the definition of connectedness here is stronger than that by deville et al.  1 . if a constraint is row convex and connected  it is arc consistent. a constraint cij is connected row convex if its reduced form is row convex and connected. the constraints obtained from the intersection or composition of two crc constraints are still connected row convex. the transposition of a crc constraint is still connected row convex. enforcing path consistency on a csp of crc constraints will make the problem globally consistent  deville et al.  1 .
모the consistency property on row convex constraints is due to some nice property on convex sets. given a set u and a total ordering 뫞 on it  a set a   u is convex if its elements are consecutive under the ordering  that is
a = {v 뫍 u | mina 뫞 v 뫞 maxa}.
consider a collection of sets s = {e1 ... ek} and an ordering 뫞 on 뫋i=1..kei where every ei 1 뫞 i 뫞 k  is convex. the intersection of the sets of s is not empty if and only if the intersection of every pair of sets of s is not empty  van beek and dechter  1; zhang and yap  1 .
1 variable elimination in crc
consider a problem  v d c  and a variable x 뫍 v . the relevant constraints of x  denoted by rx  are the set of constraints { cyx | cyx 뫍 c}. to eliminate x is to transform  v d c  to   where
. in the elimination  when composing cix and cxj  if cij 뫍/ c we simply take cij as a universal constraint  i.e.  di 뫄 dj.
theorem 1 consider an arc consistent problem p= v d c  of crc constraints and a variable x 뫍 v . let
  be the problem after x is eliminated. p is satisfiable iff p is satisfiable.
   proof we first prove if p is satisfiable  so is p. let s be a solution of p  sx an assignment of x by s  and sx몬 be the restriction of. we only need to show that sx몬 satisfies for all cix cxj 뫍 c. since s is a solution of p  sx몬
satisfies cix  cjx and cij. hence  sx몬 satisfies.
모next we prove if p is satisfiable  so is p. let t be a solution of p. we will show that t is extensible consistently to x in p. let vx be {i | cix 뫍 rx}. for each i 뫍 vx  let the assignment of i in t be ai. let s = {cix ai  | i 뫍 vx}. since all constraints of p are row convex and p is arc consistent  the sets of s are convex and none of them is empty.
모consider any two sets cix ai  cjx aj  뫍 s. since t is a solution of  where is a constraint of p. the fact that  where cij is either in c or universal  implies that there exists a value b 뫍 dx such that ai aj and b satisfy cix cjx and cij. hence  cix ai  뫌
. by the property on the intersection of convex sets  the intersection of the sets of s is not empty. for any v 뫍 뫌e뫍se  it is easy to verify that  t v  is a solution of p.
therefore  p is satisfiable.	
모based on theorem 1  we can reduce a csp with crc constraints by eliminating the variables one by one until a trivial problem is reached.

모the procedure eliminate  v d c   consistent  s  in algorithm 1 eliminates the variables of  v d c . when it returns  consistent is false if some domain becomes empty and true otherwise; the eliminated variables are pushed to the stack s in order and c will contain only the  removed  constraints associated with the eliminated variables. most parts of the algorithm are clear by themselves. the body of the while loop  lines 1 - 1  eliminates the variable x. line 1 discards from c the constraints incident on x  i.e. . and line 1 push x to the stack and put the constraints  which are associated to x  into c. after eliminate  the stack s  d  revised in lines 1  1   and c will be used to find a solution of the original problem.
모on top of the elimination algorithm  it is rather straightforward to design an algorithm to find the solutions of a problem of crc constraints  algorithm 1 . l  line 1  represents the assigned variables. cx in line 1 contains only those constraints that involve x and an instantiated variable. in line 1  when cx is empty  the domain dx is not modified.
algorithm 1: find a solution of crc constraints solve  in  v d c   out consistent 
while not s.empty    do
theorem 1 assume the time and space complexity of the composition  and intersection respectively  of two constraints are o 붸  and o 1 . further assume the time and space complexity of enforcing arc consistency are o ed1  and o 붹 . given a crc problem p= v d c   a solution of the problem can be found in o n1붸  with working space o n + 붹 .
모assume the constraint graph of p is complete. for every variable  there are at most n neighbors. so  to eliminate a variable  line 1  takes o n1붸 . totally  n variables are removed. so  the complexity of eliminate is o n1붸 . the procedure eliminate dominates the complexity of solve and thus to find a solution of p takes o n1붸 + ed1  where ed1 is the cost  amortizable  of removing values and its propagation. working space here excludes the space for the representation of the constraints and the new constraints created by elimination. it is useful to distinguish the existing nonrandomized algorithms. throughout this paper  space complexity refers to working space complexity by default. a stack s and a set l are used by solve and eliminate to hold variables. they need o n  space. the total space used by solve is o n+붹  where 붹 is the space cost  amortizable  of removing values and its propagation. 
1 composing two crc constraints
in this section  we consider only constraints that are row convex and connected. these constraints are arc consistent in accordance with our definition. remember that our definition of connectedness is stronger than the original definition. the following property is clear and useful across this section.
property 1 given two row convex and connected constraints cix and cxj  let cij be their composition. for any u 뫍 di  cij u  is not empty.
to compose two constraints cix and cxj  one can simply multiply their matrices  which amounts to the complexity of o d1  . we will present fast algorithms to compute the composition in this section. constraints here can use an interval representation defined below. for every cij 뫍 c and u 뫍 di  cij u .min is used for min{v |  u v  뫍 cij}  and cij u .max for max{v |  u v  뫍 cij}.
1 basic algorithm to compute composition
with the interval representation  we have procedure compose in algorithm 1. for any value u 뫍 di and v 뫍 dj  lines 1 compute whether  u v  뫍 cxj   cix. by property 1  min 뫞 max is always true for line 1.

proposition 1 the procedure of compose has a time complexity of o d1  and space complexity is o 1 .
the two while loops  lines 1  1  give a time complexity of
o d1 .	
모we emphasize that  due to the interval representation of constraints  for any cix and cxj we need to call compose twice to compute cij and cji separately. this does not affect the complexity of those algorithms using compose. for example  for eliminate to use compose we need to change i   j  line 1 of algorithm 1  to.
1 remove values without support
although composition does not lead to the removal of values under our assumption  the intersection will inevitably cause the removal of values. in this case  to maintain the row convexity and connectedness  we need to remove values without support from their domains. the algorithm removevalues  listed in algorithm 1  makes use of the interval representation  line 1  to propagate the removal of values. if a domain becomes empty  line 1   we let the program involving this procedure exit with an output indicating inconsistency.

proposition 1 given a csp problem  v d c  of crc constraints with an interval representation  the worst case time complexity of removevalues is o ed1  with space complexity of o nd .
let 붻i be the degree of variable i 뫍 v . to delete a value  line 1   the cost is 붻id. in the worst case  nd values are removed. hence the time complexity is
o ed1 . the space cost for q is o nd .	
모given a problem of crc constraints that are represented by matrix  for each constraint cij and u 뫍 di  we setup cij u .min and cij u .max and collect the values of di without support. let q contain all the removed values during the setup stage  we then call removevalues to make the problem arc consistent. this process has a time complexity of o ed1  with working space complexity o nd   due to q .
모by the above process  theorem 1  and proposition 1  it is clear that the procedure solve equipped with compose and removevalues has the following property. note that the time and space cost of removevalues are  amortized  in eliminate.
corollary 1 given a problem of crc constraints  solve can find a solution in time o n1  with space complexity o nd .
1 fast composition of constraints
as one may see  compose makes use of the row convexity to the minimal degree. in fact  we can do better.

figure 1: the area of 1's in the matrix of a crc constraint
모the 1's in the matrix of a crc constraint form an abstract shape  the shaded area in figure 1  where the slant edges mean monotonicity rather than concrete boundaries. it is characterised by the following fields associated with cij. let min = min{cij u .min | u 뫍 di} and max = max{cij u .max | u 뫍 di}. the field cij.t denotes the value of di corresponding to the first row that contains at least a 1  cij.b the value of di corresponding to the last row that contains at least a 1   the first value u of di such that cij u .min=min  cij.l뫐 the last value v of di such  the first value u of di such that
cij  uv  ..maxmax==maxmax. if  andccijijis row convex and connected .r뫐 the last value v of di such thatcij.t cij
= succ head  di  and cij.b = pred tail  di . the fields are related as follows.
proposition 1 given a row convex and connected constraint cij  for all u 뫍 di such that min; for all u such that max; and the relation between  cij.r뫐  can be arbitrary.

	b	q shape	p shape	.
figure 1: the possible shapes of the strips of a constraint that is row convex and connected
모consider a row convex and connected constraint cij. let l1 l1 l1 l1 be the sorted values of  and cij.r뫐. the matrix of cij consists of the following strips. 1  top strip denotes the rows from cij.t to l1  1  middle strip the rows from l1 to l1  and 1  bottom strip the rows from l1 to cij.b  b in the diagram .
모the row convexity and connectedness of cij implies that the 1's in its top strip can be of only 'b' shape or 'd' shape  the 1's in its middle strip of only ' ' shape  'o' shape  or '/' shape  and the 1's in its bottom strip of only 'q' shape or 'p' shape  see figure 1 . note that these shapes are abstract shapes and do not have the ordinary geometrical properties. the strips and shapes are characterised by the following properties.
property 1 top strip: for every u1 u1 뫍  cij.t l1  where u1 뫞 u1  cij u1    cij u1 . middle strip: for every u1 u1 뫍  l1 l1  where u1 = pred u1   shape ' ' implies cij u1 .min뫞cij u1 .min and cij u1 .max뫞cij u1 .max; shape 'o' implies cij u1  = cij u1 ; and shape '/' implies cij u1 .min뫞cij u1 .min and cij u1 .max뫞cij u1 .max. bottom strip: for every u1 u1 뫍  l1 cij.b  where u1 뫞 u1  cij u1    cij u1 .
모assume cix and cxj are row convex and connected. the new algorithm to compute cxj   cix  listed in algorithm 1  is based on the following two ideas. 1  we first compute cij u .min for all u 뫍 di  line 1   which is called min phase  and then compute cij u .max for all u 뫍 di  line 1   which is called max phase. 1  in the two phases  the properties of the shapes and strips of cix are employed to speed up the computation.
모in the min phase  the algorithm starts from the top strip of cix. let u = cix.t. find cij u .min  line 1  and let it be v.
algorithm 1: fast algorithm for computing the composition of two constraints
fastcompose  in cix cxj  out cij 
1 let l1 ... l1 be the ascendingly sorted values of
1 // min phase
1 // process the top strip of cix
1 u 뫹cixhead.b	to tail the first v 뫍 dj such that
1 find from
1 cij u .min 뫹 v
1 searchtoleft  cix cxj u l1 v cij 
1 // process the middle strip
1 if the middle strip is of 'o' shape then

1 // bottom strip
1 searchtoright  cix cxj u cij.b v cij 
1 // max phase
1 // process the top strip
1 u 뫹cix.bv 뫍 dj such that
1 find the last
1 cij u .max 뫹 v
1 searchtorightmax  cix cxj u l1 v cij 
1 // process the middle strip

due to the property of the top strip  we can find cij u .min for all u 뫍  cij.t l1  in order by scanning once from v down to head of dj  i.e.  searching to the left of v  line 1 . the search procedure searchtoleft is listed in algorithm 1 where one needs to note that v is replaced by v1 in line 1. similarly  we can process the bottom strip by searching to the right of v 뫍 dj  line 1 . for the middle strip  we have three cases for the three shapes. by property 1  lines 1 are quite straightforward for the 'o' shape. for the ' ' shape  line 1   if v is not the first column of cxj and cix u  is  above  the interval of the column before v of cxj  line 1   we need to search to the left of v to be sure we do not miss any value of dj that is smaller than v but is a support of a 뫍  u l1 . due to the property of the ' ' shape  after we hit the head of dj and no support is found  we need to search to the right until tail if necessary  line 1 . this process is implemented as searchtoleftwrap  line 1 of algorithm 1 . the correctness of this method is assured by the connectedness as well as row convexity of cix and cxj. the details are not given here due to space limit. otherwise  line 1   we only need to search to the right of v for values in  u l1 . the process for the '/' shape is similar to that for the ' ' shape with some  symmetrical  differences  line 1 .
 u .min = v   v 뫹 v   u 뫹succ  u  d  
searchtoleftwrap  inout cix cxj u l v cij 
1 // search to the left of v
1 wraptorightwhilefind firstu뫞l do뫹v1falsefrom v down to head of dj such that
	1	elseif v1{cdoes not existij u .min 뫹thenv1 {vwraptoright뫹 v1  u 뫹뫹succtrue 
1 ifwraptoright is true and u뫞 clxjthen u l  succ  head  dj   cij 
1searchtoright  cix
searchtoright  inout cix cxj u l v cij 
1 // search to the right of v
	1 while u뫞l dov	d
1 
1cij u .min 뫹 v1  v 뫹 v1  u 뫹succ  u  di 
searchtorightmax  inout cix cxj u l v cij  1 // search to the right of v
1 whilefind lastu뫞l dov1 from v to tail of dj such that
1cij u .max 뫹 v1  v 뫹 v1  u 뫹succ  u  di 
searchtorightwrap  inoutcix cxj u l v cij 
1 // search to the right of v

모the max phase is similar. finally  according to the new cij  we set the attributes of cij in a proper way  line 1 . clearly  for each phase  we only need a time cost of o d .
proposition 1 the algorithm fastcompose is correct and composes two constraints in time complexity of o d  with space complexity of o 1 .
1 csp's with sparse constraint graphs
the practical efficiency of eliminate is affected by the ordering of the variables to be eliminated. consider a constraint graph with variables {1 1 1} that is shown in the top left1 corner of figure 1. in the first row  we choose to eliminate first and then 1. in this process  no constraints are composed. however  if we first eliminate 1 and then 1 as shown in the second row  eliminate needs to make 1 compositions in eliminating each of variable 1 and 1.
모the topology of a constraint graph can be employed to find a good variable elimination ordering. here we consider triangulated graphs. an undirected graph g is triangulated if for every cycle of length 1 or more in g  there exists two nonconsecutive vertices of the cycle such that there is an edge between them in g. given a vertex x 뫍 g  n x  denotes 1
	1.	1	.	1.	1	.	1.
	.	.
	1	1	1
	1.	1
	1.	1 .	1.	1	.	1
	.		.
	1	1	1
figure 1: example on elimination variable ordering
neighbors of x: {y | {x y} is an edge of g}. a vertex x is simplicial if the subgraph of g induced by n x  is complete. a nice property of triangulated graphs is that there is a simplicial vertex for each triangulated graph and a triangulated graph remains triangulated after a simplicial vertex and its incident edges are removed from the graph. a perfect vertex elimination order of a graph g= {x1 x1 ... xn}  e  is an ordering of the vertices of g such that for 1 뫞 i 뫞 n   1  yi is a simplicial vertex of the subgraph of g induced by {yi yi+1 ... yn}.
모given a perfect elimination order  of a graph g  the elimination degree of yi 1 뫞 i 뫞 n   denoted by 횰  is the degree of yi in the subgraph of g that is induced by {yi yi+1 ... yn}. we use  to denote the maximum elimination degree of the vertices of a perfect elimination order.
모it is well known that  for a graph g that is not complete  it can be triangulated in time o n e + f   where f is the number of edges added to the original graph and e the number of edges of g  bliek and sam-haroud  1 . a perfect elimination order can be found in o n + e .
모for csp problems whose constraint graph is triangulated  the elimination algorithm has a better time complexity bound.
theorem 1 consider a csp problem p whose constraint graph g is triangulated. the procedure eliminate equipped with fastcompose has a time complexity of o n1d+ed1  and space complexity of o nd .
let be a perfect elimination for g. clearly  to eliminate yi  eliminate has to compose 횰1 constraints. since n   1 variables are eliminated by eliminate  its complexity is o n1d + ed1  where o ed1  is due to the removevalues. the space complexity is also due to removevalues.	
1 related work and conclusion
we have proposed a simple elimination algorithm to solve crc constraints. thanks to this algorithm  we are able to focus on developing fast algorithms to compose constraints that are row convex and connected. we show that the composition can be done in o d  time  which benefits from a new understanding of the properties of row convex and connected constraints. in addition to the simplicity  our deterministic algorithm has some other advantages over the existing ones. the working space complexity o nd  of our algorithm is the best among existing deterministic or randomized algorithms of which the best is o ed . however  when a graph is sparse  in contrast to the randomized algorithms  a deterministic algorithm needs space o fd  to store newly created constraints
where f is the number of edges needed to triangulate the sparse graph.
모for problems with dense constraint graphs  e = 붣 n1    our algorithm  o n1d + ed1  where e = n1  is better than the best  o n1   of the existing algorithms.
   for problems with sparse constraint graphs  the traditional path consistency method  deville et al.  1  can not make use of the sparsity. bliek and sam-haroud  1  proposed to triangulate the constraint graph and introduced path consistency on triangulated graphs. for crc constraints  their  deterministic  algorithm achieves path consistency on the triangulated graph with time complexity of and space complexity of  where 붻 is the maximum degree of the triangulated graph and e the number of constraints in the triangulated graph. the randomized algorithm by kumar  1  has a time complexity of o 붺n1  where 붺 is the maximum degree of the original constraint graph. our algorithm can achieve where  is the maximum elimination degree of the triangulated graph. since  are not compara-
ble   our algorithm is still favorable in comparison with the others.
모it is worth mentioning that  in addition to  determinism   a deterministic algorithm has a great efficiency advantage over randomized algorithms when more than one solution is needed.
모we point out that we introduce removevalues just for simplifying the design and analysis of the composition algorithms. it might be possible to design a refined propagation mechanism and/or composition algorithms to discard the ed1 component from the time complexity and decrease the space complexity of the elimination algorithm to o n .

a system for stereo computer vision with geometric models* 
d. j. burr and r. t. chien 
coordinated science laboratory 
university of i l l i n o i s at urbana-champaign 
urbana  i l l i n o i s 1 

모모모the goal of this work is the specification of a system which extracts 1-d features from images by stereo comparison  and which recognizes objects by comparing these features to geometric models of objects. models are encoded from hand measurements and consist of piecewise-linear wire frame structures. the work is in progress and some partial results are shown. 
모모모bulk correlation methods  are used with three images of a scene to insure accurate triangulation for smooth directed edges. the following pictures are obtained: 1. center. 
1. scene rotated 1뫢 east. 1. scene rotated 1뫢 north. the program compares center and east pictures for vertical edges and center and north pictures for horizontal edges. 
perceived edge center lies within a tolerance cylinder about the model edge  and direction cosines agree. the confidence is thus the total length of a l l matched edges divided by the total length of a l l scene edges. if this confidence exceeds the last computed value then it becomes the new threshold  and subseguent proposals must either exceed it or be rejected. the match of highest confidence is taken as the correct one  and the model is rotated and projected into the center view for observation  fig. 1b . 
모모모further work is being done on efficient tracking of 1-d edgres and piecewise circular representations for 1-d edges. the ultimate goal is automatic identification of an object in an occluded scene from a model data base. 

모모모edge orientation is computed after preprocessing the center picture to find edge chains. an operator developed by burr  1  finds local gradient extrema and tracks them by searching near neighbors  fig. 1a . these chains are approximated by line segments  in fig. 1b. the edge direction at a node  or line end  is taken as the average of the line direction on each side weighted by i t s length. 
모모모stereo correlation is implemented as a mean-square difference of image intensity over 1 x 1 pixel windows. search for the minimum in the corresponding view is restricted to a single line segment   1     and further  to locations where the intensity gradient exceeds a threshold. 
triangulation determines a 1-d location for each node of fig. 1b. a separate program attempts to natch this 1-d structure  fig. 1a  to a model. 

	a. 	b. 
figure 1. a. thresholded gradient extrema of car image. b. linear approximation of edges in 1a. 


모모모model matching proceeds in two steps as follows:  1  a search is made to find a model edge and perceived edge whose lengths agree. if found  each defines the z-axis of a cylindrical coordinate system   r   붿   z   . the rotational  or 붿 -ambiguity  is relieved by finding an additional edge pair which have nearly egual lengths  center positions   r c   z c     and   r   붿   z   direction cosines. the position of this feature relative to each z-axis now defines the y-axis direction of a cartesian reference frame for both model and perceived structure. the x-axes are just y x z. 
모모모 1  there may be further implied edge matches due 	to 	similarity 	of x-y-z edge coordinates and directions relative to each reference 	frame. 	an attempt 	is made to measure the confidence of this coordinate transformation by finding these implied edge 	matches. 	the criterion for an edge match is 
- perceived edge 	length 	  	model 	edge 	length  
 this work was supported by the joint services electronics program  u.s. army  u.s. navy  and j.s. air force  under contract daab-1-c-1. 
	a. 	b. 
figure 1. a. rotated view of fig. 1b after 1-d computation and removal of highly sloped depth edges. b. best match of car model to 1-d scene  confidence=.1  pdp-1 run timer=1 s e c   . 

1. burr  d. j. and r. t. chien   the minimal spanning tree in visual data segmentation   proc. 1rd ijcpr  san diego  california  nov.  1  
1. chien r. t. and l. j. peterson   image compres-sion by feature extraction and reconstruction   proc. workshop on picture data description and management  chicago  1.  april 1  1. 
1. duda  	r. 	1. 	and 	p. 	e. 	hart  	pattern 
classification an! scene  analysis  p  1  john wiley and sons  new york  1-
1. hannah  m. j .    computer matching of areas in stereo images   stanford ai memo aim-1  stanford university  july  1. 

v i s i o n - 1 : b u r r 1 

towards automatic visual obstacle avoidance 
hans p. morevec  stanford university 
this report describes ongoing research on a working system which drives a vehicle through cluttered environments under computer control  guided by images perceived through an onboard tv camera. the emphasis is on reliable and fast low level visual techniques which determine the existence and location of objects in the world  but do not identify them. included are an interest operator for choosing distinctive regions in images  a correlator for finding matching regions in similar images  a camera solver which determines camera displacement and distance to objects from stereo information tgennery  d.b.  this proceedings  and an automatic geometric distortion corrector for camera nonlinearities. many of these use pictures reduced in linear dimension by powers of 1 by summation of pixels. other operators are a high pass filter. a point noise remover  a contrast normalizes a vertical roll corrector  a picture comparator and an operator for reducing pictures by other than powers of two. 
our hardware includes an electric vehicle  called the cart  remotely controlled over a cb radio link by a pdp-kl1. it carries a b/w tv camera whose picture is broadcast over a uhf channel  and occasionally digitized by the computer. it has motors for the wheels  steering and camera pan. each can be made to run forward or backward. there are potentiometers on the steering and pan which enables them to be commanded to point straight ahead. 
budgetary and personnel limitations have resulted in crude mechanical arrangements. the motor speeds are poorly regulated  and video is the only feedback to the computer. dead reckoning errors are about 1%. our small resources have been spent gaining software experience before undertaking serious hardware work. in my opinion our major hardware limitation is one shared by all other vision work  and al in general  namely a critical shortage of raw processing power. for instance it would take about 1 efficiently programmed pdp-1's to match the human visual system. 
results 
early versions of the routines described below were used in a program which drove the vehicle in straight lines or uniform arcs. it acquired and tracked distant features  using their motion from frame to frame to build up a model of vehicle response  and to servo on the desired path. with the cart outdoors on a dirty road  it worked well. ten runs of about 1 steps were completed. the runs were usually terminated by serious hiccups of the radio control link. each step took the cart 1 feet forward  and used 1 compute seconds. the radio link has since been much improved. 
several runs involving the distortion corrector  camera solver and new versions of the interest operator and correlator have been completed. the new program trys to determine the distance to the features by applying the camera solver after tracking them through several images. the performance is poor. the camera solver results are erratic  seemingly due to the degenerate nature of the solution. objects lying near the camera axis  most of the scene  provide no depth information. 
next 
we are trying a new approach  replacing the camera pan mechanism with one which provides 1 inches of side to side motion  in three 1 in. steps. this should provide adequate parallax  and also close spacing to make the correlations easy. since the camera motion parameters will be known the correlation searches become one dimensional  and an absolute scale factor is known. the camera solving is also easy. the idea is to locate nearby features in 1 at each vehicle stop. the vehicle motion can be found from the apparent feature motions between stops. the location of the ground can be deduced from the camera height and orientation. 
interest operator 
this routine is used to acquire new features in a scene. it selects a relatively uniform scattering  to minimize the probability of missing important obstacles  and chooses distictve areas for unambiguous correlation. this is achieved by returning regions which are local maxima of a directional variance measure. featureless areas and simple edges  which have no variance in the direction of the edge  are thus avoided. 
directional variance is measured over small square overlapping windows of specified size  typ. 1 to 1 . sums of squares of differences of pixels adjacent in each of four directions  horizontal  vertical and two diagonals  over the window are obtained. the variance of the window is the minimum of these four sums. 
the operator is applied to a reduced version of the picture  where the specified window size shrinks to 1 or 1 pixels. noise sensitivity is reduced and speed increased. partly hand coded  the routine takes 1 ms for a 1 image  with 1 windows. 
binary search correlator 
given a feature in one picture  the correlator attempts to find the matching region in another image. it takes the position in the first picture  a rectangular search area  often the whole image  in the second picture  and a feature window size n. 
the search uses a coarse to fine strategy  which begins in reduced versions of the pictures. the order of reduction is chosen to shrink the smaller dimension of the search rectangle to between n and 1n pixels. an n by n window in the shrunken source image  centered on the desired feature  is considered. it covers about 1% of this tiny version of the picture. a correlation coefficient is calculated for each possible placement of this window on the search area. for a search area exactly 1n by 1n  there are  n+1 positions. the one with the highest coefficient becomes the search area for the next level of refinement. 
this is repeated with pictures reduced one step less  i.e. linearly twice as large. an n by n window is again centered around the location of the feature  and is searched for in the best matching window from the previous search  which expands to 1n by 1n at the new reduction. this goes on in successively larger versions of the pictures until an n by n window is matched in the unreduced images. there are about log1 w/n  searches in all  where w is the smaller dimension of the search rectangle in the unreduced picture. 
this approach has advantages over a simple pass of a correlation coefficient. it needs only 1 the number of pixel comparisons to find an 1 window in a 1 picture  smaller advantage for smaller searches . the simple method comparisons are without context  and a match may be found in totally unrelated parts of the image. in our technique coarse structure guides the higher resolution comparisons  and further speedup is possible because smaller windows work. the searches at coarse levels rarely fail  possibly because noise and distortions are reduced by reduction. 
the correlation measure used  designed to have limited contrast sensitivity  was obtained by multiplying the normalized correlation coefficient by twice the cosine of the angle with the line a-b. it is: 
1뫉ab/ 뫉a1 +뫉b1 . normalized correlation is the sum of the pairwise products of a and b divided by the geometric mean of the sum of their squares. the new measure  referred to as pseudo-normalized correlation  is the sum of the products divided by the arithmetic mean of the sums of the squares. 
by in-line coding the source window and using a table of squares the bulk of the correlation is done in 1 instructions per pixel comparison. an 1 window is found in a 1 area in 1 ms. the error rate is 1% on interest operator selected features. typical image pairs are taken two feet apart with a 1 degree lens. scale changes 
as the vehicle moves the image it sees changes. the major element of this transformation is an enlargement of nearby objects. we have tried correlating across images reduced by different geometric scale factors by generating pictures 1 / 1 as large as each of the binary steps. we obtain effective scale changes of 1  1  1 / 1 and 1 by comparing various combinations of reductions of the first and second images. the results are disappointing. the method often introduces as many new errors as it corrects. experiments in applying it more selectively are planned. 
camera distortion correction 
electron optics tend to have geometric distortions undesirable when using a camera as a measuring instrument. we have written a camera calibration program which is given an image of a square array of black spots on a white background  and told the array to lens center/spot spacing distance ratio. it computes a polynomial for transforming feature image positions accurately to angle in space. 
it tolerates a wide range of image sizes  1 to 1 spots across  and illumination and arbitrary rotation. after intense fiddling with a training set of 1 images  it has worked without error on 1 widely differing new images. our test pattern is a ten foot square painted on a wail  with two inch spots at one foot intervals. 
the algorithm gets an image of such an array  and finds four major peaks in the magnitude of the fourier transform of a reduced version of it  to find its rotation and spacing. the interest operator is used to find a starting spot  and a special operator  which does local thresholding and finds centroids and moments of black areas  pinpoints all the spots  guided by the rotation/spacing information. a fourth degree least squares polynomial in two variables relating the actual to the ideal position of the spots is then generated. 
acknowledgement: this work was supported in part by contracts and grants from arpa  nasa and nsf. 

v i s i o n - 1 : 	m o r a v e c 
1 

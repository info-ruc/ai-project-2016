
mechanism design has traditionally focused almost exclusively on the design of truthful mechanisms. there are several drawbacks to this: 1. in certain settings  e.g. voting settings   no desirable strategyproof mechanisms exist; 1. truthful mechanisms are unable to take advantage of the fact that computationally bounded agents may not be able to find the best manipulation  and 1. when designing mechanisms automatically  this approach leads to constrained optimization problems for which current techniques do not scale to very large instances. in this paper  we suggest an entirely different approach: we start with a na몮 ve  manipulable  mechanism  and incrementally make it more strategyproof over a sequence of iterations.
we give examples of mechanisms that  variants of  our approach generate  including the vcg mechanism in general settings with payments  and the plurality-with-runoff voting rule. we also provide several basic algorithms for automatically executing our approach in general settings. finally  we discuss how computationally hard it is for agents to find any remaining beneficial manipulation.
1	introduction
in many multiagent settings  we must choose an outcome based on the preferences of multiple self-interested agents  who will not necessarily report their preferences truthfully if it is not in their best interest to do so. typical settings in which this occurs include auctions  reverse auctions  exchanges  voting settings  public good settings  resource/task allocation settings  ranking pages on the web   etc. research in mechanism design studies how to choose outcomes in such a way that good outcomes are obtained even when agents respond to incentives to misreport their preferences  or manipulate . for the most part  researchers have focused simply on creating truthful  or strategy-proof  mechanisms  in which no agent ever has an incentive to misreport. this approach is typically justified by appealing to a result known as the revelation principle  which states that for any mechanism that does well in the face of strategic misreporting by agents  there is a truthful mechanism that will perform just as well.
모the traditional approach to mechanism design has been to try to design good mechanisms that are as general as possible. probably the best-known general mechanism is the vickreyclarke-groves  vcg  mechanism  1; 1; 1   which chooses the allocation that maximizes the sum of the agents' utilities  the social welfare   and makes every agent pay the externality that he1 imposes on the other agents. this is sufficient to ensure that no individual agent has an incentive to manipulate  but it also has various drawbacks: for example  the surplus payments can  in general  not be redistributed  and the designer may have a different objective than social welfare  e.g. she may wish to maximize revenue. other general mechanisms have their own drawbacks  and there are various impossibility results such as the gibbard-satterthwaite theorem  1; 1  that show that certain objectives cannot be achieved by truthful mechanisms.
모the lack of a general mechanism that is always satisfactory led to the creation of the field of automated mechanism design . rather than try to design a mechanism that works for a range of settings  the idea is to have a computer automatically compute the optimal mechanism for the specific setting at hand  by solving an optimization problem. a drawback of that approach is that current techniques do not scale to very large instances. this is in part due to the fact that  to ensure strategy-proofness one must simultaneously decide on the outcome that the mechanism chooses for every possible input of revealed preferences  and the strategy-proofness constraints interrelate these decisions.
모another observation that has been made is that in complex settings  it is unreasonable to believe that every agent is endowed with the computational abilities to compute an optimal manipulation. this invalidates the above-mentioned revelation principle  in that restricting attention to truthful mechanisms may in fact come at a cost in the quality of the outcomes that the mechanism produces. adding to this the observation that in some domains  all strategy-proof mechanisms are unsatisfactory  by the gibbard-satterthwaite theorem   it becomes important to be able to design mechanisms that are not strategy-proof. recent research has already proposed some manipulable mechanisms. there has been work that proposes relaxing the constraint to approximate truthfulness  in various senses . approximately truthful mechanisms can be easier to execute  1; 1   or can circumvent impossiblity results that apply to truthful mechanisms  1; 1 . other work has studied manipulablemechanismsin which finding a beneficial manipulation is computationally difficult in various senses  1; 1; 1; 1 .
모in this paper  we introduce a new approach. we start with a na몮 vely designed mechanism that is not strategy-proof  for example  the mechanism that would be optimal in the absence of strategic behavior   and we attempt to make it more strategy-proof. specifically  the approach systematically identifies situations in which an agent has an incentive to manipulate  and corrects the mechanism to take away this incentive. this is done iteratively  and the mechanism may or may not become  completely  strategy-proof eventually. the final mechanism may depend on the order in which possible manipulations are considered.
모one can conceive of this approach as being a computationally more efficient approach to automated mechanism design  insofar as the updates to the mechanism to make it more strategy-proofcan be executed automatically  bya computer . indeed  we will provide algorithms for doing so. it is also possible to think about the results of this approach theoretically  and use them as a guide in  traditional  mechanism design. we will pursue this as well  giving various examples. finally  we will argue that if the mechanism that the approach produces remains manipulable  then any remaining manipulations will be computationally hard to find.
모this approach bears some similarity to how mechanisms are designed in the real world. real-world mechanisms are often initially na몮 ve  leading to undesirablestrategic behavior; once this is recognized  the mechanism is amended to disincent the undesirable behavior. for example  some na몮 vely designed mechanisms give bidders incentives to postpone submitting their bids until just before the event closes  i.e.  sniping ; often this is  partially  fixed by adding an activity rule  which prevents bidders that do not bid actively early from winning later. as anotherexample  in the 1 trading agent competition supply chain management  tac/scm  game  the rules of the game led the agents to procure most of their components on day 1. this was deemed undesirable  and the designers tried to modify the rules for the 1 competition to disincent this behavior .1
모as we will see  there are many variants of the approach  each with its own merits. we will not decide which variant is the best in this paper; rather  we will show for a few different variants that they can result in desirable mechanisms.
1	mechanism design background
in a mechanism design setting  we are given:
  a set of agents n  |n| = n ;
  a set of outcomes o  here  if payments are used in the setting  an outcome includes information on payments to be made by/to the agents ;
  for each agent i 뫍 n  a set of types 붣i  and we denote by 붣 = 붣1 뫄 ... 뫄 붣n the set of all type vectors  i.e. the set of all possible inputs to the mechanism ;
  for each i 뫍 n  a utility function ui : 붣i 뫄 o 뫸 r;1
  an objective function g : 붣 뫄 o 뫸 r.
모for example  in a single-item auction  n is the set of bidders; o = s뫄붫  where s is the set of all possible allocations of the item  one for each bidder  plus potentially one allocation where no bidder wins   and 붫 is the set of all possible vectors  of payments to be made by the agents
 e.g.  붫 = rn ; assuming no allocative externalities  that is  it does not matter to a bidder which other bidder wins the item if the bidder does not win himself   붣i is the set of possible valuations that the bidder may have for the item  for example  붣i = r뫟1 ; the utility function ui is given by:
 is the outcome in
which otherwise.  in situations in which a type consists of a single value  we will typically use vi rather than 붿i for the type. 1
모a  deterministic  mechanism consists of a function m : 붣 뫸 o  specifying an outcome for every vector of  reported  types.1 given a mechanism m  a beneficial manipulation1 consists of an agent i 뫍 n  a type vector   and an alternative type re-
port 붿 i for agent i such that
.	in	this
case we say that i manipulates from  into
.	a mechanism is strategy-
proof or  dominant-strategies  incentive compatible if there are no beneficial manipulations.  we will not consider bayes-nash equilibrium incentive compatibility here. 
모in settings with payments  we enforce an ex-post individual rationality constraint: we cannot make an agent worse off than he would have been if he had not participated. that is  we cannot charge an agent more than he reported the outcome  disregarding payments  was worth to him.
1	our approach and techniques
in this section  we explain the approach and techniques that we consider in this paper. we recall that our goal is not to  immediately  design a strategy-proof mechanism; rather  we start with some manipulable mechanism  and attempt to incrementally make it  more  strategy-proof. thus  the basic template of our approach is as follows: 1. start with some  manipulable  mechanism m; 1. find some set f of manipulations  where a manipulation is given by an agent i 뫍 n  a type vector  and an
alternative type report 붿 i for agent i ;
1. if possible  change the mechanism m to prevent  many of  these manipulations from being beneficial; 1. repeat from step 1 until termination.
모this is merely a template; at each one of the steps  something remains to be filled in. which initial mechanism do we

1
모모the utility function is parameterized by type; while the ui are common knowledge  the types encode  private  preferences. 1
모모in general  we may have additional information  such as a prior over the types  but we will not use this information in this paper. 1
모모in general  a mechanism may be randomized  specifying distributions over outcomes  but we will not consider this in this paper. 1
 beneficial  here means beneficial to the manipulating agent.
choose in step 1  which set of manipulations do we consider in step 1  how do we  fix  the mechanism in step 1 to prevent these manipulations  and how do we decide to terminate in step 1  in this paper  we will not resolve what is the best way to fill in these blanks  it seems unlikely that there is a single  universal best way   but rather we will provide a few instantiations of the technique  illustrate them with examples  and show some interesting properties.
모one natural way of instantiating step 1 is to choose a na몮 vely optimal mechanism  that is  a mechanism that would give the highest objective value for each type vector if every agent would always reveal his type truthfully. for instance  if we wish to maximize social welfare  we simply always choose an outcome that maximizes social welfare for the reported types; if we wish to maximize revenue  we choose an outcome that maximizes social welfare for the reported types  and make each agent pay his entire valuation.
모in step 1  there are many possible options: we can choose the set of all manipulations; the set of all manipulations for a single agent; the set of all manipulations from or to a particular type or type vector; or just a single manipulation. the structure of the specific setting under consideration may also make certain manipulations more  natural  than others; we can discover which manipulations are more natural by intuition  by hiring agents to act in test runs of the mechanism  by running algorithms that find manipulations  etc. which set of manipulations we choose will affect the difficulty of step 1.
모step 1 is the most complex step. let us first consider the case where we are only trying to prevent a single manipulation  from 
. we can make this manipula-
tion undesirable in one of three ways:  a  make the outcome that m selects for 붿 more desirable for agent i  when he has type 붿i    b  make the outcome that m selects for 붿 less desirable for agent i  when he has type 붿i   or  c  a combination of the two. we will focus on  a  in this paper. there may be multiple ways to make the outcome that m selects for 붿 sufficiently desirable to prevent the manipulation; a natural way to select from among these outcomes is to choose the one that maximizes the designer's original objective. note that these modifications may introduce other beneficial manipulations.
모when we are trying to prevent a set of manipulations  we are confronted with an additional issue: after we have prevented one manipulation in the set  we may reintroduce the incentive for this manipulation when we try to prevent another manipulation. resolving this would require solving a potentially large constrained optimization problem  constituting an approach similar to standard automated mechanism design-reintroducing some of the scalability problems that we wish to avoid. therefore  when addressing the manipulations from one type vector  we will simply act as if we will not change the outcomes for any other type vector.
모formally  for this particular instantiation of our approach  if m is the mechanism at the beginning of the iteration and m is the mechanism at the end of the iteration  after the update   and f is the set of manipulations under consideration  we have argmaxo뫍o m 붿 f g 붿 o 
 here     where o m 붿 f 	 	o is the set of all outcomes o such that for any beneficial manipulation  i 붿 i   with  i 붿 붿 i  뫍 f   ui 붿i o  뫟
.	it may happen
that o m 붿 f  =    no outcome will prevent all manipulations . in this case  there are various ways in which we can proceed. one is not to update the outcome at all  i.e. set . another is to minimize the number of agents that will have an incentive to manipulate from 붿 after the change  that is  to choose argmino뫍o |{i 뫍 n :    i 붿 붿 i  뫍 f : ui 붿i o   
  and ties can
be broken to maximize the objective g .
   many other variants are possible. for example  instead of choosing from the set of all possible outcomes o when we update the outcome of the mechanism for some type vector 붿  we can limit ourselves to the set of all outcomes that would result from some beneficial manipulation in f from 붿-that is  the set {o 뫍 o :     i 붿 i  :  i 붿 붿 i  뫍 f  : -in addition to
the current outcome m 붿 . the motivation is that rather than consider all possible outcomes every time  we may wish to simplify our job by considering only the ones that cause the failure of strategy-proofness in the first place. we next present examples of some of the above-mentioned variants. 1 instantiating the methodology
in this section  we illustrate the potential benefits of the approach by exhibiting mechanisms that it can produce in various standard mechanism design settings. we will demonstrate a setting in which the approach ends up producing a strategy-proof mechanism  as well as a setting in which the produced mechanism is still vulnerable to manipulation  but in some sense  more  strategy-proofthan na몮 vemechanisms .  a third setting that we studied-deciding on whether to produce a public good-is omitted due to space constraint.  we emphasize that our goal in this section is not to come up with spectacularly novel mechanisms  but rather to show that the approach advocated in this paper produces sensible results. therefore  for now  we will consider the approach successful if it produces a well-known mechanism. in future research  we hope to use the technique to help us design novel mechanisms as well.1 we do emphasize  however  that although the mechanisms that the approach eventually produces were already known to us  the approach simply follows local updating rules without any knowledge of what the final mechanism should be. in other words  the algorithm is not even given a hint of what the final mechanism should look like. 1 settings with payments
in this subsection  we show the following result: in general preference aggregation settings in which the agents can make payments  e.g. combinatorial auctions    one variant of  our technique yields the vcg mechanism after a single iteration. we recall that the vcg mechanism chooses an outcome that maximizes social welfare  not counting payments   and imposes the following tax on an agent: consider the total utility  not counting payments  of the other agents given the chosen outcome  and subtract this from the total utility  not counting payments  that the other agents would have obtained if the given agent's preferences had been ignored in choosing the outcome. specifically  we will consider the following variant of our technique  perhaps the most basic one :
  our objective g is to try maximize some  say  linear  combination of allocative social welfare  i.e. social welfare not taking payments into account  and revenue.  it does not matter what the combination is. 
  the set f of manipulations that we consider is that of all possible misreports  by any single agent .
  we try to prevent manipulations according to  a  above  for a type vector from which there is a beneficial manipulation  make its outcome desirable enough to the manipulating agents to prevent the manipulation . among outcomes that achieve this  we choose one maximizing the objective g.
모we will use the term  allocation  to refer to the part of the outcome that does not concern payments  even though the result is not restricted to allocation settings such as auctions. also  we will refer to the utility that agent i with type 붿i gets from allocation s  not including payments  as ui 붿i s . the following simple observation shows that the na몮 vely optimal mechanism is the first-price mechanism  which chooses an allocation that maximizes social welfare  and makes every agent pay his valuation for the allocation.
observation 1 the first-price mechanism na몮 vely maximizes both revenue and allocative social welfare.
proof: that the mechanism  na몮 vely  maximizes allocative social welfare is clear. moreover  due to the individual rationality constraint  we can never extract more than the allocative social welfare; and the first-price mechanism  na몮 vely  extracts all the allocative social welfare  for an outcome that  na몮 vely  maximizes allocative social welfare. 
모before showing the main result of this subsection  we first characterize optimal manipulations under the first-price mechanism.
lemma 1 the following is an optimal manipulation 붿 i from 붿 뫍 붣 for agent i under the first-price mechanism:
  for the allocation s  that would be chosen under the first-price mechanism for 붿  report a value equal to i's vcg payment under the true valuations  u 붿 i s    =
v cgi 붿i 붿 i  ;
  for any other allocation  report a valuation of 1
모the utility of this manipulation is u 붿i s     v cgi 붿i 붿 i .  this assumes ties will be broken in favor of allocation s . 
모without the tie-breaking assumption  the lemma does not hold: for example  in a single-item first-price auction  bidding exactly the second price for the item is not an optimal manipulation for the bidder with the highest valuation if the tie is broken in favor of the other bidder. however  increasing the bid by any amount will guarantee that the item is won  and in general  increasing the value for s  by any amount will guarantee that outcome .
proof: first  we show that this manipulation will still result in s  being chosen. suppose that allocation is chosen instead. given the tie-breaking assumption  it follows that   or equivalently . however 
by definition  
  so we have the de-
sired contradiction. it follows that agent i's utility under the manipulation is ui 붿i s     v cgi 붿i 붿 i .
모next  we show that agent i cannot obtain a higher utility with any other manipulation. suppose that manipulation 붿 i results in allocation s being chosen. because utilities cannot be negative under truthful reporting  it follows that ui 붿 i s +
.	using the fact
that 
we can rewrite the previous inequality as ui 붿 i s  +
  or equiva-
lently.
=
because  we can rewrite the preui  i s  + uj  j s     uj  j s  뫟 i  i  i   
j
ui 붿i s   + ui 붿i s   or equivalently  ui 붿i s    ui 붿 i s  뫞 ui 붿i s     v cgi 붿i 붿 i   as was to be shown. 
theorem 1 under the variant of our approach described above  the mechanism resulting after a single iteration is the vcg mechanism.
proof: by observation 1  the na몮 vely optimal mechanism is the first-price mechanism. when updating the outcome for 붿  by lemma 1  each agent i must receive a utility of at least ui 붿i s     v cgi 붿i 붿 i   where s  is the allocation that maximizes allocative social welfare for type vector 붿. one way of achieving this is to choose allocation s   and to charge agent i exactly v cgi 붿i 붿 i -that is  simply run the vcg mechanism. clearly this maximizes allocative social welfare. but  under the constraints on the agents' utilities  it also maximizes revenue  for the following reason. for any allocation s  the most revenue that we can hope to extract is the allocative social welfare of s  that is   minus the sum of the utilities that we must guarantee the agents  that is . because s = s  maxi-
mizes  this means that the most revenue we can
hope to extract is  and the vcg mechanism achieves this. 
1	ordinal preferences
in this subsection  we address voting  social choice  settings. in such a setting  there is a set of outcomes  also known as candidates or alternatives  and a set of agents  also known as voters   and every agent i's type is a complete ranking  i over the candidates.  we do not need to specify numerical utilities here.  the mechanism  or voting rule  takes as input the agents' type reports  or votes   consisting of complete rankings of the candidates  and chooses an outcome.
모the most commonly used voting rule is the plurality rule  in which we only consider every voter's highest-ranked candidate  and the winneris simply the candidatewith the highest number of votes ranking it first  its plurality score . the plurality rule is very manipulable: a voter voting for a candidate that is not winning may prefer to attempt to get the candidate that currently has the second-highest plurality score to win  by voting for that candidate instead. in the real world  one common way of  fixing  this is to add a runoff round  resulting in the plurality-with-runoff rule. under this rule  we take the two candidates with the highest plurality scores  and declare as the winner the one that is ranked higher by more voters. by the gibbard-satterthwaite theorem  this is still not a strategy-proof mechanism  it is neither dictatorial nor does it preclude any candidate from winning -for example  a voter may change his vote to change which candidates are in the runoff. still  the plurality with runoff rule is  in an intuitive sense   less  manipulable than the plurality rule  and certainly more desirable than a strategy-proof rule  since a strategy-proof rule would either be dictatorial or preclude some candidate from winning .
모in this subsection  we will show that the following variant of our approach will produce the plurality-with-runoff rule when starting with the plurality rule as the initial mechanism.   the set f consists of all manipulations in which a voter changes which candidate he ranks first.
  we try to prevent manipulationsas follows: for a type  vote  vector from which there is a beneficial manipulation  consider all the outcomes that may result from such a manipulation  in addition to the current outcome   and choose as the new outcome the one that minimizes the number of agents that still have an incentive to manipulate from this vote vector.   we will change the outcome for each vote vector at most once  but we will have multiple iterations  for vote vectors whose outcome did not change in earlier iterations .
모we are now ready to present the result.  the remaining proofs are omitted due to space constraint. 
theorem 1 for a given type vector 붿  suppose that candidate b is ranked first the most often  and a is ranked first the second most often  s b    s a    ...  where s o  is the number of times o is ranked first . moreover  suppose that the number of votes that prefers a to b is greater than or equal to the number of votes that prefers b to a. then  starting with the plurality rule  after exactly s b    s a  iterations of the approach described above  the outcome for 붿 changes for the first time  to a  the outcome of the plurality with runoff rule .1
1	computing the mechanism's outcomes
in this section  we discuss how to automatically compute the outcomes of the mechanisms that are generated by this approach in general. it will be convenient to think about settings in which the set of possible type vectors is finite  so that the mechanism can be represented as a finite table   although these techniques can be extended to  some  infinite settings as well.  at the very least  types can be grouped together into a finite number; for specific settings  something better can often be done.  one potential upside relative to standard automated mechanism design techniques is that we do not need to compute the entire mechanism  the outcomes for all type vectors ; rather  we only need to compute the outcome for the type vector that is actually reported.
모let m1 denote the  na몮 ve  mechanism from which we start  and let mt denote the mechanism after t iterations. let ft denote the set of beneficial manipulations that we are considering  and are trying to prevent  in the tth iteration. thus  mt is a function of ft and mt 1. what this function is depends on the specific variant of the approach that we are using. when we try to prevent manipulations by making the outcome for the type vectorfromwhich the agentis manipulating moredesirable for that agent  we can be more specific  and say that  for type vector 붿  mt 붿  is a function of the subset ft붿   ft that consists of manipulations that start from 붿  and of the outcomes that mt 1 selects on the subset of type vectors that would result from a manipulation in ft붿. thus  to compute the outcome that mt produces on 붿  we only need to consider the outcomes that mt 1 chooses for type vectors that differ from 붿 in at most one type  and possibly even fewer  if ft붿 does not consider all possible manipulations . as such  we need to consider mt 1's outcomes on at most type vectors to compute mt 붿   for any given 붿   which is much
n
smaller than the set of all type vectors   . of course 
=1
to compute for some type vector 붿  we need to consider mt 1's outcomes on up totype vectors  etc.
모because of this  a simple recursive approach for computing mt 붿  for some 붿 will require time. this approach may  however  spend a significant amount of time recomputing values many times. another approach is to use dynamic programming  computing and storing mechanism mj 1's outcomes on all type vectors before proceeding to compute outcomes for mj. this approach will require
 time  for every iteration  for ev-
ery type vector  we must investigate all possible manipulations . we note that when we use this approach  we may as well compute the entire mechanism mt  we already have to compute the entire mechanism mt 1 . if n is large and t is small  the recursive approach is more efficient; if n is small and t is large  the dynamic programming approach is more efficient. we can gain the benefits of both by using the recursive approach and storing the outcomes that we compute in the process  so that we need not recompute them.
모all of this is for fully general  finite  domains; it is likely that these techniques can be sped up considerably for specific domains. moreover  as we have already seen  some domains can simply be solved analytically.
1	computational hardness of manipulation
we have demonstrated that our approach can change na몮 ve mechanisms into mechanisms that are less  sometimes not at all  manipulable. in this section  we will argue that in addition  if the mechanism remains manipulable  the remaining manipulations are computationally difficult to find. this is especially valuable because  as we argued earlier  if it is too hard to discover beneficial manipulations  the revelation principle ceases to hold  and a manipulable mechanism can sometimes actually outperform all truthful mechanisms.
모we first give an informal  but general  argument for the claim that any manipulations that remain after a large number of iterations of our approach are hard to find. suppose that the only knowledge that an agent has about the mechanism is the variant of our approach by which the designer obtains it  the initial na몮 ve mechanism  the manipulations that the designer considers  how she tries to eliminate these opportunities for manipulations  how many iterations she performs  etc. . given this  the most natural algorithm for an agent to find a beneficial manipulation is to simulate our approach for the relevant type vectors  perhaps using the algorithms presented earlier. however  this approach to manipulation is computationally infeasible if the agent does not have the computational capabilities to simulate as many iterations as the designer will actually perform.
모unfortunately  this informal argument fails if the agent actually has greater computational abilities or better algorithms than the designer. however  it turns out that if we allow for random updates to the mechanism  then we can prove hardness of manipulation in a formal  complexity-theoretic sense. so far  we have only discussed updating the mechanism in a deterministic fashion. when the mechanism is updated deterministically  any agent that is computationally powerful enough to simulate this updating process can determine the outcome that the mechanism will choose  for any vector of revealed types. hence  that agent can evaluate whether he would benefit from misrepresenting his preferences. however  this is not the case if we add random choices to our approach  and the agents are not told about the random choices until after they have reported their types . in fact  we can prove the following result.  as in most previous work on hardness of manipulation  this is only a worst-case notion of hardness  which may not prevent manipulation in all cases. 
theorem 1 when the updates to the mechanism are chosen randomly  evaluating whether there exists a manipulation that increases an agent's expected utility is #p-hard.
1	discussion
while we have given a framework  and a portfolio of techniques within that framework  for making mechanisms more strategy-proof and illustrated their usefulness with examples  we have not yet integrated the techniques into a single  comprehensive approach. this suggests some important questions for future research. is there a single  general method that obtains all of the benefits of the individual techniques that we have described  possibly by making use of these techniques as subcomponents   if not  can we provide some guidance as to which techniques are likely to work best in a given setting  another direction for future research is to consider other types of manipulation  such as false-name bidding . 
* 
there are computer programs that use the same flow of control when run on different inputs. this redundancy in their program execution traces can be exploited by preserving suitably abstracted call-graphs1 for subsequent reuse. we introduce a new programming transformation call-graph caching  cgc  which partially evaluates the control flow of sets of such programs into a network formed from their call-graphs. cgc can automatically generate efficient state-saving structure-sharing incremental algorithms from simple program specifications. as an example  we show how a straightforward  inefficient lisp program for conjunctive match is automatically transformed into the rete network algorithm. simple and understandable changes to elegant functional  and other  programs are automatically translated by cgc into new efficient incremental network algorithms; this abstraction mechanism is shown for a class of conjunctive matching algorithms. we establish criteria for the appropriate application of cgc to other ai methods  such as planning  chart parsing  consistency maintenance  and analogical reasoning. 
1 introduction 
caching is a general efficiency mechanism for exploiting redundancy in computation by reusing previously computed information. for example  ai systems often cache problem solving experience learned over time  or knowledge  as a set of programs. intelligent interactive systems apply this program set over repeated cycles of interaction with external data input. we define as persistent those intelligent interactive systems that apply all knowledge to all data on every cycle. straightforward implementations of persistent systems are often inefficient  since only some programs in the knowledge base are relevant each cycle  and potentially reusable intermediate computations are discarded. 
¡¡we have identified a key source of computational redundancy: a program's flow of control  or  call-graph  structure. this control-flow redundancy can be exploited by 
¡¡this work was supported in part by grant r1 lm 1 from the national library of medicine  and by the pittsburgh nmr 
institute. 
¡¡1a call-graph is a trace of an executing program's flow of procedural control. with recursive languages like lisp  this is the explicit tree of a program's dynamic procedure calls. 
1 	tools caching call-graphs. 
in this paper  we present a new program transformation 
call-graph caching  cgc  that partially evaluates and then reuses a program's control structure. we: 
1. provide applicability conditions for the use of 
cgc. 
1. present a working prototype eval' which performs partial evaluation of lisp programs into executable call-graphs. 
1. show how cgc helps in the conceptual and implementational derivation of efficient statesaving structure-sharing incremental network algorithms. 
1. illustrate how cgc exploits the fixed callgraph structure to reverse the flow of computation: data can flow up the call-graph  instead of always moving top-down from the program. thus program execution can be driven from incremental changes in input data  instead of being rigidly preset. 
the utility of cgc is demonstrated by: 
1. using cgc to transform a simple  inefficient lisp program for conjunctive matching into the classic rete match algorithm  forgy  1 . this also demonstrates the use of our automatic transformation prototype eval  
1. showing other applications of cgc in ai  such as indicating how small changes in our conjunctive match lisp program can mechanically generate alternative network join topologies. such transformations enable researchers to spend minutes modifying short functional programs  instead of months engaged in low-level network programming. 
1. suggesting that cgc is uniquely suited to ai  in that it potentially increases the efficiency of persistent knowledge-based systems. 
¡¡cgc differs from ordinary data or instruction caching  baer  1  in that control decisions  not data or actions  are stored unlike function caching  pugh  1   cgc caches network traces  not computed function values. cgc observes  records  and removes the control decisions of a program  executing on some input   whereas program dependence graph methods  ferrante  1  do not diminish control flexibility. 
¡¡after first introducing the cgc transformation  section 1   we show how to transform matching programs into rete networks  section 1 . we then present a number of other uses of cgc in ai  section 1 . 

1 call-graph caching 
call-graph caching is a program transformation from arbitrary programs1 into network programs. after defining our notion of  program   and establishing what  network programs  are  we motivate how the control flow of a program can be cached into a netwoik. we then present the mechanics of the transformation  and describe an implementation. 
1 programs 
programming languages provide action constructs that operate on input data  sequenced according to some control organization. the actions are applied to the data by an evaluator  such as lisp's eval   which may also partially determine the control sequencing. program execution proceeds by traversing the program's actions according to the control organization  and evaluating the actions on the data. for example  lisp's control mechanism is recursion  which coordinates the --expression actions on data arguments  such as symbols and lists. traversal of a lisp program's code tree recursively executes eval on the x-expressions and arguments at each node in the tree. 
1 network programs 
there are programs that operate by traversing an acyclic network. the actions of such programs reside and are executed at network nodes  while their control organization is represented by netwoik links. the links of the directed acyclic1 graph  dag  encode a partial ordering of the nodes. programs whose netwoik traversals are guaranteed to respect this partial ordering belong to the class network. partial order enumeration is usually implemented with some version of topological ordering  knuth  1   and assures that every dag node is visited exactly once: after each of its predecessors have been visited. 
¡¡when input data is presented to the leaves  computations propagate through the network. the results of local node computations can be locally stored in node memory. a node uses memories of predecessor nodes in bottom-up network computation similarly to a stack frame's use of recursive return values in usual programming languages. since the netwoik persists between cycles  finite differencing  paige  1  can reduce redundant computations at a node. to implement this incremental strategy  node memory is divided into a short-term buffer and a longer-term store  the use of which is shown below. 
¡¡network programs are very efficient  with overhead at most linear in idagi  the number of nodes and edges  hoover  1 . propagating from all the leaves  and keeping newly computed values in nodes' buffer memory  topological ordering assures that each node is recomputed exactly once  perlin  1a . if changes are made to only a 
¡¡subset of dag leaves  using the store memory  which persists between change cycles  the computation need only be propagated to the transitive closure dag subset affected  iaffectedi   idagi. this produces 
state-saving algorithms that perform minimal recomputation  directed from just the changes to their input.1 when coupled with finite differencing  state-saving incremental algorithms result. 
the price for this efficiency is inflexible control structure: 
network program dags have the restricted form of basic blocks  aho  1 . despite this limitation  network finds extensive application. efficient incremental spreadsheets use the algorithm sketched above. conjunctive matching programs are often cast in network form for efficiency. other potential applications include the representation of dependency relations  multiple inheritance  consistency maintenance reasoning  doyle  1   and incremental attribute grammar evaluation  reps  1 . 
1 caching control flow 
let p x y  be a program in some language  having arguments x and y. suppose that p's control structure is independent of y. then partial evaluation  futamura  1  of p x y  with respect to some fixed xo will yield a new program p'x1 y  of one argument having a unique callgraph. 
¡¡an interactive program's input either depends on external factors  or is independent of external interactions. now sup-
pose that program p x y  is interactive  and its argument x is independent of external factors. then p y  
1. completely characterizes p x y 's interactions with the external environment  and 
1. has a unique call-graph. 
we define an interactive program p x y  to be basic when x is independent of external factors  and p's control structure is independent of y. 
p' y  has a unique call-graph which can be cached as a 
network program for later reuse. the program's actions are encoded in the call-graph nodes; each node is allocated local memory. the program's control flow decisions are recorded as call-graph edges. applying input data to the call-graph leaves  a bottom-up graph traversal  respecting the nodes' partial ordering represented by the edges  can correctly execute the program. we therefore have a new network program operationally equivalent to the partially evaluated p  as illustrated in figure 1. 


1 the transformation 
we describe the call-graph caching  cgc  transformation in several loosely coupled steps. the first step assembles the call-graph from its subgraph components. the second collects a set of call-graphs into a network. the resulting cached call-graph network structure is used  and reused  as a data cache. pedagogical examples on simple polynomials are detailed in  perlin  1b . 
1.1 building the call-graph 
¡¡control-flow caching is an algorithm which builds the call-graph of a program on some input. the construction takes as 
¡¡¡¡  input either 
1. the compile-time text of a program  together with its partial input  or 
1. the run-time program executing on its complete input  and 
¡¡¡¡  outputs the call-graph of that program. the procedure employs an auxilliary data structure  the conxrol-flow cache  which is used in the assembly of the final call-graph structure. there is also an optional argument specifying the key execution steps to cast into graph nodes. 
control-flow caching proceeds as three separate steps. 
first  with a program   partial  input  and a user-definable set of the key steps to abstract1 a trace is formed of the program's execution. each node in the resulting call-graph represents one  key  step in the program's trace. the actual formation of the call-graph is facilitated by specific controlflow cache management strategies. one such strategy is the above abstraction mechanism of recording only the  key  steps as nodes. another strategy  used in chart parsing  winograd  1   ls exploiting the constraints posted in the control-flow cache to help reduce the executing program's computation  i.e.  dynamic programming. yet another  say for a lisp program  would be to passively cache the succession of execution branches into a full call tree. regardless of the specific strategies  the resulting callgraph captures  in space  the program's execution over time  as shown in figure 1  step 1. 

	 1  	 1  	 1  
figure 1: control-row caching: assembling the call-graph. 
program p x y  has thus far been evaluated on input xq  with the partially evaluated p' y  preserved as a call-graph. the second step of control-flow caching connects the external input y to the program's graph. as shown in figure 1  step 1  the resulting call-graph of the complete program is a dag1. 
¡¡the third step operationalizes the call-graph into a usable data structure. for example  graph nodes can be augmented with the requisite buffer and store memory with a system-specific representation. 
¡¡at this point  saving and reusing just this single callgraph provides a fully functional state-saving network program. directing input y through the graph in a partially ordered node enumeration  with the node memories as a 
¡¡data cache  will perform the computations of p xo y . more efficient incremental evaluation via finite differencing is effected by using the local buffer memory to  1  record intracycle computations and  1  differentially update the local intercycle store memory. 
1.1 collecting call-graphs 
¡¡the call-graph caching transformation is completed by collecting a set of p xo y  call-graphs  for a variety of p's and xo's. this set is called the call-graph cache  and  like other caches  usually employs efficient cache management strategies. for example  spreadsheets and conjunctive matchers exploit common shared prefix structure  with trie-like  aho  1  merging of call-graphs into a single connected network. in allocating the often limited resource of space  another common strategy is to perform a cost/benefit analysis  detemiining which call-graphs stay in the cache  and which are removed. 
1 using the call-graph cache 
¡¡after building the call-graphs of {p xiy  i ie 1} and collecting them into a call-graph cache  the resulting network is used  and reused  as a data cache. values or sets of values of y propagate bottom-up through the network  employing the buffer memory within each propagation cycle  and store memory between cycles. for efficiency and correctness  the network traversal control mechanism is partial order enumeration  implemented with a topological sort . 
¡¡this completes the transformation of a finite set of basic programs  in any programming language  into an efficient state-saving network program. 
1 an implementation 
to demonstrate the workability of call-graph caching  we implemented in common lisp a simple partial evaluator eval  which transforms a large class of lisp programs into their corresponding call-graphs. the input to eval' is the symbolic lisp expression representing  p xo y '  for some p and xq  and a set of labels denoting the key execution steps to cache. the output is a call-graph  where each node specifies 
  the label of the node type; 
  a lambda expression containing all the infor-mation required to execute the node's computation when applied to the values of its immediate predecessor nodes; 

  recursively  the 	nodes 	of 	its 	immediate predecessors. 
eval' performs the following computations: 
1. arrive at  the label of  a key node  i.e.  lisp function or symbol  to be abstracted. 
1. perform eval' on the unevaluated arguments to the function. 
1. substitute these values into the function  and then execute eval' on the lisp function's code tree. 
this delayed evaluation is done recursively  caching the control structure into a call-graph. the call-graph's nodes abstract out the set of labelled functions  preserving the local actions required for later execution. 
¡¡we have also developed a variety of network structuresharing programs for merging call-graphs  and a partial order network traversal toolkit for executing these cached call-graph networks as programs. our working implementations have demonstrated the efficacy of transforming simple lisp specifications into efficient incremental network programs on ai examples such as rete matching. 
1 rete networks: an example of call-graph caching 
rete matching is a state-saving structure-sharing incremental algorithm used in ops-1 and other production systems for conjunctively matching many patterns against many objects. because it provides excellent average-case behavior for an important np-hard ai problem  it has been extensively studied and varied. it is also a good example of the call-graph caching program transformation  illustrating nontrivial usage of the control-how cache and the callgraph cache. 
1 rule matching 
forward-chaining rule systems  or  production systems   such as ops-1 are programming languages with match as their control element. program data is organized into a set of rules  having left-hand-side  lhs  tests and rhs actions. external input  often called  working memory   comes from a slowly varying set d of data objects. if a rule's tests match objects  the rule becomes a candidate for firing; when executed  its actions serve to modify d. 
¡¡following common practice  we fix the form of the rules' lhss to be a set of conjunctive conditions  each condition containing tests restricting the set of matchable objects. an instantiation of a rule having n lhs conditions is an n-tuple of objects satisfying the rule's lhs tests. on every interaction cycle  the rule evaluator must try to match each rule against all possible combinatioas of objects in d  forming its set of instantiations 

which applies a set of tests to a set of objects  producing a filtered set of n-tuple instantiations. 
production systems are persistent  in that they 
1. maintain their knowledge in a finite set of experientially derived programs  the rule set   and 
1. apply all programs to all available data on each interactive cycle. 
they are also inefficient. consider just one rule having n conditions matching against only two data objects- the set of candidate instantiations dn grows exponentially in n. in fact  conjunctive rule matching is np-hard  minton  1 . generally  however  only a small fraction of the object set changes each cycle. so instead of rigidly applying all rule programs to the data  perhaps the incremental changes to data should drive the matching computation. 
¡¡for each rule program in the rule set specifying some tests in tests  atoc/i tests d  is the computationally expensive subprogram. observe that with 
p = match  x = tests  and y = d  
1.x is independent of the external data input d  and 
1. the conjunctive matcher p x y  is programmable so that p's control is independent of y  e.g.  section 1 . 
therefore p is basic  and call-graph caching will generate an efficient state-saving structure-sharing incremental matching algorithm. 
1 transforming rule matching into rete networks 
we illustrate the use of call-graph caching by generating the rete network from a simple functional programming specification of the matching function. 
1. we stan from an easily specified  though inefficient  set of functional programs. 
1. using an auxilliary control-flow cache  partial evaluation of the basic program match t1x   produces a call-graph capturing match1 d 's control flow. this call-graph is usable as an incremental data-driven state-saving network program which can store processed input data as intermediate matching results. 
1. the call-graph cache merges the individual call-graphs in order to conserve space  and achieve some speedup. this is done by test sharing: nodes with common test prefixes are combined to form a single trie data structure. 
we now detail this construction of the rete network algorithm. 
1.1 rule matching as lisp programs 
   a rule specifies a fixed set of tests t1 for its match component. the conjunctive match program match t1 d  can be formulated so that its control is independent of working memory d. we now write such a filter match as a functional-style lisp program. 
¡¡for efficiency on a serial processor  we first impose a fixed ordering on the rules' conditions. each test examines one or more objects in a candidate n-tuple e dn; these objects are now ordered by the condition ordering. we now order the test set: associate to each test the number of the 
	perlin 	1 
last object it examines  and arrange the tests with respect to this index. for efficiency  the match is performed by a 
conditional and  testing a candidate n-tuple against the first test subset  then the second  and so on through the nth. within the kth test subset  k   n  the tests may be further grouped into two classes: 
a. alpha tests on a single object e d  and 
b. beta tests on more than one object  i.e.  ktuples € dk. 
¡¡there are many ways to write the lisp code for this simple filter  e.g.  as one function  iteratively  recursively  etc. . while the cgc transformation is independent of programming style  for clarity  we present match using linear recursion. 
; match r u l e ' s t e s t s against the data  
 define match 	 tests data  
  b e t a - j o i n 
	  f i r s t 	tests  
  second tests  data   
; 	join together the preceding s i f t and 
; 	j o i n sets with a f i l t e r i n g beta t e s t   
 define b e t a - j o i n  a b d    i f 	  n u l l a  m o   
	  f i l t e r 	  f i r s t b  
 set-product 
	  a l p h a - s i f t 	  f i r s t a  d  
 beta-join 
	 rest a  	 rest b  d           
; 	s i f t the objects with alpha t e s t s   
 define a l p h a - s i f t 	 a d  
  s e t - f i l t e r a d   
¡¡match takes a preordered set of tests  and a set of data objects as its arguments. the key interesting function is beta-join  which merges the simple alpha-sift filter with further recursive calls to beta-join; this produces a linearly recursive call-graph. note how the tests in match's tests argument are deposited locally at each level of filtering  and that no control decisions are made using the data argument. 
¡¡the auxilliary function set-filter returns the subset satisfying some predicate tests  while the function set-product operates similarly on a pair of sets. 
1.1 building the call-graph 
¡¡step 1. for any mle r  calling eval' on matchitcsts.  d  with the set of labels  match  alpha-sift  beta-join  will save the calling structure of the rule's tests. the control-flow cache is used with the functional program match to store to the growing call tree. as shown in figure 1 a  the call-graph has a linear spine  with the appropriate tests localized at each node. 
¡¡step 1. in figure 1 b  the free input variable data is attached to the call-graph as an input source  turning the call tree into a dag. 
¡¡step 1. the graph structure of this single rule's match component can now be completed. memory for the intracycle buffer and the inter-cycle store  and other information  can be specialized into a specific graph representation. this call-graph can be reused as a bottomup network filtering program. in figure 1 c  the domains of the filtered objects are shown. 
¡¡using the buffer memory  partial order traversal of the call-graph from the data computes the filtered instantiation subset of dn. if the nodes' longer-term store memories are initially loaded with d  and then continually updated   only 
1 	tools 

	figure 1: 	cgc on a linearly recursive conjunctive matcher. 
changes to the object set ad are needed for computing further instantiations. that is  the call-graph is a incremental state-saving data-driven network program for computing the state of a single rule's match. 
¡¡this is not surprising: figure 1 d shows the rete network beta join topology  which is isomorphic to the match call-graph in figure 1 c. 
1 collecting call-graphs 
¡¡a rule system is comprised of a finite set of rules; we therefore form the corresponding set of call-graphs  one for each rule's match component. this set is the call-graph cache. one cache management strategy for conserving cache space  with some associated speedup  is to merge the call-graph dags into one connected network. the matcher's behavior is unchanged if  proceeding from the data input source  nodes are merged based on prefix sharing of tests. a succession of call-graphs merging into a common beta-join node trie is depicted in figure 1. 
¡¡when an alpha discrimination net is added to the beta join trie  the classical rete match network is generated. we implemented this addition by modifying the alpha-sift lisp function to perform its tests tail recursively. this illustrates how cgc readily produces new desired network topologies from small changes in lisp program specifications. 
1.1 using the call-graph cache 
¡¡partial order traversal of the rete network will perform the match of the rule set  cached as a shared set of callgraphs  against working memory input d. the intracycle buffer and intercycle store memories at each node are used as a data cache to preserve the partial match computations 


 within and between  each cycle. working memory elements are then incrementally added or deleted from these memories. 
1 alternate join topologies 
call-graph caching generates more than rete networks: one application is the generation of families of efficient con-
junctive matchers. by making simple variations in match's lisp specification  and changing which key function names are cached into call-graph nodes  many different join topologies can be designed  easily specified  and automatically constructed. also  there are other call-graph cache merging strategies besides trie-based prefix sharing. 
¡¡the rete example was described above: a linearly structured call graph. one known alternative approach is to not cache the beta join nodes  miranker  1 . another is to structure the call graph as binary tree  stolfo  1   reducing the long linear chains problematic in rete. we are currently exploring and assessing a variety of new join topologies using cgc as a rapid prototyping tool. these topologies can be custom tailored to task-specific requirements  such as learning or parallelism. 
1 other uses 
with general recursive computation  actions  e.g.  floating point arithmetic  file access  are often expensive  whereas actions' control organization and input data can be uninteresting. with intelligent systems  however  actions  e.g.  precomputed motions  user queries  are commonly mundane; it is the sequencing of such actions to achieve concrete goals that is complex and computationally difficult. since the cgc method explicitly records such control decisions for subsequent modification and reuse  it provides both a conceptual framework and an implementation strategy. in script-based planning  schank  1   for example  knowledge-based action sequences are retrieved  and each simple action step is replayed. analogical reasoning  carbonell  1  can extend this retrieval by transformations of retrieved plans. other applications of cgc in ai are discussed below. 
1 control-flow caching 
the control-flow cache may simply record the unraveling of an execution tree over time  as in the rete example  or take a more active role  such as enabling constraint-directed dynamic programming. for example  in efficient contextfree parsing  each graph node represents an individual firing of a grammar production; the control-flow cache  or 
 chart   records past firings to constrain future ones. 
¡¡if rule firings are recorded as cgc nodes  the call-graph of a rule system's problem solving instance forms a trace of the rules' executions. this record  dag  of the rule and data dependencies may then aid in consistency maintenance analysis for exploring alternative reasoning scenarios. here the call-graph would form a network program utilizing its data cache  with ground instance changes incrementally propagated via dag traversal. 
1 call-graph caching 
persistent processes maintain their knowledge in a program cache; this cache is augmented or modified as the knowledge changes over time. when the cached programs 
have call-graphs with sufficient redundancy  e.g.  are basic   the knowledge may be compiled into an efficient callgraph cache network. for example  consider the rule trace discussed above: dags representing arbitrary rule execution are not likely to share similar morphology  and  therefore  they are not usually cached as networks. rather  such call-graphs are abstracted into networks having a single inner node  or  chunk   using ebg  mitchell  1  or some other execution trace generalization method. these reformed networks have sufficient operationality to then be reused in the program cache  resulting in potential efficiency improvements.  in some systems  laird  1   they may be compiled into rete networks at a lower level of abstraction for further efficiency gains.  
¡¡there are many common persistent processes comprised of basic programs. for example  a  multiple  inheritance network will be automatically generated as the cached callgraph set from the process of successive subset classification on some input set. as another example  window systems may be thought of as caching an inefficient  painter's algorithm  redisplay execution into a call-graph based on the in-front-of relation. efficiencies accrue since  in general  the data inside the windows is independent of window redisplay. 
1 extensions 
cgc is applicable when persistent interactive intelligent systems are comprised of basic programs. since not all programs are basic  we consider how to use cgc under weaker assumptions. 
¡¡as in section 1  let p' y  be a partially evaluated program. p y  need not have a unique call-graph for cgc to be useful. as long as its set of call-graphs is manageable  some caching strategy could succeed. for instance  p' y  might have only a small finite number of call-graphs. alternatively  a skewed distribution of p' y 's call-graphs could probabilistically ensure manageability. extending the rete match example  when disjunction  i.e.  choice  is introduced into primarily conjunctive rules  there is still much redundancy in control flow. though weaker  this redundancy is effectively exploited in rete-based ops-1 via copying and conflict resolution. 
1 future work 
the cgc transfonnation lets us reexamine many network algorithms impartially evaluated programs which have their call-graphs preserved. further  as with rete  it may be the case that reformulation of the network into a new program in some appropriate language leads to clearer specification of the algorithm. since network-like efficiency is guaranteed by the cgc transfonnation  improvements can 
	perlin 	1 

then be effected in the abstracted programming language  rather than in the low-level network language. 
¡¡conversely  given a clear specification of a set of programs in some language  when control-flow redundancy is present  whether guaranteed by the  basic  property  or simply empirically observed  cgc becomes another route for improving performance. possibilities include: 
1. refining classic state-saving incremental network algorithms where call-graph redundancy has already been observed 
1. reexamining inefficient ai architectures for reusable redundancy in control-flow. 
1. developing new and efficient persistent interactive processes by starting from precise  inefficient programs that have sufficient controlflow redundancy for the cgc transformation to succeed. 
1 conclusion 
the call-graph caching program transformation is simpler than many modem compilation techniques. nonetheless  cgc can mechanically transform programs having sufficient control-flow redundancy into highly efficient incremental counterparts. cgc's chief practical use is in rapidly specifying  and testing  complex network algorithms as simple programs in ordinary programming languages. this was demonstrated with the rete matching example. 
¡¡intelligent systems  unlike fully general computation  must often rely on viable sequences of actions in order to solve their problems. to the extent that such systems exploit redundancies in their control  i.e.  sequencing  decisions as they evolve over time  cgc can help in the analysis and implementation of this aspect of intelligence. we therefore suggest that the caching and reuse of call-graphs could 
prove applicable to a broad range of problem areas and techniques in ai. 
acknowledgments 
jaime carboneu provided much assistance in the initial formulation of these ideas. peter lee  david steier  and milind tambe also contributed to the ideas' evolutioa 


this paper deals with methods exploiting treedecomposition approaches for solving constraint networks. we consider here the practical efficiency of these approaches by defining five classes of variable orders more and more dynamic which preserve the time complexity bound. for that  we define extensions of this theoretical time complexity bound to increase the dynamic aspect of these orders. we define a constant k allowing us to extend the classical bound from o exp w + 1   firstly to o exp w + k + 1    and finally to o exp 1 w + k+1  s     with w the  tree-width  of a csp and s  the minimum size of its separators. finally  we assess the defined theoretical extension of the time complexity bound from a practical viewpoint.
1 introduction
the csp formalism  constraint satisfaction problem  offers a powerful framework for representing and solving efficiently many problems. modeling a problem as a csp consists in defining a set x of variables x1 x1 ...xn  which must be assigned in their respective finite domain  by satisfying a set c of constraints which express restrictions between the different possible assignments. a solution is an assignment of every variable which satisfies all the constraints. determining if a solution exists is a np-complete problem.
﹛the usual method for solving csps is based on backtracking search  which  in order to be efficient  must use both filtering techniques and heuristics for choosing the next variable or value. this approach  often efficient in practice  has an exponential theoretical time complexity in o e.dn  for an instance having n variables and e constraints and whose largest domain has d values. several works have been developed  in order to provide better theoretical complexity bounds according to particular features of the instance. the best known complexity bounds are given by the  tree-width  of a csp  often denoted w . this parameter is related to some topological properties of the constraint graph which represents the interactions between variables via the constraints. it leads to a time complexity in o n.dw+1   denoted o exp w + 1   . different methods have been proposed to reach this bound like tree-clustering  dechter and pearl  1   see  gottlob et al.  1  for more details . they rely on the notion of tree-decomposition of the constraint graph. they aim to cluster variables such that the cluster arrangement is a tree. depending on the instances  we can expect a significant gain w.r.t. enumerative approaches. most of works based on this approach only present theoretical results. except  gottlob et al.  1; je∩gou and terrioux  1   no practical results have been provided. so  we study these approaches by concentrating us on the btd method  je∩gou and terrioux  1  which seems to be the most effective method proposed until now within the framework of these structural methods.
﹛while the problem of finding the best decomposition has been studied in the literature firstly from a theoretical point of view  recently  some studies have been realized in the field of csp  integrating as quality parameter for a decomposition  its efficiency for solving the considered csp  je∩gou et al.  1 . yet  these studies do not consider the questions related to an efficient use of the considered decompositions.
﹛this paper deals with this question. given a treedecomposition  we study the problem of finding good orders on variables for exploiting this decomposition. as presented in  je∩gou and terrioux  1   the order on the variables is static and compatible with a depth first traversal of the associated cluster tree. since enumerative methods highlight the efficiency of dynamic variable orders  we give conditions which allow to exploit in a more dynamic way the treedecomposition and guarantee the time complexity bound. we proposefive classes of orders respecting these conditions  two of them giving more freedom to order variables dynamically.
consequently  their time complexity possess larger bounds: o exp w +k +1   and o exp 1 w +k +1  s     where k is a constant to parameterize and s  the minimum size of separators. based on the properties of these classes  we exploit several heuristics which aim to compute a good order on clusters and more generally on variables. they rely on topological and semantic properties of csp instance. heuristics based on the expected number of solutions enhance significantly the performances of btd. meanwhile  those based on the cluster size or on the dynamic variable ordering heuristic provide often similar improvements and may outperform the first ones on real-world instances. finally  we report here experiments to assess the interest of the extensions based on the time complexity bound.
this paper is organized as follows. the next section provides basic notions about csps and methods based on treedecompositions. then  in section 1  we define several classes of variable orders which preserve the classical bounds for time complexity. section 1 introduces two extensions giving new time complexity bounds. section 1 is devoted to experimental results to assess the practical interest of our propositions. finally  in section 1  we summarize this work and we outline some future works.
1 preliminaries
a constraint satisfaction problem  csp  is defined by a tuple  x d c . x is a set {x1 ... xn} of n variables. each variable xi takes its values in the finite domain dxi from d. the variables are subject to the constraints from c. given an instance  x d c   the csp problem consists in determining if there is an assignment of each variable which satisfies each constraint. this problem is np-complete. in this paper  without loss of generality we only considerbinary constraints  i.e. constraints which involve two variables . so  the structure of a csp can be represented by the graph  x c   called the constraint graph. the vertices of this graph are the variables of x and an edge joins two vertices if the corresponding variables share a constraint.
﹛tree-clustering  dechter and pearl  1  is the reference method for solving csps thanks to the structure of its constraint graph. it is based on the notion of tree-decomposition of graphs  robertson and seymour  1 . let g =  x c  be a graph  a tree-decomposition of g is a pair  e t  where t =  i f  is a tree with nodes i and edges f and e = {ei : i ﹋ i} a family of subsets of x  such that each subset  called cluster  ei is a node of t and verifies:  i  ﹍i﹋iei = x   ii  for each edge {x y} ﹋ c  there exists i ﹋ i with {x y}   ei  and  iii  for all i j k ﹋ i  if k is in a path from i to j in t  then ei ﹎ ej   ek.
﹛the width of a tree-decomposition  e t  is equal to maxi﹋i|ei| 1. the tree-width w of g is the minimal width over all the tree-decompositions of g.
﹛assume that we have a tree-decomposition of minimal width  w   the time complexity of tree-clustering is o exp w + 1   while its space complexity can be reduced to o n.s.ds  with s the size of the largest minimal separators of the graph  dechter and fattah  1 . note that tree-clustering does not provide interesting results in practical cases. so  an alternative approach  also based on treedecomposition of graphs was proposed in  je∩gou and terrioux  1 . this method is called btd  for backtracking with tree-decomposition  and seems to provide among the best empirical results obtained by structural methods.
﹛the btd method proceeds by an enumerative search guided by a static pre-established partial order induced by a tree-decomposition of the constraint-network. so  the first step of btd consists in computing a tree-decomposition. the obtained tree-decompositionallows to exploit some structural properties of the graph  during the search  in order to prune some branches of the search tree  what distinguishes btd from other classical techniques. firstly  the order for the assignment of the variables is induced by the considered treedecomposition of the constraint graph. secondly  some parts of the search space will not be visited again as soon as their consistency is known. this is possible by using the notion of structural good. a good is a consistent partial assignment on a set of variables  namely a separator  i.e. an intersection between two clusters   such that the part of the csp located after the separator is consistent and admits a solution compatible with the good. so  it is not necessary to explore this part because we know its consistency. thirdly  some parts of the search space will not be visited again if we know that the current instantiation leads to a failure. this is possible in applying the notion of structural nogood. a structural nogood is a particular kind of nogood justified by structural properties of the constraints network: the part of the csp located after the nogood is not consistent  a nogood is a consistent assignment of a separator of the graph .
﹛to satisfy the complexity bounds  the variable ordering exploited in btd is related to the cluster ordering. formally  let us consider a tree-decomposition e t  of the csp with t =  i f  a tree and assume that the elements of e = {ei : i ﹋ i} are indexed w.r.t. a compatible numeration. a numerationon e compatible with a prefix numeration of t =  i f  with e1 the root is called compatible numeration. an order x of variables of x such that  x ﹋ ei   y ﹋ ej  with is a compatible enumeration order. the numeration on the clusters gives a partial order on the variables since the variables in the ei are assigned before those in ej if i   j  except variables in the descent of a good  namely those located in the subproblem rooted on the cluster containing the good. in fact  using goods and nogoods allows not to explore twice subproblems if their consistency  inconsistency  with the current assignment is known. if we use a good to avoid visiting again a subtree  we known that the variables in it can be assigned consistently with the current assignment. so btd does not assign them effectively  but they are considered done. for consistent problems  an additional work must be performed to assign these variables if we want to provide a solution  je∩gou and terrioux  1 . they are named consistently assignable variables thanks to a good. thus the variables in ej are assigned if the variables in ei are either already assigned or consistently assignable thanks to a good. to complete this order  we have to choose variable ordering heuristics inside a cluster. finally  a compatible enumeration order on the variables is given by a compatible numeration on clusters and a variable order in each cluster.
﹛in  je∩gou and terrioux  1; 1   the presented results were obtained without heuristics for the choice of the clusters and thus the choice of the variables. only a traditional dynamic order was used inside the clusters. obviously  the variable ordering have a great impact on the efficiency of enumerative methods. thus  we study here how the benefits of variable orderings can be fully exploited in btd. nevertheless  to guarantee the time complexity bounds  it is necessary to respect some conditions. so  in the next section  we define classes of orders guaranteeing complexity bounds.
1 dynamic orders in o exp w+1  
the first version of btd was defined with a compatible static variable ordering. we provehere that it is possible to consider more dynamic orders without loosing the complexity bounds. the defined classes contain orders more and more dynamic. these orders are in fact provided by the cluster order and the variable ordering inside each cluster.
let  x d c  be a csp and  e t  a tree-decomposition of the graph  x c   we exploit an order 考i on the subproblems pi1 ... pik rooted on the sons eij of ei and an order 污i on the variables in ei. we define recursively the following classes of orders. in the three next classes  we choose the first cluster to assign  the root : e1 among all the clusters and we consider p1 the subproblem rooted on e1  i.e. the whole problem .
definition 1 we begin the search in e1 and we try recursively to extend the current assignment on the subproblem rooted on ei by assigning first the variables in ei according to 污i and then on pi1 ... pik according to 考i.
  class 1. 考i and 污i are static. we compute 考i and 污i statically  before starting the search .
  class 1. 考i is static and 污i is dynamic. we compute statically 考i  while 污i is computed during the search.
  class 1. 考i and 污i are dynamic. both  考i and 污i are computed during the search. 考i is computed w.r.t. the current assignment as soon as all the variables in ei are assigned.
  class ++. enumerative dynamic order. the variable ordering is completely dynamic. so  the assignment order is not necessarily a compatible enumeration order. there is no restriction due to the cluster tree.
the defined classes form a hierarchy since we have: class 1   class 1   class 1   class ++.
property of the class 1. let y be an assignment  x ﹋ ej  
 ei ﹎ ej  with ei the parent of ej: x ﹋ y iff: i  v ﹋ ei 
 
v	iu  v ﹋	iii  v ﹋	j s.t. 污j v 	污j x   v ﹋	.
﹛in  je∩gou and terrioux  1   the experiments use class 1 orders. formally  only the orders of the class 1 are compatible. nevertheless  for an order o1 in the class 1 and a given assignment a  one can find an order o1 in the class 1 that instantiates the variables in a in the same way and the same order o1 does. this property gives to the class 1  thus class 1  orders the ability of recording goods and nogoods and using them to prune branches in the same way class 1 orders do. the class ++ gives a complete freedom. yet  it does not guarantee the time complexity bound because sometimes it is impossible to record nogoods. indeed  let the cluster ej be a son of the cluster ei  we suppose that the enumeration order assigns the variables in ei except those in ei ﹎ ej  as well as the variables in the clusters which are on the path from the root cluster to ei. let x  the next variable to assign  be in ej and not in ei ﹎ ej. if the solving of the subtree rooted on ej leads to a failure  it is impossible to record a nogood on ei ﹎ ej  if it is consistently assigned  because we do not try the other values of x to prove that the assignment on ei ﹎ej cannot be consistently extended on this subtree. if the subproblem has a solution  we can record a good. actually  this solution is a consistent extension of the assignmenton ei﹎ej which is a good. a nogood not recorded could be computed again. thus the time complexity boundis not guaranteed anymore. meanwhile  the class 1 orders guarantee this bound.
theorem 1 let the enumeration order be in the class 1  the time complexity of btd is o exp w + 1  .
proof we consider a cluster ej in the cluster tree  and we must prove that any assignment on ej is computed only once. let ei be the cluster parent of ej and suppose that all the variables in ei are assigned and those in ej    ei ﹎ ej  are not. since the order belongs to the class 1  the variables of the clusters on the path from the root to ei are already assigned and those in the subtree rooted on ej not yet. a consistent assignment a on ei ﹎ej is computed at the latest when the variables in ei are assigned  before those in the subproblem rooted in ej . solving this subproblem leads to a failure or a solution. in each case  a is recorded as a good or nogood. let a be an assignment on ej compatible with a. the next assignment of variables in ei leading to a on ei ﹎ej will not be pursued on the subproblem rooted on ej. a is not computed twice  only the variables in ei ﹎ ej are assigned again. so the time complexity is o exp w +1  .  the properties of the class 1 offer more possibilities in the variable ordering. so it is possible to choose any cluster to visit next among the sons of the current cluster. and in each cluster  the variable ordering is totally free. in section 1  we propose two natural extensions of the complexity bound.
1 bounded extensions of dynamic orders
we propose two extensions based on the ability given to the heuristics to choose the next variable to assign not only in one cluster  but also among k variables in a path rooted on the cluster that verifies some properties. so  we define two new classes of orders extending class 1. first  we propose a generalization of the tree-decomposition definition.
definition 1 let g =  x c  be a graph and k a positive integer  the set of directed k-covering tree-decompositions of a tree-decomposition  e t  of g with e1 its root cluster  is defined by the set of tree-decompositions  that verify:
 the root cluster of 
 and ei1 ﹍ei1 ﹍
 a path in t
   where w = maxei﹋e|ei|   1 now  we give a definition of the class 1.
definition 1 let  x d c  be a csp   e t  a treedecomposition of the graph  x c  and k a positive integer. a variable order is in the class 1  if this order is in the class 1 for one directed k-covering tree-decomposition of  e t .
we derive a natural theorem:
theorem 1 let the enumeration order be in the class 1  the time complexity of btd is o exp w + k + 1  .
proof this proof is similar to one given for class 1 since we
can consider that btd runs on a tree-decomposition of width at most w + k + 1. 
﹛a second extension is possible in exploiting during the search  a dynamic computing of the tree-decomposition  we can use several directed k-covering tree-decompositions during the search . then  the time complexity bound changes because sometimes it would be impossible to record nogoods.
definition 1 let  x d c  be a csp   e t  a treedecomposition of the graph  x c  and k a positive integer. a variable order o1 is in the class 1  if for a given assignment a  one can find one directed k-covering tree-decomposition

... ﹍ eir  with ei1 ...eir a path in t and find an order o1
  in the class 1 that instantiates the variables in a in the same way and the same order o1 does.
this definition enforces to use directed k-covering treedecompositions  that verify the additional condition:. hence  a separator in  is also a separator in  e t . we denote by s  the minimum size of separators in  e t .
theorem 1 let the enumeration order be in the class 1  the time complexity of btd is o exp 1 w + k + 1    s   .
proof let  x d c  be a csp   e t  a tree-decomposition of the graph  x c  and e1 its root cluster. we have to prove that any assignment on a set v of 1 w+k+1  s  variables on a path of the tree t is computed only once. let a be an assignment containing v . the order in which the variables of a were assigned is in the class 1 for a directed k-covering tree-decomposition that verifies 
  with ei1 ...eir a path in t. the size of the clusters in  is bound by w+k+1  so the set v is covered by at least two clusters since s  is the minimum size of the separators. let be a path on 
covering v . the solving of the subproblem rooted on with the assignment a leads to the recording of  no goods on the separators of these clusters. if is the root cluster of
  then v contains e1. thus a will not be computed again because it contains the first variables in the search. we suppose that is not the root cluster of . since q ≡ 1  we record a  no good on the separator of and its parent and at least an other on the separator of. let b be a new assignment that we try to extend on v with the same values in a. one of the  no goods will be computed first. thus before all the variables in v are assigned  the search is stopped thanks to this  no good. so a is not computed again. we prove that any assignment on v is computed only once.
﹛note that the new defined classes are included in the hierarchy presented in section 1: class i   class j  if i   j and for 1 ≒ i   j ≒ 1  with also class 1   class ++.
﹛to define the value of k  we have several approaches to choose variables to group. a good one consists in trying to reduce the value of the parameter s and  by this way  to enhance the space complexity bound. then  we can observethat grouping clusters with large separators permits to achieve a significant reduction of s.
1 experimental study
applying a structural method on an instance generally assumes that this instance presents some particular topological features. so  our study is first performed on instances having a structure which can be exploited by structural methods.
in practice  we assess here the proposed strategies on random partial structured csps in order to point up the best ones w.r.t. csp solving. for building a random partial structured instance of a class  n d w t s nc p   the first step consists in producing randomly a structured csp according to the model described in  je∩gou and terrioux  1 . this structured instance consists of n variables having d values in their domain. its constraint graph is a clique tree with nc cliques whose size is at most w and whose separator size does not exceed s. each constraint forbids t tuples. then  the second step removes randomly p% edges from the structured instance. secondly  we experiment the proposed heuristics on benchmark instances of the cp'1 solver competition1. all these experimentations are performed on a linux-based pc with a pentium iv 1ghz and 1gb of memory. for each considered random partial structured instance class  the presented results are the average on instances solved over 1. we limit the runtime to 1 minutes for randominstances and to 1 minutes for cp'1 benchmark instances. above  the solver is stopped and the involved instance is considered as unsolved  what is denoted by the letter t in tables . in the following tables  the letter m means that at least one instance cannot be solved because it requires more than 1gb of memory.
﹛in  je∩gou et al.  1   a study was performed on triangulation algorithms to find out the best way to compute a good tree-decomposition w.r.t. csp solving. as mcs  tarjan and yannakakis  1  obtains the best results and is very easy to implement  we use it to compute tree-decompositions in this study. we do not provide the results obtained by classical enumerative algorithms like fc or mac since they are often unable to solve several instances of each class within 1 minutes.
﹛here  for lack of place  we only present the more efficient heuristics:
  minexp a : this heuristic is based on the expected number of partial solutions of clusters  smith  1  and on their size. it chooses as root cluster onewhich minimizes the ratio between the expected number of solutions and the size of the cluster.
  size b : we choose the cluster of maximum size as root cluster
  minexps c : this heuristic is similar to minexp and orders the son clusters according to the increasing value of their ratio.
  minseps d : we order the son clusters according to the increasing size of their separator with their parent.
  nv e : we choose a dynamic variable ordering heuristic and we visit first the son cluster where appears the next variable in the heuristic order among the variables of the unvisited son clusters.
  minexpsdyn f : the next cluster to visit minimizes the ratio between the current expected number of solutions and the size of the cluster. the current expected number of solutions of a cluster is modified by filtering the domains of unassigned variables.
cspw+sclass 1class 1class 1class 1babaabbaab n d w t s nc p dcdcfgdcfg 1 1 1 1 111111111111 1 1 1 1 111111111111 1 1 1 1 111111111111 1 1 1 1 111111111111 1 1 1 1 111111111111 1 1 1 1 111111111111 1 1 1 1 111111111111 1 1 1 1 111111111111 1 1 1 1 111111111111 1 1 1 1 111111111111 1 1 1 1 111111111111 1 1 1 1 111111111111 1 1 1 1 11mmmmmm1111 1 1 1 1 111111111111 1 1 1 1 111111111111table 1: parameters w+ and s of the tree-decomposition and runtime  in s  on random partial structured csps with mdd for class 1 and mdddyn for classes 1  1 and 1.
csp
instancenew+sclass 1class 1class 1babaaebddccfggqa 111.1.1.1.1.1.1.1qcp-1-1-qwh-111tm1tt11qcp-1-1-qwh-111tt11111qwh-1-1-qwh-111tm11111qwh-1-1-qwh-111t111111table 1: parameters w+ and s of the tree-decomposition and runtime  in s  on some instances from the cp'1 solver competition with mdd for class 1 and mdddyn for classes 1 and 1.  nvsdyn g : it is similar to nv. we visit first the son cluster where appears the next variable in the heuristic order among the variables of the unvisited son clusters.
inside a cluster  the heuristic used for choosing the next variable is min domain/degree  static version mdds for class 1 and dynamic mdddyn for the other classes .
﹛table 1 shows the runtime of btd with several heuristics of classes 1  1  1 and 1. for class 1  we cannot get good results and then  the results are not presented. also it presents the width of the computed tree-decomposition and the maximum size of the separators. clearly  we observe that class 1 orders obtain poor results. this behaviour is not surprising since static variable orders are well known to be inefficient compared to dynamic ones. a dynamic strategy allows to make good choices by taking in account the modifications of the problem during search. thus these choices are more justified than in a static case. that explains the good results of classes 1 and 1 orders. the results show as well the crucial importance of the root cluster choice since each heuristic of the classes 1 and 1 fails to solve an average of 1 instances over all instances of all classes because of a bad choice of root cluster. we note that the unsolved instances are not the same for size and minexp heuristics. the memory problems marked by m can be solved by using a class 1 order with the sep heuristic for grouping variables  we merge cluster whose intersection is greater than a value smax . table 1 gives the runtime of btd for this class with smax = 1.
﹛when we analyze the value of the parameter k  we observe that its value is generally limited  between 1 to 1 . nevertheless  for the csps  1 1 1 1   the value of k is near 1  but this high value allows to solve these instances.
﹛the heuristics for the classes 1 and 1 improve very significantly the results obtained. the impact of the dynamicity is obvious. minexp and nv heuristics solve all the instances except one due to a bad root cluster choice  size solve all the instances. except the unsolved instance  minexp obtains very promising results. the son cluster ordering has a limited effect because the instances considered have a few son clusters reducing the possible choices and so their impact. we can expect a more important improvement for instances with more son clusters. the best results are obtained by minexp + minexpsdyn  but size + minseps obtains often similar results and succeed in solving all instances in the class 1. the calculus of the expected number of solution assumes that the problem constraints are independent  what is the case for the problems considered here. thus  size + minsep may outperform minexp + minexpsdyn on real-world problems which have dependent constraints.
﹛when we observe the results in table 1  we see the relevance of extending the dynamic order. merging clusters with k less than 1 decreases the maximal size of separators and allows a more dynamic ordering of variables. that leads to an important reduction of the runtime. these experiments highlight the importance of dynamic orders and make us conclude that the class 1 gives the best variable orders w.r.t csp solving with a good value of k. of course  this behaviour has been observed on random instances. the next step of our study consists in assessing the proposed heuristics on benchmark instances of the cp'1 solver competition. at the beginning of the section  we reminded that structural methods like btd assume the csp has interesting topological features. this is not the case for a great part of instances of this competition. since the space complexity of btd is in o n.s.ds   if the size of the cluster separators of the computed tree-decomposition of csp is too large  the method needs more than 1gb of memory. many instances have treedecompositions with very large separators and clusters. reducing the required space memory leads to group all the variables in one cluster and so to perform like the fc algorithm. in table 1  which provides results on these instances  we do not present the results for instances with very bad topological features for which btd has a behavior close to fc one.
﹛on these instances  the size heuristic outperforms minexp except on qcp instance. to resume  we can say that the dynamicity improves significantly the method and the expected number of solutions provides an important improvement on random csps  while the size + minsep heuristic outperforms the others on real-world instances.
1 discussion and conclusion
in this article  we have studied the csp solving methods based on tree-decompositions in order to improve their practical interest. this study was done both theoretically and empirically. the analysis of the variable orders allows us to define more dynamic heuristics without loosing the time complexity bound. so  we have defined classes of variable orders which allow a more and more dynamic ordering of variables and preserve the theoretical time complexity bound. this bound has been extended to enforce the dynamic aspect of orders that has an important impact on the efficiency of enumerative methods. even though these new bounds are theoretically less interesting that the initial  it allows us to define more efficient heuristics which improve significantly the runtime of btd. this study  which could not be achieved previously  takes now on importance for solving hard instances with suitable structural properties. for example  the structured instances used here are seldom solved by enumerative methods like fc or mac.
﹛we have compared the classes of variable orders with relevant heuristics w.r.t. csp solving. this comparison points up the importance of a dynamic variable ordering. indeed the best results are obtained by class 1 orders because they give more freedom to the variable ordering heuristic while their time complexity is o exp w+k+1   where k is a constant to parameterize. note that for the most dynamic class  the class 1   we get a time complexity in o exp 1 w +k +1  s   . it seems that this bound should be too large to expect a significant practical improvement.
﹛concerning heuristics  we exploit the notion of expected number of partial solutions in order to guide the traversal of the cluster tree during the solving. even though the other heuristics presented  size + minsep  are less efficient  often they obtain similar results. they are also more general what induces a stabler behaviour. so  on real-world problems with dependentconstraints  they may outperformthe expected number of solutions based heuristics. then  for class 1  we aim to improve the criteria used to compute the value of k and to define more general ones by exploiting better the problem features.
﹛this study will be pursued on the valued csps  schiex et al.  1  which are well known to be more difficult.
acknowledgments
this work is supported by a  programme blanc  anr grant  stal-dec-opt project .

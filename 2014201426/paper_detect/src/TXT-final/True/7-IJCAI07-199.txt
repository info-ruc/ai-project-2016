
we introduce a weakening of standard gametheoretic dominance conditions  called 붻dominance  which enables more aggressive pruning of candidate strategies at the cost of solution accuracy. equilibria of a game obtained by eliminating a 붻-dominated strategy are guaranteed to be approximate equilibria of the original game  with degree of approximation bounded by the dominance parameter  붻. we can apply elimination of 붻-dominated strategies iteratively  but the 붻 for which a strategy may be eliminated depends on prior eliminations. we discuss implications of this order independence  and propose greedy heuristics for determining a sequence of eliminations to reduce the game as far as possible while keeping down costs. a case study analysis of an empirical 1-player game serves to illustrate the technique  and demonstrate the utility of weaker-than-weak dominance pruning.
1	introduction
analysis of games can often be simplified by pruning agents' strategy sets. for instance  a strategy is strictly dominated iff there exists a mixture  randomization  over the remaining strategies that achieves strictly higher payoff regardless of the strategies played by other agents. elimination of strictly dominated strategies is a venerated idea  established at the dawn of game theory as a sound way to remove unworthy strategies from consideration  gale et al.  1  luce and raiffa  1 . in particular  the dominated strategy cannot be part of any nash equilibrium  ne . moreover  the elimination conserves solutions in that any ne of the pruned game is also an ne of the original.
모weak dominance relaxes strict dominance by allowing that the dominating strategy achieves payoffs only equally as great. although weakly dominated strategies may appear in ne of the full game  it remains the case that ne of the pruned game are ne of the original as well. additional refinements and variants of dominance are possible  for example based on rationalizability  or minimal sets of strategies closed under rational behavior  benisch et al.  1 .
모elimination of a dominated strategy for one player may enable new dominance relations for others  as it removes cases for which the defining inequality must hold. therefore  we generally invoke dominance pruning iteratively  until no further reduction is possible. this requires some care in the case of weak dominance  since the set of surviving strategies is order dependent  that is  may differ based on the order of eliminations  gilboa et al.  1  myerson  1 . whether a strategy is eliminable through some sequence of removals of weakly dominated strategies is a computationally hard problem  in general  conitzer and sandholm  1 . in contrast  iterated strict dominance is order independent.
모in this paper we investigate a further weakening of weak dominance  which enables more aggressive pruning by allowing that the  dominated  strategy actually be superior to the  dominating  by up to a fixed value 붻 in some contexts. such 붻-dominated strategies may participate in ne of the original game  and ne of the pruned game are not necessarily ne of the original. however  any ne after pruning does correspond to an approximate ne of the original game.
모iterated application of 붻-dominance is likewise order dependent. the order of removals dictates not only eliminability  but also the degree of approximation that can be guaranteed for solutions to the reduced game. we explore alternative elimination policies  focusing on greedy elimination based on local assessment of 붻.
모we illustrate the techniques by applying them to a twoplayer 1-strategy symmetric game derived from simulation data. our case study demonstrates the potential utility of the weaker dominance condition  as it reduces the game substantially with little loss in solution accuracy.
1	preliminaries
a finite normal form game is formally expressed as  i {si} {ui s }   where i refers to the set of players and m = |i| is the number of players. si is a finite set of pure strategies available to player i 뫍 i. let s = s1 뫄 몫몫몫 뫄 sm be the space of joint strategies. finally  ui : s 뫸 r gives the payoffto player i when players jointly play s =  s1 ... sm   with each sj 뫍 sj.
모it is often convenient to refer to a strategy of player i separately from that of the remaining players. to accomodate this  we use s i to denote the joint strategy of all players other than i.
모let  r  be the set of all probability distributions  mixtures  over a given set r. a mixture 횰 뫍  si  is called a mixed strategy for player i. the payoff ui   of a mixed strategy profile   뫍  s   is given by the expectation of ui s  with respect to .
모a configuration where all agents play strategies that are best responses to the others constitutes a nash equilibrium.
definition 1 a strategy profile  constitutes a nash equilib-
  ne  of game iff for every i 뫍 i  i 뫍   i   i  i  i  i  i  i .
we also define an approximate version.
definition 1 a strategy profile  constitutes an -nash equi-ne  of game iff for every i 뫍 i 
	i  i	 i .
모in this study we devote particular attention to games that exhibit symmetry with respect to payoffs.
definition 1 a game  i {si} {ui s }  is symmetric iff
 i j 뫍 i   a  si = sj and  b  ui si s i  = uj sj s j  whenever si = sj and s i = s j
that is  the agents in symmetric games are strategically identical  since all elements of their strategic behavior are the same.
1 붻-dominance
we start by defining our weaker-than-weak dominance condition.
definition 1 strategy sdi 뫍 si is 붻-dominated iff there exists 횰d 뫍  si   {sdi}  such that:
	붻 + ui 횰d s i    ui sdi s i   s i 뫍 s i.	 1 
in other words  sdi is 붻-dominated if we can find a mixed strategy  on the set of pure strategies excluding sdi   that  when compensated by 붻  outperforms sdi against all pure opponent profiles. notice that unlike the standard conditions  in considering whether strategy sdi is dominated  we must exclude it from the domain of potential dominators. otherwise  sdi would be 붻-dominated by itself.
모suppose sdi is 붻-dominated in game 붞. as noted above  if 붻   1  sdi may well appear with positive probability in ne profiles. we may nevertheless choose to eliminate sdi  obtaining a new game   which is identical to 붞 except that   and the payoff functions apply only on the reduced joint-strategy space. although 붞 does not necessarily conserve solutions  we can in fact relate its solutions to approximate solutions of 붞.1
proposition 1 let 붞 be the original game and let sdi be 붻dominated in 붞. if  is an -ne in 붞 sdi  then it is a -ne in 붞.
note that with  the proposition states that exact ne of 붞   sdi are 붻-ne of 붞  where 붻 is the compensation needed to support dominance.
모we may also eliminate 붻-dominated strategies in an iterative manner.
proposition 1 let 붞1 ... 붞n be a series of games  with 붞1 the original game  and 붞j+1 = 붞j   tj. further  suppose the eliminated strategy tj is 붻j-dominated in 붞j. then  if  is an
-ne in 붞n  it is also a -ne in 붞1.
the result follows straightforwardly by induction on proposition 1.
1	identifying 붻-dominated strategies
definition 1 characterizes the condition for 붻-dominance of a single strategy. it is often expedient to eliminate many strategies at once  hence we extend the definition to cover 붻-dominance of a subset of strategies.
definition 1 the set of strategies t   si is 붻-dominated iff there exists  for each t 뫍 t  a mixed strategy 횰t 뫍  si   t  such that:
	붻 + ui 횰t s i    ui t s i   s i 뫍 s i.	 1 
propositions 1 and 1 can be straightforwardly generalized to eliminations of subsets of strategies for a particular player.
모it is well known that standard dominance criteria can be evaluated through linear programming  myerson  1 . the same is true for 붻-dominance  and moreover we can employ such programs to identify the minimal 붻 for which the dominance relation holds. the problem below characterizes the minimum 붻 such that the set of strategies t is 붻-dominated. the problemfor dominatinga single strategy is a special case. min 붻	 1 
s.t.   t 뫍 t

모problem  1  is not quite linear  due to the strict inequality in the first constraint. we can approximate it with a linear constraint by introducing a small predefined constant  뷉. the result is the linear program lp-a s t . min 붻
s.t.   t 뫍 t

1	controlling iterated 붻-dominance
by proposition 1  every time we eliminate a 붻-dominated strategy  we add 붻 to the potential error in solutions to the pruned game. in deciding what to eliminate  we are generally interested in obtaining the greatest reduction in size for the least cost in accuracy. we can pose the problem  for example  as minimizing the total error to achieve a given reduction  or maximizing the reduction subject to a given error tolerance.
모in either case  we can view iterated elimination as operating in a state space  where nodes correspondto sets of remaining strategies  and transitions to elimination of one or more strategies. the cost of a transition from node s =  si s i  to  si  t s i  is the 붻 minimizing lp-a s t . we can formulate the overall problem as search from the original strategy space. however  the exponential number of nodes and exponential number of transitions from any given node render any straightforward exhaustive approach infeasible.
모as indicated above  the problem is complicated by the order dependence of strategy eliminations. eliminating a strategy from player i generally expands the set of 붻-dominated strategies for the others  though it may shrink its own 붻dominated set. we can formalize this as follows. let 붻 t 붞  denote the minimum 붻 such that strategy t is 붻-dominated in
붞.1
proposition 1 let.
1.  for all  and
1.  for all.
because eliminating a strategy may decrease the cost of some futureeliminations and increase others  understandingthe implications of a pruning operation apparently requires some lookahead.
모our choice at each point is what set of strategies to eliminate  which includes the question of how many to eliminate at one time. for example  suppose 붻 t1i 붞  = 붻1  and 붻 t1i 붞   t1i  = 붻1. in general  it can be shown that 붻1 뫞 붻 {t1i t1i} 붞  뫞 붻1 + 붻1. in many instances  the cost of eliminating both strategies will be far less than the upper bound  which is the value that would be obtained by sequentially eliminating the singletons. however  since the number of candidate elimination sets of size k is exponential in k  we will typically not be able to evaluate the cost of all such candidates. instead  we investigate heuristic approaches that consider only sets up to a fixed size for elimination in any single iteration step.
1	greedy elimination algorithms
we propose iterative elimination algorithms that employ greedy heuristics for selecting strategies to prune for a given player i. extending these to consider player choice as well is straightforward. the algorithms take as input a starting set of strategies  and an error budget  붟  placing an upper bound on the cumulative error we will tolerate as a result of 붻-dominance pruning.
모algorithm 1  greedy s 붟   computes 붻 ti 붞  for each ti 뫍 si  and eliminates the strategy that is 붻-dominated at minimal 붻. the algorithm repeats this process one strategy at a time  until such a removal would exceed the cumulative error budget.
algorithm 1 simple greedy heuristic. at each iteration  the strategy with least 붻 is pruned.

greedy s 붟 
1: n 뫹 1  sn 뫹 s 1: while 붟   1 do
1: 1:for s 뫍 sin do 붻 s  뫹 lp-a sn {s} 1:end for1:t 뫹 argmins뫍sin 붻 s 1:d 뫹 붻 t 1:if 붟 뫟 d then1:붟 뫹 붟   d1:sin+1 뫹 sin   {t}  sn+1 뫹  sin+1 s i 1:n 뫹 n + 1:else1:붟 뫹 1:end if1: end while
1: return sn

모algorithm 1  greedy-k s 붟 k   is a simple extension that prunes k strategies in one iteration. we identify the k strategies with least 붻 when considered individually  and group them into a set k. we then employ lp-a s k  to determine the cost incurred for pruning them at once. since the set k is selected greedily  it will not necessarily be the largest possible set that can be pruned at this cost  nor the minimumcost set of size k. nevertheless  we adopt greedy selection to avoid theoptimizations it would take to consider all the candidates.
1	computing tighter error bounds
we can reduce several players' strategy spaces by running algorithm 1 sequentially. let 붞 be the original game  and let 붞 be the reduced game. let {si} and be the set of all players' strategy spaces for 붞 and 붞 respectively. for each player i  let 붟i be the accumulated error actually used in greedy-k. the total error generated by these reductions  according to proposition 1  is bounded by. by taking into account the actual resulting game 붞  however  we can directly compute an error bound that is potentially tighter.
모let n be the set of all ne in 붞. the overall error bound is the maximum over n of the maximal gain available to any player to unilaterally deviating to the original strategy space.
	 	 1 
where. to compute  with  1   we must first find all ne for 붞. however  computing all ne will generally not be feasible. therefore  we seek a bound that avoids explicit reference to the set n.
모since  is an ne in 붞  we have that ui 횰  i  뫟 ui xi  i   for all. with each i 뫍 i  t 뫍 ti  we associate a mixed strategy xti. replacing 횰 by xti in  1  can only increase the error bound. the resulting expression no longer involves i's equilibrium strategy. we can further relax the bound by replacing maximization wrt equilibrium mixalgorithm 1 generalized greedy heuristic  with k strategies pruned in each iteration.

greedy-k s 붟 k 
1: n 뫹 1  sn 뫹 s
1: while 붟   1 do 1:	for s 뫍 sin do
1:	붻 s  뫹 lp-a sn {s} 
1:	end for
1:	k 뫹 {}
1:	for j = 1 to k do
1:	tj 뫹 1:	k	k tj
1:	end for
1:	붻k 뫹 lp-a
1:	if 붟 뫟 붻k then
1:	붟 뫹 붟   붻k
1:	sin+1 뫹 sin   k  sn+1 뫹  sin+1 s i 
1:	else
1:	if 붟 뫟 t1 then
1:	붟 뫹 붟   붻 t1 
1:	sin+1 뫹 sin   {t1}  sn+1 뫹  sin+1 s i 
1:	else
1:	붟 뫹 1
1:	end if
1:	end if
1:	n 뫹 n + 1
1: end while 1: return sn

tures  i with maximization wrt any pure opponent strategies  s i  yielding

according to  1   we can bound  which does not refer to the set n. we can find 몬 by solving the following optimization problem:
		 1 
s.t.
.
note that this formulation is very similar to lp-a s t   defined in section 1. the major difference is that lp-a s t  is defined for a particular player i  whereas  1  considers all players at once. we employ this bound in experimental evaluation of our greedy heuristics  in section 1.
1 붻-dominance for symmetric games
thus far  we have emphasized the operation of pruning one or more strategies from a particular player's strategy space. the method of the previous section can improve the bound by considering all players at once. for the special case of symmetric games  definition 1   we can directly strengthen the pruning operation. specifically  when we prune a 붻dominated strategy for one player  we can at no additional cost  prune this strategy from the strategy sets of all players.
proposition 1 let 붞 be a symmetric game  and suppose strategy s is 붻s-dominatedin 붞. let 붞 be the symmetric game obtained by removing s from all players in 붞. if  is an -ne in 붞  then it is a -ne in 붞.
모based on proposition 1  we can specialize our greedy elimination algorithms for the case of symmetric games. for algorithm 1  we modify line 1  so that {t} is pruned from all players' strategy spaces within the same iteration. for algorithm 1  we modify lines 1 and 1 analogously.
모when a game is symmetric  symmetric equilibria are guaranteed to exist  nash  1 . as kreps  argues  such equilibria are especially plausible. in our analysis of symmetric games  therefore  we focus on the symmetric ne.
1	iterative 붻-dominance elimination: a case study
to illustrate the use of 붻-dominance pruning  we apply the method to a particular game of interest. on this example  we evaluate the greedy heuristics in terms of the tradeoff between reduction and accuracy. we also compare the theoretical bounds to actual approximation errors observed in the reduced games.
1	the tac뫻1 game
the subject of our experiment is a 1-player symmetric game  based on the trading agent competition  tac  travelshopping game  wellman et al.  1 . tac travel is actually an 1-player symmetric game  where agents interact through markets to buy and sell travel goods serving their clients. tac뫻1 is derivative from tac travel in several respects:
  tac travel is a dynamic game with severely incomplete and imperfect information  and highly-dimensional infinite strategy sets. tac뫻1 restricts agents to a discrete set of strategies  all parametrized versions of the university of michigan agent  walverine  wellman et al.  1b . the restricted game is thus representable in normal form.
  payoffs for tac뫻1 are determined empirically through monte carlo simulation.
  the game is reduced to two players by constraining groups of four agents each to play the same strategy. this can be viewed as assigning a leader for each group to select a strategy for all to play. the game among leaders is in this case a 1-player game. the transformation from tac 뫻1 to tac 뫻1 is an example of the hierarchical reduction technique proposed by wellman
et al.  1a  for approximating games with many players. note that this form of reduction is orthogonal to the reduction achieved by eliminating strategies through dominance analysis.
모although tac뫻1 is a highly simplified version of the actual tac game  wellman et al.  1b  argue that analyzing such approximations can be useful  in particular for focusing on a limited set of candidate strategies to play in the actual game. toward that end  dominance pruning can play a complementary role to other methods of analysis.
모the actual instance of tac뫻1 we investigate comprises 1 strategies  1 distinct strategy profiles  for which sufficient samples  at least 1 per profile  were collected to estimate payoffs.
1
	1	1 accumulated1 붻1	1	1
figure 1: number of strategies versus accumulated 붻  for
모as the graph apparently indicates  greedy-1 reaches any particular reduction level at a cost less than or equal to greedy-1. with the error tolerance 붟 = 1  greedy-1 prunes the game down to ten strategies  whereas greedy-1 takes us all the way down to two. however  we must decouple two factors behind the difference in measured results. first  the algorithms may prune strategies in a different order. second  the algorithm greedy-k computes the bound for each iteration taking into account all k strategies pruned at once.
모in this instance  in fact the sequence of eliminations is quite similar. the first four strategies eliminated by greedy-1 and greedy-1 are the same  and the next four are the same except for a one-pair order swap. thus  we can attribute the difference in apparent cumulative error after eight removals  1 versus 1  entirely to the distinction in how they tally error bounds. in general  the elimination orders can differ almost arbitrarily  though we might expect them typically to be similar. in another instance of tac뫻1  based on an earlier snapshot of the database with 1 strategies   we also observed that the first eight 붻-eliminations differed only in a one-pair swap. we have not to date undertaken an empirical study of the comparison.
모a more accurate assessment of the cost of iterated elimination can be obtained by computing the tighter bounds described in section 1  or directly assessing the error. figure 1 presents the data from figure 1  axes inverted   along with the more precise error measurements.

모모in some instances  gambit was unable to solve our reduced games in reasonable time due to numerical difficulties. in these cases  we tried small random  symmetry-preserving  perturbations of the game until we were able to solve one for all ne. the errors reported are with respect to the solutions we found  which thus tend to overstate the error due to elimination because they include an additional source of noise.
conservative. in all cases  after a few eliminations the tighter bounds are far more accurate. the actual errors are in many cases quite small  often zero . that is  in at least this  real  example game  we can aggressively prune weaker-than-weakly dominated strategies and then still have games where all solutions are near equilibria of the original game.1
1	loss of equilibria
the preceding analysis considers the accuracy of solutions to the reduced game with respect to the original. we may also be concerned about losing solutions to the original that may include 붻-dominated strategies. to examine this issue  we track the 1 symmetric ne found for the instance of tac뫻1 analyzed above  which has 1 strategies after eliminating those strictly dominated.1 figure 1 shows how many of these original ne survive after successive rounds of eliminating a 붻dominated strategy  using the greedy-1 algorithm. as seen in the figure  all solutions survive the first three eliminations  and two still remain after the eight iterations of greedy-1.

figure 1: original ne surviving after successive iterations of 붻-dominated strategy elimination.
모for situations where the purpose of analysis is to characterize all or most  approximate  equilibria  eliminating 붻dominated strategies sacrifices potentially desired coverage. if the objective  in contrast  is to identify samples  i.e.  particular examples  of relatively stable profiles  this loss of equilibria is not a paramount concern.
1	conclusion
eliminating strategies that are only nearly dominated enables significantly more aggressive pruning than standard dominance  while introducing a controllable amount of solution error. our 붻-dominance concept represents such a relaxation  and we exhibit bounds on the degree of approximation for solutions of the reduced game with respect to the original  for individual or iterated eliminations of single strategies or strategy sets. results are generally order dependent  however greedy selection techniques may work well in practice. the bounds for iterated elimination are quite conservative  and can be tightened by retrospective analysis of the actual set of strategies eliminated.
모a case study applying iterated elimination of 붻-dominated strategies to an empirical game illustrates the approach. the exercise demonstrates the possibility of identifying a much smaller subgame with solutions that are excellent approximations wrt the original. further work should evaluate the methods more broadly over a range of games.
acknowledgments
we thank kevin lochner and daniel reeves for assistance with the tac뫻1 analysis. this work was supported in part by grant iis-1 from the national science foundation.

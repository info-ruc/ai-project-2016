 
     this paper examines a programmed model  called decider-1  that 1  recognizes scenes of things  among which are a  objects and b  words that form commands  or questions or other types of statements   1  recognizes the import of these commands  1  decides whether to obey one  and then 1  uses the command to guide the consequent actions  along with any necessary perceptual search. 
     it uses the same mechanisms to handle a  the perceptual processes involved with recognizing objects and describing scenes  b  the linguistic processes involved with parsing sentences and understanding their meaning  and c  the retrieval processes needed to access pertinent facts in pertinent memory. this is in sharp contrast to most of today's systems  which receive the command through one channel  to be  understood  by one special-purpose set of routines  and perceive their environments through an entirely different channel. 
     decider-1 continues to characterize patterns  parse symbol strings  and access facts implied by input questions until an action is chosen  because it is sufficiently implied by this search through the memory net . then it executes the implied action. possible actions include answering  describing  finding  moving  and naming. 
introduction 
     the basic purpose of this paper is to examine how word-things recognized in the external environment can help trigger actions that include recognition and manipulation of other  object-things  in the same environment. to do this we must examine several issues that have scarcely been touched upon in the research literature of psychology or computer science: 
     how does a system recognize that a perceived input is a symbol  how does it understand the import of a structure of symbols  e . g . that it is a command  or a question  how does it understand the meaning of that structure   how does it decide what type of thing to do - whether to obey a command  and which command  or whether to continue to perceive  to respond to internal needs  or external presses from perceived objects   how do the understanding of commands and other symbolic percepts and the recognition of perceived objects interact  helping one another; e . g . how does it recognize which objects are appropriate for carrying out a command  how does a system choose and execute the appropriate response  from 
variety of possible responses   
this research has been partially supported by grants from the national institute of mental health  mh1   the national science foundation  gj-1   nasa  ngr-1-1  and the university of wisconsin graduate school. 
     these are extremely complex and subtle matters  and the work presented here is only a first step. 	but there appear to be relatively simple yet powerful ways in which we can begin to handle them. 
description of the problem  background and motivation 
     we will examine systems that a  input streams of information from the environment  b  attempt to recognize things  including symbols  and larger structures of these things  c  decide whether to continue in this perceptual process or to respond  and d  generate the appropriate response. 
     let's look at recent research with chimpanzees and with robots for some examples. 
chimps that obey commands 
     two chimps have been taught  by gardner and gardner  1  and by premack  i1  1j  to learn vocabularies of over 1 words  and to learn to use these words in simple sentences. one of the most interesting things sarah  premack's chimp  learned was to respond to a sentence like  sarah put banana box  by going to the banana   grasping it  carrying it over to the box  and dropping it into the box. sarah is in an experimental room with a number of objects  including a banana and a box  but also such things as a pail  an apple  a cracker  and other objects  and a board on which the experimenter places the words sarah  put  banana  and box.  these  words  are colored nonsense shapes: all previous attempts to get chimps to talk failed because of their limited vocal 
apparatus.  thus words  sentences and objects are perceived visually/ with words static objects much like chinese ideograms. 
     words are things that have symbolic significance. they come in through the same input channel as objects like the  image of the  banana. the chimp responds to the command  which is a structure of several wordthings  by manipulating the objects to which the words 
refer: sarah grasps the #banana  not the symbol 
banana.  i w i l l use stars  *   as in *banana  *box  *apple  to indicate the actual object  as opposed to the word. note that the star is not a built-in symbol for the computer program  but simply helps the reader distinguish between the word and the simplified representation of the object.  
today's pr1grams cannot model such chimps 
1      the above description may appear to belabor the obvious. but although any three year old human child  and now two chimps  can successfully sort out words and objects  recognize structures of words as commands  understand the import of the commands  and act appropriately  we have little idea how all this is done. psychologists have given us no theoretical models  and even the most sophisticated of computer programs for pattern recognition or language manipulation are designed to handle only small pieces of this process  
a sufficiently powerful pattern recognizer  e.g. 
uhrandvossier  i1i 1 ; andrewset. al  1; munson  1; zobrist  1  can correctly name many different examples of a pattern  all distorted in extremely complex  and unanticipated  non-linear ways. it can contend with very complex possible confusions between 
objects. in comparison  a *banana and an *apple are very different  and the symbols premack has chosen for banana and for apple are also different enough so that the chimp has no perceptual difficulties.  this is not at all to say that the chimp and human are not sophisticated pattern recognizers  but simply to point out that the particular single-pattern problem we are examining  in which only a few very different patterns need be recognized  is simple compared to problems that programs  as well as chimps and people  can handle.  but today's pattern recognizers will not handle scenes of several things  much less compose things into structures like sentences  or sort out the words and the objects  and their interrelationships. 
     a sufficiently powerful language processor  e.g. winograd  1; see simmons  1  can handle more complex grammatical structures than the simple actor-act-object-indirect object of our example sarah put banana box. but it will handle only clean  clear-cut sentences. it cannot content with sentences with misspelled words and noise that are embedded in larger scenes that include other objects. 
     at the very least  pattern recognizers must be extended to handle scenes of objects  and to parse word-phrases as well as characterize parts of objects 
 see sauvain and uhr  1; jordan  1;uhr  1 1 . 
robots that are pre-programmed to obey commands 
     recent work with robots  in which they deduce paths to cluster boxes  and stack blocks  e.g. nilsson  1 raphael  1; feldman et. a l .   1   has made some steps toward this interaction. but it has the flavor of interconnecting several separate black boxes  each performing a separate function  even though there often appears to be a great amount of overlap. thus the reported robots input and handle commands and perceptual environment completely separately. 
     today's robots use extremely complex systems of computer programs  almost always separated into four major sub-systems  to 1  understand the command  1  recognize and build up a model of the objects in the environment  1  deduce the set of actions appropriate to carrying out the command  and 1  apply them to the environment. each subsystem has its own subsystems: 
     1} the command is given through a teletype  and the system applies language  understanding  programs  to recognize words  parse the command statement  and derive from the statement a goal state that the robot must achieve  to obey the command. 
     1  separate perceptual programs are used to handle the robot's perceived spatial environment  which a l most always includes inputs from a tv camera  and occasionally is supplemented with inputs from range finders  touch sensors  photocells  or sonar. these programs input the sensed information  take a sequence of preprocessing steps  e.g. to eliminate noise  find gradients and edges  and begin to connect short edge fragments into lines   and try to build the salient features up into something that matches some internal description of some object  e.g. brice and fennema   1 . this results  if all goes well - which today means if objects are sufficiently simple  with enough background space between them  painted in colors that contrast sharply enough in the black-and-white tv image  and amply lighted  in the assignment of names to objects  and the assignment of these objects to their locations within the perceived environment. 
     1  a deductive problem-solving program  often a theorem prover  is used to generate a sequence of actions that the robot might apply to the objects it has tentatively recognized in its perceived space  in order to achieve the desired goal state  e.g. fikes and nilsson  1 . 
     1  this entails binding the objects  including the robot itself  to the proposed actions  so that the robot can in the real world try out an action that it has deduced would make progress toward satisfying the overall command. 
perceiving the import of inputs 
real-world commands must first be perceived 
     in the real world there is no separate input channel for a command  and there is no god-given a priori signal  known to commander and slave alike  that says   this is a command    this is a question    name this object    describe this scene   and so on. a question-answering program has built into its guts that inputs will be questions  and it is straightforwardly pre-programmed to answer them. a robot program similarly has built into it that teletype inputs are 
commands  and that it is to carry them out  by manipulating the environment that it perceives through its sensory inputs. 
     but in the real world the command always comes in through sensory input channels. in fact the command is itself a complex structure of perceived objects. 
e.g. the command   put the banana in the box   is made up of a string of words that are further structured grammatically and  more importantly  semantically  in that they refer to things like bananas  
relations between bananas and boxes  an understanding that bananas can go into certain boxes  and the implied action of the entity being commanded - that it. should put the banana in the box . 	and each word is made 
up of parts {letters if written  phonemes if spoken   each letter or phoneme is made up of parts  and so on. 
     the command may sometimes come through a separate perceptual mode channel  as when it is spoken and refers to visually perceived objects. but this is not the issue  for commands and objects often come in through the same channel  with the receiver hardly noticing. 	it is not the difference in channel that allows the human to infer  this is a command composed of symbols  and  that is an environment of objects . rather  the hearer first recognizes the parts of the command as objects and only later as symbols  combines them up into larger and larger structures  and 
recognizes that these structures have symbolic import  
and are commands. 
deciding whether to obey which command 
       closely related  the hearer has no built-in understanding that it w i l l receive one command at a time  pointed to and surrounded by special symbols. rather  since it must infer that parts of its perceived environment are commands  it always has the possibility of receiving more than one command. it must decide whether to obey a command  and which. and for any real-world receiver there will always be the issue of whether it should drop everything to carry out whatever command it has just received and understood  or whether it should do something else - what it was already doing  or what will best satisfy some internal need  e.g. hunger  that is arising  or what will best respond to some interesting new object  e.g. a steak . 
       thus a system should be able to decide which from among a set of alternative action-sequences it wants to carry out - whether to gather more information  or to obey this command or that  or to satisfy its own needs or goals. 
key problems being handled 
       this paper focuses on the problem of handling fields of things  some of which are symbols  where these things combine into larger structures  e.g. eyes  nose  mouth  chin combine into face; sarah put banana box combines into a command; b 1  x combine into box   some of which imply that the system should respond with an implied action upon other things to which reference is made. 
       we have discussed one example of such a situation  when the environment contains something like;  cracker sarah put apple pail *box *banana 
*apple *pail  or  *box1 robot push box1 next box1 
*box1 *box1 *box1 *box1 
       such a system can handle a number of other problems  for example an input like: 
 cracker  box describe *apple this scene *box  banana *pail  in which case it must recognize the command describe this scene and as a result output cracker box apple box banana pail . 
or it can be given an input like: 
  cracker  box find a box  apple *banana  pail 
 in which case it must recognize the command find 
box and as a result output something to indicate the  box has been found.  or it can be asked to move an object  or to answer a query. 
a brief description of decider's behavior1 
overall flow 
       decider-1 inputs a 	scene that contains all physical objects and verbal utterances mixed together  as the above argument has shown is inevitably the case for real world intelligences. 	it applies two types of pattern recognition techniques to begin sensing this scene: 
       1  a set of primitive perceptual transforms is put onto the ideas list  thus initializing ideas to look for whatever the primitives suggest are the basics. 
       1  delimiters  such as the edges  gradients and background spaces that often delineate objects and verbal utterances  are used to decompose the scene  giving a first tentative set of possible objects. then decider-1 searches its memory for anything that these objects might imply  and  if it finds any  merges them onto the ideas list. 
       decider-! applies the set of ideas  serially  to the input scene. 	each idea that succeeds implies a variety of different objects  new ideas to apply  and acts. 	the single most highly implied idea is applied in turn to further characterize the scene - until it is a response act like answer  describe  find  move  or 
name  in which case it is carried out  and the next scene is input.  note that the particular primitives  perceptual characterizers  verbal rewrite rules  and action transforms depend upon what the programmer  or learning  has tabled into decider-1  just as parsers or table-driven compilers depend upon the grammars given them.  
perceiving sensed objects and understanding verbal utterances 
       decider-1 acts much like a typical pattern recognizer vis-a-vis sensory patterns to recognize and name  and much like a typical parser vis-a-vis verbal utterances. so it can handle mixed inputs of objects and words. it handles both the recognition characterizers and the parsing rewrite rules  let's call them both  transforms   in the same way: it gets the most highly implied transform from the ideas list  applies it to the input scene  which includes all previously-effected transforms   evaluates whether this transform succeeds and  if it does  merges the transforms that it implies onto the ideas list  and the objects that it implies onto the scene.  a transform looks for a configurational n-tuple  of which parsing rewrite rules are simple 
examples  see uhr  i 1 i 1   1d 1  .  
       the ideas list starts with primitive perceptual characterizers. as these transforms succeed  they 
w i l l imply higher-level characterizers and  if decider-1 recognizes verbal utterances  verbal rewrite rules. these w i l l continue to imply perceptual 
see uhr  1d for more detailed descriptions  and the actual decider-1 program. 
1 caps refer to major constructs in the decider-1 program. 
and verbal transforms  	a  for still higher levels  
b  to glance about at other parts of the scene in which what has so far been recognized suggests other things should be looked for  and c  to gather more information to confirm or deny the presence of tentatively implied objects  including words . 
deciding to act 
       decider-1'g decision to act is deceptively simple. each transform on ideas has a type associated 
with it. as discussed up to now  at first the most highly implied transforms will be of type = p  to perceptually parse  - until the system has gathered enough information 
about the scene to imply some response action with a high enough weight to be chosen. 
       decider-1 chooses the single most highly implied transform from ideas. at first these will be perceptual and verbal transforms. but they will begin to imply various possible acts  which will be merged back into ideas- thus ideas serves as a vehicle for deciding among the various possible acts  at the same time that it serves to decide whether to continue looking and gathering information  or whether to 
respond. 
       when a response is chosen  as the most highly weighted transform on ideas  decider-1 branches to effect that response - whether to answer  describe  find  move  or name. 	thus the response acts and the information-gathering acts are all ordered on the single ideas list  from which decider-1 continues to choose and execute the single most highly implied act  until a response act is chosen. 	this serves to order the execution of each type of act  and serves to choose when to decide to respond  as well as which response to make. 
types of response acts 
       decider-1 can effect g variety of acts. since our purpose has been to examine how a system can decide to act  the acts themselves are kept as simple as possible. 
       answer outputs the piece of information  e.g.  a fact  or a document name  that is stored in the answer transform that was chosen from the ideas list. 
       describe outputs the names of all objects that have been recognized and placed on the scene with a sufficiently high weight to exceed a choose parameter. 
       find searches for and brackets  in order to indicate where it is  an object of the class specified by the particular find transform chosen. 
       move finds an object of the first class specified  and moves it from its original location in the scene  so that it is next to an object of the second class specified. 
       name gets and outputs the single most highly implied thing that is the name of an object in the scene. 
the flow of processes is multi-determined 
     any transform that succeeds can imply any potential act of any type. characterizing transforms can be implied by what has been found so far about the input. a recognized and understood command can imply the act that obeys it. but an object can also imply an act  e.g. to name  or find it . and internal needs can imply acts  e.g. hunger can imply find an object of the class = food . 
     thus  e . g .   when decider-1 chooses to name this can be because a  a number of nameable objects have been perceived  and each implies the act of naming with a low weight  	b  a command like  name this  or a query like  what is this  has been recognized  as implying the act of naming  and/or 
c  an internal need implies that the act of naming may lead to its satisfaction. 	i should emphasize again  because it is a subtle point  that an act like naming is not built in  but must be decided upon. 
some examples of decider-1 's behavior1 
recognizing  parsing   understanding  and naming 
     decider-1 is given input scenes that contain mixtures of words and objects.  these should be two-  or even three-dimensional scenes that extend over time. then a written or spoken word like  apple  would extend in two dimensions just as does the perceived apple. we reduce these to 1-dimensional strings  to keep decider-1's characterizing processes from getting cumbersome. but see uhr  1b  1c for the relatively straightforward extensions that allow a 
system to handle two-dimensional scenes that extend 
over a third time dimension.  
when given an input like: 
name this   along with the representation of an object   
     decider-1 will  if lthas been given  or has learned  the needed transforms  output that object's name  e.g.  apple  or  table . to do this it applies whatever perceptual transforms have been given it as primitives  and continues to apply linguistic rewrite transforms until the name transform is triggered. by that time enough perceptual transforms have already been applied  o imply object names  and decider-1 chooses and outputs the name of the most highly implied thing that 
belongs to the class of  object s. 
     the objects might be represented at any level desired - from a linearized 1-dimenaional matrix of light and dark  e . g . : 
1 1  1    1 x 1 apple   to a set of characteristics: 
stem apple-color red round   apple character-
istics   to a template-like representation: object1   an encoded name for  apple  objects   
1 see uhr  1d for a more detailed development of a wider variety of examples  showing the transforms used and the ways these process inputs. 
　　note that words can similarly be given at any of these levels. 
　　edges {e.g. 1  or 1  of objects and spaces afterwords  characteristics  or templates  are used to delimit things. and the primitives that are initially put on the ideas list  e.g. the letters of the alphabet  
and simple edges  angles  or other pattern recognition characterizers that are commonly useful  begin to recognize parts of the input. thus the letters  and then words like  name  and  this   and the edges of objects  and then the objects themselves  will all be implied. 
     these in turn imply still other transforms that build compounds like  name this  or larger objects. these in turn imply response acts. this means that characterizers will imply an apple  and probably some other objects  e.g. a pear and a face   and the implied 
objects may themselves imply the act of naming - at the same time that the verbal utterance name this also implies the act of naming  with a very high weight  
so that it is very likely to be chosen. 
describing 
an input of the sort; 
describe this { representation of one or more objects   will get decider-1 to output a simple description  of the names of all things belonging to the  object  class the objects implied above a choose level  e.g.  apple table chair banana . the recognition of objects is much as for naming  but additional linguistic transforms will recognize the word  describe  and the import of the phrase  describe this  - as implying the describing act. 
any number of variants can be handled  e.g.: 
what is here { objects   say what you see   objects   
so long as the needed rewrite rules are in decider-1's 
memory. 
finding objects 
     if the verbal utterances within the scene {and/or internal needs  are recognized as implying the act of finding  decider-1 will branch to the find routine. this searches for an implied object that has been put into the transformed scene that is of the class designated by the particular find transform being executed. if the object is found  success is indicated by the placement of brackets  as though pincers  around it. 
acts are multi-determined   by words  things and internal needs 
the verbal utterance can be a command  e.g.: 
find food   a scene of objects     or   where is food   a scene of objects   or a request: 
is any food around   a scene of objects   or any other kind of utterance that  when parsed and understood  implies that a food object be found. 
1 
     but remember that an act like finding can be implied not only by verbal utterances  but also by objects in the scene  and by internal needs. thus  e.g.  the recognition of a valued object  hjce a banana  or the partial recognition of several food objects  like apples  
bananas  and crackers  can serve to imply  and  possibly  lead to the choice of  the act of finding  that is  getting  or grasping  the banana  or the food object. similarly  an internal need-state of hunger can imply the getting of a food object that will satisfy that hunger. 
moving and manipulating objects 
an input like: 
move box1 to box1  {a scene of objects   will lead to the recognition of the particular objects to be manipulated and the overall action desired. when move is chosen as response act  because it has become the most highly implied transform on ideas  decider-1 will look for the specific objects or class members involved in the action  and actually change the scene  as specified. 
     decider-1 assumes that the action will not be triggered until all the needed objects have been recognized. so the perceptual characterizers must be implied with high weights  so they are merged onto ideas with higher weights than are the response actions. but it would be quite easy to extend decider-1 so that it continued to try to perceive objects not yet recognized  but needed to effect an act that it had decided to do {see uhr  1 . 
answering queries 
     decider-1 can output internally stored information in response to an input. thus we see it a  talk about parts of the scene  naming  describing   b  manipulating parts of the scene  finding  moving   and c  answering  by accessing information stored in its memory in response to questions  either direct or implied  in the scene. thus  e.g.; who is the president might lead to the response  nixon . 
     now the scene is treated as a purely verbal utterance  simply because only verbal rewrite transforms succeed on it. but note how similar this is to the situation in which a request like: what is this { scene of objects   is intermingled with objects in a scene  in which case the act refers to information that has been extracted and recognized from that scene  rather than to information that has been stored in memory. 
further examples and future extensions 
     decider-i is described more fully  with a number of examples worked out in detail  in uhr  1  the actual program is presented  explained  and discussed. it is coded to easey  an english-like programming language  a variant of snobol  designed to be easy to understand  uhr  1 . 
     decider-1 is presently being extended to handle scenes that continue over time. in this extension  perceiving  responding  and problem-solving all go on in parallel. the system decides when to respond. but to respond it may need to perceive further objects appropriate to its response. or it may need to solve problems  to deduce a sequence of actions appropriate to the chosen response. or it may output a request for needed objects  or for help. thus perceiving  problem-solving  and acting are all intermingled. each may call upon  and depend upon the other. 

 
this paper considers the valiant framework as it is applied to the task of learning logical concepts from random examples. it is argued that the current interpretation of this valiant model departs from common sense and practical experience in a number of ways: it does not allow sample dependent bounds  it uses a worst case rather than an average case analysis  and it does not accommodate preferences about hypotheses. it is claimed that as a result  the current model can produce overlyconservative estimates of confidence and can fail to model the logical induction process as it is often implemented. a bayesian approach is developed  based on the sample dependent notion of disagreement between consistent hypotheses. this approach seems to overcome the indicated problems. 
1 	introduction 
the field of machine learning has accrued experience across a broad number of areas  and there is now a push for developing a more formal theory of learning. while we are still a long way from this general aim  fundamental principles exist on which such a theory should be based: statistics  the representation and utility of knowledge.  computational complexity  valiant  1   manmachine interaction  buntine and stirling  to appear   and the psychology of learning. perhaps the first attempt to encompass some of this broad spectrum in a formal theory was made by valiant in his  theory of the learnable   valiant  1 ; valiant argued that a theory of learning should show classes of concepts are le unable in the context of an appropriate information gathering mechanism and in a reasonable number of steps. the best known instance is valiant's model for learning logical concepts from random examples. 1 shall refer to this as the valiant model  which is distinct  from his general framework. the valiant model has subsequently been developed by a number of researchers to yield an impressive array of results and research tools  llaussler  1  rivest  1 . the valiant model has also recently received strong criticism from amsterdam  amsterdam  
1a   who said 
valiant's formal model of concept learning . . . has rarely been used in practice  in part because the known learnable concept classes are too restricted. 
amsterdam suggested a number of extensions to the model  incorporating queries and learning approximate representations of a concept  and criticised the model for its restricted scope  amsterdam  1b . 
¡¡the valiant model is becoming recognised as a standard for formal learning theory and several extensions exist  angluin and laird  1  amsterdam  1a  rivest and sloan  1 . but if it is to be a standard  we should heed amsterdam's criticisms and first consider 
just how well the valiant model handles its intended task  without extensions and considering only its  admittedly restricted  current scope. this paper does just that; the paper is a critique of the statistical component of the valiant model. 
¡¡the two principle claims of this paper are that the current interpretation of the valiant  model can produce overly-conservative estimates of error  even accounting for the approximations used ; and that the model fails to match the induction process as it is often implemented. it is argued that these supposed shortcomings occur because the model gives sample independent bounds  the model is based on worst case analyses  and the model fails to accommodate preferences  or hunches  about hypotheses. overly-conservative estimates would cause problems in the knowledge acquisition context  for instance  where only a limited sample may be available  extra examples costly to obtain  and realistic estimates of error are required regardless. 
¡¡these shortcomings suggest that the statistical component of the model is inadequate for a comprehensive analysis of the problem of designing learning algorithms  although the model does produce valuable upper bounds on learning performance. the shortcomings may be viewed as symptomatic of the underlying pseudoclassical statistical philosophy of the valiant model. the bayesian approach is instead adopted here. the main theoretical machinery that this approach adds is the notion of a prior. while priors certainly have to be used with caution  berger  1  pi1   there use allows a much more powerful statistical analysis of the logical induction problem that still shares all the  distributionfree  advantages of the valiant model  llaussler  1  
	buntine 	1 
p1   albeit in an average-case rather than worst-case sense. 
¡¡other support for the bayesian approach appears substantial. there are strong foundational arguments for the approach as a method of reasoning about uncertainty  concept learning is an instance of such reasoning   berger  1  horvitz et al.  1   and the approach tackles a broad range of other problems in intelligent systems  pearl  1 . more relevant to the present topic  however  the bayesian approach handles the problem of learning uncertain concepts  a central problem that the valiant model has been criticised for not handling  amsterdam  1b . bayesian methods are competitive with some other machine learning approaches  cheeseman et a/.  1  buntine  1c . a version of quinlan's infor-
mation theoretic heuristic for greedily building decision trees  quinlan  1  can be derived from bayesian principles  and the widely reported tradeoff between concept simplicity and prediction accuracy has a well known explanation in bayesian decision theory  cheeseman  1  buntine  1a . these last two issues have recently been reported as open problems  haussler  1  fisher and schlimmer  1 . the bayesian approach  however  only addresses the uncertainty in learning  and clearly needs to be complemented  for instance  with the computational concerns that are central to valiant's broad learning framework  and indeed crucial to any theory of machine learning. 
¡¡sections 1 and 1 introduce the task of learning logic concepts from random examples and the valiant model to that task  sections 1  1 and 1 each illustrate a problem with the model. section 1 then outlines the bayesian solution and section 1 concludes with some open problems. 
1 	the learning task 
the valiant model is primarily concerned with the logic induction problem. for example  suppose for discussion that we are designing a system to plan the routing of sheet steel through a large manufacturing plant. for the purposes of deciding whether to use the annealing process or not  a product may be classified by a number of attributes that together uniquely determine whether the process should be used. that is  there is known to exist a necessary and sufficient  logical  definition of the  annealing  class given in terms of attributes  this is the classification rule we hope to approximate. 
¡¡let us assume there are 1 binary-valued attributes: cold-rolled  aluminium-killed  deep-drawing  skin-passed  exposed-surface and carbon. and we have been provided with some examples  each gives values for the attributes  that have also been classified as either positive or negative  use annealing  or not  by the resident metallurgist. in this instance  there are 1 = 1 possible examples  each having one of 1 possible classifications. a distribution on the examples gives the frequency of any par-
ticular steel product  as uniquely determined by the 1 attributes  would occur  irrespective of its actual classification. examples are known to have come from a fixed distribution. a random sample is a set of classified examples drawn independently and identically according to the distribution on examples. this implies sampling 
1 	machine learning 
with replacement. 
¡¡a simplistic notion of the logic induction problem  then  is to find the  true  classification rule given only the classified examples. in practice  of course  we would at best hope to find a classification rule that minimises errors in some sense on future predictions. an hypothesis space h represents a space of classification rules that can feasibly contain the  true  one. for instance  in the steel routing application  if we consider the complete hypothesis space  all possible classification rules over the 1 examples  the space is of size 1 or approximately 1 billion. 
1 	the valiant model 
angluin and laird precis the statistical component of the valiant model as follows  angluin and laird  1 : 
the idea is that after randomly sampling  classified examples  of a concept  an identification procedure should conjecture a concept that with  high probability  is  not too different  from the correct concept. 
angluin and laird have termed this notion probably approximately correct  pac  and a common interpretation  haussler  1  is  in a nutshell: there are so few hypotheses left that are consistent with the classified examples that every consistent hypothesis is with a confidence of 1 - 1 approximately correct with error at most e on future samples. i shall refer to this as the classical interpretation. 
¡¡with  hi  hypotheses  blumer  ehrenfuecht  haussler and warmuth  blumer et a/.  1  show that to be assured of pacness with error c and confidence 1-s with a random sample of size n examples  the following should hold 
		 blumer bound  . 
i shall refer to this as the blumer bound. for a complete propositional hypothesis space h over n propositional symbols   h  is 1  there are 1n different examples  each can be true or false . for various other propositional languages the blumer bound gives tighter results than those obtained using the vapnik-chervonenski dimension  buntine  1b  haussler  1 . for learning then  after setting an acceptable level of confidence and error  we select a plausible hypothesis space  choose an algorithm and buy the sufficient sample  and then apply the algorithm to find a hypothesis consistent with the sample. 
1 	the impact of the sample on estimating pacness 
the classical interpretation ignores what is perhaps the most vital piece of information in the whole equation: what actual examples are obtained. results are always given purely in terms of the size of the sample. while this is acceptable if we currently wish to estimate how large a sample should be obtained  if we actually have a sample there may well be other information in it apart from its 

size able to tighten the bounds on pacness. a learning algorithm should make use of this sort of information. 
¡¡to understand the potential of this other information  consider the analytically simple but impractical situation where the the hypotheses space is complete  it includes all possible classification rules. for instance  in the steel routing example   h  = 1. with a sample of size 1 and confidence of 1% the blurner bound gives a bound of c   1. experience with induction tools such as id1 
 quinlan  1  indicates that this bound is not optimal. in fact  stochastic simulation shows that according to most distributions on examples  given a random sample of 1 classified examples  many of the 1 possible different examples will have been included  so we know their classification! of the remaining  because we haven't seen them in a rather large sample  they are probably rare anyway. it is possible but very unlikely that the random sample will contain all possible examples  then the predicted error rate should be zero! if only 1 out of the 1 where not included  then the error rate should now be non-zero and of the order of 1 = 1  certainly much less than 1. at the other extreme  if the random sample consisted of 1 repetitions of the same example  then the predicted error rate should be higher again. knowledge of the actual sample clearly has potential for improving error analysis  and a theory of learning should account for this. 
¡¡a careful inspection of the proof of the blumer bound reveals that it assumes the size of the sample is known  but the examples making up the sample are unknown. information about the sample cannot be incorporated. 
fortunately  a sample-dependent bound for determining 
pacness can be found using bayesian statistics. this is based around a notion of the disagreement between consistent hypotheses. 
definition 1 let s be a random sample of classified examples of a concept drawn from a finite example space and let h be a hypothesis space for the concept. the 
maximum disagreement induced by s on h is the maximum for i such that h1 h1 e h  h1 and h'1 are consistent with s  and h  and h1 disagree on i classifications out of all possible distinct examples. 
¡¡for a complete hypothesis space  the maximum disagreement induced by s is just the number of distinct possible examples that do not occur in 1. 	for a con-
junctive hypothesis space  maximum disagreement has an upper bound of 1 n + 1 s c  s  - 1 n + 1 - i c   s   where n is the number of propositional symbols  sc s  denotes the length of the shortest conjunction consistent with s  and lc s  denotes the length of the longest such conjunction  buntine  1b . for this last bound  bare in mind that there are 1n distinct possible examples. 
¡¡disagreement can be used to find an upper confidence limit on the chance that any consistent hypothesis will disagree on the classification of an example. the result assumes the so called non-informative dirichlet prior on a distribution over n example types  pr e1 ...  en  ¦Á iiie ¦Á-1  where e  is the probability of seeing the i-th example and ¦Á is set to 1. as always  the choice of prior is application specific so some other value of a might be more appropriate for a given problem. 
lemma 1   buntine  1b   let s be a random sample of n classified examples  h be a hypotheses space on e distinct examples  and k be the maximum disagreement induced by s on h. in addition  suppose that a prior belief in the distribution on examples is noninformative. define beta error to be the value of e for which 
 1  
where lt is the incomplete beta function  abramowitz and stegun  1 . for any arbitrary hypothesis h consistent with the sample s  we have better than 1 - 1 confidence according to a posterior belief  conditioned on the sample  that the error rate of h is less than the beta error. 
¡¡fast formulae for computing the incomplete beta function and its inverse are available in mathematical handbooks  abramowitz and stegun  1 . to give an idea of the behaviour of beta error  the following approximation can be made  buntine  1b . 
  
where z1-s denotes the standard normal deviate for 1 - 
1  that is pr z   z1/s  =1 - 1. for instance  z1 = 1 and z1 = 1. this approximation should be compared with the blumer bound. notice that k/1 and in |h| roughly correspond in the two bounds. 
¡¡consider  again  the simple situation where the hypothesis space is complete. figure 1 shows how the beta error in which we have 1% confidence varies as a larger sample is taken. twenty-four samples were generated by first randomly generating  according to the non-informative prior  a distribution if on the e = 1 distinct examples  and then randomly generating examples from this distribution. two representative samples where then selected for display. accumulated sample size is given by n. the line graphs marked by boxes and the left axis give beta error. the line graphs marked by circles and the left axis give the true value of the maximum error for a consistent hypothesis. notice how the beta error usually tracks along but just above the true maximum error. this occurred in all twenty-four samples  with the beta error occasionally under-estimating error. the blumer bound1 is the line marked by diamonds in the top part of the graph. the bar graphs and left axis give the maximum disagreement induced by the accumulated sample  k  represented as a proportion of the distinct examples  k/e . notice how the beta error stays well below this proportion as equation  1  indicates  but the blumer bound remains with it. with the well behaved nature of the beta distribution  similar shaped graphs should occur for other values of e and 1. 
¡¡figure 1 shows how the beta error in which we have 1% confidence varies with k  the maximum disagreement induced by a sample on a hypotheses space. this is given for two different sample sizes  tv = 1  
	1	n 
¡¡¡¡ for a fairer comparison  a tighter version b   |h| 1 - e   has been used in this and later graphs. 
	buntine 	1 


from e = 1 distinct classified examples. the blumer bound given assumes the hypothesis space is complete. notice how the beta error decreases with the maximum disagreement  i.e. when more example types are seen in the sample  consistent hypotheses will have lower error. this demonstrates just how important it is to make use of knowledge about a sample when evaluating pacness. 
1 	average rather than worst case pacness 
the use of the bound obtained in lemma 1 or the blumer bound  as with haussler's notion of c-exhausting a hypothesis space  haussler  1   are really worst case analyses: they apply to every consistent hypothesis. if we choose a single consistent hypothesis arbitrarily  then we may choose a worst case  or we may choose a more accurate hypothesis. to see what is wrong with this worst case analysis  suppose we have a carton of 1 apples  of which at most 1 are known to be bad. according to a worst case analysis  we cannot be confident of picking a 
good apple out of the carton because in the worst case we will get a bad apple. an average case analysis  like common sense  tells us that if we pick an apple out of the carton  we can be confident  1% in this case  it will be a good apple. 
¡¡to introduce an average case analysis  we could  for instance  determine the confidence 1 - 1 that error is at most c for an arbitrarily chosen consistent hypothesis  bearing in mind that some consistent hypotheses may have a worse error. this confidence represents our 
1 	machine learning 

strength of belief that we have not obtained an unrepresentative sample and that we have not chosen a worst case hypothesis from those consistent with the sample. both are chances we have no control over. 
1 	considering preferences on hypotheses 
as mentioned above  the classical interpretation and the result in lemma 1 give confidence on error bounds for the worst case consistent hypothesis. in practice  of course  we do not build induction programs that try to find the worst conjecture consistent with the sample  nor do we arbitrarily choose one. most induction practitioners spend their time trying to find a conjecture that they believe is in some sense the best. how should this be done  
¡¡merely choosing just any consistent hypothesis may ignore vital information of a form not able to restrict the hypothesis space. suppose  as littlestone considers  littlestone  1   we suspect there arc abundant irrelevant or .redundant attributes. it would be an obscure application where we know exactly how many attributes are irrelevant or redundant. suppose  as rivest considers  rivest  1   we believe decision lists form a suitable hypothesis space. do we use 1-dl  decision lists with conjunctions of size 1 at each decision  or maybe 1-dl  in fact  this is what we typically want the induction system to tell us. suppose we make a guess and consider a hypothesis space of r-dl. if we undershoot on r  we may end up finding no consistent hypothesis at all. if we overshoot  there may be many hypothesis left consistent with the limited sample we do have  and we have no assurance that an arbitrarily chosen one will have a suitable mecisure of pacness. clearly  we should not choose such a hypothesis arbitrarily. 

¡¡this issue has caused mitchell to propose the need for  bias  in induction  mitchell  1 . bias is information extraneous to the sample used when choosing a hypothesis. for instance  we might choose a hypotheses that is  preferred  in some sense. in the situation above  if we believe irrelevant attributes abound  we might search for a consistent hypothesis that incorporates a smaller number of tests  for instance  a shorter decision list. an early paper by gold  gold  1  gave a result that supported mitchell's proposal. gold showed that there is no logic learning algorithm that uniformly requires a smaller number of examples to correctly identify a hypothesis than the  identification by enumeration  algorithm. since almost all reasonable logic learning algorithms can be classed in this broad category  we can conclude that some algorithms perform well on some types of problems  others perform well on other types of problems  but no algorithm performs uniformly better. as a consequence  the best we can do in logic induction is to hope that we choose an algorithm that performs well on the style of problem we are presented; and only information extraneous to the sample can help us in this choice. 
¡¡the approach used by many applied logic induction systems is to use occam's razor as a  preference ordering  on hypotheses. these systems search for  simpler  consistent hypotheses where the notion of simple is a syntactic notion relative to the description language chosen for the application. for instance  quintan's id1  quinlan  1  does this by searching for a more compact decision tree consistent with the sample. as a result  the id1 algorithm could not be expected to perform well  for instance  in learning some dnf formulae. these can have quite complex decision tree representations. 
   notice that this use of a preference ordering must be relative to the application concerned because any syntactic measure is a language dependent concept  and the language used is typically supplied by a domain expert. caution also dictates that we only use an ordering that we have some prior justification for  otherwise we may as well arbitrarily pick a consistent hypothesis. gold's result also assures us that this is the best methodology available when learning logic concepts. finally  the classical and the two revised pacness notions are now inappropriate because they do not account for the use of preferences. 
1 	the bayesian approach 
the only induction theories that address the use of preference  or  bias   specifically are bayesian statistics and its logarithmic counterpart  the minimum description length  mdl  method. these answer mitchell's concerns  mitchell  1  in mathematical detail: how  bias  is required  how it can be implemented  as a measure of belief   and how it effects the logical induction process. 
the bayesian approach is discussed here. 
¡¡for each hypothesis h € h  we have pr h  an a priori measure of belief in it being  true  before the sample s is seen  and pr h   s  an a posterior measure of belief after the sample has been seen. the prior measure may be uniform for all hypotheses in the space; in which case we are using a non-informative prior  and acknowledging that we have no basis to prefer one hypothesis other another. when using occam's razor as a preference ordering on hypotheses  we are tying the prior to some measure of hypothesis size. 
¡¡for each hypothesis h  prior and posterior are related as follows: 

it is quite simple to show that this relation holds even when a sample is made without replacement  or when examples are obtained through the learner making queries. the relation shows that the prior preference ordering we choose before obtaining the sample is also appropriate  given a sample  for ordering those hypotheses consistent with the sample. 
it is implicit in the current interpretation of the 
valiant model and in the mdl model that we should choose just a single consistent hypothesis to make predictions with. to be more in the spirit of the bayesian approach  we should instead choose several of the  better  hypotheses and pool their predictions  as a means of  hedging our bets . this is a consequence of the decision theory component of the bayesian approach. experiments show this hedging of bets may give only minor improvement in subsequent prediction accuracy  but can also lower the variance of prediction accuracy for classification rules built from different samples  buntine  forthcoming . 
¡¡the bayesian approach also gives a method for determining confidence in error estimates  for example  pacness. this method does not appear to suffer the three broad problems claimed earlier about the valiant model. for the classification rule c to be used  we first need the mean error e according to posterior belief  uc 1  representing how much error we expect c to have  and the variance of this error      representing our uncertainty in the expected error. for the case of a random sample and the so called non-informative prior these quantities are as follows: 

where k c  h  represents the disagreement between c and 1  which is the number of classifications out of all possible distinct examples on which c and h disagree  and n and e have their usual meaning1. the mean error is calculated as the average disagreement divided by 1n + e. the mean and variance could be approximated stochastically by finding a small number of hypotheses consistent with the sample and then evaluating the two summations in the above equations on these hypotheses. pacness can then approximated from these quantities. 
1
these equations follow using the method of proof for 
lemma 1 and knowledge of the mean and variance of the beta distribution. 
	buntine 	1 

1 	conclusion 
it has been argued that analysis of learning algorithms would better consider how to search for one or several preferred consistent hypotheses  and that prediction error can be approximately bounded using the sample dependent quantities maximum disagreement and average disagreement. these quantities play the role of log|h| in the blumer bound. 
¡¡the following open problems illustrate the kinds of computational issues that need to be addressed to develop the bayesian approach given here in the manner of valiant's  valiant  1  broad learning framework. 
1. how can maximum disagreement or some average measure of disagreement be efficiently estimated for samples from different concept classes  
1. the analysis in sections 1 to 1 consider how to more accurately determine pacness given a sample  but not how large a sample is initially required. how is maximum disagreement or some average measure of disagreement expected to grow with the sample size  or what is pr k   n   
1. what are suitable algorithms and what is the computational complexity of searching for  preferred  consistent hypothesis for various concept classes and preference criteria  both haussler  haussler  1  section 1  and rivest  rivest  1  section 1  have briefly considered this question using  simplicity . 
1. just how good is the stochastic approximation for determining pacness  outlined in section 1  under a range of different priors and concept classes  
¡¡if current trends on applied machine learning are any guide  then even more interesting problems revolve around the learning of uncertain concepts. 

 
an approach for designing countermeasures to cure conflict in aircraft pilots' activities is presented  both based on artificial intelligence and human factors concepts. 
the first step is to track the pilot's activity  i.e. to reconstruct what he has actually done thanks to the flight parameters and reference models describing the mission and procedures. the second step is to detect conflict in the pilot's activity  and this is linked to what really matters to the achievement of the mission. the third step is to design accurate countermeasures which are likely to do better than the existing onboard devices. the three steps are presented and supported by experimental results obtained from private and professional pilots. 
1 introduction 
the review of civilian and military reports reveals that a conflictual situation is a precursor to the loss of aircrews' situation awareness and is a major cause of air accidents. conflict may occur through different forms: open conflict between the different operators  air philippines crash  april 1   representation conflict about the aircraft position  korean air  august 1   resource conflict  streamline  may 1   knowledge conflict  crossair  january 1   or more recently  a conflict between automated systems  tcas  and human operators  air collision between a tupolev 1 and a boeing 1 over switzerland  july 1 . therefore  the idea is to detect conflict so as to propose accurate on-line countermeasures to pilots. 
the first step is to track the pilot's activity  i.e. to reconstruct what he has actually done thanks to the flight parameters and reference models describing the mission and procedures. the second step is to detect conflict in the pilot's activity  and this is linked to what really matters to the achievement of the mission. the third step is to design accurate countermeasures which are likely to do better than the existing onboard devices. the three steps are presented and supported by experimental results obtained both from private and military pilots. 
1 track the pilot's activity 
1 reference model 
the approach to capture the pilot's activity is based on situation tracking classically used for system diagnosis  monitoring and intelligence  ghallab  1; chaudron et al  1; rota and thonnat  1 . whatever the formalism used to represent knowledge  situation tracking rests on a matching between observed facts and known situations  reference models   and its object is to carry out postdictions  predictions or to diagnose the current state of the system. 
to represent knowledge  we use the concept of propositional attitude   which covers the notions of belief  desire  intention   ...  which have in common the fact of being identified by their pwpositional contents    tessier et al  1 . definition: a propositional attitude  pa  is a pair  k.t  where k is a logical cube  i.e. a conjunction of first order literals  chaudron et al  1   and t is the time interval within which the properties captured by k are true. the pilot's knowledge is divided into three categories of pas  which constitute the reference model: 
  propositional attitude goal describes a goal of the mission. ex: pa-goal goal 1    landing francazal   t  
means that the fifth goal of the mission is to land at francazal during time interval t. 
  propositional attitude plan describes the properties the pilot is committed to satisfy to reach a pa-goal as long as he carries out this goal. 
ex: pa.plan goal 1     vor-frequency  1    vor-heading.def lection  true    gear down  true    flaps-down  1    v i s i b i l i t y  true    t  means that to satisfy goal 1  the pilot has to select the accurate radio frequency  fly a correct route  lower gears and flap deflection 1 and have a good visibility during time interval t.   a crucial propositional attitude describes the hard constraints associated to one or several goals. 
ex: pa-crucial goal 1   visibility true   t  
means that to succeed in landing at francazal  the pilot must have a correct visibility during t. 
cognitive modeling 	1 remark: the model does not implement deontic logic  traum and allen  1  to capture the pilot's obligations; at each time step  the system will check whether the pilot meets the different constraints on the pa-goals. 
1 	observed activity 
the pilot's activity is observed and analyzed through his actions on the airplane interface: during the experiments  the flight parameters are recorded every second. the parameters are then translated into symbolic knowledge and aggregated to build observation prepositional attitudes. the numerical thresholds that are used for numerical to symbolic translation are adjusted during interviews with the pilots to built an accurate model for each pilot. for example  if the pilot has to fly 1 ft  he defines his own flight envelope where he feels secure  amalberti and wioland  1 . after numerical to symbolic translation  parameter altitude is characterized as altitude  false   i.e. out of flight envelope  or allitude  true   i.e. within flight envelope . the same kind of analysis is performed with parameters such as the route  the fuel level  etc. 
therefore  propositional attitude observation describes perceived and deduced facts from the pilot's activity: 
ex: pa.obs   vor f requency  1    
vor heading.def lection  true    gear down  true    flaps-down  1    visibility  false     1 1   means that at time 1  the pilot has selected the accurate radio frequency  is flying a correct route  has lowered gears and flap deflection 1 and has a bad visibility. 
1 detect conflict 
1 conflict 
considering research in the field of a.i. and particularly on multi-agent systems  the focus has been brought much on how to avoid  solve or get rid of conflicts  especially via negotiation  sycara  1; rosenschein and zlotkin  1   argumentation  jung and 
tambe  1  or constraint satisfaction  conry et al.  1; 
khedro and genesereth  1; hannebauer  1 . such approaches  where  i  conflict is likened to formal inconsistency and  ii  the internal knowledge of the agents is clearly identified  are not suited to our purpose. indeed in aeronautics  uncertainty on data is high and the human behavior is extremely variable and unpredictable. moreover  while in air  aircrews frequently face incoherent situations due to the uncertain environment  e.g. weather  failures  or because of their own errors. nevertheless  these situations are not necessarily conflictual  and pilots are used to going on with their missions with such inconsistencies. an inconsistency becomes conflictual only if it leads to a critical flight phase and matters to the mission or to the aircrew's safety. therefore we are very close to eastcrbrook's definition of conflict  easterbrook  1 :   ...  viewpoints are free to differ  and only conflict when that difference matters for some reason  leading to interference.  ...  a conflict  then  is simply a difference that matters.  this point of view has been emphasized in social sciences  festinger  1; lewin et al.f 1  and in a.l. applied to social modeling 
 castelfranchi  1   where human conflict is seen as the result of an impossibility to succeed in a goal that matters. definition: a conflict is a set of propositional attitudes that is not coherent1 and the fact that it is not coherent matters. the inconsistency of a set of pas matters either because there is a need: 
  to satisfy the rationality1 of the agent s  involved  pilot  copilot... ; 
  or to build a coherent set of knowledge; 
  or to decide on further goals. 
all these different reasons are implemented in the reference model as crucial propositional attitudes  see section 1 . therefore a conflict is an incoherent set of knowledge that matters through one or several crucial propositional attitudes. 
1 	conflict detection 
conflict detection is a tracking process that monitors the pilot's pas at each time step t. it is a two-step process:  1  detect the sets of pas that are not coherent at time t and  1  detect the conflicts given the crucial pas that concern time t. one could have designed a single-step process  however it is of great interest to track pas that are not coherent and do not conflict: indeed  contrary to the minimal inconsistent sets approach  de kleer  1   we aim at capturing all the inconsistencies and analyzing how they are managed by the pilots for  lessons learned  and further man-artefact interaction model tuning. 
 1  detect the sets of pas that are not coherent predicate not -hold-together detects incoherent sets of pas inct at time t . 
ex: given the set of pas 
 pa goal goal 1    landing francazal    1 tl   
  pa plan goal  1     vor f requency  1    vor heading.deflection  true    gear down  true    flaps-down 1  visibility true    l1 tl   
  pa.obs   vor.frequency  1    
vor heading deflection  true    gear down  true    f laps down 1  visibility false   /  1 / 1    two incoherent sets of pas arc detected: 
-  not hold altogether  pa plan  1  flaps-down  1      pa.obs  flaps down  1     1   ; -  not hold together  pa.plan  1   visibility  true    pa.obs visibility false    1  . 
 1  detect the conficts 
the crucial pas that concern time t are then considered. definition: let inct an incoherent set of pas at time /. if inct includes pas or properties that matter through one or several crucial pas  then inct is a conflict. 
predicate matters screens sets inct thanks to the crucial pas  so as to determine whether they are conflicts or not. ex: for the previous example  the crucial pa that holds at time 1 is: 
  pa.crucial goal 1   visibility true    
 1 tl   
predicate matters detects that one of the two incoherent 
1  in relation to the formalism used to represent the properties in 
the pas. 1  according to festinger  festinger  1  who postulates that an individual always aims at being coherent when interacting with his environment. 

1 	cognitive modeling 

sets of pas is conflictual: 
matters  pa plan goal  1    v i s i b i l i t y  true      pa obs visibility false   1   
the other set of pas relative to flaps deflection is not a conflict because a landing with flap deflection 1 is possible even though less recommended. 
1 	preliminary experiment and results 
a preliminary experiment designed to test conflict tracking 
 dehais  1  was conducted with ten pilots on a research flight simulator. the pilots were proposed a flight scenario whose aim was to follow a flight plan at a constant altitude and then land with instruments. the difficult point in this scenario was to manage the fuel consumption correctly considering refuelling areas. 
this experiment has validated conflict detection and interestingly enough has shown that a psychological perseveration phenomenon appeared with conflict : the pilots who faced conflictual situations did not come to the right decision to solve their conflict  on the contrary they got themselves tangled up in it  and all the more so since the temporal pressure was increasing. the most surprising thing was that all the necessary data to come to the accurate decision were available and displayed on the onboard equipments. ex: one of the pilots flew toward waypoint 1 instead of flying first over waypoint 1 for refuelling  and started circling around  until he ran out of fuel  see figure 1 . 

figure 1: conflict and perseveration 
vinced that waypoint 1 was the refuelling area  in spite of the map displayed in the cockpit ; he reached it and noticed that the fuel level did not increase. thinking he had missed waypoint 1  he decided to fly back to waypoint 1. he did this manoeuvre again and again till he ran out of fuel  getting more and more stressed. 
1 send accurate countermeasures 
1 	guidelines 
the findings of the preliminary experiments are akin to a recently published report of the bea1  the french national institute for air accident analysis  that reveals that pilots' erroneous attitudes of perseveration have been responsible for more than 1 percent of casualties in air crash  in civilian aeronautics . this behavior  called the  perseveration syndrome   is studied in neuropsychology  vand der kolk  1; pastor  1  and psychology  beauvois and joule  1 : it is known to summon up all the pilot's mental efforts toward a unique objective  excessive focus on a single display or focus of the pilot's reasoning on a single task . once entangled in perseveration  the pilot does anything to succeed in his objective even if it is dangerous in terms of security  and worse  he neglects any kind of information that could question his reasoning  like alarms or data on displays . 
　therefore the idea is to design countermeasures in order to break this mechanism and get the pilot out of the conflict. the design of the countermeasures is grounded on the following theoretical and empirical results: 
  conflictual situations lead pilots to persevere; 
  additional information  alarms  data on displays  designed to warn pilots arc often unnoticed when pilots persevere. 
our conjectures are then: 
-  with an accurate on-line conflict detection  it is possible to analyze and predict the subject of the pilot's perseveration; -  instead of adding information  classical alarms   it is more efficient to remove the information on which the pilot is focused and which makes him persevere  and to display a message to explain his error instead. 
ex: in the experiment described afterwards  pilots persevere in trying a dangerous landing at francazal despite the bad visibility  with a particular focus on an instrument called the h.s.i.1 to locate francazal airport. the countermeasures will consist in removing the h.s.i  during a few seconds  to display two short messages instead  one after the other   landing is dangerous ...  look at central display   and next to send an explanation of the conflict on the central display   low visibility on francazal  fly back to blagnac  . the idea here is to shock the pilot's attentional mechanisms with the short disappearance of the h.s.i.  to introduce a cognitive conflict   iff land  i crash   to affect the pilot's reasoning  and to propose a solution on the central display. 

during the debriefing  the pilot explained that he was con- 

1  http://www.bea-fr.org 
1 the h.s.i is a display that gives the route to follow and indicates any discrepancy from the selected route. 

cognitive modeling 	1 

1 	ghost 
ghost is an experimental environment designed to test countermeasures to cure the pilot's perseveration. it is composed of; 
  flightgear1  an open source flight simulator  which means that many modifications can be made  e.g. implementing new displays. to fly the airplane  pilots have a stick  rudder and a keyboard. almost all the airports and beacons  ndb and vor1  of the world are modeled  and the air traffic control is simulated. during the experiment  the flight simulator interface is displayed on a giant screen; 
  atlas1  a freeware designed to follow the pilot's route. the airplane trajectory  cities  airports and beacons arc displayed with an adjustable focus; 
  a wizard of oz interface  see figure1  we have designed and implemented  which allows a human operator to trigger events  failures  weather alteration and the countermeasures  from an external computer via a local connection  tcp/ip protocol  sockets communication . 
as far as the countermeasures are concerned  several actions are available to the wizard of oz: 
  replace a display on which the pilot is focused by a black one  time of reappearance is adjustable ; 
  blink a display  frequency and time of blinking is adjustable ; 
  fade a display and brighten it again; 
  send a message to a blinked  removed or faded display;   send a message to the central display for explicit conflict solving. 

figure 1: the wizard of oz interface - countermeasures 
1 	experimental scenarios 
as conflict appears when a desired goal cannot be reached  we have designed three experimental scenarios where a cru-
1  http://www. fightgear. org/ 
1 ndb and vor are two kind of radionavigation beacons used to guide pilots. 1 http://atlas.sf.nct 
cial goal of the mission cannot be achieved: 
  scenario 1 is a navigation task from toulouse-blagnac air-port to francazal airport including three waypoints  vor 1  ndb 1 and ndb 1 . an atmospheric depression is positioned in such a way that the pilot cannot see the landing ground but at the last moment when it is too late to land on it. 
  scenario 1 is a navigation task from toulouse-blagnac air-port to francazal airport including three waypoints  vor 1  ndb 1 and ndb 1 . the visibility is decreased from the runway threshold: from far away  the landing ground is visible but as the pilot gets closer to it  it disappears totally in a thick fog. 
  scenario 1 is a navigation from toulouse-blagnac back to toulouse-blagnac including three waypoints  vor 1  ndb 1 and ndb 1 . an atmospheric depression is positioned over waypoint 1  ndb 1   and as the pilot flies over this waypoint  the left engine fails. 
in scenarios 1 and 1 the pilot's conflict can be summarized as 
 should i try a dangerous landing at francazal or should i fly back to blagnac for a safer landing  . if our conjectures hold  pilots will persevere and try to land at francazal. 
in scenario 1  the pilot's conflict can be summarized as 
 should j go on with the mission despite the failure or should i land at francazal and therefore abort the mission   
1 	experimental results 
1 experiments were conducted with ghost in december 1  see figure 1 . the pilots' experiences ranged from novice  1 hours  small aircraft  to very experienced  1 hours  military aircraft . conflicts where detected with the conflict tracker  described above  and were inputs for the wizard of oz to elaborate the countermeasures. 
results for scenarios 1 and 1:  impossible landing  
in these scenarios  the pilots faced the decision of mission abortion  i.e. not to land at francazal and fly back to blagnac. both scenarios were tested within two different contexts: without countermeasures and with countermeasures. 
  context 1: no countermeasures 
1 pilots tested scenario 1 or 1 without any countermeasures  see next table .  circuits  corresponds to the number of circuits performed by the pilot round francazal before crashing or landing. 

　the results suggest that without any countermeasures  none of the pilots came to the right decision  fly back to blagnac : they all persevered at trying to land at francazal. 
four of them hit the ground  and the other three had a  chance landing   which means that while they were flying round francazal  the runway appeared between two fog banks and 

1 	cognitive modeling 

they succeeded in achieving a quick landing. during the debriefing  all of them admitted they had come to an erroneous and dangerous decision.   context 1: with countermeasures 
1 pilots tested scenario 1 or 1 with countermeasures  see next table .  circuits  corresponds to the number of circuits performed by the pilot round francazal before a countermeasures is triggered by the wizard of oz. 

　the results show the efficiency of the countermeasures to cure perseveration: 1 pilots out of 1 changed their minds thanks to the countermeasures  and flew back safely to blagnac. during the debriefing  all the pilots confirmed that the countermeasures were immediately responsible for their change of mind. moreover  the short disappearance of the data due to the countermeasures did not cause any stress to them. 1 military pilots found that the solutions proposed by the countermeasures were close to what a human co-pilot would have proposed. 
the results with pilot 1 suggest that the more a pilot perseveres  the more difficult it is to get him out of perseveration. during the debriefing  pilot 1 told us that he was obsessed by the idea of landing  and that he became more and more stressed as long as he was flying round francazal. he then declared that he did not notice any countermeasures. pilot 1 and pilot1 also persevered despite the countermeasures: they declared they knew they were not flying properly and that they had done that on purpose because they wanted to test the flight simulator. 
results for scenario 1:  failure  
only 1 pilots tested scenario 1. one pilot experimented this scenario without any countermeasures: he did not notice the failure and hit the ground. the second pilot was warned through the countermeasures that he had a failure and that there was a landing ground at vector 1: the pilot immediately performed an emergency landing on this landing ground. other experiments are currently being conducted with this scenario. 
other results 
during the experiments  1 pilots made errors  e.g. selection of a wrong radio frequency  erroneous altitude  omission to retract flaps and landing gear. to warn them  the wizard of oz blinked the display on which they were focusing and displayed the error  e.g.:  gear still down  . in each case  the countermeasure was successful: the pilots performed the correct action at once. during the debriefing  the pilots declared that this kind of alarm was very interesting  and much more efficient and stressless than a classical audio or visual alarm because they could identify at once what the problem was. 
　these experiments have shown also the significance of the message contents on the blinked display. for example  as far as the erroneous landing at francazal is concerned  the initial message was  don't land''  but the pilots did not take it into account  thinking it was a bug of the simulator. when the message was changed to  fly back to blagnac  or  immediate overshoot  it was understood and taken into account at once. 

figure 1: ghost 
1 conclusion and perspectives 
we have presented an approach to detect and cure conflicts in aircraft pilots' activities. a first experiment has validated the conflict detection tool and has shown that pilots facing conflicts have a trend to persevere in erroneous behaviors. this agrees with the observations made by experts of the pilots' behaviors in real air accidents. these first results have led us to design ghost  an experimental environment dedicated to test countermeasures designed to get pilots out of perseveration. a second experiment was conducted with twenty-one pilots in this new experimental environment: it has proved the efficiency of the countermeasures to cure perseveration and has also confirmed the relevance of conflict detection. further experiments are to be conducted to go on tuning the countermeasures according to the pilots' feedback. 
　the next step is to design and implement the whole countermeasures closed-loop  i.e to remove the wizard of oz and perform an automated conflict and perseveration management. this is currently done thanks to  see figure 1 : 
  the conflict detection tool  see section 1 . 
  kalmansymbo aero   a situation tracker and predictor  tessier  1  which is based on predicate/transition timed petri nets for procedure and pilot's activity modeling. 
cognitive modeling 	1 kalmansymbo assesses the current situation thanks to the pa-
rameters received in real-time from flightgear and predicts what is likely to happen. both the current situation and the predictions are inputs for the conflict detection tool  which allows possible conflicts to be better anticipated. 
  a tool for building and sending accurate countermeasures back to the pilot via the flightgear cockpit. 

figure 1: the countermeasures closed-loop 
acknowledgments 
many thanks to olivier grisel and fabrice schwach for their wonderful work on flightgear and the wizard of oz. 

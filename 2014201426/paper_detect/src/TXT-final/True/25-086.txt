 
many ai problems  when formulated  reduce to evaluating the probability that a prepositional expression is true. in this paper we show that this problem is computationally intractable even in surprisingly restricted cases and even if we settle for an approximation to this probability. 
we consider various methods used in approximate reasoning such as computing degree of belief and bayesian belief networks  as well as reasoning techniques such as constraint satisfaction and knowledge compilation  that use approximation to avoid computational difficulties  and reduce them to model-enumeration problems over a propositional domain we prove that counting satisfying assignments of propositional languages is intractable even for horn and monotone formulae  and even when the size of clauses and number of occurrences of the variables are extremely limited. this should he contrasted with the case of deductive reasoning  where horn theories and theories with binary clauses are distinguished by the existence of linear time satisfiability al gorithms. what is even more surprising is that  as we show  even approximating the number of satisfying assignments  i.e.   approximating  approximate reasoning   is intractable for most of these restricted theories. 
we also identify some restricted classes oi propositional formulae for which we develop efficient algorithms for counting satisfying assignments. 
1 	introduction 
investigating the computational cost of tasks that are of interest to al has been argued  levesque  1  valiant  1  to be essential to our understanding and our ability to characterize these tasks and to finding knowledge representation systems adequate for them. 
    supported by nsf grants ccr-1 and ccr-1 and by darpa afosr-f1-j- 1. 
the problem discussed most extensively in this context is the problem of propositional satisfiability  the typical np-hard problem  which is of special concern to ai because of its direct relationship to deductive reasoning. many other forms of reasoning  including default reasoning  planning and others which make direct appeal to satisfiability  have also been shown to be np-hard in practice  there is a fundamental disagreement about the implications of this. there is no debate that something has to be given up: restrict the form of the statements in the knowledge base  settle for approximate output and so on. one consequence of the intensive research in that direction is the identification of restricted languages for which propositional satisfiability can be solved efficiently  e.g.. horn . 
   in this paper we consider a related problem  that of enumerating satisfying assignments of propositional formulae. we argue that the role played by satisfiability problems in many ai problems in which deduction is of special concern  is replaced by that of counting satisfying assignments when approximate reasoning techniques are used. to support this argument we show that various methods used in approximate reasoning  such a s computing degree of belief and bayesian belief networks  as well as reasoning techniques that  use approximation to avoid computational difficulties such as constraint satisfaction and knowledge compilation  can be reduced to solving enumeration problems. 
   we analyze the computational complexity of counting satisfying assignments of propositional languages  and prove that this is intractable even for horn and monotone formulae  and even when the size of clauses and number of occurrences of a variable in the formula are extremely limited this should be contrasted with the case of deductive reasoning  where horn theories and theories with binary clauses are distinguished by the existence of linear time algorithms for their satisfiability. what is even more surprising is that  as we show  even approximating the number of satisfying assignments  that is   approximating  approximate reasoning   is intractable for most of those1 restricted theories. we identify some restricted classes of propositional formulae for which we develop efficient algorithms for counting satisfying assignments while we show that our positive results can sometimes be used to find tractable languages for the approximate reasoning technique discussed  the lmplica-
	roth 	1 

tions of our fairly surprising and widely applicable hardness results are not fully clear. 
   in the next section we briefly give background material from computational complexity. section 1 summarizes and sketches the proofs of our technical results  which we put in the context of various approximate reasoning techniques in section 1. 
1 the computational complexity of counting problems 
we give in this section a brief overview of the computational complexity of enumeration problems and the related problems of approximate enumeration and random generation of solutions. for a detailed discussion consult  valiant  1a; valiant  1b; carey and johnson  1; jerrurn et al.  1 . 
   with a large number of decision problems we can naturally associate a counting problem. for example  counting the number of satisfying assignments of a boolean formula  counting the number of perfect matchings in a bipartite graph and counting the number of cycles in a 
   graph. clearly  the counting version is at least as hard as the decision problem but in many cases  even when the decision problems is easy  no computationally efficient method is known for counting their number. the class of #p was introduced by valiant.  valiant  1a  valiant  1b  in an effort to explain this phenomena. 
   in particular  is was shown that counting the number of satisfying assignments of a cnf formula as well as the counting versions of many other np-complete problems are complete for # p   but counting versions of some problems in p are also complete for # p . examples include counting the number of satisfying assignments of a dnf formula  counting the number of cycles in a graph and many other problems  valiant  1a; valiant  1b; provan and ball  1 . 
   problems that are #p-complete are at least as hard as np-complete problems  but probably much harder evidence to the hardness of problems in #p is sup plied by a result of  toda  1  which implies that one call to a #p oracle suffices to solve any problem in the polynomial hierarchy in deterministic polynomial time. this may serve also as indication that #p is outside of the polynomial hierarchy. it is therefore natural to consider the problem of approximate counting. the notion of approximation we use is that of relative approximation  karp and luby  1; stockmeyer  1; jerrurn et ai  1 . we say that m' approximates m within t iff 

   indeed  approximating a solution to a #p problem might be easier than finding an exact solution in fact  it is no harder than solving np hard problems  stockmeyer  1 . for example  there exists a polynomial time randomized algorithm that approximates the number of satisfying assignments of a dnf formula within any constant ratio  karp and luby  1; jerrurn et al.  1 . it is possible  though  for a # p complete problem  even if its underlying decision prob-
1 	knowledge representation 
lem is easy  to resist even an efficient approximate solution. an example for that was given in  jerrurn et a/.  1   and in this paper we exhibit a similar phenomena. we prove  for various propositional languages for which solving satisfiability is easy  that it is np-hard to approximate the number of satisfying assignments even in a very weak sense. 
   we note that a related class of problems of interest to ai  that of randomly generating solutions from a uniform distribution  was shown in  jerrurn et al  1  to be equivalent to randomized approximate counting  for a wide class of problems.  all natural problems considered here  e.g. finding satisfying assignments of boolean formulae and various graph problems are in this class.  it is therefore enough  from the computational complexity point of view to consider the problems of exact and approximate counting  as we do here. 





	roth 	1 

1 	reducing approximate reasoning to counting 
in this section we consider various techniques for approximate reasoning and show that in each case inference is equivalent to solving a counting problem. thus  the results in section 1 apply to all these methods. due to space limitations the techniques description and the interpretation of the results are brief. we elaborate only in the case of computing degree of belief  the underpinning of approximate reasoning  since the results there have wider implications. 
1 	degree of b e l i e f 
the inference of a degree of belief is a generalization of deductive inference  and can be used in case the knowledge base is augmented by  e.g.  statistical information  or as an effort to avoid the computationally hard task of deductive inference. 
   consider a kb consisting of a propositional theory and assume we would like to assign a degree of belief to a particular statement . this situation is natural in various ai problems such as planning  expert systems and others  where the actions an agent takes may depend crucially on this degree of belief. in  nilsson  1  it is suggested that the kind of reasoning used in expert system is the following:  we are given a knowledge base of facts  possibly  with their associated probabilities ; we want to compute the probability of some sentence of interest. ... according to probabilistic logic  the probability of a sentence is the sum of the probabilities of the 
sets of possible worlds in which that sentence is true... 
   indeed  the general .approach to computing degree of belief is that of assigning equal degree of belief to all basic  situations  consistent with the knowledge base  and computing the fraction of those which are consistent with the query. much work has been done on how to apply this principle  and how to determine what are the basic situations  bacchus  1; bacchus et al.  1 . 
   we consider here the question of computing the degree of belief in a restricted and simpler case  in which the knowledge base consists of a propositional theory and contains no statistical information1. using the above approach  all possible models of the theory are given equal weight and we are interested in the computational complexity of computing the degree of belief of a propositional formula i.e.  the fraction of models that are consistent with a propositional query. 
¡¡given a propositional theory   the probability that is satisfied    is computed over the uniform distribu-
tion on a set of n variables. 

given a propositional theory and a propositional statement the conditional probability of a with respect to 
   1this problem was considered in the first order case  grove et a/.  1  and it was shown that almost all problems one might want to ask are highly undecidable. in some cases  though  it was shown that the asymptotic conditional probabilities exist  and can be computed. the hardness results we get in the restricted just highlights the computational difficulties in the more general cases. 
1 	knowledge representation 

observation 1 computing  approximating  the degree of belief in a propositional statement with respect to a propositional theory  is equivalent to computing  approximating  the number of models of the statement. 
based on this observation  our results prove the intractability of computing and even approximating the degree of belief for restricted propositional languages such as horn and monotone formulae of bounded degree and bounded size of clauses. the observation also implies that the positive results for  e.g.  acyclic theories and theories of degree 1 can be applied directly. 
1 	bayesian belief n e t w o r k s 
bayesian belief networks provide a natural method for representing probabilistic dependencies among a set of variables and are considered an efficient and expressive language for representing knowledge in many domains  holtzman  1 . we consider here the class of multiple connected belief network  i.e.  networks that contain at. least one pair of nodes  variables  that have more than one undirected path connecting them. it has been argued that the expressiveness of these networks is required for representing knowledge in several domains  like medicine. for definitions and an elaborate discus-
sion of bayesian belief networks  the expressiveness of this representation and the type of inference one can utilize using it see  pearl  1 . 
   the general inference problem using belief network is that of calculating the posterior probability p s1 s'1   where s1  s1  is either a single instantiated variable or a conjunction of instantiated variables. the most restricted form of probabilistic inference  determining p y = t  for some propositional variable y  with no explicit conditioning information   was analyzed by  cooper  1  who proved it is np-hard. this hardness results for the exact inference problem shows that one cannot expect to develop general-purpose algorithms for probabilistic inference that have a polynomial running time and therefore there is a need to divert attention toward trying to construct approximation algorithms for probabilistic inference. our results show that this is not the case; cooper's argument can be modified and his results strengthen in the following way: we reduce the problem of counting satisfying assignments of a propositional formula  e.g.  in 1sat  to that of computing the probability that a node in a belief network is true. the results presented in section 1 imply: 
t h e o r e m 1 computing the probability that a node in a bayesian belief network is true  is complete for #p. approximating this probability is np-hard. 
the proof consists of reducing a counting problem to the inference problem  and is given in the full version of the paper. we note that based on the results in section 1  formulae from restricted propositional languages can be 

reduced to an inference problem in a similar way  resulting in even stronger results  in which the topology of the network is further restricted. recently   dagum and luby  1  have proved that even finding an absolute 
 additive  approximation of a solution to the inference problem is np-hard. 
other hand  due to the tight relations between counting satisfying assignments and the quality of the approximation  it might be worthwhile to use our positive results and investigate the question of approximating a theory by languages for which we can efficiently count satisfying assignments. 


roth 	1 

   our hardness results seem to indicate that computing degree of belief  as well as other approximate reasoning techniques  are intractable for almost all propositional languages. moreover  even an approximate computation of the probability was proved to be intractable for a wide class of propositional languages. the fact that most applications are believed to require much more than propositional calculus just highlights these computational difficulties. these results do not rule out the possibility for efficient algorithms that apply in restricted cases  as our positive results suggest; identifying more positive results and investigating how they apply to various techniques might be one direction to extend this work. 
   on the other hand  the extent to which the hardness results apply calls for a more profound investigation of the implication of these computational difficulties. 
acknowledgments 
1 am very grateful to les valiant for very helpful discussions and for his comments on an earlier draft of this paper. i would also like to thank karen darnels for her comments on earlier drafts of this paper. 

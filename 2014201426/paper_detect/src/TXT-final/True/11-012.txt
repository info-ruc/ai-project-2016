* 
     this paper describes work on the development of symbolic registration and change analysis techniques applied to the problem of the comparison of pairs of images of a scene to generate descriptions of the changes in the scene. 	unlike earlier work in change analysis  all the matching and later analysis is performed symbolically. 	we also discuss techniques for the generation of symbolic descriptions of images  both the segmenta-
tion and feature extraction problems. these techniques have been applied to several different scenes and in this paper we present the results for two of these scenes. 
introduction 
     this paper describes research toward the development of a general image understanding system. we w i l l describe a system for the analysis of pairs of images of the same scene to generate partial descriptions of the changes in the scene. we directed this work toward general 
image analysis and matching rather than toward specific  related problems such as motion or stereo analysis. 
     this work in change analysis differs from earlier computer change detection in the use of symbolic analysis of the image to detect and ex-
press the changes which have occurred. 	earlier efforts in the change analysis area  quam  1; lillestrand  1; allen et.al.  1  used correlation guided matching to establish a set of corresponding point pairs. 	these point pairs are then 
used to transform the second image so that it is precisely aligned with the first. the aligned i m ages are subtracted and changes are indicated by a large difference in the intensity value of the point in the two images. that i s   two images are processed to produce a third image which indicates possible changes. for further machine analysis of 
the changes  the change results should be represented symbolically. rather than generate a symbolic description of the difference image  which 
*this work was performed at carnegie-mellon 
university and was supported in part by the defense advanced research projects agency under contract number f1-c-1 and is monitored by the a i r force office of scientific research. 
is not always reliable  the initial matching should also be done symbolically. this use of symbolic analysis is intended to expand the class of images which can be successfully analyzed for changes compared to the class of images handled by tech-
niques depending on point to point matching and global transformations. 	past work on symbolic 
motion analysis has used completely and correctly segmented images  that is  the segmentation and recognition performed by humans  not by machines  balder  1 . we w i l l be using   r e a l   images which w i l l require the generation of the symbolic descriptions in addition to the processing 
of the symbolic descriptions. 
     there are several segmentation techniques which might be applied to a wide range of images  yakimovsky  1; ohlander  1   and we have chosen the region splitting system of ohlander. the processing starts with the pair of input images and first produces a partial or complete segmentation of these images. feature values are computed for all these segments. the features include size  location  shape  etc. the feature based description of the segmented image constitutes the symbolic representation of the image. the sym-
bolic representations of two images are compared to determine the corresponding regions in the two images  this is called symbolic registration. these results are used to guide further segmentations  to guide further registration  or to analyze changes in the regions which occurred between the 
two views  changes in color  size  location  shape  etc. . 
     we have applied this procedure on several diverse scenes: a simple house  a cityscape  satellite images  aerial images  and radar images. for each of these scenes a different task was performed. the task controls the segmentation  feature analysis  symbolic registration  and the final change analysis  price  1 . because of space limitations  we w i l l present results f r o m 
only two of these scenes. 
summary of the tasks and images 
     before any analysis is possible a task must be given and any knowledge about the images and the task must be specified. 	for a system designed to solve a specific problem  the task description and available outside knowledge are used throughout the implementation. 	but  in a more general system  such as this one  the task and knowledge 
v i s i o n - u : 	price 
1 must be expressed explicitly for each stage of the processing. this outside information w i l l be used to control the type of regions which are segmented  the portion of the image which is analyzed  which segments are matched  what change information 
is generated  and the final use of this change information. 
     the first scene is given in two views of a single house  figures la and lb . this scene is represented by full color images with about 1  1 
million pixels for each color input. 	there are originally three colors  red  green  and blue   and 
these are transformed to generate other color parameters  kender  1 . there are few real changes between these two images  so that the 
p r i m a r y task is to illustrate the operation of the segmentation  feature extraction  and symbolic registration procedures. for this task  the large  clearly segmented  regions are sufficient; thus 
there is no need to segment each individual brick. 
     the other pair is two aerial views of an urban scene  figures 1a and 1b . these images are 
monochromatic and contain about 1 million pixels each. this scene contains many  relatively small  distinct objects  and many other smaller objects. there are several global changes between the two images; objects are larger in the first image  there is a translation difference  and there is a sun angle difference so that shadows in the first image do not appear in the second image. the basic task for this scene is to analyze changes in the pier area of the scene  specifically changes in the number of ships. before this analysis can take place  the corresponding subsections of the two images must be located  therefore the entire image must be partially segmented to locate certain anchor regions which can be used to limit the area of the pier subsections. additional refinement of this area w i l l be 
necessary and can be performed by using a description of the pier area: 	piers jutting out f r o m the land surrounded by water or ships  and the land is not 
included in this final model. therefore the total processing of this scene w i l l include the segmentation of anchor regions in the two images  bright regions w i l l be used   the registration of these par-
tial segmentations  the restriction of the area of detailed analysis by using the symbolic registration results  the partial segmentation of this area to aid 
the refinement of the pier area  the complete segmentation of the refined area  and the analysis of the segmented regions to produce the desired change 
results. 
segmentation 
     our work on segmentation is an extension of the histogram guided region splitting technique developed by ohlander  1 . this method was originally developed for use on color images. basically the procedure splits a region into subregions by thresholding one of the spectral inputs. the threshold values are selected by the analysis of the histograms of the values for all pixels in the region  one histogram for each spectral input . the threshold values are selected as the upper and lower bounds of the  best separated1' peak which appears in the set of histograms. m o r e details of this basic segmentation method are given in ohlander  1  and price  1 . there are two problems in the use of this technique for the segmentation of our set of images. first  the segmentation method is much too slow to process a large set of images in a reasonably short time. second  the segmentation technique was developed for multi-spectral images and is not expected to work as well on monochromatic images. 
     planning: the first problem is solved by the introduction of  planning   kelly  1; hanson  1 . by planning  we mean the generation of an approximation for the final segmentation using a reduced version of the image and the use of this approximation as a plan to more efficiently derive the true segmentation of the image. the use of planning reduces the total time to segment the image by about one order of magnitude compared to segmentation  by this method  without planning. the plan generation is performed by the application of the basic segmentation procedure to the reduced images. an expansion procedure uses the segments generated by the planning procedure to restrict the area in the large image where the 
threshold is applied  and generates the full size seg mentation. 
	monochromatic images: 	the segment-
ation of monochromatic images required additional alterations to the initial segmentation method. the original segmentation method was based on the hope that if one spectral feature cannot provide a reasonable split of the region  then  perhaps  another color parameter w i l l . if the procedure is presented with only one spectral input  there is no other color parameter to turn to when there is only one peak in the histogram. the large monochromatic images also contain many small different objects which cause the histogram to have only one peak. this occurs because the range of intensity for each object overlaps the ranges of intensities for other objects. 
     we can introduce additional spectral-like features by the use of simple textural operators designed to show specific features such as homogeneous regions  or high contrast areas. 	we use one feature  the number of micro-edges in the 
reduction window  to indicate general homogeneous regions  rosenfeld  1 . a homogeneous region 
is one which contains few micro-edges so that these regions can be extracted by using a threshold of zero edges in a reduced image. the regions which are extracted by the edge feature are more sensitive to noise in the image  especially local 
noise such as scratches. this feature is not useful for the extraction of small detailed regions  but is useful for the extraction of general homogeneous regions. 
     many other spatial or textural operators are possible  e.g. haralick et. a l .   1 . for easy incorporation in a general segmentation method  similar to this one  the operators should produce 
image-like values for all points in the image. 
     we also used the computation of histogram for portions of the image rather than for the entire image  chow  1 . 	this was intended to approach a solution to the problem of the occurrence of many 
small similar regions in a single image. the use of partitions means that the number of separate 

v i s i o n - 1 : 	p r i c e 

objects which contribute to one histogram is re-	this section has discussed a segmentation 
duced. 	procedure  not a combined segmentation and inter-
pretation procedure as given in yakimovsky  1  
results and evaluation of segmentation: 	or tenenbaum et. al.  1 . 	this segmentation 
     figures 1a and 1b show the regions segmented procedure can be used as a component of a larger in both images: the sky  roof  lawn  four wall system to completely segment a scene before any regions  several bushes  chimney  door  shadows  other analysis is performed  to select specific 
and several regions in the window area. 	there are 	regions for further analysis  or to further analyze 
some differences in the segmentations: 	differences previously segmented regions. 
in the number and size of the bushes  different 
regions in the window and door areas  and a cloud feature extraction is segmented in the second image. these images the matching and change analysis will be per-

are segmented with the planning procedure outlined above  with the images reduced by a factor of eight in each direction. no textural properties are used in the segmentation because the color parameters are sufficient. the total segmentation required about 1 minutes  1 million instructions on a pdp-ka1  with about 1% of the time for the reduction of the images  1% for the plan genera-
tion  and 1% for expansion of the plan. an approximation of the segmentation time for these i m ages without planning can be generated by scaling the times in the planning step which depend on the image size  by the reduction factor. this gives a segmentation time of about 1 minutes  1 million instructions   but  in reality  the time required would be much greater due to the extra overhead involved in processing images which are 
too large to fit in primary memory. 
     figures 1a and 1b give the partial segmentations for the entire urban scene images  and figures 1a and 1b show the complete segmentation for the pier subsections of these images. 	because of the task description  no attempt was made to completely segment the entire image  and only the 
bright regions are extracted. there are some differences between the two segmentations: some regions in one image are not in the other image  
and some regions change shape due to the different sun angle. but  there are enough corresponding 
pairs to determine the scale and location changes and to use as anchor regions. a final refinement of the pier area  the removal of the land portion  is required before the complete segmentation is attempted. in both images the regions generated by the first segmentation step are used  shadows in the first image and water in the second. in the pier subsection segmentations  there are some obvious   e r r o r s   : single objects such as ships or piers are broken into two or more regions and multiple objects such as adjacent ships appear as single segments. these two segmentations used 
the textural measures described above  and were generated by the planning procedure with a reduc-
tion factor of four. 
     the segmentation procedure is automated  but includes provisions for operator interaction. the special case segmentation operations to generate general partial segmentations  bright regions only  homogeneous regions only  etc.  may require operator intervention. it is difficult to judge segmentation quality  except to ask if the segmentation is sufficient for the given task. the absolute formed with a feature based description  symbolic representation  of the images rather than the signal description of the image. this section w i l l 
describe the type of features which are used. 
     the features fall into several general classes: size  shape  color  including texture   and location. the exact feature measures are intended to capture some aspect of these feature classes. the measures given here are not intended to be a complete set  just an indication of the type of features which can be used. the features include: 
absolute size 
colors 
absolute location 
relative position 
neighbors 
orientation 
length to width ratio 
fractional fill 
perimeter1 /area number of pixels in the region mean of spectral parameters over the region  one for each spectral input and 
one for each textural 
measure 
location of the center of mass of the region the regions above  below  to-left  and 
to-right of the region 
the adjacent regions the orientation of the major axis of the region 
orientation independent  ratio of minor 
and major axis fraction of the m i n i m u m bounding ellipse 
filled by the region square of the p e r i meter divided by the 
area      as we implemented these features  the total computation time for all the feature measures for one image is approximately the same as the time for the segmentation of the image. this would not be the case in a more optimized implementation  since the feature computation times can easily be reduced more than the segmentation times by s i m -
ple prograrnming changes and the elimination of some generality in the implementation of feature computations. 
symbolic registration and change analysis 
earlier systems for change analysis relied on 

accuracy of the segmentation could be improved 	a correlation guided matching procedure to locate 
by the use of additional features  but this was not corresponding point pairs. the location differences necessary for our tasks. of these point pairs are used either for transform-
	v i s i o n - 1 : 	price 
1 

ing one image so that it is aligned with the other  or for depth analysis if the system uses stereo pairs  quam  1; lillestrand  1; allen et. a l .   1; levine et. a l .   1 . the aligned images are subtracted  producing a third  difference  image. this difference image must be analyzed to determine where the changes occurred  and the type of changes that occurred. special purpose systems have been built to perform these tasks  so that these apparently expensive operations are performed quickly. but  change analysis systems which are intended to operate on uncontrolled image pairs  i.e. not on stereo pairs  encounter several problems. major changes in the point of view of the observer  especially in oblique views  w i l l cause inaccurate matches when the matches depend on intensity values in a small neighborhood of a point on the edge of the object. these changes are 
difficult  if possible  to account for in a global warping of the image. 	most systems assume a  rubber sheet  warping  so that points adjacent in one image are assumed to be adjacent in the other image. 	a new object in the scene can cause s i m i l ar errors in matching  and would usually be indicated as a large difference in the subtracted image. 
     symbolic matching is an alternative technique to eliminate these problems encountered by signal based change analysis methods. since the matching for one region does not necessarily depend on the intensity values adjacent to the region being matched  the change in the relative position of objects should not reduce the chances of a correct match. the knowledge about a scene can specify that the relative position or adjacency relations w i l l change; this indicates that these features are not to be used for symbolic registration. new objects in the scene are indicated by regions in 
the second image which had no corresponding 
region in the first image  and missing objects by regions in the first image which fail to match with 
any region in the second. a symbolic change analysis system describes the changes as changes in the features of regions. thus there is no need for extensive processing of a difference image to discover the kinds of changes which occurred. many of these changes are given directly from the symbolic analysis. symbolic change analysis is composed of symbolic registration: finding the corresponding regions in the two regions  and change analysis: determining what changes in feature values occurred between the two views of 
the scene. we w i l l now discuss these two problem areas in more detail. 
     symbolic registration: the basic symbolic registration procedure computes a numerical rating for the match between any two regions in different  or even the same  images. this rating procedure combines the differences in each available feature of the two regions and produces an overall rating for the region to region match. the same procedure also produces a rating for each feature to 
feature match. the feature to feature match rating can be used for later change analysis. if the match 
is exact  e.g. when matching a region with itself  then the rating w i l l be zero  and as the match worsens  the rating decreases. 
the outside knowledge sources can indicate 
that certain features may change and thus should not be used in the matching procedure. for example  when the task description indicates that 
there are rotation differences between the two images  the matching procedure should not use the rotation dependent features  such as the absolute 
position  the orientation  the regions above  the regions below  etc. in the registration process. rather than eliminate the use of these features altogether  v/e use different strengths for the features which should remain constant and the features which w i l l change. the strengths are selected so that a bad match rating in one feature 
that should remain constant w i l l have more impact than several bad match ratings in features which may change. 
¡¡¡¡¡¡the region to region match procedure is used by the symbolic registration procedure to find the best available match for a given region. to find the region in the second image which corresponds to a given region in the first image  the symbolic registration procedure matches the region in the first image with each region in the second. the best matching region is considered to be the corresponding one. even if a region does not have a corresponding region in the other image  some region w i l l be selected as the corresponding region. this region w i l l be the most similar region  but these two regions may have differences in features which should remain constant. also  when this occurs  another region in the first image may correspond to the same region in the second image. new regions are indicated by regions in the second image which had no corresponding region in the first image  but missing regions must be confirmed by matching the regions in the second image with regions in the first. 
     change analysis: some change analysis can be performed directly on the symbolic registration results and used by the symbolic analysis proced-
ures. 	for example  in the urban images we are given  through the task and image description  the fact that there is a scale change between images. the amount of the scale change is not given by the outside knowledge  but it can be computed from the size differences found in early matches. 	this scale change is used to adjust the size measures for regions in the later matches. 	since there is a scale difference between the two images  the absolute size and location features w i l l change and cannot be used as constant features in the match-
ing operation. 	but  with the computed scale 
difference  the size feature can be used as if it is a constant feature. this use of change results can be extended to the absolute location and orientation features. these adjustments can apply only when the changes are uniform throughout the image  which is not the case when there are perspective changes as in oblique views. but  such adjust-
ments are possible to use on these types of feature changes in most aerial images. 
results and evaluation: 
vision-1: 	price      the house scene is completely segmented  therefore most regions in the first image should have a corresponding region in the second image. figure 1 shows the results f r o m the symbolic registration procedure. in this figure  the corresponding regions in the two images are given the same colors. the major regions are all matched 
to the proper corresponding region  such as the sky  roof  lawn  wall sections  bushes  shadows  etc. . the differences in the segmentations and in the size of some regions  because they are adjacent to the edge of the image  did not interfere with the symbolic registration of these images. this pair of images is very straightforward to analyze  and 
there are few opportunities for mistakes. for example  no other region resembles the sky in terms of color and location  so that this match  and many other matches  could be determined with very few features. some changes are indicated in the color parameters of most of the regions  and in the size  shape  and position features of some of the regions. 
     the full urban scene is only partially segmented so that corresponding regions in the two images are found for only a small number of the objects in the scene  figure 1 . 	the first pairs of corresponding regions were used to adjust the size and location features for the later matches. the size adjustment is 1  for the area of a region . 	the translation differences are 1 pixels 
in the   i   direction and -1 in the   j   direction. the regions labeled   b   and   m   were used for this purpose. these regions matched well even with the size and location differences. in regions   c       d     and   e     where their shapes are different  the use of the adjusted location feature in the matching is very important. some changes are found between the regions in these two images: the regions in the second image are brighter than the regions in the first image. some of the regions 
change size  shape  and location due to differences 
in segmentations  or actual differences in the bright objects. the location changes are usually induced by the size changes. 
     the pier subsections were not registered to each other because the desired changes were not changes in the features of objects  but changes 
in the number of ships. to effectively perform this final task  a recognition procedure would be required to identify the segmented regions. if the recognition procedure were given the segments which were extracted  several errors might be 
expected because of the segmentations. several ships are broken into two regions and these may be recognized as two individual ships or as no ships. also  some of the piers are broken into several pieces and some of these pieces may resemble a 
ship more than a pier. 
conclusions 
     we have presented an initial effort in the use of symbolic techniques for change analysis. the results of this work indicate that symbolic analysis can be applied to a large class of scenes by a general change analysis system. the use of a general analysis system introduces the problem of specifying and incorporating task knowledge which 
is not encountered in special purpose systems. we are not proposing that symbolic analysis techniques are the best solution to each special problem  but that symbolic analysis techniques offer a chance for 
v i s i o n - 1 : 
1 
the development of more general change analysis systems. 
     further work is still required in the area of segmentation  especially the refinement of segments and merging of segments into objects; in the area of feature extraction  especially the use of textural or spatial features; in the use of knowledge in the registration and analysis of the multiple views; and the application of symbolic 
change analysis to other tasks. 

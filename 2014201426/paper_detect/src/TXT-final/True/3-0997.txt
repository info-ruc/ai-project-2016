
belief-based programs generalize knowledgebased programs  fagin et al.  1  by allowing for incorrect beliefs  unreliable observations  and branching conditions that refer to implicit graded beliefs  such as in  while my belief about the direction to the railway station is not strong enough do ask someone . we show how to reason off-line about the possible executions of a belief-based program  which calls for introducing second-order uncertainty in the model.
1	introduction
knowledge-based programs  or kbps  fagin et al.  1  are a powerful notion for expressing action policies in which branching conditions refer to knowledge  an agent acts according to what he knows   such as  typically  ifk  then 羽 else 羽1
where k is an epistemic  usually s1  modality  and 羽  羽1 are subprograms. however  branching conditions in kbps cannot refer to possibly erroneous beliefs or to graded belief  such as in  repeatask to someone about the way to the railway station until my belief about the direction to take is strong enough . recently   laverny and lang  1  made a first step towards reasoning with belief-based programs  bbps   where knowledge modalities of kbps are replaced by graded belief modalities  whose semantics relies on belief states defined as ranking functions  which can be revised by observations and progressed by physical actions  which enables the agent to maintain his current belief state about the world while executing a bbp. note that bbps extend a restricted class of kbps  in which  a  there is a single agent   b  the agent has perfect recall and  c  branching conditions concern the agent's knowledge about the present state of the world.
﹛however   laverny and lang  1  cannot deal with offline reasoning about the effects of a belief-based program.
assume for instance that agent a is looking for the way to the railway station in a foreign town; her initial belief state is void  and she follows a plan consisting in sequentially asking to several pedestrians about the direction to follow  until she has acquired a sufficient level of certainty. assume moreover that answers  although not fully reliable  are normally correct. each time a gets a direction confirming  resp. contradicting  her current belief  this belief becomes stronger  resp. weaker . now  the assumption that answers are normally correct implies  for instance  that if a has already got 1  right  and no  left  then the next answer is more likely to be  right  again than  left : the plausibility of getting an observation depends on the current state.
﹛coping with this issue results in a natural way in secondorder uncertainty when projecting a belief state by a bbp: in our example  the agent is able to predict beforehand something like  after asking 1 pedestrians  normally i'll have a very firm belief about the direction to the station  although i cannot totally exclude the possibility that i'll have only a weak  or even a totally void belief . such a complex belief state is a belief state about  future  belief states  that is  a
﹛second-order belief state. thus  the main concern of this paper is how to do a priori reasoning about the possible states of belief produced by executing the program: uncertainty about which of these states of belief will result is itself represented as a ranking over states of belief.
﹛after recalling some background in section 1  belief-based programs are introduced in section 1. section 1 deals with complex belief states and their progression by actions and programs. in section 1 we show how to compute progression syntactically. related work is discussed in section 1.
1	background
in this section we briefly recall some notions from  laverny and lang  1 . let ps be a finite set of propositional symbols. lps is the  non-modal  propositional language generated from ps  the usual connectives and the boolean constants   and ﹠. s = 1ps is the set of states associated with ps. formulas of lps are said objective. if   ﹋ lps then mod    = {s ﹋ s|s |=  }. for a   s  form a  is the objective formula  unique up to logical equivalence  such that mod form a   = a.
﹛belief states are identified with ordinal conditional functions  ocf   spohn  1 : a belief state is a function 百 :
s 1 ↙ n  where n = n﹍{+﹢}  such that mins﹋s 百 s  = 1. 百 is lifted from s to lps by 百    = min{百 s  | s |=  }  with the convention min    = +﹢  we will use this convention throughout the paper without recalling it . 百 s  can be seen as the exceptionality degree of s. in particular  百 s  = 1 means that s is a normal state and 百 s  = +﹢ that s is totally impossible. for any   ﹋ lps  the belief state 百  is
	1	s |=  
defined by. in particular  百 
is the void belief state:  s  百  s  = 1.
﹛beliefs are expressed syntactically in a graded extension kd1g of kd1  whose language lps is defined as follows:
 a  if   ﹋ lps then b1   b1   ...  b﹢  are in lps;
 b  if 朴 and 朵 in lps then  朴  朴 ˍ 朵  朴 ＿ 朵 in lps.
﹛note that lps considers only subjective and flat formulas1. formulas of lps are denoted by capital greek letters 朴 朵 etc. while objective formulas are denoted by small greek letters   肉 etc. bi  intuitively means that the agent believes   with strength i. the larger i  the stronger the belief expressed by bi  and b﹢ is a knowledge  true belief  modality.
﹛the truth of a formula of lps in an belief state 百 is defined by:
 a  for   objective and i ﹋ n  百 |= bi  iff 百       i;
 b  百 |= 朴 ˍ 朵 iff 百 |= 朴 or 百 |= 朵;  b  百 |= 朴 ＿ 朵 iff 百 |= 朴 and 百 |= 朵;  c  百 |=  朴 iff 百 1|= 朴.
﹛thus  百 |= bi  holds as soon as any countermodel of   is exceptional at least to the degree i  or  equivalently  that all states such that 百 s    i are models of  . in particular  b1  is satisfied when all normal states satisfy    and b﹢  is satisfied when all possible states  to any degree  are models of  .
﹛an observation is a belief state 百obs  representing all we observe when getting the observation. observations can be incomplete and partially unreliable  see  laverny and lang  1  for examples . the agent revises her current belief state by an observation by combining both: the revision of 百 by 百obs is undefined when mins 百+百obs  = ﹢  and otherwise is the belief state defined by
 s ﹋ s  百  百obs  s  = 百 s  + 百obs s    min 百 + 百obs 
s
in particular  百   百obs = 百obs and  百  百   = 百 .|    where 百 .|   is spohn's conditioning  spohn  1 .
﹛a physical action 汐 is a feedback-free action  that is  it possibly changes the state of the world but does not give any feedback   defined by a transition model consisting of a collection of belief states {百汐 .|s  s ﹋ s}. 百汐 s1|s  is the exceptionality degree of the outcome s1 when performing 汐 in state s. the progression of a belief state 百1 by 汐 is the belief state defined  cf.  boutilier  1   by

﹛a positive formula of lps is a formula where no bi appears in the scope of negation. a positive conjunctive  pc  formula of lps is a formula of the form b﹢ ﹢ ＿ bn n ＿ ... ＿ b1; without loss of generality we can assume  i |=  i+1  since b﹢ ﹢ ＿ bn n ＿ ... ＿ b1 is equivalent to b﹢ ﹢ ＿ bn  ﹢ ＿  n  ＿ ... ＿ b1  ﹢ ＿  n ＿ ... ＿  1 . there is a one-to-one correspondance between belief states and satisfiable pc formulas  modulo logical equivalence : for each 百  the pc formula g 百  = 朴百 is defined as b﹢ ﹢ ＿ bn n ＿ ... ＿ b1  where n = max{k   ﹢  s such that 百 s  = k}  and for every i ﹋ n    i = form {s 百 s    i} .  note that n is finite  because s is finite and min百 = 1.  for instance  let 百  a b   = 1  百  a  b   = 1  百   a b   = 1 and 百   a  b   = ﹢  then 朴百 = b﹢ aˍb ＿b1a＿b1a＿b1 a＿b  - which is equivalent to b﹢ a ˍ b  ＿ b1a ＿ b1b. conversely  for each satisfiable pc formula 朵 there is a belief state 百朵 = h 朵  such that g h 朵   √ 朵. g 百  represents all the agent believes in 百1. we will sometimes make the following slight abuse of notation: when a pc formula 朵 is equivalent to a shorter  but not pc  formula 朵1  we write 百朵1 instead of 百朵. for instance  the pc formula 朵 = b﹢ ﹢ ＿b1 ＿b1r ＿b1r is equivalent to b1r  therefore we write 百b1r instead of 百朵.
1	belief-based programs
belief-based programs  bbp  are built up from a set of actions act and program constructors:
  the empty plan 竹 is a bbp;
  for any 汐 ﹋ act  汐 is a bbp;
  if 羽 and 羽1 are bbps then  羽;羽1  is a bbp;
  if 羽 and 羽1 are bbp and 朴 ﹋ lps  then  if 朴 then 羽 else 羽1  and  while 朴 do 羽  are bbps.
thus  a bbp is a program whose branching conditions are doxastically interpretable: the agent can decide whether she believes to a given degree that a formula is true  whereas she is generally unable to decide whether a given objective formula is true in the actual world . for instance  the agent performing the bpp
羽 = while   b1r ˍ  b1 r  do ask;
if b1r then goright else goleft
performs the sensing action ask until she has a belief firm enough  namely of degree 1  about the way to follow  whether 羽 is guaranteed to stop is a good question! .
﹛progression and revision in  laverny and lang  1  are used for maintaining the agent's current belief state while the program is being executed. however  predicting the future possible states resulting from the execution of a bbp before it has started to be executed  off-line evaluation  cannot be done in a satisfactory way. consider 羽 = ask;ask;ask;ask  consisting in asking in sequence to 1 pedestrians about the way to the station. assume that each occurrence of ask can send back obs1 = 百b1r or obs1 = 百b1 r  corresponding respectively to a pedestrian telling that the station is on the right  resp. left   taken with some limited reliability  for the sake of simplicity we exclude  don't know  answers . then all we can predict is that after doing 羽 the agent will be in one of the 1 belief states 百b1r  百b1 r  百b1r  百b1 r  百 1. the point now is that obs1 and obs1 cannot always be considered as likely as each other: for instance  we may wish to express that accurate observations are more frequent than inaccurate ones. therefore  observations should be ranked by their plausibility of occurrence given the current state and the sensing action performed. then  the projection of an initial belief state by a program results in a second-order  or complex  belief state: in our example  one would expect to obtain that after asking to two persons  then normally the agent is the belief state 百b1r or in the belief state 百b1 r  and exceptionally in the void belief state 百 . this issue is developed in next section.
1	complex belief states and progression
1	complex belief states
definition 1 let bs be the set of all belief states on s. a complex belief state  cbs  is an ordinal conditional func-
tion 米 on bs  i.e.  a function 米 : bs ↙ n such that min百﹋bs 米 百  = 1
米 is a second-order belief state expressing the beliefs  before executing some given program 羽  about the  future  possible belief states resulting from its execution.
example 1 let s = {r  r}.

is a cbs  by convention  for any belief state 百 not mentioned we have 米 百  = +﹢ ; it intuitively represents a situation where the agent expects the resulting belief state to be either 百1  百1 or 百1  these last two being normal results and 百1 being exceptional. note that 百1 = 百   百1 = 百b1r and 百1 = 百b1 r.
﹛we define 米百 as the  degenerated  cbs defined by 米百 百  = 1 and 米百 百1  = ﹢ for all 百1= 百.
﹛note that since  unlike s  bs is not finite  some cbss cannot be finitely represented. we say that 米 has a finite support iff only a finite number of belief states have a finite plausibility  i.e.  {百 ﹋ bs|米 百    ﹢} is finite; in this case we define n米  or simply n where there is no ambiguity  as max{i   ﹢ |  百 such that 米 百  = i}.
1	progression by sensing actions
consider a finite set acts of sensing actions  that send feedback to the agent  under the form of observations. each sensing action is defined by a state-dependent plausibility assignment on possible observations.
definition 1 let obs   bs be a finite set of possible observations  recall that observations are belief states . an observation model is a collection of functions
百obs .|s 汐  : obs ↙ n
for every 汐 ﹋ acts and every s ﹋ s  such that:
1. for every 汐 ﹋ acts and every s ﹋ s  minobs﹋obs 百obs obs|s 汐  = 1
1. for every obs ﹋ obs  if obs s  = ﹢ then for every 汐 ﹋ acts  百obs obs|s 汐  = ﹢.
﹛百obs obs|s 汐  is the exceptionality degree of getting observation obs as feedback when executing the sensing action 汐 in state s. this definition first appears in  boutilier et al.  1   and is similar in spirit to correlation probabilities between states and observations in partially observable markov decision processes. condition 1 expresses that there is always at least one normal observation; condition 1 is a weak consistency condition between states and observations  an observation totally excluding a state cannot occur in that state .
example 1
let s = {r  r}  obs1 = 百b1r  obs1 = 百b1 r  and let 百obs obs1|r ask  = 1	百obs obs1|r ask  = 1 百obs obs1| r ask  = 1	百obs obs1| r ask  = 1
 all other observations being impossible  i.e.  for obs 1= obs1 obs1  百 obs|s 汐  = ﹢; by convention we omit these when specifying 百 .|s 汐  . this means that accurate observations are the normal ones  whereas incorrect obervations are 1-exceptional.
definition 1 let 百1 be a belief state and 汐 ﹋ acts. given obs ﹋ obs  the plausibility of obtaining obs after 汐 in belief state 百1 is defined by
百obs obs|百1 汐  = min 百1 s  + 百obs obs|s 汐   s﹋s
the progression of 百1 by 汐 is the complex belief state prog 百1 汐  = 米 .|百1 汐  defined by: for all 百 ﹋ bs 

﹛thus  百 is all the more normal in the projected cbs 米 .|百1 汐  as there exists a normal state s and a normal observation obs  given s  such that 百 is the revision of 百1 by obs. condition 1 in definition 1 guarantees that 百1  obs is defined whenever 百obs obs|百1 汐    ﹢  which ensures that 米 .|百1 汐  is a cbs.
example 1 the figure on the left  resp. right  shows the progression of 百1  resp. 百1  by ask.
百1 :   rr: 1: 1 百1 :   rr: 1: 1 
	obs	1	
﹛﹛ r : 1   r : 1  r : 1   r : 1  百1 :  r : 1 百1 :  r : 1百1 :  r : 1 百1 :  r : 1 米 百1  = 1 米 百1  = 1米 百1  = 1 米 百1  = 1

1	progression by physical actions
in addition to sensing actions we consider a finite set actp of physical  feedback-free actions1. in section 1  the progression of a belief state by a physical action was defined as a belief state. for the sake of homogeneity  we have now to define it as a cbs: the progression 米 .|百1 汐  of a belief state 百1 by 汐 ﹋ actp is defined by  i.e. 
if
	米 	1 汐  =	﹢	otherwise
1	progression by belief-based programs
the progression of a belief state 百 by a bbp 羽 is the complex belief state 米 .|百 羽  defined inductively by
  if 羽 = 竹 then 米 .|百 羽  = 米百;
  if 羽 = 汐 then 米 .|百 羽  is defined in section 1 if 汐 ﹋ actp and in section 1 if 汐 ﹋ acts;
米 百 百 羽  = min百1﹋bs 米 百 百 羽1  + 米 百 百  羽1  
朴	then
  otherwise
  if 羽 = while 朴 do 羽1 then
if 百 |= 朴
	米 	百 羽  =	米百 百1 	otherwise
﹛if 羽 contains no while construct then this definition is well-founded  it can be proved that it results a sbs which moreover does not depend on the order in which the above rules are applied . this is not so with while constructs  since the  recursive  definition leads to a fixpoint equation whose solution  when defined  is taken to be its least fixpoint when the latter is a cbs  which is not necessarily the case: consider 百1 = 百  and 羽 = while   doask; applying the above definition leads to 米 百|百1 羽  = ﹢ for all 百  which is not a cbs. moreover  when 米 .|百1 羽  is defined  it does not necessarily have a finite support.
example 1
  米 .|百   ask;ask   =  百1 : 1; 百1 : 1; 百1 : 1 ;
  米 .|百   ask;ask;ask;ask  
=  百b1r : 1; 百b1 r : 1; 百1 : 1; 百1 : 1; 百1 : 1 ;
  羽1 =  ask;ask;if b1r ˍ b1 r then 竹 else ask . then 米 .|百  羽1  =  百1 : 1; 百1 : 1; 百1 : 1; 百1 : 1 ;
  羽1 = while   b1r ˍ b1 r  do ask. applying the definition gives a fixpoint equation whose solution is 米 .|百1 羽1  =  百1 : 1; 百1 : 1 .1
1	two particular cases
an unobservable environment consists of a set of physical actions only  acts =   .
﹛a fully observable environment is somewhat harder to define formally because of the separation between physical and sensing actions  which prevents us to say that all actions send a full feedback. to cope with this  we assume that acts contains one action sense x  for each propositional variable  which returns the truth value of x with full certainty  and we require that in a program  any physical action 汐 should be followed by all actions sense x  - which means that after 汐 and this sequence of sensing actions  the state is known with full certainty. any program of this kind is said to be admissible. the initial state is also required to be known with certainty.
proposition 1
1. in an unobservable environment  for any 百1 and any program 羽 for which 米 .|百1 羽  is defined  there exists a belief state 百 such that 米 .|百1 羽  = 米百;
1. in a fully observable environment  for any belief state 百1 and any admissible program 羽 such that 米 .|百1 羽  is defined  米 百|百1 羽    ﹢ implies that 百 is a precise belief state  i.e.  百 = 百s for some s ﹋ s.
1	progression: syntactical computation
applying progression as it is defined above has a prohibitive complexity  since it amounts at iterating over all belief states  states  and observations. in this section we give a more friendly  syntactical way of computing progression  based on a compact representation of complex belief states.
﹛so as to be able to reason about the resulting belief states  we now introduce a new family of modalities p1  p1  ...  p﹢ in addition to b1  ...  b﹢. while the bi modalities deal with uncertainty  about the current state   p1   p1  ...  p﹢ deal with second-order uncertainty  i.e.  uncertainty about the projected belief state  with respect to some program . l1ps is the language defined by:
  if 朴 is a formula of lps then for all i  pi朴 is a formula of l1ps;
  if 成 and 成1 are formulas of l1ps then 成 ＿ 成1  成 ˍ 成1 and  成 are formulas of l1ps.
like for bi modalities  we need not consider nested pi modalities  neither heterogeneous combinations of pi and bi modalities  resp. objective formulas . satisfaction of a l1ps formula by a cbs is defined by
  米 |= pi朴 iff for all 百 ﹋ bs  百 |=  朴 implies 米 百    i;
  米 |= 成 ＿ 成1 iff 米 |= 成 and 米 |= 成1
 and similarly for the other connectives .
validity  satisfiability and logical consequence are defined in the usual way. intuitively  p1朴 means that all belief states that do not satisfy 朴 are exceptional at least to the degree i.
﹛when reasoning about cbs  we are mainly concerned with inferring positive formulas - inferring negative formulas such as  pi朴 is somewhat derivative. we define a positive l1ps formula as follows:
  if 朴 is a positive lps formula and i ﹋ n then pi朴 is a positive l1ps formula;
  if 成1 and 成1 are positive l1ps formulas then 成1 ＿ 成1 and 成1 ˍ 成1 is a positive l1ps formula.
moreover  a canonical l1ps formula is a l1ps formula of the form 成 = p1朴1 ＿p1朴1 ＿...＿pn朴n ＿p﹢朴﹢  where 朴1 
...  朴n  朴﹢ are positive lps formulas1.
﹛given a cbs 米 with finite support  the canonical l1ps formula g+ 米  = 成米 associated with 米 is defined by

where n = n米 and g 百  is the canonical lps formula cor-
responding to 百  cf. section 1 .
proposition 1 for any cbs 米 with finite support and any positive conjunctive l1ps formula 成  米 |= 成 if and only if 成米 |= 成  that is  成米 is the strongest positive conjunctive l1ps formula satisfied by 米.
example 1  continued 
成米	= p1 b1r ˍ b1 r  ＿ p﹢ b1r ˍ b1 r ˍ b﹢  
√ p1 b1r ˍ b1 r 
﹛we are now in position to give a syntactical characterization of progression.
definition 1 let 朴 be a positive conjunctive lps formula and 汐 be any action. the progression of 朴 by 汐 is the canonical l1ps formula prog 朴 汐  corresponding to the
cbs 米 .|百朴 汐   i.e. 
prog 朴 汐  = g+ 米 .|百朴 汐   = 成米 .|百朴 汐 
﹛we now show how the formula prog 朴 汐  can be computed without first generating the corresponding 米.
proposition 1
let 汐 be a sensing action and 朴 = b1＿...＿bp p＿b﹢  a positive conjunctive lps formula. we define:
  for any obs ﹋ obs and i ﹋ n  肉i obs 汐 = form{s ﹋ s | 米obs obs|s 汐    i};
  xi 朴 汐 = {obs ﹋ obs |   1 ＿ 肉i obs 汐  ˍ ... ˍ   i ＿ 肉1 obs 汐  1√ ﹠};
  x﹢ 朴 汐 = {obs ﹋ obs |   ＿ 肉﹢ obs 汐 1√ ﹠};
  n is the largest integer i such that xi 朴 汐 x﹢ 朴 汐.
then
i=n
	prog 朴 汐  =  pi   	朴   朴obs 
	i=1	obs﹋xi 朴 汐
	＿p﹢ 	 	朴   朴obs 
obs﹋x﹢ 朴 汐
 where   is the syntactical revision operator  proposition 1 of  laverny and lang  1    which satisfies 朴   朴obs = g h 朴   obs .

	1	1
﹛﹛notice that canonical lps formulas are positive lps formulas in which there is no disjunction at the level of the pi modalities  but disjunctions may appear in the scope of a pi modality  and of course in the scope of a bi modality too .
example 1  continued 	let 朴	= b1r.	we get
x1 朴 ask = {obs1}  x1 朴 ask = {obs1 obs1} and for all n   1  xn 朴 ask = {obs1 obs1}. proposition 1 gives prog 朴 ask  = p1 b1r   b1r  ＿ p﹢  b1r   b1r  ˍ  b1r   b1 r   √ p1r ＿ p﹢ b1r ˍ b﹢   √ p1r.
the characterization for physical actions is much easier.
proposition 1 for any physical action 汐 and any pc lps formula .
moreover   can be computed efficiently using
proposition 1 of  laverny and lang  1 .
﹛lastly  the progression of a positive conjunctive lps formula 朴 by a bbp 羽 is the canonical l1ps formula prog 朴 羽  defined inductively as follows:
  prog 朴 竹  = p﹢朴;
  prog 朴 汐  is defined at definition 1 if 汐 is an action;
  prog 朴  if 朵 then 羽1 else 羽1  if 朴 |= 朵 otherwise
i=n
	 	 
   pi   prog  prog 朴 羽1  u 羽1  v  i=1 u+v=i+1
＿p﹢  prog  prog 朴 羽1  ﹢ 羽1  ﹢ 
  prog 朴  while 朵 then 羽1  = if 朴 |= 朵
	prog 朴 竹 	otherwise
where
1. for any canonical l1ps formula 成   成 i is the strongest positive lps formula 朵  unique up to logical equivalence  such that 成 |= pi朵 .
1. for any positive conjunctive lps formulas 朴1 and 朴1:  prog 朴1 ˍ 朴1 羽  i =  prog 朴1 羽  i ˍ  prog 朴1 羽  i.
proposition 1 prog 朴百 羽  = 成米 .|百 羽  example 1
let 羽 =  ask;ask;if b1r ˍ b1 r then 竹 else ask  and 羽1 =  while   b1r ˍ b1 r  do ask .
  prog b﹢  ask  √ p﹢ b1r ˍ b1 r 
  prog b﹢  ask;ask  √ p1 b1r ˍ b1 r .
  prog b﹢  羽  √ p1 b1rˍb1 r ＿p﹢ b1rˍb1 r 
  prog b﹢  羽1  √ p﹢ b1r ˍ b1 r 
1	related work
partially observable markov decision processes
pomdps are the dominant approach for acting under partial
observability  including nondeterministic actions and unreliable observations . the relative plausibility of observations given states  as well as the notion of progressing a belief state by an action  has its natural counterparts in pomdps. now  there are two important differences between pomdps and our work.
﹛first  in pomdps policies  branching is conditioned by the observation sequence that has lead to the current belief state; the policy is therefore directly implementable  without the need for an on-line reasoning phase. in our framework  branching conditions are expressed logically  which may allow for much more compact policies than branching on observations. in this view  bbps can be seen as high-level  compact specifications of pomdp policies  the policy being the implementation of the program . our work can thus be seen as a first step towards bridging knowledge-based programs and pomdps.
﹛second  we allow for second-order uncertainty whereas pomdps get rid of it: if pproj p|p1 羽  is the probability of obtaining the probabilistic belief state p after executing 羽 in p1  this second-order belief state is systematically reduced into the first-order one p   following the lottery reduction principle: p  s  = pp﹋pbs pproj p .p s   where pbs is the set of probability distributions on s . this is a loss of expressivity  as seen on the following example: consider the action 汐 of tossing a coin and the action 汕 of sensing it. the agent knows that after performing 汐 only  she will be for sure in a belief state where p heads  = p tails  = 1. this differs from projecting the effects of 汐;汕: then she knows that he will reach either a belief state where she knows heads or a belief state where she knows tails  with equal probability. after reduction  these two plans and their projections can no longer be distinguished - whereas our cbs do distinguish them1.
cognitive robotics
another fairly close area is that of cognitive robotics  especially the work around golog and the situation calculus  e.g.   reiter  1    which is concerned with logical specifications of actions and programs  including probabilistic extensions and partial observability.  bacchus et al.  1  gives an account for the dynamics of probabilistic belief states when perceiving noisy observations and performing physical actions with noisy effectors.  grosskreutz and lakemeyer  1  considers probabilistic golog programs with partial observability  with the aim of turning off-line nondeterministic plans into programs that are guaranteed to reach the goal with some given probability. in both works  branching conditions involve objective formulas and there is no account for secondorder uncertainty. bridging belief-based programs and the situation calculus  and golog  is a promising issue.
belief revision with unreliable observations
 boutilier et al.  1  might be the closest work to ours  as far as the dynamics of belief states in the presence of noisy observations is concerned. our notion of an observation model  definition 1  owes a lot to theirs  which also makes use of ranking functions . now  their objectives depart from ours  as they focus on a general ontology for belief revision and do not consider physical actions nor programs  nor do they give a syntactical way of computing their revision functions.
counterfactual belief-based programs
 halpern and moses  1  consider belief-based programs with counterfactuals whose semantics  like ours  is based on ranking functions. they do not allow for graded belief in branching conditions  nor unreliable observations  ranking functions are used for evaluating counterfactuals   but they allow for counterfactual branching conditions  possibly referring to future belief states  such as  if i believe that if i were not sending this message now then my partner might not get this important information  then i should send it . adding counterfactuals and beliefs about future states to our framework is worth considering for further research.
acknowledgements
thanks to the anonymous referees for many relevant and helpful suggestions.

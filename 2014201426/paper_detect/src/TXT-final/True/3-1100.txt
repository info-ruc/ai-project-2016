
we consider the problem of coordinating the behavior of multiple self-interested agents. it involves constraint optimization problems that often can only be solved by local search algorithms.
using local search poses problems of incentivecompatibility and individual rationality. we thus define a weaker notion of bounded-rational incentive-compatibility where manipulation is made impossible with high probability through computational complexity. we observe that in real life  manipulation of complex situations is often impossible because the effect of the manipulation cannot be predicted with sufficient accuracy. we show how randomization schemes in local search can make predicting its outcome hard and thus form a bounded-rational incentive-compatible coordination algorithm.
1 introduction
there are many practical settings where multiple selfinterested agents have to coordinate their actions. this coordination often involves joint decisions about resource allocation  scheduling and planning that can be formulated as constraint optimization problems. we thus extend the standard definition of constraint optimization to the multi-agent setting as follows:
definition 1 a discrete multi-agent constraint optimization problem  mcop  is a tuple   a x d c r   where:
  a = {a1 .. am} is a set of agents.
  x = {x1 .. xn} is a set of variables.
  d = {d1 .. dn} is a set of domains of the variables  each given as a finite set of possible values.
  c = {c1 .. cp} is a set of constraints  where a constraint ci is a function di1뫄..뫄dil 뫸{1} that returns 1 if the value combination is allowed and 1 if it is not.
  r = {r1 .. ro} is a set of relations  where a relation ri is a function di1 뫄 .. 뫄 dil 뫸   giving the utility of choosing each combination of values.
  ri is the subset of r that gives the relations associated with agent ai.
the solution of an mcop is an assignment of values to all variables that satisfies all constraints and maximizes the sum of agent utilities as expressed by their relations. note that variables  domains and constraints are common and agreed upon knowledge among the agents. on the other hand  relations are specified by the individual agents  and they do not necessarily have to report them correctly.
모an example of an mcop problem is allocating capacity in a public network  for example a train or pipeline network. the network is a graph of connections  and only one agent can use any one connection at a given time. this can be represented by having one variable per link and time interval whose domain ranges over the set of agents. constraints would enforce for example that successive links and times are assigned to the same agent.
모agents serve customers' transportation demands with different efficiency by using different combinations of links. thus  each agent has utilities for being able to use certain combinations of links  and reports these as relations. agents want to find a combined assignment that maximizes the sum of their utilities. such combinatorial optimization is npcomplete and thus can be solved exactly only for small problems. for large instances  in many cases only local search methods can be implemented. they can provide no optimality guarantees  but with high probability will find a solution that is very close to optimal.
모two additional considerations need to be addressed due to the multi-agent setting: individual rationality and incentivecompatibility. we say that a mechanism is individually rational if and only if it is in the best interest of each agent to participate in the mechanism  i.e if the expected utility that each agent gets when it participates in the mechanism is at least as high as if it did not. this is important because otherwise  agents may choose not to participate in the mechanism. we say that an optimization mechanism is incentivecompatible if and only if each agent maximizes its expected utility when the protocol finds the truly optimal solution. depending on the protocol  incentive-compatibility often means that each agent is reporting its relations truthfully  thus one also speaks of truthful mechanisms. clearly  incentivecompatibility is important to obtain a meaningful solution to the mcop. it is often achieved through tax or auction mechanisms such as the vcg mechanism   vickrey  1; clarke  1; groves  1  .
모the seminal work of ephrati and rosenschein  was the first to propose applying vcg mechanisms to agent coordination. for constraint optimization  game theory has shown that the only practical mechanism for incentive-compatibility in mcop is of the form of a vcg mechanism   green and laffont  1  . however  it has also been shown that vcg mechanisms require finding the provably optimal solution   nisan and ronen  1  . many practical settings of optimization problems are too large for complete optimization algorithms. we thus introduce a weaker concept of bounded-rational incentive-compatibility where manipulation is hard through computational complexity. the uncertainty created by randomized local search makes it computationally intractable to evaluate the outcome of an untruthful behavior  thus rendering it uninteresting to agents.
모this paper is structured as follows: we first present the local search framework for solving mcop and define boundedrational incentive-compatibility. we show how incentivecompatibility can be achieved in each local search step  and then address the key issue of avoiding speculation through the succession of local search steps. we report on experimental results on randomly generated network resource allocation problems that show their performance.
1 assumptions and definitions
1 local search framework
since finding the optimal solution for mcop is computationally infeasible  np-complete   in this paper we use local search algorithms  also called neighborhood search  to find good  but not necessarily optimal solutions at a reasonable computational cost. local search is widely used for solving large optimization problems. it has been particularly well studied for satisfiability problems  based on the gsat procedure   selman et al.  1  . the local search framework we assume in this paper is given in algorithm 1.
algorithm 1 local search algorithm for mcop procedure localsearch a x d c 
v 뫹 selectinitialsolution x d c  for i 뫹 1 : m do
모ri 뫹 askrelations ai v  end for repeat

agents make/receive payments according to pay
until termination condition met return v
end procedure

모the algorithm manipulates a complete assignment of values to all variables  represented as a vector v. it is initially set by function selectinitialsolution to an assignment that satisfies all constraints and could be random. the algorithm then asks each agent to state its set of relations ri  where the utilities should be relative to the initial assignment v such that the utility of all relations for the assignment v is zero. this fixes the otherwise open utility of the initial assignment which has no influence on the optimization result.
모search then proceeds iteratively by local improvements. function chooseneighbours provides a set of candidate assignments that are close to the current one and could possibly improve it. in our implementation  they are generated by randomly selecting a variable xi 뫍 x and generating all assignments that are equal to vold but assign to xi different values in the domain of xi that are consistent with the rest of vold and the constraints in c.
모in the second step of the iteration  the assignment v is updated using the function localchoice. it chooses a new assignment to optimize the combined utility according to the relations in r. it also computes a vector of payments pay that agents must make or receive in the third step of the iteration. the payments sum up to zero and the way they are derived is described in detail in section 1.
모the iteration continues until a termination condition is met  for example when there is no further improvement in the utility of all agents for some number of steps. to avoid getting stuck in local optima  the performance of a local search procedure is significantly improved by randomization   kirkpatrick et al.  1; selman et al.  1  . this means that occasionally localchoice chooses a value that may even decrease agent utility.
1 bounded-rational incentive-compatibility
the local search procedure can only work correctly if agents accurately report their utilities r. using side payments  we can create an incentive-compatible mechanism where agents are motivated to truthfully report these valuations. wellknown results in game theory   green and laffont  1   have shown that all mechanisms for mcop that are incentivecompatible  individually rational and select the optimal solution must be a kind of vcg mechanism. furthermore  nisan and ronen  have shown that a vcg mechanism requires a provably optimal solution. thus  there is no mechanism that makes local search incentive-compatible while maintaining individual rationality.
모we thus replace incentive-compatibility with a weaker notion  called bounded-rational incentive-compatibility that uses computational complexity to rule out manipulation:
definition 1  bounded-rational agent : an agent is called bounded rational if it can examine at most c states of the local search before declaring its utilities ri.
definition 1 let pt be a bound on the probability that a bounded rational agent can predict whether it has an expected utility gain from an untruthful utility declaration. a mechanism is bounded rational incentive compatible if by varying a parameter  pt can be made arbitrarily close to 1.
earlier work  such as   conitzer and sandholm  1    has proposed using np-hardness as a protection against manipulation. however  our definition goes further as it requires in almost all cases  manipulation requires an amount of computation that is beyond the means of a bounded-rational agent. any real computational agent is bounded rational for a sufficiently high c.
1 local choice step
we now consider incentive-compatibility and randomization of a single step in the local search  carried out by the function localchoice. we consider that local changes are made to an individual variable x only  but it is straightforward to generalize the mechanism to other neighbourhoods.
모we assume that the number of possible alternatives is sufficiently small so that localchoice can apply a systematic and complete optimization procedure. we call vc the current assignment to x  and let vs  be the value that would be optimal for the set of agents s  i.e. would most improve the sum of their utilities.
1 incentive-compatibility
as the local choice depends on the relations declared by the individual agents  agents would normally have an incentive to report excessive utility gains for their preferred changes so that they impose them over those preferred by others. thus  the optimal solution according to the declarations of a set of agents a  which we call va  could be different from va  . we counter this tendency by imposing side payments depending on the utility declarations and the change chosen by the mechanism.
모as already mentioned earlier  the only side payments that achieve incentive-compatibility  individual rationality and choose the optimal solution are vcg payments. for an agent ai  the vcg payment is the  damage  it does the others  i.e. the decrease in utility gain its presence causes to the remaining agents:

note that since va ai is optimized for a ai  the sum of its utilities for these agents will always be at least as large as that for va and thus the v cgtax is never negative. thus  the payments of all agents together leave a positive budget surplus.
1 randomization
randomization has first been proposed as simulated annealing   kirkpatrick et al.  1    a technique inspired from the cooling of spin glasses. more recently  it has been studied more systematically  particularly in the context of satisfiability problems. for example  the gsat algorithm   selman et al.  1   has been turned into the gwsat algorithm   selman et al.  1   by adding a random walk strategy: with some probability  the strategy forces an improvement in a clause by ignoring the other clauses that would also be affected. it has been shown that this randomization has the effect that the algorithm eventually finds the optimal solution with high probability.
모the random walk steps in gwsat leave certain randomly chosen constraints out of the local choice steps. we adopt a
모similar scheme where we randomly select a set of relations to be left out of the optimization at a local choice step. it turns out that a good way to select these relations is to take all the relations belonging to a randomly selected agent ae. as we show below  this way of randomizing allows us to simultaneously guarantee budget-balance of the vcg tax mechanism.
1 payment budget balance and individual rationality
one problem with the vcg mechanism is that agents generate a surplus of taxes that cannot be returned to them without violating the incentive-compatibility properties. this not only reduces their net utility gain  but also creates incentives for whatever third party receives this gain.
모the randomization allows us to make the vcg tax scheme budget balanced by simply paying the payment surplus to the agent ae that was excluded from the optimization step. each agent ai other than ae pays to ae the following tax:

and the mechanism chooses va ae to implement. this can be seen as compensating the agent for the loss of utility it is likely to incur as a consequence of having been left out of the optimization  and does not affect the incentive-compatibility properties:
  for agents other than ae  it is still best to report their utilities truthfully since they follow a vcg mechanism in a world where ae does not exist.
  for ae  its declarations have no effect on the outcome or payments so any declaration is equally good. however  it does not know in advance that it will be excluded  so it still has an interest to make a truthful declaration.
this mechanism is similar to the proposal in  ephrati and rosenschein  1   who proposed giving the surplus to agents that have no interest in the variable being considered. we call such agents uninterested agents. the mechanism proposed here applies even when no uninterested agent exists. when there are uninterested agents  optimization can be improved by selecting these to be chosen as excluded agents. more details on the mechanism can be found in  faltings  1 .
모in certain cases the sum of the taxes could be less than the utility loss of the excluded agent  and thus it would not be individually rational for the agent to participate. in fact  no matter what payment scheme is used  whenever the local search step leads to a reduction in total agent utility  there must be at least one agent for which individual rationality is violated. any randomized local search algorithm will occasionally make such moves  for otherwise it would be susceptible to getting stuck in local optima. thus  no scheme can guarantee individual rationality at every randomized local choice step.
모as the algorithm on the whole improves utility for the community of agents  this does not mean that the local search process as a whole is not individually rational. no agent is systematically disadvantaged by the randomization  and so in expectation the scheme is individually rational for all agents.
this is confirmed in our simulations  where individual rationality was always satisfied for all agents in all runs.
1 sequences of local choices
a local search algorithm is in general incomplete and not guaranteed to find a particular optimal solution. thus  as pointed out by  nisan and ronen  1   non-truthful declarations can drive the local search algorithm to a solution that gives a manipulating agent  ma  a better utility than the truthful declaration. however  effectively using such manipulation requires that the ma is capable of correctly predicting the effect of a non-truthful utility declaration on the outcome  and compare it against the utility loss it incurs by carrying out the manipulation in one or several local choice steps. we now show that in a randomized local search algorithm and a sufficiently large problem  with high probability  arbitrarily close to 1   such prediction would require an amount of computation that is beyond the capabilities of a bounded-rational agent.
모to obtain a worst-case result  we assume that a manipulating agent  ma  has complete and accurate knowledge of the relations declared by all other agents. furthermore  we assume that is has access to an oracle that provides it with the most promising manipulation.
모the remaining task of the ma is then to show that the manipulation actually produces a better utility than truthful behavior. as the local search algorithm is randomized  the ma can only predict an expected utility  obtained by considering the probability of certain states and the utilities that the agent would obtain in each of them. the key idea of our argument is that with high probability  the number of states that need to be considered in this calculation will grow exponentially with the size of the problem. thus  for a certain problem size it will exceed the computational capacity of a bounded rational agent.
모to show this result  we first argue that the ma has to examine a significant fraction of the probability mass of the states to ensure success of the manipulation. this fraction depends on two factors:
  the utility distribution of the problem: if only few states give a significant utility  or if there are strong symmetries so that the state space can be factored  it could be sufficient to sample only a small subset of the states  and
  the desired confidence of the prediction: since a manipulation will mean a certain utility loss to the agent in the search step where it is applied  the manipulation needs to succeed with a certain minimal probability in order to give an increase in expected utility. depending on the utility distribution  this translates to a certain fraction of the state probability mass that will need to be examined.
note that both parameters are independent of the size of the search space. thus  we can assume that the ma will have to examine a minimal number of states that corresponds to some fraction 붸 of the probability mass of the entire search space.
모next  we show that with high probability  this probability mass is distributed over a number of states that grows exponentially with problem size.

figure 1: new states discovered in successive cycles of a simulation of local search  for several problem sizes.
모the local search algorithm contains several possibilities for randomization that can make its outcome hard to predict:
  random choice of neighbourhood 
  random choice of excluded agent ae 
  random choice of equivalent local choices.
to make the effect of randomization easy to analyze  we consider only randomizations whose outcomes can be regarded as independent. this is not the case of the random choice of neighbourhood  as it will often be the case that choosing n1 and then n1 will lead to the same states as choosing n1 and then n1  thus cancelling the randomization effect. also  local search has to ensure that all neighbourhoods are considered  placing limits on the amount of randomization that can be allowed. furthermore  a manipulating agent could make declarations to create symmetries that makes the randomization ineffective.
모fortunately  for the choice of excluded agent as well as the choice among equivalent solutions  it does appear reasonable to assume independence of subsequent random choices. furthermore  since the manipulating agent's relations may be excluded  it cannot render the randomization invalid through its own declarations.
모to find the global optimum  a local search algorithm has to be able to reach the entire search space. however  eventually it will come close to the global optimum and then remain within a much smaller subspace of nearly optimal states. while it is possible to give a theoretical analysis that shows that with arbitrarily high probability  the probability of reaching any given state is bounded by an exponentially decreasing value  such an analysis requires many independence assumptions that may not hold in practice. here  we present the following experimental measurements  obtained on the experimental scenario given in the next section.
모figure 1 shows the number of new states discovered in successive cycles of a simulated randomized local search. it initially grows exponentially  but eventually search stabilizes on certain optimal outcomes and thus fails to discover new states. importantly  however  the total number of states discovered  shown in figure 1  still grows exponentially with problem size: in this example  it muliplies with a factor of about 1 whenever the size increases by 1. thus  the total

figure 1: growth of the total number of states involved in a local search simulation as a function of the problem size.
number of states has exponential growth with problem size  even though it does not reach the total state space because of the convergence of the algorithm.
모another aspect that needs to be shown is that the ma cannot limit its consideration to only certain states in this space  i.e. that the probability mass is distributed over a large subset of the states. we show this by considering the probabilities of the resulting states at each randomized step. let pm denote the probability that at a random branch  each of the branches is taken with probability at most 1/m. we have measured pm experimentally  see later section  and have obtained for example for p1 ' 1  showing that the search process has a significant branching factor. thus  with high probability the probability mass is distributed among a large number of states.
모a theoretical analysis with independence assumptions on this basis gives for example that in a local search with 1 variables  a stopping probability of 1  expected number of cycles = 1  and 붸 = 1  the probability that an agent would have to examine less than 1 states is bounded by pt   1. this is certainly well beyond the capability of any computational agent today.
모while we have so far only analyzed relatively simple models  it seems clear that in general the probability mass is very likely to be spread among a large set of states as the size of the problem increases  and thus the method will be boundedrational incentive-compatible with the parameter being the problem size.
1 experimental results
we have implemented the mechanism we described for a network resource allocation problem. it consists of allocating tracks in the train network shown in figure 1 to different operators. to avoid collisions  each arc in the graph can only be allocated to one operator who can then run trains on it. at the same time  there are certain demands for transporting goods. for each demand  1 feasible routes are computed and it can take any of these routes. this is modelled as an mcop having a variable for each task whose domain is the agent and route assigned to it. for example  if task 1  london manchester  is assigned to agent a1 on the path

figure 1: the transportation network used in the experiments

figure 1: average utility gain of different local search algorithms as a function of the number of steps.
 london 뫸 birmingham 뫸 manchester   the corresponding variable x1 is assigned the value  a1 london 뫸 birmingham 뫸 manchester .
모the network capacity is modelled by binary constraints between any pair of tasks whose routes share at least one arc that rule out assigning it to such overlapping routes but different agents. each operator has a different and randomly generated profit margin for being assigned a demand/route combination  and declares these through its relations. we randomly generated tasks and routes and simulated the problem starting from a situation where no task is assigned to any agent.
모we used the experiments to observe three properties: efficiency  branching probabilities and individual rationality. first  we want to show the efficiency of the randomized protocol with respect to straight hill-climbing to show that it indeed escapes from local minima. figure 1 compares the performance of local search with randomization  loo  shown by the thick line  with stochastic search  ss  thin line  and strict hill-climbing  ls  dashed line  on 1 randomly generated problem instances. we see that local search gets stuck in a local optimum and only reaches about half the total utility that the randomized search gets. thus  the scheme seems to be effective at avoiding local minima.
second  we are interested in the average probability pm
m1111뫟 1r m 1111table 1: computational results for pm

u1 
u1 
u1 
u1 
u1 
u1 
u1 
u1 
u1 
u1 
u total figure 1: agents' utilities during search
that a localchoice generates no branch with probability mass larger than 1/m. we thus took a histogram over 1 iterations of the number r m  that this condition is satisfied for m. table 1 shows the result for m 뫞 1. from the table  we can estimate for example p1 ' 1.
모third  we are interested in the actual utilities for each agent  and in particular whether we can guarantee individual rationality. figure 1 shows the utilities of agents during the local search process. in this experiment  we run the local search on random problems with 1 agents and 1 tasks for 1 rounds. it can be seen that the agents' net utilities are positive and stable when the number of rounds increases.
1 conclusions
finding an optimal coordination between multiple selfinterested agents is a problem that occurs frequently in practice. incentive-compatibility is an essential property to ensure meaningful results of such an optimization. previous work   ephrati and rosenschein  1   has shown the applicability of vcg mechanisms to such problems. however  it requires provably optimal solutions to the np-hard optimization problem and thus cannot be applied to large problems.
모our work is based on the observation that in real life  the potential for manipulation is limited by uncertainty and risk. this uncertainty makes it difficult for a manipulator to predict the consequences of his manipulation and thus makes attempts at manipulating it uninteresting. similar uncertainty exists in local search algorithms where randomization is necessary to escape local optima. we have analyzed a scheme for randomization and shown that in sufficiently large problems  it creates a large amount of uncertainty so that simulating a sufficient part of the possible outcomes quickly surpasses the computational capacity of any real computational agent. problems that are too small for this result to apply can likely be addressed by vcg mechanisms with complete optimization.
모note that the techniques in this paper all rely on local choices and payments and are thus very suitable for asynchronous  distributed implementation.
모an important limitation of the mcop formulation is that agents cannot claim private constraints. thus  it is impossible to model trading scenarios where an agent has control over certain variables  for example the ownership of a good.
this limitation is important because it ensures that the vcg payments never leave a deficit that would have to be covered by the excluded agent.
모while no randomized local search algorithm can guarantee individual rationality  we found that it seems to be satisfied with high probability. it would be interesting to analyze the individual rationality properties of local search schemes to obtain probabilistic guarantees similar to those for nonmanipulability.
모the most important weakness of the current scheme is that the parameter that needs to be varied to guaranteed boundedrational incentive-compatibility is the size of the problem. it would be much better if we had a mechanism that could guarantee high manipulation complexity even for small problems through suitable randomization of this choice  similarly to certain cryptographic hash functions.
acknowledgements
this work has been funded by the swiss national science foundation under contract no. 1/1.

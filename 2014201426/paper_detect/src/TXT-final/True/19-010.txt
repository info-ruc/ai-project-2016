 
 this paper describes a new parallel logic programming language designed to exploit the or- and independent andparallelisms. the language is based on conventional prolog but with natural extensions to support handling of multiple solutions and expression of parallelism. 
1. i n t r o d u c t i o n 
 pepsys  parallel ecrc prolog system  is a research project started in mid 1 in the computer architecture group of the european * computer-industry research centre 
 ecrc . its general goals are to study and evaluate new and practicable solutions to the problems of parallel logic programming. although the project aims at investigating parallel computer architectures for logic programming  it began with an attempt to define the application programmer's needs  ratcliffe and robert  1   as well as a study of existing parallel logic models  syre and westphal  1 . these considerations led us to define a high level language for parallel logic programming  which offers facilities for sequential programming  as in conventional prolog  as well as others allowing the expression of and-parallelism  orparallelism  controlled by the programmer. beside the language definition  we have also defined  a parallel computational model  and we are currently writing a compiler for the language generating a parallel intermediate-level language. this will be used for an implementation of pepsys on a commercial multiprocessor system. simultaneously  we are studying parallel computer architectures adapted to our approach. these will be evaluated by simulation. 
this paper focuses on the pepsys high level language 
 |ratcliffe and robert  1  section 1 presents the objectives of the language and compares them with other approaches. section 1 describes the main characteristics of the language  and an example showing its main features. section 1 gives results obtained by a high level interpretation of the language  combined with an evaluation of the execution of some application programs. section 1 discusses the useful extensions that are felt important but kept aside for further study. section 1 presents the current status of the activities in the pepsys project. 
 in addition to the writers of this paper  the co-authors of the work pre*ented here are max hailperin  philippe robert  and harald westphal. the pepsys project team includes also uri baron  jacques chassin de kergommeaux  bounthara lng  and donald peterson  all full time researchers at ecrc  most of whom have contributed to the definition of the language by their comments or the use of it. 
iffe and jean-claude syre 
  1 muenchen 1  west germany 
1. objectives of the language 
 in order to present the objectives of pepsys  we would first like to situate our approach among the numerous proposals under study for parallel logic languages. due to lack of space  we will restrict our short review to the most characteristic works. more on the subject can be found in 
 syre and westphal  1   gregory  1   crammond  
1  
1. c o m m i t t e d choice languages 
 historically  the committed choice language approach has received considerable attention  clark and gregory  1   shapiro  1   ueda  1  . although we do not intend to fight against this class of languages  we find it quite complementary to our own   this approach lacks at least two important features: 
  it is not really user-oriented: almost all these languages  parlog  concurrent prolog  kll  suffer from a complicated semantic definition  which is reflected in the numerous existing implementations and discussions around both the languages and their implementations. their most recent derivatives  e.g. kernel parlog  flat cp and the logix system  silverman and houri  1   or flat 
ghc have reduced capabilities in order to simplify and clarify the semantics of the guards in a clause. the or-parallelism  a very important source of useful parallelism  is somewhat difficult to handle because it is basically excluded by the principle of guards. the annotations in cp or the modes in parlog  even if they make the writing of programs not too difficult  often lead to a painful re-reading of the program. 
  it is not really implementation-oriented: this approach often leads to an explosion of processes which often bring very little parallelism for very much control and synchronization overhead. it is our strong feeling thai the user must be able to control the parallelism to avoid such situations. 
the synchronization. 
1 	architectures and languages  this class of languages seems to be well adapted to some applications such as systems programming  simulation or expression of control for numerical programming  where it is useful to have some kind of synchronization mechanisms. although different but probably aimed at the same applications is delta prolog  pereira et al.  1  in which explicit events are managed by the programmer to express 
1.   a l l solutions  	languages. 
 by contrast  another class of languages avoids implicit or explicit synchronisation constructs  and concentrates on pure parallelism  and-parallelism  or-parallelism  induced parallelism . this approach has also been addressed by many people  and at different levels: automatic parallelism detection jchang and despain  1   pure or-parallel models |ciepielewski and hausmann  1  |kumon et al.  1   more complete systems including a language like prism {kasif et al.  1   an execution model such as p1m-d  lto and masuda  1  or argonne labs anlwam  butler et al.  1 . among those works  only prism really addresses the problems from the language level to the implementation on parallel processors. 
1. objectives of the pepsys l a n guage. 
 the main objectives of the pepsys language are the result of the careful study of the existing proposals  complemented by an analysis of the programmer's requirements. as part of a much larger project involving a computational model  and execution models  with which it is totally consistent  it provides an integrated solution to the problem of parallel logic programming. this is often not the case with other approaches which only deal with one facet of the problem. let us briefly define the objectives of the pepsys language: 
  an  all-solutions  language: pepsys is targeted for non-deterministic logic computations which lead to potentially several solutions  all of them being considered useful to the user. decision making systems  and open problems often need this non determinism  simply because the  right  solution cannot be defined by the program  but only by the user inspecting the several solutions obtained from his query. 
  a language with a declarative semantics: while it is true in some cases that one knows the behaviour of a predicate and its clauses  as is necessary in parlog  for example   our approach is to retain the declarative property. our language is compatible with prolog  which may be useful when the user writes sequential portions of his program  and there are always sequential parts in a program . 
  a flexible language  both at the expression level and at the implementation level. the flexibility at the expression level is conveniently achieved only if the programmer is given enough explicit control capabilities. 
  a language to produce easy-to-write  eaay-to-read programs  with a simple syntax  and a clear semantics  even at the expense of some additional writing. punctuations and special keyboard characters are not felt the best way to express such important features as asynchronism or parallelism  especially when the program is to be updated. 
 the next section will present the language. it attempts to fulfil these objectives with three basic ideas: modularity  explicit independent and-parallelism  and user-controllable or-parallelism. 
1. the p e p s y s language 
1. modules and interfaces 
 when developing any large piece of software  imposing a modular structure on a language greatly aids compile-time error checking and analysis  particularly when compiling a small part of a very large program. pepsys modules are completely self-contained. this means that all predicates accessible from within the module must be either explicitly declared within it or else explicitly imported into it. similarly  any definitions required by other modules must be explicitly exported from the module containing the definition. 
 in order to achieve such a closed structure  two built-in predicates are used to declare inter-module interfaces: 
 - export  |exp/1   . 
 -import from  'other inodu1e.par'   imp/1   . 
 the definition of the predicate tzp/s is exported from the current module and is available for importing into any other module. the definition of the predicate imp/1  defined in the module other   module .par  is imported into the current module and therefore available for use within it. it is not possible to implicitly import predicates  other than the standard builtin predicates  since no global declaration is provided. this restricts the scope of any possible name clashes to a local module. 
 a pepsys program has two types of modules: serial and parallel. 
 serial modules contain conventional prolog code and use the the normal prolog depth first execution strategy with backtracking to select alternative clauses. the only unusual feature is that all the clauses for a predicate must be grouped together. access to any other predicates defined within other serial modules is provided directly by the declarations illustrated above. 
 access to predicates defined in parallel modules is also provided through the same interface mechanism but the actual usage of such predicates must only occur from within the built-in predicates oneof/j  bagoj/s and setof/s. the oneof predicate is used to obtain a single result  the first in time  generated by a predicate call whilst the other two collect alternative solutions from the predicate call. these three predicates will all fail on backtracking. 
parallel modules contain only the parallel pepsys language. 
this includes most of the usual prolog predicates  plus oneof/1  bagof/s and setof/s  but excludes all side-effect predicates  e.g. assert/}  retract/1  read/1  write/s  f/1 etc. . parallel modules may use predicate definitions declared within other parallel modules using the same interface declaration convention as used in serial modules. it is not allowed to import a predicate from a serial module into a parallel one and it i  not necessary to use the built-in predicates oneof  bagof and setof when using predicates defined within other parallel modules. 
 these two module types are distinguished by the file name extension used to contain their code. thus serial modules 
	ratcliffe and syre 	1 

have the extension . er and parallel modules the extension 
.par. 	this follows the approach used in ecrcprolog 
 estenfeld and meier  1 . 
 this structure separates the parallel and sequential parts of a program in a clear way. the programmer is relieved of the burden of having to imagine and manage complex interactions between asynchronous concurrent processes whilst still having access to powerful side-effect facilities. large application programs are easy to manage and comprehensive compile-time error checking is facilitated. 
1. 	a n d - p a r a l l e l i s m 
 the parallel pepsys language supports the parallel execution of independent goals. two goals are considered independent only if they have either no uninstantiated shared variables or else cannot instantiate any shared uninstantiated variables to different values*. in this way  the overheads of general and-parallelism is avoided. 
 progress has been made in automatically detecting such independent goals. however  with state-of-the-art technology  we still believe the programmer to be the best guide  particularly to decide what is worthwhile parallelism  i.e. worth the overheads . 
 goals which are independent in this sense are separated with the independent operator  #  instead of the usual comma    . this indicates to the compiler and/or runtime system that these goals may be safely executed in and-parallel mode. 
 the language places no restriction on the number of solutions each goal of an and-parallel execution produces. there are no constraints as to how parallel constructs may be nested. 
1. 	or-parallelism a n d predicate properties 
 in a parallel module  as well as being grouped together  the clauses of a predicate must be preceded by a properties declaration. this declaration contains additional information about the predicate to that expressed within the clauses themselves. this information is used to express whether it is worthwhile executing all clauses concurrently  i.e. orparallelism   whether the clause ordering is significant  and the number of valid solutions the predicate is allowed to generate. some of this information is semantic in that it reflects on the meaning of the clauses written as the predicate's definition  whilst some is pragmatic in that it is merely advice' to a compiler or runtime support system. 
property declarations have the form: 
- proper ties   l i  t  of p roper t i es   . 
 three properties are supported by the language; they are completely orthogonal: 
¡¡ this is also referred to as restricted and-parallelism in the literature. 
so 	architectures and languages 
  the solutions property   specifies whether all or only one of the solutions the predicate is able to generate are to be considered as valid. 
  the clauses property - specifies whether the ordering of clauses is significant or not. 
  the execution property - specifies whether executing all clauses concurrently is likely to be useful or not 
 it is important to note the fundamental difference in nature between the solutions and clauses properties and the execution property. the latter has no effect on the semantics of the predicate definition. it merely acts as advice to a run-time scheduler  effectively saying  if there are enough free resources  then allocate the execution of these clauses to different processes . thus  the parallelism exploited may be constrained to the resources available. 
 conventional sequential execution is also embedded in this scheme with the use of the following property declaration: 
-propert ies |solutions all   clauses ordered   execut ion laey j . 
 in this example  the solutions property allows all the solutions the predicate can generate to be considered as valid  the clauses property forces the clause ordering to be significant. that is  solutions from the first clause will be returned before any from later clauses. finally  the execution property recommends lazy execution. this invokes the usual execution mechanism of generating choice-points and backtracking to these when failure occurs. however  note again that the execution property is purely advisory; there is no observable difference to the user if the execution property had been processed as if it were eager  that is  if all clauses had been executed concurrently. the resulting solutions from different clauses would still be ordered in the sequence order of the clauses generating them  and all the solutions generated would still be valid. the only difference would be that the backtracking mechanism could have been replaced by parallel execution. in general  it is assumed that any implementation would only exploit parallelism where it is recommended to do so. 
 although there is no cut operator in the parallel language  its effect can be simulated using the solutions property. if the solutions property is defined as one  meaning that only the first solution generated in time is considered valid  then this is equivalent in conventional prolog to having a cut as the last goal in every clause. if the predicate also has the property clauses  ordered   then the solution generated must come from the first clause able to generate a solution. using this mechanism it is possible to devise a general program transformation for any prolog predicate with cuts into the pepsys language. 
1. 	a n e x a m p l e p r o g r a m 
 this now seems an appropriate point at which to look at the pepsys code for a short program. for this purpose  we will present a pepsys coding for the n queens program  see fig 1 . 

	pepsys n-queens programme 	 c  copyright borc qnbh 	*/ 
                                         muenchen 1 	*/ /* 	authors: m. j. ratcliffe and p. robert. 	*/ 
/* 	description: 	serial module of the 'n-queens' program 	*/ 
/* 	entry point: go/1 ... argument is the integer board site 	*/ 
/* 	v 
   exportf |go/l   . 	/* user entry point */ 
 - import from  'queens.par'  |get solutions/1   . 
go  site   :bagof  soln  get so 1 ut i oris   size  soln    solutions    
member s  solutions   writeln  s    fail. 
go  site  . 
	pepsys n-queens program-lie 	 c  copyright ecrc qnbh 
                                         muenchen 1 /  authors: m. j. ratcliffe and p. robert. 
/* 	description: 	parallel module of the 'n-queens' program 
/* 	entry point: get so 1 ution/1 ... called from serial module 
/* 
 -export  |get solutions/1    . 	% export entry point 
-prope r t i e s    |  . get solutions  board size  soln  :- so 1ve boardsize   j  soln . 
% accumulate the positions of occupied squares 
-propert ies   solut ions al1  clauses ordered  execut ion 1 azy     . solve bs   square bs  y  | l    square bs  y  | l  . 
so 1ve board size  initial  final  :  newsquare 1nitial  next  boardsiic   so 1ve board sile  |next | initial   final . 
% generate legal positions for next queens 
- proper ties   solutions al   clauses ordered  execution  azy    . 
newsquare  square     j  j rest j  square x  y   boardsize  :1   boardsize  x is 1 -+ 1  snint y  boardsize   not threatened i  j  x  y   # safe x  y  rest   
newsquare j   square l  x   boardsize  :- snint x  boardsize . 
% generate all possible positions for the next queen 
-properties   solutions all  c1-auses unordered  execution eager |  . s n i n t   x  x   . snint  n  np1 usoneormore   :- m is npi usoneormore - 1   m   1  snint  n  m  . 
% check whether queens on squares  i  j  and  x  y  threaten each other -properties!  solutions one  clauses unordered  execut ion lazy |  . threatened 1  j  x  y  - 1 = x. threatened i  j  x  y  - j = y. threatened l  j  x  y  - u is 1 - j  v is x - y  u = v. threatenedfl  j  x  y  - u is 1 + j  v is x + y  u   v. 
% checks whether square x  y  is threatened by any existing queens -properties   solutions one  clauses ordered  execution lazy    . safe x  y   . 
safe x  y  |square i  j  | l   :not threatened l  j  x  y   # safe x  y  l . 
	figure 1: 	a pepsys coding of the n-queens program 
ratcliffe and syre 

 this program is coded in two modules. the serial module  queens.ser  contains the user interface whilst the parallel module  queens.par  contains the parallel code. the interface between the two is provided by the get    solutions/¡ê predicate. this is called from the serial module using the bagoj/s predicate to collect all the solutions. 
 this program exploits both or- and and-parallelism. orparallelism is used to generate  and continue processing with  all the possible positions for the next queen. these are generated by the snint/1 predicate. and-parallelism is then used in the newsquare/s and safe/1 predicates to execute the validity tests on the newly generated position of the next queen in parallel. 
 it is informative to consider the property declarations of the parallel predicates a little more closely: 
  get   solutions/t. the properties are defaulted since only the solution* property is relevant and this is defaulted to all. 
  solve/s: all solutions are required but if is not worth executing the two clauses in parallel. 
  newsquare/1: all solutions are required but it is not worth executing both clauses concurrently since unification  which will mostly choose the first clause  will decide between them. 
  sntnt/b: this predicate generates the or-parallelism by generating all possible row positions in a column for a new queen. 
  threatened/1: it is only necessary to prove one condition of a false position for a queen but the tests are not complex enough to be worth parallel execution. 
  safe/1: this is a vector operation to try and find any previously placed queen threatening the newly placed one. 
1. language e v a l u a t i o n 
 any computer language is valueless without an implementation so we have written an interpreter for our language in cprolog. this interpreter can also generate an execution trace file. this file can than be interpreted by an analysis program in terms of parallel concurrently executing processes. 
 the analysis of the trace file makes several assumptions to simplify its work. it must be remembered that the purpose of this analysis is to evaluate a pepsys coding for a program rather than predict the performance on a particular system; it measures the amount of parallelism expressed by the code. the main assumptions are presented below: 
  each goal executes in one time unit 
  no overhead for process splitting 
  unlimited resources are available 
  all and-parallel goals are executed to completion 
1 	architectures and languages 
  or-parallel processes split after unification 
 the assumption of unlimited resources violates a fundamental principle of the pepsys project  namely that the amount of parallelism exploited should be restricted by the resources available. however  when investigating how much parallelism is expressed within a program and estimating what resources it could usefully utilise  this assumption is reasonable. 
 it is in fact an option that all or-paralle  processes are split after unification. the alternative is to perform unification in the child process es . this case is a little naive and results in the creation of processes which may fail after performing unification  thus wasting the overhead/ of process creation. the assumption presented here can be thought of as representing a perfect indexing scheme in /the selection of candidate clauses. the real situation lies somewhere between these extremes; we hope nearer the latter than the former! 
 using these tools  the execution of five pepsys programs was analysed. the table below summarises the results: 
+ 	+ 	+ 	+ 	+ 
| program 	| total no | maximum no j speedup | 
| name 	j of goals | of active 	| factor 	| 

1 argl 	| 
| four queens | 
| mapl 	| 
| pathsearch | | warplan 	| 
+ 	+-1 
1 
1 
1 
1 
- + - -1 
1 
1 
1 
1 1 
1 
1 
1 
1 
.. + . 	- +  the speedup factors quoted above are calculated by dividing the total number of goals executed by the execution time  which is also measured in numbers of goals . this is valid when all solutions are generated but is otherwise questionable. 
 the first program  argl  is the salt and mustard problem recoded from the original written at argonne labs. the second is a specific example of the n queens program discussed above; in this case two solutions are generated. the mapl program is an implementation of the map colouring problem; this coding follows that used in  ciepielewski et al.  1  and exhibits much or-parallelism. the path program is a simple heuristic search application implemented at ecrc. using a representation of a public transport network it generates all reasonable ways of travelling between two nodes. the network used here has only 1 nodes. the final program  warplan  is a simple re-coding of warrens original. here it is solving a block's world problem presented in the same paper. 
the graph below shows the number of concurrent processes 
 y-axis  as a function of time  x-axis  for two of the programs analysed. the solid line corresponds to the four queens problem and the dashed line to the mapl problem: 


 using the language  the programmer can tune the parallelism in his program. the effects of adjusting the granularity of the parallelism in this way is illustrated in the table below. this shows the speedup factor for a single program  a soccer team selection problem  as a function of the amount of parallelism added to the basic sequential source program: 
+ 	+ 	+ 	+ 	+ 	+ 
| amount of or-//ism | none | full | full | full | j amount of and-//ism | none | none | part | full | | execution time | 1 j 1 j 1 j 1 j | speedup factor j - j 1 j 1 | 1 | 
+ 	+ 	+ 	+ 	+ 	+ 
 another result of this preliminary evaluation of parallel programs concerns the potential dangers of not controlling the parallelism. a program can generate a large amount of parallel activities  but many of them may be just duplicates: some or branches in the program may produce the same intermediate solutions  and every parallel path generated afterwards will perform identical computations. the activation of and-parallel branches can lead to a cross product of intermediate results which are just permutations of the same subresults. in the same vein  an or-paralle  branch can lead to so many parallel computations that it would saturate any multiprocessor system. the pepsys language offers the programmer an adequate set of explicit constructs to adjust and refine his source programs in a clear and simple way. 
 we find these results encouraging in that our language does indeed lend itself to the expression of significant parallelism. it has even proved possible to get significant gains from simple translations of conventional prolog programs. 
1. proposals for language extensions 
 when coding programs  we have come to recognise tome limitations in the language. these proposals are designed to eliminate these. 
 the parallel pepsys modules are completely static in nature. whilst this presents a very clean language  it also has problems  particularly when it comes to comparing the efficiency of some prolog programs with their pepsys equivalents. this proposal provides a global dynamic database within the parallel environment with the unusual property  when compared with conventional prolog  of not guaranteeing coherence. there are three areas in which this could be useful: lemmas  avoiding repeatedly computing the same intermediate solutions   constraining the search space  heuristic rules may be dynamically adjusted to generate only reasonable solutions  and process synchronisation  a process may actively wait for another to transmit a message . 
 in some cases it is desirable to modify a particular predicate's properties for a particular call of that predicate. only modifications which do not override the basic nature of the predicate definition are allowed: 
clauses:  unordered  to  ordered  execution:  eager  to  laey  
 no modification of the tolvtioni property is necessary since the built-in predicate oneof/1 accomplishes the same function. such modifications may also be used with built-in predicates. 
 a vector relation is a relation between corresponding elements of lists  vectors  which can be executed concurrently for each set of corresponding elements. in the basic language  this is expressed by using recursion to select the list elements and executing the recursive goal call in andparallel mode. this has been identified as an important source of parallelism in prolog |ratcliffe and robert  1 . the exploitation of this parallelism is inefficient because a recursive goal call must be executed before the next vector element process can be generated. a special syntax for vector operations would save the execution time of n goals  where n is the length of the vector  and initiate the concurrent processes faster. 
 the unification between a goal and a clause head is often augmented by the execution of a few simple tests. such goals are really unification constraints and should be expressed as such. by compiling such constraints into the unification process the overall efficiency of execution will be improved. the so-called flat guarded languages essentially use guards in this manner. 
 the use of guards could be introduced in the style of pprolog at keio university. in this case guards could be used to express a predicate able to produce multiple solutions but commit execution to a single clause. currently this can only be done using multiple layers of predicates. 
1. c u r r e n t and f u t u r e w o r k on the pepsys project 
 the parallel programming language described in this paper is one activity of the pepsys project. associated with it  we have defined a parallel logic computational model. this model handles sequentiality  and-parallelism and or-parallelism  in a resource-limited environment  with as little overhead as necessary. when the resources become saturated  the potentially parallel processes are executed sequentially  and conversely  a parallel process which was forced to run sequentially may be retroactively made parallel with a minimal overhead if resources become available. this facility outperforms the existing models. it is more general than the models defined by hermenegildo  mcc  and-parallel only  or ciepielewski  s1cs  or-parallel only   or even overbeek 
ratcllffeandsyrt 

 anl  only deterministic and-paralle  branches . it uses an improved hash windows scheme for representation of data structures  and thus is more efficient than the kabu wake method  recopy of the whole state to start retroactive parallelism   and the other models mentioned above  however the anl model  also in use at s1cs and manchester university with the concept of  favored  branches  seems to be very efficient  too . 
 from the language and the model definitions  we are currently working in three areas of interest: 
  language and applications: we are writing application programs  to test the language  as well as to evaluate our global approach. the programs are adaptations of sequential ones  press  logic circuit fault finder   or they are developed from scratch with an initial parallel analysis of the problem  public transportation system adviser  tourist information adviser . 
  direct implementation on a commercial multiprocessor system. the pepsys language and the computational model are currently being implemented on a siemens mx-1 multiprocessor  similar to a sequent balance 1 system . a compiler  using the technology developed at ecrc for the ecrc compiler and for the sequential inference processor  is under test. 
  evaluation of execution models of multiprocessor systems adapted to pepsys. we are defining new architectural models adapted to the computational model. we will implement a set of simulation tools that will evaluate those models on benchmark programs written in the pepsys language. 
 further results will include the performance evaluation of the direct implementation  the simulation of new parallel computer architectures for logic programming  in our class of languages  i.e. not the committed choice class   and a revised version of the programming language. 
1. conclusion 
 in this paper we have defined the main features of a parallel logic language which covers most of the user's requirements for programming lage scale applications containing potential and and or-parallelisms  as well as sequential portions. the modularity and some built-in predicates allow for a clean  structured programming methodology  with well-defined interfaces between sequential and parallel modules. within a sequential module  conventional prolog is used  with all the facilities to interface with the user or the system. within a parallel module  a 
 predicate is written in a familiar syntax close to prolog  and augmented with a property declaration. this property declaration defines the parallel behavior of the predicate  as seen by the programmer with regard to its use in the program. it also provides some flexibility in that the programmer can tune the real parallelism he wishes to have. the explicit expression of parallelism is considered better than any other solution  since it reflects more the specification of the initial problem. some examples  most of them taken from existing sequential implementations   and their pseudo-dynamic evaluation by the interpreter  have shown a promising parallel behavior  which should be even 
1 	architectures and languages 
better in the programs whose specifications use directly the capabilities offered by the language 
 the basic language is associated with a computational model and is currently being implemented on a commercial multiprocessor system. real world  but still small  applications are being written to evaluate its capabilities. 
 we are aware that the language presented here is not the  ultimate  parallel logic language  but may be the starting point for an extended one  incorporating more tools to express other kinds of concurrency  such as those existing now in parlog  ghc  or delta prolog. in the same vein  extensions to an asynchronous data base allowing loose  chaotic synchronisation  or vector parallelism constructs  may appear useful in real applications. this will be studied in conjunction with the other work in the pepsys system at ecrc. 

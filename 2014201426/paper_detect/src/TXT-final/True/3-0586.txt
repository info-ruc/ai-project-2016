 variable ordering heuristics have long been an important component of constraint satisfaction search algorithms. in this paper we study the behaviour of standard variable ordering heuristics when searching an insoluble  sub problem. we employ the notion of an optimal refutation of an insoluble  sub problem and describe an algorithm for obtaining it. we propose a novel approach to empirically looking at problem hardness and typical-case complexity by comparing optimal refutations with those generated by standard search heuristics. it is clear from our analysis that the standard variable orderings used to solve csps behave very differently on real-world problems than on random problems of comparable size. our work introduces a potentially useful tool for analysing the causes of the heavy-tailed phenomenon observed in the runtime distributions of backtrack search procedures.
1 introduction
the conventional wisdom in systematic backtrack search is that a variable ordering heuristic should be chosen so that if a bad assignment is made  and search enters an insoluble  sub tree  the heuristic will prefer variables that have a high likelihood of proving quickly that the current  sub tree is indeed unproductive. this property of a variable ordering heuristic is often referred to as failfirstness  haralick and elliott  1 . fail-firstness can be seen as an explanation for why particular variable ordering heuristics are better than others for solving csps  and it has received considerable attention from the research community  smith and grant  1; beck et al.  1 . various ways of explaining the quality of variable ordering heuristics in terms of fail-firstness have been proposed. some authors argue that heuristics that minimise branching depth are best  haralick and elliott  1   while others argue that such a policy can cause an increase in branching factor which can have the effect of increasing the size of the resultant  sub tree  smith and grant  1 .
　a search algorithm enters an insoluble search tree either because the problem itself is insoluble  or because the current partial solution has just been extended with an assignment that cannot lead to a complete solution. in either case  the ideal is that insolubility can be proven with the least amount of effort. in this paper we will measure such effort by the number of nodes visited to prove that an insoluble  sub tree has no solution. we can evaluate variable ordering heuristics by comparing the number of nodes that they visit to prove the insolubility of a  sub problem with the minimum number of nodes required to draw the same conclusion.
by comparing optimal refutations with those generated by
mac  sabin and freuder  1   when combined with various standard variable ordering heuristics  we show empirically that there is a significant difference between the performance of heuristics on typical random problems and those found in the real world. we also suggest that small-tomedium sized random binary csps are of limited value when studying and developing variable ordering heuristics. while this has been the intuition amongst constraints researchers  our analysis shows empirically that this is indeed the case and gains insights into the nature of the difference in behaviour between randomand real-worldproblems.finally  we discuss how our results may provide further insights into the causes of the heavy-tailed phenomenon observed in the runtime distributions of backtrack search procedures. for example  by focusing on the distributions of actual and optimal refutations we can study whether heavy-tailedness is present because of the variable orderingheuristic  the value orderingheuristic  or is more fundamentally related to the structure of the problem.
1 preliminaries
definition 1  constraint satisfaction problem . we define a csp as a 1-tuple p =  hv d ci where v is a finite set of n variables v =  {v1 ... vn}  d is a set of finite domains d =  {d v1  ... d vn } such that d vi  is the finite set of possible values for vi  and c is a finite set of constraints such that each cij （ c is a subset of d vi  〜 d vj  specifying the combinations of values allowed between vi and vj  where i   j. we say that p is arc-consistent  ac  if  vk （ d vi  and  j such that cij （ c   vl （ d vj  with  vk vl  （ cij. an assignment aik =  hvi = vki represents a reduction of d vi  to {vk}   d vi . a solution to p is a set of distinct assignments s =  {al1 ... alnkn| vki vkj  （ cij}.
definition 1  search algorithm . a search algorithm Θ =  hΛ    v   vi is a combination of a branching method Λ  a consistency enforcement method    a variable ordering  v and a value ordering  v  both of which can be either static or dynamic.
definition 1  search tree . a search tree t for a problem p is a set of nodes and arcs. each node corresponds to a set of assignments  n =  {al1 ... alp 1kp 1 alpkp}  totally ordered by a dynamic variable ordering heuristic  v . the root of the search tree is a special node r =   . two nodes n1 and n1 are connected by an arc if  aij such that n1 = n1 “ aij  in which case we say that n1 is the parent of n1  and n1 is the child of n1. for every node n  its children are totally ordered by a dynamic value ordering heuristic  v.
　search trees are defined in the context of a specific search algorithm. for a particular csp instance p  and search algorithm Θ  a one-to-one mapping exists between the nodes in the search tree t and the assignments made by Θ.
definition 1  mistake point . for a soluble problem p  a mistake point m is a node identified by a set of assignments m =  {al1 ... alp 1kp 1 alpkp}  totally ordered by  v   for which  s （ s such that m   {alpkp}   s  but   s （ s such that m   s. since an insoluble problem does not admit any solutions  we define the mistake point associated with an insoluble problem as the root of its search tree.
　informally  a mistake point corresponds to an assignment that  given past assignments  cannot lead to a solution even though  in the case of a soluble problem  a solution exists. whenever the value ordering heuristic makes such a mistake  the role of the variable ordering heuristic is to guide the search out of that insoluble search tree as quickly as possible. however  it is important to realise that the actual set of mistake points encountered during search is also dependent on the variable ordering heuristic used.
　for a soluble problem p  let pm =  {vm dm cm} be the insoluble  sub problemcorrespondingto m  where vm = 
v   {vl1 ... vlp}  cm =  {cij|vi vj （ vm cij （ c}  and dm is the set of current domains after arc-consistency has been restored to reflect the domain reductions due to m. if p is insoluble  as a notational convenience  we define m =    and pm as the arc-consistent version of p. for brevity  we will refer to the insoluble  sub tree rooted at a mistake point and its corresponding insoluble  sub problem interchangeably.
definition 1  refutations . given a search algorithm Θ  a refutation for a given insoluble  sub problem pm  rooted at mistake point  m  is simply the corresponding search tree tm. we will refer to |tm|  the number of nodes in tm  as the size of the refutation.
we study the refutations found using a version of mac
that uses ac-1  mackworth  1  for consistency enforcement and selects values randomly. our goal is to determine how close to optimality are the refutations obtained when well known variable ordering heuristics  with randomly broken ties  are substituted for  v . for each heuristic  v we first collect the mistake points it generates when using mac  note that each variable ordering heuristic will generate a different set of mistake points . when we analyse mac in conjunction with a certain  v on a mistake point m  we will refer to the refutation for the  sub problem pm as the actual refutation. we will contrast the actual refutation with the optimal refutation for pm  obtained by replacing  v with a new variable ordering heuristic such that |tm| is minimised.
　sometimes  rather than using the optimal refutation  we compare against the quasi-optimal  defined as the smallest refutation whose depth does not exceed that of the actual. by selecting variables based on a depth-first traversal of the tree of minimum size  causes mac to generate the smallest possible search tree proving insolubility for pm. in our experience it is extremely rare that the quasi-optimal refutation is larger than the optimal. by accepting quasi-optimality we can use the depth of the actual refutation as an upper bound  dramatically speeding-up search for better refutations.
definition 1  improvement ratios . for a given mistake point  the refutation improvement ratio is the ratio between the size of the actual refutation and that of the optimal refutation. the overall refutation improvement ratio is simply the ratio between the total number of nodes in all the actual refutations and the total number of nodes in all their corresponding optimal refutations encountered when finding the first solution or proving insolubility.
1 analysing refutations
our focus here is only on how a variable ordering heuristic behaves when trying to prove insolubility for a  sub problem. we are not interested in focusing on how often a variable ordering heuristic enters an insoluble  sub tree. therefore  our analysis is centered around finding optimal refutations for all the mistake points in a search tree. unfortunately  this is a herculean task  as we have to search through all the possible permutations of assignments  i.e. consider all possible search trees rooted at each mistake point. without clever optimisations  this would not be feasible for anything but the tiniest problems.
1 basic algorithm
given a problem instance  a search algorithm  mac in our case  and the variable ordering heuristic to be evaluated  we begin by searching for a solution  with the goal of identifying all the mistake points. the mistake points represent the roots of the insoluble  sub trees the search algorithm happens to encounter before finding the first solution. for each such mistake point we compute both the actual refutation  by rerunning mac on the current  sub problem using the heuristic we are evaluating  and the optimal refutation  by considering all the possible permutations of assignments to the variables involved in that  sub problem. note that insoluble instances are just a special case where the only mistake point is before the first assignment. furthermore  when analysing insoluble problems  it is important to realise that the optimal refutation is independent of the heuristic used; in other words no other ordering could possibly prove insolubility more quickly.
　both the search algorithm with the variable ordering heuristics being analysed and the exhaustive search for the optimal refutation use the same method of enforcing consistency  ac in our case . failure to do so would make the refutation improvement ratio a function of both the variable ordering and the level of consistency enforced  thus being detrimental to our goal of analysing variable ordering heuristics.
　the version of mac that we use employs k-way branching  smith and sturdy  1   rather than binary branching  so that selecting a variable vi creates |d vi | branches in the search tree. thus  we make sure that refutation sizes are not influenced by the value ordering. 1 optimisations
there are a number of optimisations that we have applied.
　firstly  we can easily maintain an upper bound on the size of the optimal refutation by initially setting it to the size of the actual refutation  then updating it as smaller refutations are found. therefore the search for the optimal refutation can be implemented as a branch-and-boundprocedure.
　secondly  we can improve the search by looking ahead to avoid choices that cannot improve on the current smallest refutation. whenever a variable vi is selected at a certain depth all the values in its domain have to be tried  and they all have to fail for the current  sub problem to be proved insoluble. consequently  we know that by selecting vi  the size of the current partial refutationwill increase by at least a number of nodes equal to |d vi |. we call this a 1-level look-ahead.
　by temporarily assigning to vi  in turn  every value v in its domain  and by attempting to restore arc-consistency after every such assignment  we can associate with each v a minimum contribution to the size of the refutation. if the assignment makes the subproblem arc-inconsistent  v's contribution will be 1  given by the node corresponding to the assignment itself. however  if arc-consistency can be restored after the assignment  at least one more variable will have to be considered before the current subproblem can be proved insoluble. therefore  v will carry a minimum contribution equal to the smallest domain size amongst all the remaining unassigned variables. we call this a 1-level look-ahead.
　in general  vi's selection would increase the size of the current partial refutationby at least the sum of the minimumcontributions of all the values in its domain. if that would cause the current partial refutation to exceed the size of the smallest refutation found so far  vi will be skipped at the current depth. this dramatically reduces the search space and brings reasonable size problems within reach.
1 experiments
the basic experiment we run is this: for each variable ordering heuristic we first find all the mistake points that mac visits when finding the first solution or proving insolubility; for each mistake point  we find mac's actual refutation  still with the same heuristic ; using the size of the actual refutation as an upper bound  we find the  quasi- optimal refutation. this approach was adopted because different variable orderings generate potentially different sets of mistake points.
　we have performed experiments1 on random binary problems  various instances of the n-queens problem for varying values of n  and a subset of the rlfap celar scen1  cabon et al.  1 . we have studied the following dynamic variable ordering heuristics: min-domain  haralick and elliott  1   max-degree  min domain/degree   bessie`re and regin  1   and brelaz  bre＞laz  1 ; their corresponding anti-heuristics; and random variable selection. these are regarded as the standard general-purpose variable ordering heuristics used in the csp literature. ties were broken randomly. throughoutour experiments we have used a dynamic random value ordering.
　note that for heuristics we report the optimal refutations for random problems and n-queens  and the quasi-optimal refutations for rlfap. for anti-heuristics we always compute quasi-optimal refutations. while the true optimal refutations for rlfap may be smaller than those reported  based on our observations the difference is not significant. limiting the search to quasi-optimal proofs allowed us to gather significantly more data for this problem.
1 random and n-queens problems
due to the extreme computational requirements of the search for optimal refutations  we had to limit our experiments to random problems with 1 variables and uniform domain sizes of 1 values. we generated 1 instances for each tightness point using a random problem generator that conforms to the model-b specification  gent et al.  1 .
　we selected instances at the highest peak of difficulty for these problems  found to pass through a plane corresponding to density 1. tightness was varied along this plane. specifically  we identify a distinct tightness at which we move from generating a set of problem instances that are all soluble to generating instances that are all insoluble. in figure 1 this transition occurs at a tightness of 1. we indicate the range of tightness for which all problems were soluble  resp. insoluble  with a  high   resp.  low   line.

fig.1: mean overall improvement ratios  y-axis  for random problems as a function of tightness  x-axis . heuristics  anti-heuristics  are in the top  bottom  plot. median plots are virtually identical.
　in figure 1 we present the results associated with each of the variable ordering heuristics studied. note that we are not ranking heuristics  but are simply studying how close their actual refutation sizes are to optimality. the overall refutation improvement ratio peaks at 1 for min domain/degree  at a tightness of about 1  meaning that for the set of mistake points encountered when solving these problems using min domain/degree  there does not exist a variable ordering that could decrease the number of nodes in the corresponding refutations by more than that factor  on the average. since at the peak of difficultyprovinginsolubilityaccountsfor most of the time spent in search  this result suggests that no improvement in the ordering of variables  for the problems we have studied  would ever lead to an order of magnitude speedup. indeed  in the soluble region we can see that at best we can hope to halve the time taken by max-degree. in theory  however  for soluble problems heuristics could do better by failing less.
　once we move through the phase-transition to insoluble problems  all heuristics offer improvement ratios less than 1 for max-degree and less than 1 for all other heuristics  except random. in the case of min domain/degree  we see that when using mac at the peak of difficulty the ratio is approximately 1. this is an interesting result since is demonstrates that for proving insolubility no variable ordering heuristic exists  for these problems  that can improve upon min domain/degree  by more than a factor of 1 at the peak of difficulty.
　figure 1 presents a plot of the distribution of actual refutation sizes against optimal  per mistake point  for the random and min domain/degree  variable ordering heuristics. of interest here is the apparent linear relationship between actual versus optimal refutation size. a similar linear relationship was observed for all other heuristics and anti-heuristics studied. when we discuss the performance of variable ordering heuristics on a real-world problem in the next section we will see that this linear relationship does not hold and that for very large refutations found by a heuristic  the optimal refutation can be many orders of magnitude smaller.

fig.1: refutation sizes for mistake points in random problems when using random and min domain/degree  variable orderings: actual  yaxis  as a function of optimal  x-axis .
　the performance of a random variable ordering is of comparable quality to that of a good variable ordering heuristic in this problem class. from figure 1 we see that the improvement ratio of the random heuristic is approximately 1 at the phase transition  close to that of standard heuristics.
　finally  in figure 1 we present  for each variable ordering heuristic  the distribution of insoluble  sub trees in the dataset as a function of the improvement ratio. we see that almost all ratios were close to 1  meaning that almost all of the time the standard variableorderingheuristics performedveryclose to perfection.we also see that for the random orderingheuristic ratios of 1 are found less that 1% of the time and that there does not exist a single insoluble  sub tree that provides an opportunity to make improvements of more than an order of magnitude over current heuristics.
　in experiments performed over a large data-set of insoluble subtrees generated from problems ranging from 1 to 1 queens we have observed similarly small refutation improvement ratios for n-queens  only slightly bigger than those observed for random problems. also  the linear relationship between actual and optimal refutationsize was observed as well as a similar distribution of ratios.

fig.1: probability of an insoluble  sub tree in the data-set for random problems  y-axis  having an improvement ratio greater than a certain value  x-axis .
1 rlfap celar scen1
the small improvement ratios obtained for random problems and n-queens  and estimated in  li and ge＞rard  1  for hard random unsatisfiable 1-sat  do not seem to hold for real-world problems. a popular benchmark for binary csps  rlfap celar scen1 was an obvious candidate for our analysis. unfortunately  at 1 variables  we could not analyse the entire problem. instead  we extracted a subset of the original problem made up of 1 variables that were part of the backdoor set  williams et al.  1  over which mac backtracked while solving the original problem. we analysed all the mistake points found when solving this subset of rlfap over 1 times for all variable ordering heuristics.
　refutation improvement ratios of 1 and over were observed  even when using the best heuristics  as seen in figures 1 and 1  while they were non-existent for random and nqueens problems. comparing figures 1 and 1 we can clearly see that heuristics behaves very differently on this problem than on the random problems presented earlier. specifically  we can see that actual refutations correlate very poorly with quasi-optimal and that no linear relationship exists; note that a log-scale had to be used on the y-axis of the left plot in figure 1 due to the spread of actual refutation sizes for each quasi-optimal point on the x-axis.
　however of particularinterest in this problemis the pattern we observe in figure 1. while the vast majority of refutations

　　　　　 1 1 1 1 1 1 fig.1: refutation sizes for mistake points in the rlfap data-set when using random and min domain/degree  variable orderings: actual  y-axis  as a function of quasi-optimal  x-axis .
offer small improvement ratios  it is possible to find subtrees on which the standard heuristics perform very poorly. for example  we can see that in a small number of subtrees maxdegree did 1 times worse than quasi-optimal  while the other heuristics  except min domain/degree   sometimes did 1 times worse than quasi-optimal. clearly  the behaviour of standard variable orderings is significantly different on realworld problems than on the random problems that many researchers use as a basis for studying these heuristics. in the case of a random variable ordering  we observed a very small number of subtrees where the refutation found was more than a factor of 1 worse than quasi-optimal  and that in the vast majority of cases it performed more than an order of magnitude worse than quasi-optimal.

fig.1: probability of an insoluble subtree in the rlfap data-set  yaxis  having an improvement ratio greater than a certain value  xaxis .
　therefore  our standard heuristics behave very differently  indeed much worse  on real-world problems than on random and n-queens problems. in particular  they can be less robust in the sense that they can sometime waste significant amounts of time finding refutations for insoluble  sub trees that are far worse than optimal.
1 discussion
it is clear from our analysis that the standard variable orderings used to solve csps behave very differently on realworld problems than on random problems of comparable size  which are frequently used to study the performance of heuristics in the research literature. our results demonstrate that there are considerable opportunities to improve search performance on real-world problems. some researchers have already begun developing the necessary infrastructure needed to study real-world problems in a systematic way  gomes et al.  1; walsh  1; walsh  1 . there have also been some recent successful results demonstrating that one can benefit considerably from developing variable ordering heuristics that can exploit characteristics one encounters in real-world problems  boussemart et al.  1; dubois and dequen  1; refalo  1 .
　it is not known whether the linear relationship between actual and optimal refutations is preserved as the size of random problems increases. recent work on studying the performance of variable ordering heuristics on very large csps has shown that there can be orders of magnitude differences betweenheuristics  bessie`re et al.  1 . however those results do not contradict the results presented in this paper with respect to the relative performanceof standard variable orderings on random and non-random problems.
　our analysis is related to the work of li and gerard on studying the limits of branching heuristics for random 1-sat  li and ge＞rard  1 . however  our interests here are in studying the limits of variable ordering heuristics in a constraint satisfaction context. furthermore  our analysis is capable of finding exact optimal refutations  rather than approximating them  and focuses on the differences observed between random and real-world problems. our work is also closely related to the theoretical analysis of proof complexity for satisfiability and constraint satisfaction  beame et al.  1; mitchell  1 .

fig.1: probability of an insoluble subtree in the rlfap data-set  yaxis  being greater than an optimal/actual  top/bottom  refutation of a given size  x-axis .
　in this paper we introduce a potentially useful tool for analysing the causes of the heavy-tailed phenomenon observed in the runtime distributions of backtrack search procedures  gomes et al.  1 . figures 1 and 1 show  for rlfap  a very small percentage of insoluble  sub problems for which standard variable ordering heuristics will find refutations that are significantly larger than optimal  leading to a long runtime. furthermore  it is also interesting to note from figure 1 that the vast majority of actual refutations are very close to being optimal  with the exception of those found with a random variable ordering heuristic.
　gomes et al.  report a high correlation between the distribution of the depth of mistake points and the runtime distribution  e.g. the presence of heavy-tails. we can further extend this analysis by also considering the size of optimal refutations rooted at these mistake points. this may provide a
　way of isolating the causes of heavy-tailedbehaviourby making a distinction between the effects of the algorithm and its components  propagation method  variable and value orderings   versus the effects of the inherent structure of the problem  walsh  1; walsh  1 . as part of our future work in this area we will study optimal refutations for problems that are well known to exhibit heavy-tail behaviour.
1 conclusions
in this paper we have proposed a novel approach to empirically looking at problem hardness and typical-case complexity by comparing optimal refutations with those generated by standard search heuristics. we have compared refutations of insoluble  sub trees found using well known variable ordering heuristics combined with a standard csp search algorithm against optimal refutations. our results show that there is a significant difference between the performance of heuristics on typical random problems and those found in the realworld. we suggest that small-to-mediumsized random binary csps are of limited value to constraints researchers and introduced a potentially useful tool for analysing the causes of the heavy-tailed phenomenon observed in the runtime distributions of backtrack search procedures.
acknowledgments
this material is based on work supported by science foundation ireland under grant 1/pi.1/c1. we would like to thank barbara m. smith  eugene c. freuder  nic wilson  chris beck  bart selman  carla gomes and susan epstein for their comments and suggestions  and to john morrison and the boole centre for research in informatics for providing access to their beowulf cluster.

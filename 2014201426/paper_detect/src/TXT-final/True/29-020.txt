 
current machine learning and discovery techniques focus on discovering rules or regularities that exist in data. an important aspect of the research that has been ignored in the past is the learning or discovering of interesting holes in the database. if we view each case in the database as a point in a it-dimensional space  then a hole is simply a region in the space that contains no data point. clearly  not every hole is interesting. some holes are obvious because it is known that certain value combinations are not possible. some holes exist because there are insufficient cases in the database. however  in some situations  empty regions do carry important information. for instance  they could warn us about some missing value combinations that are either not known before or are unexpected. knowing these missing value combinations may lead to significant discoveries. in this paper  we propose an algorithm to discover holes in databases. 
1 introduction 
current machine learning and machine discovery techniques mainly focus on finding rules or formulas in data. they typically analyze each case  or tuple  in the database to induce or discover regularities that exist in the data cases. for example  a typical classification rule learning system  e.g.  c1 
 quinlan  1   induces a set of characteristic descriptions  or classification rules  from the cases in the database for some given classes. a clustering system  e.g.  cobweb  fisher  1   groups cases in the database into various similarity classes and derives a concept hierarchy. a scientific discovery system  e.g.  bacon  langley et al.  1   typically discovers  among other things  mathematical formulas that fit the data. in this paper  we show that an important aspect of the research that has been ignored in the past is the discovering of large empty areas  or holes  in databases. if we view each case  or tuple  in the database as a point in a k-dimensional space  then a hole is simply a region in the space that contains no data point. in a continuous space  there always exist a large number of holes because it is not possible to fill up the continuous space with data points. the 
1 	learning 
existence of large holes is  however  mainly due to the following two reasons: 
1. the data cases collected are insufficient  resulting in some regions having no data point. 
1. certain value combinations are not possible. for example  in a particular domain  we have a database with two continuous attributes x and y. both x and y can take values from 1 to 1. however  when x   1  y is always less than 1. in other words  there exists an empty area  i.e.  a rectangular region defined by 1   x   1 and 1   y   1. 
clearly  learning or discovering associative relationships 
 e.g.  rules  formulas  etc.  that exist in data is important. in this paper  we argue that discovering the missing associations is also significant. for example  in a disease database we may find that certain symptoms and/or test values do not occur together  or when a certain medicine is used  some test values never go beyond certain range. discovery of such information can be of great importance in medical domains because it could mean the discovery of a cure to a disease or even some biological laws. 
　it must be stressed that in many applications  producing the discovered rules alone does not provide the user with the complete information. for example  a particular organization has used a learning system to generate a set of rules from their database. one of the rules is: 
if compy size   1 then service = yes. 
this rule says that if the compy size  company size  is greater than 1  the company uses the service provided by the organization. assume the company size is partitioned into 1 categories. a close inspection of the database may reveal that no company  whose size is in the range of 1  uses the service. hence  there is a hole in the data. realizing the existence of this hole may lead this organization to probe into the possibilities of modifying its service or of doing more promotion to attract the medium size companies to use its service. in the case of one dimensional dataset  discovering the hole is simple. however  when the number of dimensions increases  the problem quickly becomes rather complex. to the best our knowledge  there is no existing technique that is able to perform this task. this paper proposes such a technique. 
   in general  a database contains a large number of holes because each case in the database is only a point in a kdimensional space. even if each attribute takes discrete or 

nominal values  it may be still quite difficult to fill the whole space. however not all holes are interesting. most of them are not. the following types of holes are not interesting: 
1. small holes: they exist because there is only a limited number of cases in the database. 
1. known impossible value combinations: they exist because certain value combinations are not possible and this fact is known previously. 
however  certain types of holes can be of great importance: 
1. holes that represent impossible value combinations that are not known previously. 
1. holes that indicate that the data collected within those areas are insufficient. 
1. holes that are suspected by the user and need confirma-
.tion. 
this paper proposes an algorithm that is able to find the holes in a k-dimensional continuous space  and sort them according to their sizes. 
1 	preliminaries 
the database that our algorithm works with is a normal database  which consists of the descriptions of n cases in the form of tuples. each case in the database is described by w distinct attributes  a1 ...  ai ...  aw  so that in an instantiation of case description  an attribute ai takes on the value v  e domain ai . some attributes take continuous or ordinal values  and we call these attributes continuous attributes. other attributes take nominal values  and we call them discrete/nominal attributes. 
　since the focus of this paper is on the space formed by continuous attributes  the proposed algorithm only uses the continuous attributes in its discovering process. in many situations  the user may not be interested in the holes that exist in the whole database  but only a segment of the database that satisfies certain requirements. then  some preprocessing can be performed to extract the segment of the database. assume the resulting segment of the database has k continuous attributes. the user then needs to specify the bounding  minimum and maximum  values for each attribute  denoted by mini and maxi for 1   i    k. with these attributes and their bounding values  a it-dimensional continuous space s is defined  within which the data tuples  or points  in the segment of the database are contained. 
   in theory  a hole can be of any shape. in this paper  we restricts the shape to hyper-rectangles  holes of this shape are easily understood by the user . in particular  we are interested in the so-called maximal hyper-rectangles  mhr . 
definition: given a it-dimensional continuous space 1  where each dimension i  1    i    k  is bounded by a minimum and maximum value  denoted by mm  and maxi . there exist n n n  data points  or tuples  in s. a maximal hyper-rectangle  mhr  is an empty hyper-rectangle that has no data point within its interior and has at least one data point on each of its 1k bounding surfaces. we call these points the bounding points of the hyperrectangle. each side i of the mhr is parallel to one axis of 1 and orthogonal to all the others. 
the number of mhrs in a continuous space can be huge. however  we are only interested in those mhrs that are sufficiently large  or significant . the user can specify how to measure the size of a mhr and what size is considered sufficiently large. these are all application dependent. a simple way of measuring the size of a mhr is by its volume. as for what size is considered sufficiently large  we may use a threshold volume or a minimal length for each side of the mhr  or a combination of both. 
　our objective is to find all the mhrs in the user-specified k-dimensional continuous space that satisfy the sufficiently large criterion and to rank them according to their sizes. 
1 the proposed algorithm 
1 	overview of the algorithm 
the main idea is as follows. given a k-dimensional continuous space s  and n points  or data cases  in s  we first start with one mhr  which occupies the entire space s. then each point is incrementally added to s. at each insertion  we update the set of mhrs that have been found this far. the update is done as follows. when a new point is added  we identify all the existing mhrs that contain this point. these hyper-rectangles are no longer mhrs since they now contain a point within their interiors. using the newly added point as reference  a new lower and upper bound for each dimension are formed to result in 1 new hyper-rectangles along that dimension. if these new hyper-rectangles are found to be sufficiently large  they are inserted into the list of existing mhrs  otherwise they are discarded. 
1 	the details of the algorithm 
given a point x  we denote x i  as the value of x along the ith dimension. a mhr  h  is denoted as: 

where li  and ui  are respectively the sets of lower and upper bounding points of h along the ith dimension. note that the lower  or the upper  bound of h is bounded by a set of lower  or upper  bounding points  rather than a single value. let t denote a data structure that stores a collection of mhrs  and t supports the following functions: 
1. insert t  h : it inserts the mhr h into t. 
1. deleted  t h : it deletes the mhr h from t. 
1. containmentsearch t  x : it returns a list of mhrs from t that contain the point x. 
the data structure t can be implemented by first transforming the mhrs into 1k-dimensional points  preparata and shamos  1  and then storing them in a pseudo 1k-d tree  overmars and leeuwen  1 . 
we also define a function bigenough h  which returns 
true if the mhr h is considered to be sufficiently large  or significant . note that bigenough   must satisfy the following: if bigenough h'  is true  then bigenough h  must be true for all h that contain h'. 
for simplicity of notation in the algorithm  we let s/i  and 
sui  for each dimension i  to be  points   where sli  i  = mini   
	liu ku  & hsu 	1 


1 	learning 


	liu ku  & hsu 	1 

1. show that those mhrs in t not containing x will not be affected  which justifies the use of the function containmentsearcho . 
1. show that those mhrs in t containing x will not be maximal anymore  which justifies why they are deleted . 
1. show that the new mhrs must be inside the union of the mhrs found by containmentsearchi   which justifies why the new mhr are generated only from these mhr found . 
1. show that the new mhrs must touch x and all possible mhrs that touch x will be reported  which justifies the way the new mhrs are constructed . 
1. show that no identical mhrs can be generated using this algorithm  which justifies why we do not check for duplicates . 
a final point is that in our algorithm  the newly generated 
mhr is always contained within the mhr from which it is derived from  hence it is safe to discard any mhr that is not accepted by bigenough    by the definition of bigenough   . with this  the correctness of the algorithm findmhr is proved. 

periments on 1 different datasets. the lower and upper bounds for x and y in all the three datasets are 1-1 and 1-1 respectively. the bounds for z are 1.1  1-1 and 1-1 respectively for the three datasets. the planted empty areas are of the same size  1  1 and 1 along x  y and z dimensions respectively. table 1 summarizes the run time results of the three datasets  running on digital alpha 1 under normal loading conditions . note that t  which stores all the mhrs  is currently implemented as a linked list. 
table 1. results of the first set of experiments. 

　column 1 indicates the dataset number. column 1 shows the number of data points in each dataset. column 1 gives the 

1 	learning 

running times for finding all the mhrs that satisfy the minimal length requirements along the 1 dimensions. this column is further divided into two sub-columns. one of them shows the running times when the minimal lengths along x  y and z dimensions of the mhrs are 1  1 and 1 respectively  i.e.  the bounds used by bigenoughq . the other shows the running times when the minimal length is reduced by half along each dimension  i.e.  1-1 . column 1 gives the number of mhrs discovered by the algorithm in each of the two situations. from the table  we see that when the minimal size of the mhr decreases  the time taken to find all the sufficiently large mhrs increases. we also see that as the number of data points increases  the time taken to find all the large mhrs also increases. in general  however  the relationship between the number of data points and the time taken to find all the large mhrs is complex because there are other factors that play a role  e.g.  the density and/or the distribution of the data points  and the number of large mhrs that exist in the dataset. in all experiments  the running times are reasonable. in spite of the large number of discovered mhrs  both planted and unknown   many of them actually represent the same general regions with slight variations  slightly different sets of bounding points . in practice  post-processing can be performed to extract those general empty regions. 
　in the second set of experiments  we use a real-life disease dataset. this dataset has 1 continuous attributes  and 1 data points. the algorithm is run 1 times using different attribute combinations  i.e.  combining 1  or 1 or 1 attributes. the minimal size of the mhrs in each experiment is specified by a doctor. the running times of all the tests are within 1 or 1 seconds. 
　in these experiments  a number of interesting holes are discovered. for example  it is suspected that if the systolic blood pressure  sbp  of a subject is high  then his/her disystolic blood pressure  dbp  is also high. a hole is discovered in the region of high sbp and low dbp. this hole confirms the suspected fact. some holes are quite unexpected. 

for instance  the doctor has a strong belief that the higher the sbp  the more likely the subject will get the disease. however  it is found that between the age of 1  the upper bound of age is 1   there is no subject whose sbp is higher than 1  the upper bound is 1  and is diagnosed to have the disease. 
1 	related work 
to the best of our knowledge  no existing algorithm is able to find interesting holes in a multi-dimensional database. although there are algorithms in geometry  chazelle et al  
1; orlowski  1  that can find empty rectangles in the 1d space  these algorithms cannot be extended to the multidimensional space. 
　most current research in machine learning and machine discovery focuses on finding rules or formulae that exist in data. our work is different from rule induction  e.g.  quinlan  1  because rule induction is not concerned with empty areas. it typically groups the empty areas with the data areas in order to arrive at some generalized rules. 
　typical existing scientific discovery systems discover qualitative and numeric laws from data. examples of wellknown systems include abacus  falkenhainer and michalski  1   bacon  langley et al  1   fahrenheit  zytkow  1   and ids  nordhausen and langley  1 . they are different from our work because our algorithm is targeted at discovering those empty areas  which may represent impossible value combinations. 
　conceptual clustering systems  e.g.  fisher  1  typically partition the data cases into similar classes and form concept hierarchies. again  they are not concerned with those empty areas that do not contain any data. 
　in data mining research  many techniques have been proposed to discover regularities in data  fayyad et al  1 . they are similar to those above for machine learning. here  we would like to mention specifically the association rule discovery technique in  agrawal et al  1 . this technique discovers associations that exist in the database whose attributes are all nominal  or discrete  attributes. for this type of databases  the concept of mhr does not apply. the equivalent concept of mhr in the nominal case is missing associations. since the algorithm in  agrawal et al  1  can find all the existing value associations in a database. using a simple technique  e.g.  generate and test   it is possible to find all the missing associations  without going through the database again . however  the problem is the efficiency and the representation of the missing associations. in our future work  we will study this problem. this paper only focuses on discovering those significant mhrs in a continuous space. 
1 	conclusion 
this paper argues that although discovering rules or regularities that exist in data is important  in many situations  discovering of large holes in the database is also interesting. an algorithm that is able to discover holes in the continuous space  also known as maximal hyper-rectangles  mhr   is proposed and implemented. we believe this algorithm will be useful in scientific discovery and data mining. 
acknowledgments 
we would like to thank dr. hing-yan lee  ms. hwee-leng 
ong and ms. angline pang from information tehcnology 
institute  and dr. ke-qing gong and dr. king-hee ho from national university hospital for many useful discussions  for providing us the databases  and for their help in the testing of our system. 

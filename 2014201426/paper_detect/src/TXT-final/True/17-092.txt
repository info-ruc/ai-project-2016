 
   this paper presents an evidential approach to knowledge representation and inference wherein the principle of maximum entropy is applied to deal with uncertainty and incompleteness. it focuses on a restricted representation language - similar in expressive power to semantic network formalisms  and develops a formal theory of evidential inheritance within this language. the theory applies to a limited  but we think interesting  class of inheritance problems including those that involve exceptions and multiple inheritance hierarchies. the language and the accompanying evidential inference structure provide a natural treatment of defaults and conflicting information. the evidence combination rule proposed in this paper is incremental  commutative and associative and hence  shares most of the attractive features of the dempster-shafer evidence combination rule. furthermore  it is demonstrably better than the dempster-shafer rule in the context of the problems addressed in this paper. the resulting theory can be implemented as a highly parallel  connectionist  network made up of active elements that can solve inheritance problems in time proportional to the depth of the conceptual hierarchy. 
i. introduction 
   the computational cost of gathering  processing and storing information about a complex and constantly changing environment makes it impossible to maintain complete knowledge. however  the need to act on available information compels an agent to make decisions  inferences  based on incomplete knowledge. this underlines the importance of formalizing inference structures that can deal with incompleteness and uncertainty  as is well recognized in al  do  fo  hm  jo  lei  md  mcd  mo  ni  re . 
   this paper presents an evidential approach based on the principle of maximum entropy to deal with incomplete knowledge. evidential reasoning permits the association of numeric quantities with assertions to indicate their degree of belief and has long been used in expert system design  po  sho  dhn . this paper demonstrates that it is possible to adopt an evidential approach in solving some well known problems in knowledge representation. it focuses on a restricted representation language - similar in expressive power to semantic network formalisms  and develops a formal theory of evidential inheritance within this language. the resulting theory has an efficient parallel implementation. 
   one reason for considering an evidential formulation instead of a traditional approach such as default logic  re   is that the latter is not suitable for reasoning about relative likelihoods and in particular it handles conflicting information inadequately. it makes the implicit assumption that all default rules have the same  significance  or  import.  from this assumption it follows that // two or more rules have conflicting consequences then either the use of one rule should preclude the use of the other rules  or no conclusions should be drawn based on these rules. this is not always desirable. we illustrate the point with the help of an example. 
given the following world knowledge: 
quakers tend to be pacifists. - sirepublicans tend to be non-pacifists. - s1-
	dick is a quaker and a republican. 	- s1-
suppose we need to draw conclusions about dick's pacifism. 
   a system based on default logic  er  would arbitrarily choose between one of two possible extensions and respond with an answer that lies in the chosen extension. the choice of extension would depend on which of the two default rules -  quakers tend to be pacifists   dr-l  and  republicans tend to be nonpacifists   dr-1   is selected first by the inference algorithm. for example  if the default rule dr-1 happens to be selected first  the system would infer that  dick is a non-pacifist . once this inference is made  dr-1 would no longer be justifiable with reference to dick and hence would not play any role in drawing conclusions about dick. the case where dr-l is selected first is entirely analogous. in either case  the conclusion drawn would depend on only one of the two rules and in turn on an ad hoc order of rule application. 
   our intuitions about the knowledge in the quaker example suggest that in drawing conclusions about dick  both statements si and s1 are relevant and hence  both must affect the final conclusion. in general  the final conclusion should reflect the combined effect of all the relevant information. furthermore  the statements si and s1 need not have the same import. for instance  an agent may believe that the tendency of quakers to be pacifists outweights the tendency of republicans to be non-pacifists and an epistemologically adequate formalism should be capable of expressing such differences. 
   
1 	l shastri and j. feldman 
   a way to formalize these distinctions is to treat statements like s1 and s1 as evidential assertions and to associate a numeric quantity with each assertion to indicate its evidential import if one could assign meaning to these numbers and explain how they may be extracted from world knowledge and also specify a formal calculus for computing the combined effect of evidential assertions  then one would be able to handle situations such as the quaker example more satisfactorily. deciding whether dick is a pacifist or a non-pacifist need not be based on arbitrary choices  but instead  be resolved by a formally specified theory of evidential reasoning. 
   one may handle interactions between default rules by enumerating the possible cases of interactions and specifying the correct inference in each case  rc . however  having a formal calculus for computing the effects of interactions between default rules in a justifiable manner seems more desirable to us than having to explicitly list the outcome of every possible interaction. 
   recently  touretzky  to   has suggested a nonevidential theory of inheritance based on the principle of inferential distance ordering which states that: if a inherits p from b  and ~p from c  then  if a has an inheritance path via b to c and not vice versa  then conclude p; if a has an inheritance path via c to b and not vice versa  then conclude ~p; otherwise report an ambiguity.  in effect  his formalism treats all rules at the same inferential distance as having the same import and this forces him to report an ambiguity in situations such as the quaker example. 
   rich  ri   has proposed that default reasoning be treated as likelihood reasoning. however  she does not offer a formal theory of evidential reasoning; she concludes  ... the introduction of likelihoods poses new questions such as how to best assign  certainty factors  when there are conflicts ... these questions ... should be addressed.  
   this paper specifies a formal theory of evidential reasoning with respect to a restricted representation language. the theory can handle a limited  but we think interesting  class of multiple inheritance situations  including those that involve exceptions and multiple inheritance  analogous to multiple extensions . the theory may be realized in terms of a highly parallel network that can solve inheritance problems in time proportional to the depth of the conceptual hierarchy. 
   section 1 specifies the representation language  section 1 derives the evidence combination rule and discusses its relation to the dempster-shafer evidence theory  sha  glf  ba  gil  section 1 develops the theory of evidential inheritance and section s discusses related issues. 
1 representation language 
   we will be dealing with the problem of evidential reasoning in the context of a restricted knowledge representation language that is similar to semantic network formalisms such as  fa  br  bw  and may be viewed as an 
evidential extension of inheritance hierarchies with exceptions  erj. an outline of the language follows. 
   
	l. shastri and j. feldman 	1 

following: 
   
1 	l shastri and j. feldman 
    given the state of the agent's knowledge i.e.  taking into account what the agent knows  which choice is most 
probably correct . 
   the theory developed below is based on the notion of maximum entropy  a notion that is fundamentally related to information theory and statistical mechanics   jal  ja1  
ch . 
1 problem formulation 
   given the knowledge in section 1  a rational agent would have no difficulty in guessing the most probable identity of an object given one of its property values. for example  he would guess that a red object is probably an apple because there are 1 instances of red apples as against 1 of red grapes. 
   our goal is to suggest how a rational agent should decide the most probable identity of an object given a description specifying multiple property values such as  red and sweet . 
   the information about apples and grapes in section 1 may be expressed in the form of matrices as shown in figure 1. the rows of the two matrices correspond to the different values of the property has-taste while the columns correspond to the different values of the property has-color. the numbers at the end of each row  column  represent the number of instances of the concept that have the appropriate value of taste  color . 

given by the number of distinct values the property may have. the #a p v s appear as marginals or the sums of hyper-rows and hyper-columns. 
   the internal matrix elements may be used to specify the number of instances of the concept that have the appropriate combination of property values. for instance  the top left element of the apple  grape  matrix in figure 1 indicates the number of instances of apples  grapes  that are both red in color and sweet in taste. 
   to guess the identity of a red and sweet object would be trivial if the agent knew the internal matrix elements. he could simply compare the top left elements of the two matrices in figure 1 and choose the concept that has the higher value. 
   however  if the agent does not know the internal matrix elements the best that he can do is find the most probable estimates of these on the basis of the available information and use the estimates to reason about the world in the remainder of this section we show how the most probable estimate may be found. 
1 computing the most probable configuration 
   the general 1-dimensional case  may be represented as shown in figure 1. 

   
figure 1 
   in general  an agent's knowledge about a concept a 
   may be represented as an n-dimensional matrix where n 
 each dimension of the matrix corresponds to an applicable property and the extent of a dimension is 
   
figure 1 
	l shastrl and j. feldman 	1 
let a configuration be a specification of all the aijs. 
   
our goal is to find the most probable configuration indicated by the following information: 

   the problem of finding the most probable configuration may be recast as follows: 
   consider distributing n distinct objects into a 1dimensional array of cells. 
   let a placement be the complete specification of the result of such a distribution that is  for each cell a placement specifies the objects that are placed in the cell. 
　　let the number of objects located in the ijth cell be given by ajj. then  it follows that there is a many to one mapping from the space of placements to the space of configurations. 
　　let a placement be termed feasible if it satisfies the constraints imposed by row sums and column sums. then: 
   given his knowledge  an agent has no basis for assuming that a particular feasible placement is more probable than some other feasible placement and the only rational assumption he can make is that all feasible placements are equally probable. 
   in view of the above assumption the most probable configuration will be that which results from the greatest number of feasible placements. 
   if w denotes the number of placements resulting in a configuration then w is given by: 

{number of ways of dividing n distinct objects into n*m groups of 
one may now maximize w subject to the constraints: 

in order to find the most probable configuration. 
   it may be shown that for the above maximization problem: 
* this is in essence the principle of indifference or the principle of insufficient reason first stated by bernoulli in 1. 
satisfies the condition of maximality. 
   the above derivation involves taking the logarithm of w and using the stirling's approximation to eliminate the factorials. the maximization is performed by setting the derivative of the resulting expression with respect to ay's to zero; the constraints being incorporated as lagrange multipliers. 
   the above result can be extended to higher dimensions. the result is analogous to the result for 1dimensions and is given by. 

where n equals the total number of objects  n equals the number of dimensions in the array  .. denote the sums of hyper-rows or hyper-columns and is the most probable number of objects in t h e c e l l of the array. 
   the above result will be referred to as the best estimate rule and may be restated as follows. based on the knowledge of: 

   referring back to the example about apples and grapes - the result derived above implies that a rational agent would believe that the most probable way in which the instances of apples and grapes could be distributed is given by the matrices shown in figure 1. thus  he will identify a  red and sweet  object to be an apple as there are probably 1 apples meeting this description as against only 1 grapes. 
1 relation to the dempster-shafer theory 
the dempster-shafer  ds  evidence theory  sha  
glf  ba   suggests an evidence combination rule that is currently in vogue in aritificial intelligence. one can show that a straight forward application of the ds rule for evidence combination does not produce the correct results - for the kinds of problems we wish to solve. it is shown that the ds result agrees with the best estimate rule if one assumes that the frequency  i.e. the prior probability  of all concepts is the same. 
   a simple example illustrates the point. consider the information about apples and grapes as given in section 
1. 
　　if one wishes to use the ds rule to decide whether a green and sour object is an apple or a grape one would essentially proceed as follows: 
1 	l. shastri and j. feldman    one would treat each property value as a source of evidence. the evidence provided by green and sour will be: 
e apple | green  = 1  e grape | green  = 1 
e apple | sour  = 1  e grape | sour  = 1 
   applying the ds rule for evidence combination we get: 
e apple | green & sour  =  1 * 1  and 
e grape | green & sour  =  1 * 1  
   {the above is a simplified account of the actual steps using ds theory. we have focused on the essentials. in particular  we have not normalized the quantities because we are only interested in a relative measure.}. 
   comparing the evidence for apples and grapes we have 
e apple | green & sour : e grape | green & sour  equals  
    1 * 1  :  1 * 1  = 1 : 1 and the decision is in favor of apple. 
   however  on the basis of the given information  the best  most probable  estimate of the number of green and sour apples is 1 and that of green and sour grapes is 1.  see figure 1 . hence the appropriate ratio is: 
   but  introducing an evidential source to account for the prior probability only introduces the factor # a / # b   which acts in the wrong direction. 
1 relation to bayes's rule 
the best estimate rule is consistent with the use of 
bayes's rule if one assumes that the properties are independent the maximum entropy approach simply determines the most probable configuration on the basis of all the available information. if there is nothing in the information to suggest a dependence or  correlation  then none is assumed. if additional information suggesting dependence is available  it is incorporated in the derivation of the most probable configuration as an additional constraint. for example  if the agent knows one of the matrix elements  say the number of red and sweet apples   then the most likely configuration is as follows: without toss of generality  let the agent know that 

   however  the above computations get complex if many internal elements are known; the implications of this are discussed in section 1. 
   
	l. shastri and j. feldman 	1 

   
1 l shastri and j. feldman 

	l. shastri and j. feldman 	1 
1 parallel implementation 	1. conclusion 
   
it is possible to encode 1 as a highly parallel 
 connectionist  network made up of active elements connected via weighted links. the network can perform the computations required to solve the inheritance problem in only 1 d  time  where d is the length of the longest path in the ordering defined on  the weights on links encode the ratios discussed above. 
　　an interesting property of the parallel implementation is that the weights on links can be computed on the basis of purely local information. thus  the weight on a link from node a to node b  is a function of the activities of nodes a and b alone. 
for a description of the parallel implementation see 
 shas ; the connectionist paradigm is described in  fbj. an earlier parallel implementation  along with some extensions of this work is described in  sf . 
1. discussion 
　　this paper has developed an evidential framework based on the principle of maximum entropy and has applied it to' the problem of inheritance. the evidential treatment solves the problem of exceptions and a class of multiple inheritance problems. by combining information from multiple ancestors in a formally justifiable manner  it allows the result to be based on relevant information  and not just on an arbitrarily chosen subset of information.  recall the quaker example in section 1 . 
　　the formalism presented here has an efficient parallel implementation  section 1   though the results apply only to a restricted representation language. we believe that work in ai on representation and inference should not ignore the issue of tractability  a.k.a. performance  effeciency . a formalism that has limited expressiveness but that is computationally tractable seems at least as relevant to ai as one that is extremely expressive but hopelessly intractable  le1 . we feel that our formalism lies at a significant point on a metaphorical  curve  that might describe the tradeoff between expressiveness and tractability. 
　　this formulation demonstrates that as long as the knowledge about concepts and their property values is in the form of    there exists an efficient way of utilizing this knowledge. in section 1 we saw how a  limited  amount of knowledge outside this form could be incorporated. however  the computations soon become too complex. this suggests that the goal of a concept formation  learning  mechanism should be to create concepts - and the ensuing type structure  such that most of the distribution information may be expressed in terms of #c p v 's of existing concepts. 
　　the evidential formulation is extendable to the recognition problem  given a description consisting of property value pairs  find the concept that is best indicated by the description . the extension is described in  shas . 
   this paper demonstrates that certain problems in knowledge representation and reasoning have elegant solutions within an evidential framework. we hope that this work provides a point of contact between researchers who adopt various non-monotonic logics and researchers who adopt an evidential approach to deal with partial and uncertain knowledge. we further hope that this will lead to a greater interaction between the two groups. 
acknowledgment 
	this research 	was sponsored by the 	national 
science foundation  in part under grant no. ist1  in part under grant no. dcr-1  and in part under grant no. ist-1. 

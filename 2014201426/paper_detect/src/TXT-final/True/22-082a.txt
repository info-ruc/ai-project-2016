 
 learning how to make decisions in a domain is a critical aspect of intelligent planning behavior. the ability of a planner to adapt its decision-making to a domain depends in part upon its ability to optimize the tradeoff between the sophistication of its decision procedures and their cost. since it is difficult to optimize this tradeoff on a priori grounds alone  we propose that a planner start with a relatively simple set of decision procedures  and add complexity in response to experience gained in the application of its decision-making to real-world problems. our model of this adaptation process is based on the explanation of failures  in that it is the analysis of bad decisions that drives the improvement of the decision procedures. we have developed a test-bed system for the implementation of planning models employing such an approach  and have demonstrated the ability of such a model to improve its procedure for projecting the effects of its moves in chess. 
1 introduction 
the ability to plan effectively involves many different forms of reasoning: projecting the effects of actions in a current or hypothetical situation  deciding which goal to pursue from among the many that might be pursued at any given time  constructing sequences of actions that can achieve a given goal  determining whether to execute such a sequence  and so on. by and large  most research on planning in al has concentrated on those aspects of planning that in vol ve reasoning about actions  and more specifically  on how sequences of actions can 
1 this research was supported in part by the defense advanced 
research projects agency  monitored by the air force office of scientific research  under contract number f1-c-1  and in part by the office of naval research under contract number n1-k-1. 
be constructed to achieve particular and well-defined goals. considerably less attention has been devoted to those aspects of planning that we might term decisionmaking: deciding whether  or when  to pursue a given goal  or whether to use a given plan for the goal  or for that matter whether even to consider the goal in the first place. 
to make such decisions correctly  a planner must know a great deal about the particular environment in which they arise. for example  a person's decision about whether to turn around and look if he hears footsteps behind him depends crucially on the situation in which he finds himself: his decision is likely to be quite different on a moderately populated suburban street in the middle of the day than in an empty city street late at night. the relevant characteristic of the environment  obviously  is the rate at which threats can be expected to arise  and in particular the threat of being victimized by a criminal. 
one of the major issues confronting any planner is determining how much effort to expend on evaluating a given decision. decision-making in general is subject to a tradeoff between the sophistication of the procedure employed to make the decision  and the time and effort required to perform the analysis. a more sophisticated decision-making procedure will  generally speaking  either consider more alternatives  consider each alternative in more depth  or do both. this requires more reasoning  and is correspondingly more expensive. whether a more sophisticated procedure is worth using depends on whether the gain from its superior performance outweighs this extra cost. consider  for example  the tradeoffs involved in deciding which goal to pursue: the planner must first determine which of a myriad possible goals-including goals to acquire resources  protect desired states  or improve the current situation  among others-are reasonable candidates  and then compare the expected benefits from each of these candidates. obviously  the more goals the planner considers as reasonable candidates  the more likely it will be to find a better goal to pursue. on the other hand  the more goals 
collins  birnbaum and krulwich 
the planner must compare in making its decision  the more this procedure will cost. 
the key point about such tradeoffs in the sophistication of the decision-making process is that  like the decisions themselves  they are highly dependent upon the particular planning environment. for example  in a highly timelimited situation  e.g.  basketball or some other fastpaced game   a planner simply cannot afford to consider very many candidate goals when trying to determine what it should do next. thus  when confronted with a novel planning environment  a planner must be prepared to adapt its decision-making processes to that environment  balancing the tradeoff between their sophistication and their cost. 
it seems difficult to imagine how an agent might find the roughly optimal level of decision-making sophistication on the basis of a priori reasoning alone. this suggests that planners should be prepared to alter their decisionmaking processes on the basis of experience within a new planning environment. the approach we have taken  therefore  is to start with a relatively simple model of decision-making-one that ignores many potential alternatives  and many of the factors that might bear on deciding among them-and to progressively make it more sophisticated in response to poor decisions  i.e.  decisions to pursue goals and plans that ultimately fail. in other words  our model of how a planner adapts its decision-making to new planning domains is failuredriven  see  e.g.  sussman  1; schank  1; hayesroth  1; minton  1; hammond  1 . in such an approach  when a plan fails  the goal of preventing a similar failure in the future leads to an attempt to explain the current failure.1 the explanation of the failure  in turn  suggests ways in which similar failures might subsequently be avoided. 
we have elsewhere presented our model of failuredriven learning in planning domains  birnbaum and collins 1;collinsand birnbaum  1a and 1b . in our approach  the planner encodes a description of the intended functioning of its plans in explicit justification structures. when the expectation that a plan will succeed is violated  the planner can trace back through the justification structure to identify the culprit among the initial assumptions  see  e.g.  dekleer  et ah  1; doyle  1 . by identifying which assumptions have failed  the planner is able to arrive at a characterization of how the particular si tuation brought about this failure  which can then serve as the basis for a rule that suggests what to do when similar situations arise subsequently. 
this paper describes the application of our model to the progressive adaptation of decision-making procedures to new planning environments. such an application requires spelling out the assumptions involved in the expectation that simple decision procedures will suffice  how those assumptions can fail  and how the procedures can be improved upon the diagnosis of such failures. we first discuss how these issues arise in a case study of the chess fork. we next briefly describe a program which implements some of our ideas  and then discuss its application to a second case study  concerning the development of a planner's ability to predict its opponent's move in deciding its own move in chess. 
1 case study: the fork 
as our first case study in improving decision-making in planning  we will consider how a novice chess planner can learn to deal with a fork-a situation in which the planner's opponent confronts it with an attack on two pieces simultaneously. unless a move can be made that will defend both pieces at once-or alternatively one piece can be moved or defended in a way that at the same time poses a strong counter-threat to the opponent-one of the pieces in question will surely be captured. the fork is something that all chess players eventually learn about  usually as a result of being victimized by it. the question is  what does a novice learn about the fork from this experience  
a planner victimized by an opponent's tactic should learn two things: how to avoid being victimized in the future  and how to use the same tactic to victimize others. we will concentrate here on the first of these  the question of how a planner learns to avoid the fork. since the fork takes advantage of the planner's plan for defending its pieces  we must begin by considering what the planner knows about this plan  and in particular  what he knows about the assumptions upon which its efficacy depends. 
the plan that almost every novice chess player seems to have for defending his pieces is this: before each turn  check to see if any of the opponent's pieces is in position to move to the location of one of your pieces. if this is the case  then you can prevent the execution of the threat by moving the threatened piece  or by guarding it with another piece. this plan makes the assumption that a one-move warning of a threat to a piece is sufficient to to allow it to be defended  and this is generally the case. it is this assumption  however  that the fork takes advantage of: when two imminent threats are detected on the same turn  there is not time to block both of them. 
given that a novice planner understands that its plan depends upon this assumption  a plausible explanation 

for how it comes to understand the fork can be constructed. the fork results in the failure of the plan to protect materiel  since it results in the capture of a piece. this failure can be traced to the violation of an underlying assumption of the plan  namely that a one-move warning of any threat would be sufficient.1 the violation of this assumption was  in turn  brought about by the opponent's positioning of a piece so that it attacked two pieces simultaneously. the key point here is this: such an analysis not only explains the fork  it suggests the way to guard against it. the failure of the assumption that a onemove warning is sufficient implies the need to detect at least one of the two threats earlier. moreover  the fact that the failure was brought about by the positioning of a piece to attack two pieces at once means that efforts at earlier detection can be limited to situations where the opponent can  with a single move  produce a threat to two pieces. thus  understanding how the fork violates its assumptions enables a planner to determine how it can avoid being victimized by the fork in the future: it must modify its plan for scanning the board to include a check for opponent's pieces that can be moved into position to attack two unguarded pieces of its own. 
this explanation of how a novice planner learns from experiencing the fork leaves us with a question  however: why would the planner have assumed that a onemove warning was enough in the first place  the most obvious answer is that the planner was simply unable to imagine a circumstance in which this would not be the case. unfortunately  this explanation does not hold up upon further reflection. the idea that multiple threats pose a problem for defenses that involve detecting and blocking individual threats is well known to all human planners: this is the fundamental reason  for example  why  ganging up  allows a superior force to be defeated by a collection of inferior forces in any competitive situation. it seems likely that any human planner would have experienced this phenomenon  and grasped its significance  long before learning to play chess. but given the knowledge that detection-based plans for blocking threats are vulnerable to an overload of threats  plus the lack of any particular reason to believe that this problem would not arise in chess  it seems unlikely that the planner would nevertheless conclude that a onemove warning would always be enough. to argue this would be to conclude that vulnerability to the fork is the result of a mistake-a mistake made consistently by almost every person who ever learns the game of chess. it would be difficult to explain why such an error in reasoning should be made by nearly everyone. 
in fact  the answer lies not in the logic of the situation  but in its economics. the reason for not detecting threats two 
'see collins and birnbaum  1b  for a discussion of how this is accomplished. 
moves in advance is that it would cost too much to do so: the planner would be swamped by the need to respond to a massive number of threats  since in two moves most of the opponent's pieces would be able to move to at least one square currently occupied by one of the planner's pieces. most of these  threats  would never develop  and the planner would at best waste a great deal of time that could better be used plotting strategy. there is  in other words  a tradeoff: by detecting threats early  the planner provides more time to deal with multiple threats  but at the cost of being forced to consider an enormous number of possible-but unlikely-threats. by detecting threats later  the planner runs the risk of not having enough time to deal with multiple threats  but avoids being swamped with too many low probability reports. in this case  the tradeoff clearly is on the side of later detection  and this is likely to be true in many domains. 
a key characteristic of the appropriate defense against the fork is that it avoids a blow-up in the number of detected threats by looking only for cases in which one piece can be moved so as to attack two pieces at once. in other words  by looking for forks in particular  rather than detecting all threats two moves in advance  the planner focusses its attention narrowly enough to make the extra effort worthwhile. so this is what the planner really learns from the fork: not that one move's warning might not be enough-it already knew that-but a characterization of the circumstances in which it is not that is precise enough to allow them to be detected efficiently. 
we can now provide a coherent account of how the fork is learned. the planner begins with the understanding that threats to pieces will arise periodically in chess. the standard strategy for dealing with threats in any domain is this: first  construct methods for detecting individual instances of threats in advance. second  construct methods for blocking threats that can be executed when a threat is spotted. and third  ensure that all threats will be detected in time for a blocking routine to be carried out. 
in chess  first  the obvious method for detecting threats is to determine which of the opponent's pieces could move to locations occupied by the planner's pieces in some particular number of moves. second  the obvious method for blocking these threats is to move the threatened piece out of harm's way; a slightly more sophisticated plan is to guard the piece with another. and third  since any piece can generally either be moved or guarded in a single turn  and since-all other things being equal-it is best to detect threats as late as possible  a planner can conclude that one move's warning will generally be enough. however  the planner cannot prove that one move will always be enough  and so is forced to make the assumption that this will generally be the case. by 
collins  birnbaum and krulwich 
making this assumption explicit  and by ensuring that it is monitored whenever a threat arises  the planner assures itself of being alerted to cases in which the assumption fails  as it does in the fork. so  while the planner is forced to accept the cost of a few failures as the price of an efficient threat-detection strategy  by monitoring the assumptions it is forced to make  and analyzing the failures that occur  it is able to gradually improve its performance by dealing with problematic cases one at a time. 
in a sense  this explanation argues that a planner is deliberately courting failure as a shortcut to a better plan. viewed this way  the alternative would have been for the planner to reason out  a priori  the circumstances in which multiple threats could occur  rather than waiting for those circumstances to arise in practice. in effect  this would mean inventing the fork before actually playing the game. while this is possible in principle  in practice the computational cost is likely to be extremely high- high enough that it is almost certainly cheaper to wait for the fork to happen. we believe that similar explanations underlie the acquisition of a wide range of decisionmaking strategies employed by planners. 
1 an implementation and a second case study 
 in order to explore more concretely our failure-driven approach to the adaptation of decision-making processes in planning  we have constructed a test-bed- comprising mechanisms for inference and rule application  justification maintenance  expectation handlers  failureexplanation  and rule patching-and implemented within it a simple model of decision-making and planning for turn-taking games. this model  in turn  has been used for exploring rudimentary planning and learning in tic-tac-toe and in chess. 
 def-brule proj-factor-1 
 world  move move   player player  result  weight integer  
 opp-move move   time time  
 better-move move   better-goal goal  
 better-value integer   orig-value integer    
 project-factor proj-factor-1 world move player result weight  
 and  = world  world-at-time time   
 decide  player-opponent player  
 possible-moves-at-time  player-opponent player  time  world simple-dec-factors opp-move  
 = result  world-after-move opp-move  world-after-move move world     = weight 1  
  
 justification herel  
figure 1: initial projection method 
the planning model is implemented in 1 fairly general rules  concerning the detection of threats and opportunities  making choices  forming and checking expectations  and the like; some typical rules are shown later in 
cognitive models 
this section. in addition  there are 1 chess-specific reasoning rules. all of these rules  general as well as specific  have associated justification structures  as do all particular facts and expectations contained in the system's data base. these justification structures are constructed and utilized by the rule applier  the failure explanation algorithm  and the rule patching mechanism. we devote the rest of this section to describing the program's application to a second case study  concerning the development of a planner's ability to predict its opponent's move in deciding its own move in chess. 
the decision-making process within our planning model is composed of three interleaved components: a decider  which determines what move to make  a projector  which projects the results of a possible move in a given situation  and an evaluator  which evaluates a situation from a given player's perspective. our planner starts with extremely primitive methods for accomplishing each of these decision-making tasks. first  to decide what move to make it simply projects the results of each move available to it  evaluates each resulting situation  and chooses the move that yields the best result. to project the results of making a given move  the planner simply assumes that its opponent will behave as it would in any given situation; the projection method that implements this is shown in figure 1. finally  to evaluate a given situation  the planner computes the difference between the total values of the two player's pieces remaining on the board. 

figure 1: game board sequence consider now how a planner endowed with these primitive decision-making methods would behave in the situation shown in figure 1. to such a planner  moving the rook to take the knight looks like the best move. this decision is based on the erroneous expectation that its opponent will take the planner's knight. it forms this expectation because the projection method shown in figure 1 simply evaluates the opponent's options in the original situation  i.e.  without taking into account the effects of the planner's own move. the use of such an unsophisticated procedure considerably simplifies the projection problem  because it obviates the need to recompute the opponent's response individually for each move contemplated by the planner. however  its validity  and hence the validi ty of theexpectationsthe planner generates concerning the opponent's moves  depends on an assumption that nothing will occur that will enable the opponent to make a better move than those currently available to it. this assumption  is an instance of what is sometimes referred to as an inertia assumption  namely an assumption that things will stay as they are as much as possible. in our planner  this assumption is itself justified by a conjunction that says roughly  nothing will happen to give him a better move because he can't do anything to give himself one  i won't do anything to give him one  and no outside forces will give him one.  because the planner's decision to take the knight is justified by its projection that its opponent will take a knight in response  it monitors the status of this expectation. the expectation  in turn  is justified by the assumptions underlying the projection method used to produce it. 
applying rules in new-expectation-failure-rules -expectation failure: 
item= move-to-make  move opponent move-take pawn 
　　　　　　　　　　　　　　 ro loc 1   rc- loc 1  knight  opponent  goal-unknown  1  traversing... 
checking fact 
# fact 1:  project  move computer move-take rook 
 move opponent move-take pawn 
 rc- loc 1}  rc- loc 1  knight  
checking b-rule #{b-rule proj-factor-1  -  valid: 
 not  exists  c event  
          move-to-make  e.1 opponent  better-goal.1    -  valid: 
 not  exists  e event  
 and  extraneous-event  e.1  
　　　　　 event-enables-event  e.1  better-move.1     -  found a bug: 
 no  and  move-enables-move  move.1  better-move.1  
 move-possible  better-move.1  time.1  
 move-legal  better-move.1  
 evaluate  world-after-move  better-move.1 
　 world-after-move  move.1  world.1  eval-factors 
 player-opponent  player.1  
 better-value.1  
 evaluate  world-after-move  opp-move.1 
    world-after-move  move.1  world.1d  eval-factors 
 player-opponent  player.1  
 orig-value.1  
    better-valuc.1  orig-value.1    
*** returning a bug *** 
figure 1: traversing an expectation's justification 
unfortunately  as we can see  the opponent is not going to make the move that the computer expected  and the move that he will make-namely taking the planner's rook-is a better move than the one the planner expected. when this happens  the planner detects that its expectation that the opponent will take the knight has failed. this then causes the planner to traverse the justification structure for that expectation  checkingthe assumptions upon which it depends. 
 in particular  the planner will discover that its assumption that the opponent will not have a better move has been violated. a partial transcript of this process is shown in figure 1  but it should be clear that the assumption in the justification that will fail is the inertia assumption that no event will occur that will give the opponent a better move than we expect him to have  and in particular the assumption that no action of the program's will give the opponent a better move. 
as can be seen in figure 1  the system knows more than just the identity of the assumption that failed: it also knows how that assumption failed. the program's domain knowledge allows it to determine that the opponent's move was in fact a legal one  and a comparision of the justification for this belief with the program's prior expectation reveals that the event that enabled the opponent to make a better move than expected was in fact the computer's own move. once the program discovers this  it must modify its reliance on the inertia assumption to take the problem into account  using the information provided in its justification structures and its analysis of the failure. the program uses standard goal regression techniques  see  e.g.  dejong and mooney  1; mitchell etal.  1  todetermine just those aspectsof the situation that caused the expectation to fail. 
the resulting generalized explanation for the failure is used to patch the method that predicts the opponent's response  as utilized by the projection component  so that it checks for opportunities presented to the opponent by the planner's own move  thus ensuring that this mistake will be avoided in the future  see figure1 . the new rule says roughly the following: 'to see what the world will be like after making move m  see what you would do in the opponent's situation at the current time  and assume 
collins  birnbaum and krulwich 

that he will make that move  as long as your move m doesn't enable a better move for him.  when the same example is run with the new rule antecedant  the computer does not make the same mistake. 
 def-brule proj-factor-1 
 world  move move   player player  result  weight integer  
 opp-move move   time time  
 better-move move   better-goal goal  
 better-value integer   orig-value integer    
 project-factor proj-factor-1-mod world move player result weight  
 and  = world  world-at-time time   
 decide  player-opponent player  
　 possible-moves-at-time  player-opponent player  time  world simple-dec-factors opp-move  
 = result  world-after-move opp-move 
 world-after-move move world    
 = weight 1  ; here's the new stuff: 
 no  and  move-enables-move move better-move  
 move-possible better-move  current-time   
 move-legal better-move  
 evaluate result eval-factors 
 player-opponent player  orig-value  
 evaluate  world-after-move better-move 
          world-after-move move world   eval-factors  player-opponent player  
better-value  
   better-value orig-value       
　　　figure 1: the modified projection method 1 conclusion 
learning how to make decisions in a domain is a critical aspect of intelligent planning behavior. the ability of a planner to adapt its decision-making to a domain depends in part upon its ability to optimize the tradeoff between the sophistication of its decision procedures and their cost. since it is difficult to optimize this tradeoff on a priori grounds alone  we propose that a planner start with a relatively simple set of decision procedures  and add complexity in response to experience gained in the application of its decision-making to real-world problems. our model of this adaptation process is based on the explanation of failures  in that it is the analysis of bad decisions that drives the improvement of the decision procedures. we have developed a test-bed system for the implementation of planning models employing such an approach  and have demonstrated the ability of such a model to improve its procedure for projecting the effects of its moves in chess. 

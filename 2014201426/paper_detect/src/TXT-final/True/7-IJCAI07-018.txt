
in an arc consistency  ac  algorithm  a residual support  or residue  is a support that has been stored during a previous execution of the procedure which determines if a value is supported by a constraint. the point is that a residue is not guaranteed to represent a lower bound of the smallest current support of a value. in this paper  we study the theoretical impact of exploiting residues with respect to the basic algorithm ac1. first  we prove that ac1rm  ac1 with multi-directionalresidues  is optimal for low and high constraint tightness. second  we show that when ac has to be maintained during a backtracking search  mac1 presents  with respect to mac1rm  an overhead in o 뷃ed  per branch of the binary tree built by mac  where 뷃 denotes the number of refutations of the branch  e the number of constraints and d the greatest domain size of the constraint network. one consequence is that mac1rm admits a better worst-case time complexity than mac1 for a branch involving 뷃 refutations when either 뷃   d1 or 뷃   d and the tightness of any constraint is either low or high. our experimental results clearly show that exploiting residues allows enhancing mac and sac algorithms.
1 introduction
it is well-known that arc consistency  ac  plays a central role in solving instances of the constraint satisfaction problem  csp . indeed  the mac algorithm  i.e.  the algorithm which maintains arc consistency during the search of a solution  is still considered as the most efficient generic approach to cope with large and hard problem instances. furthermore  ac is at the heart of a stronger consistency called singleton arc consistency  sac  which has recently attracted a lot of attention  e.g.   bessie`re and debruyne  1; lecoutre and cardon  1  .
모for more that two decades  many algorithms have been proposed to establish arc consistency. today  the most referenced algorithms are ac1  mackworth  1  because of its simplicity and ac1.1  bessie`re et al.  1  because of its optimality  while being not too complex . the worstcase time complexities of ac1 and ac1 are respectively o ed1  and o ed1  where e denotes the number of constraints and d the greatest domain size. the interest of an optimal algorithm such as ac1 resides in its robustness. it means that ac1 does not suffer from some pathological cases as ac1 does. this situation occurs when the tightness of the constraints is high  as it is the case for the equality constraint  i.e. constraint of the form x = y  . indeed  as naturally expected and demonstrated later  ac1 admits then a practical behaviour which is close to the worst-case  and the difference by a factor d between the two theoretical worst-case complexities becomes a reality.
모in this paper  we are interested in residues for ac algorithms. a residue is a support that has been stored during a previous execution of the procedure which determines if a value is supported by a constraint. the point is that a residue is not guaranteed to represent a lower bound of the smallest current support of a value. the basic algorithm ac1 can be refined by exploiting residues as follows: before searching a support for a value from scratch  the validity of the residue associated with this value is checked. we then obtain an algorithm denoted ac1r  and when multi-directionality is exploited  an algorithm denoted ac1rm.
모in fact  ac1r is an algorithm which can be advantageously replaced by ac1 when ac must be established standalone on a given constraint network. however  when ac has to be maintained during search  mac1r which corresponds to mac1residue  likitvivatanavong et al.  1  becomes quite competitive. on the other hand  ac1rm is interesting of its own as it exploits multi-directional residues just like ac1  lecoutre et al.  1 . but  let us see the interest of exploiting residues.
모first  we prove in this paper that ac1rm  contrary to ac1  admits an optimal behaviour when the tightness of the constraints is high. to illustrate this  let us consider the domino problem introduced in  bessie`re et al.  1 . all but one constraints of this problem correspond to equality constraints. the results that we obtain when running ac1  ac1  ac1 and the new algorithm ac1rm on some instances of this problem are depicted in table 1. the time in seconds  cpu  and the number of constraint checks  ccks  is given for each instance of the form domino-n-d where n corresponds to the number of variables and d the number of values in each domain. clearly  ac1rm largely compensates the weakness of the basic ac1.
instancesac1ac1rmac1ac1domino-1cpu ccksdomino-1cpu ccks모모1m1
1m1
1m1
1mdomino-1cpu ccks     1m1
1m1
1m1
1mdomino-1cpu ccks모모1m모모1m모모1m모모1mtable 1: establishing arc consistency on domino instances
모next  we analyse the cost of managing data structures with respect to backtracking. on the one hand  it is easy to embed ac1rm in mac and sac algorithms as these algorithms do not require any maintenance of data structures during mac search and sac inference. on the other hand  embedding an optimal algorithm such as ac1 entails an extra development effort  with  in addition  an overhead at the execution. for mac1  this overhead is o 뷃ed  per branch of the binary tree built by mac as we have to take into account the reinitialization of a structure  called last  which contains smallest found supports. here  뷃 denotes the number of refutations of the branch  e denotes the number of constraints and d the greatest domain size.
1 constraint networks
a constraint network  cn  p is a pair  x  c  where x is a set of n variables and c a set of e constraints. each variable x 뫍 x has an associated domain  denoted by dom x   which contains the set of values allowed for x. each constraint c 뫍 c involves a subset of variables of x   called scope and denoted scp c   and has an associated relation  denoted rel c   which contains the set of tuples allowed for the variables of its scope. the initial  resp. current  domain of a variable x is denoted dominit x   resp. dom x  . for each r-ary constraint c such that scp c  = {x1 ... xr}  we have: rel  r  xi  where
cartesian product. also  for any element t =  a1 ... ar   called tuple  of r denotes the value ai. it is also important to note that  assuming a total order on domains  tuples can be ordered using a lexicographic order  . to simplify the presentation of some algorithms  we will use two special values 뫐 and  such that any tuple t is such that.
definition 1 let c be a r-ary constraint such that scp c  = r
is said to be
allowed by c iff t 뫍 rel c   valid iff  xi 뫍 scp c   t xi  뫍 dom xi   and a support in c iff it is allowed by c and valid.
모a tuple t will be said to be a support of  xi a  in c when t is a support in c such that t xi  = a. determining if a tuple is allowed is called a constraint check. a solution to a cn is an assignment of values to all the variables such that all the constraints are satisfied. a cn is said to be satisfiable iff it admits at least one solution. the constraint satisfaction problem  csp  is the np-complete task of determining whether a given cn is satisfiable. a csp instance is then defined by a cn  and solving it involves either finding one  or more  solution or determining its unsatisfiability. arc consistency  ac  remains the central property of cns and establishing ac on a given network p involves removing all values that are not arc consistent.
definition 1 let p =  x  c  be a cn. a pair  x a   with
x 뫍 x and a 뫍 dom x   is arc consistent  ac  iff  c 뫍 c | x 뫍 scp c   there exists a support of  x a  in c. p is ac iff  x 뫍 x   dom  is ac.
모the following definitions will be useful later to analyze the worst-case time complexity of some algorithms.
definition 1 a cn-value is a triplet of the form  c x a  where c 뫍 c   x 뫍 scp c  and a 뫍 dom x .
definition 1 let  c x a  be a cn-value such that scp c  = {x y }.
  the number of supports of  x a  in c 	denoted
	  corresponds to the size of the set {b	뫍
	   	 	  뫍	    .
  the number of conflicts of  x a  in c  denoted c c x a   corresponds to the size of the set {b 뫍 dom y   |
 a b  뫍/ rel c }.
모note that the number of cn-values that can be built from a binary constraint network is o ed . to sum up all evaluations of an expression expr c x a  wrt all the cn-values of a given cn  we will write:.
1 ac1rm
in this section  we introduce ac1rm  and we propose a detailed analysis of its complexity. it is important to remark that our algorithm is given in the general case  i.e. it can be applied to instances involving constraints of any arity . hence  strictly speaking  its description corresponds to gac1rm since for non binary constraints  one usually talks about generalized arc consistency  gac . however  to simplify  theoretical complexities will be given for binary instances. more precisely  for all theoretical results  we will consider given a binary cn p =  x  c  such that  to simplify and without any loss of generality  each domain exactly contains d values.
모to establish  generalized  arc consistency on a given cn  doac  algorithm 1  can be called. it returns true when the given cn can be made arc-consistent and it is described in the context of a coarse-grained algorithm. initially  all pairs  c x   called arcs  are put in a set q. once q has been initialized  each arc is revised in turn  line 1   and when a revision is effective  at least one value has been removed   the set q has to be updated  line 1 . a revision is performed by a call to the function revise  and entails removing values that have become inconsistent with respect to c. this function
algorithm 1 doac  p =  x  c  : cn : boolean1: q 뫹 { c x  | c 뫍 c 뫇 x 뫍 scp c }
1:do
1:	pick and delete  c x  from q
1:	if revise c x  then
1:
1:	뫹	 	 	=	=
1: return truescp  algorithm 1 revise c : constraint  x : variable  : boolean

1: nbelements 뫹 | dom x  |
1: for each a 뫍 dom x  do
1:	if supp c x a  is valid then continue
1:	t 뫹 seeksupport c x a 
1:	 then remove a from dom x 
1:	else for each y 뫍 scp c  do supp c y t y    뫹 t
1: return nbelements


algorithm 1 seeksupport c  x  a  : tuple

1: t 뫹 뫐
1: while do
1:	if c t  then return t
1: t 뫹 setnexttuple c x a t  1: return	

returns true when the revision is effective. the algorithm is stopped when a domain wipe-out occurs  line 1  or the set q becomes empty.
모following the principle used in ac1  lecoutre et al.  1   we propose a mechanism to partially benefit from  positive  multi-directionality. the idea is that  when a support t is found  it can be recorded for all values occurring in t. for example  let us consider a binary constraint c such that scp c  = {x y }. if  a b  is found in c when looking for a support of either  x a  or  y b   in both cases  it can be recorded as being the last found support of  x a  in c and the last found support of  y b  in c. in fact  one can simply record for any cn-value  c x a  the last found support of  x a  in c. however  here  unlike ac1  by exploiting multi-directionality we cannot benefit anymore from unidirectionality. it means that  when the last found support is no more valid  one has to search for a new support from scratch. indeed  by using multi-directionality  we have no guarantee that the last found support corresponds to the last smallest support. this new algorithm requires the introduction of a three-dimensional array  denoted supp. this data structure is used to store for any cn-value  c x a  the last found support of  x a  in c. initially  any element of the structure supp must be set to 뫐. each revision  see algorithm 1  involves testing for any value the validity of the last found support line 1  and if  it fails  a search for a new support is started from scratch  see algorithm 1 . it uses setnexttuple which returns either the smallest valid tuple t built from c such that if it does not exist. without any
loss of generality  we assume that any call to setnexttuple is performed in constant time. note that c t  must be understood as a constraint check and that c 뫐  returns false. if this search succeeds  structures corresponding to last found supports are updated  line 1 .
모to summarize  the structure supp allows to record what we call multi-directional residues. of course  it is possible to exploit simpler residues  likitvivatanavong et al.  1   called here uni-directional residues  by not exploiting multidirectionality. we can then derive a new algorithm  denoted ac1r  by replacing line 1 of algorithm 1 with:
else supp c x a  뫹 t
however  with ac1r  when ac must be established standalone  rather than searching a new support from scratch when the residue is no more valid  it is more natural and more efficient to perform the search using the value of the residue as a resumption point. this is exactly what is done by ac1. it means that  in practice  ac1r is interesting only when it is embedded in mac  likitvivatanavong et al.  1  or a sac algorithm.
ac1rm has a space complexityof o ed  and a non-optimal
worst-case time complexity of o ed1 . however  it is possible to refine this result as follows:
proposition 1 in ac1rm  the worst-case cumulated time complexity of seeksupport for a cn-value  c x a  is o cs+ d  with c = c c x a  and s = s c x a .
proof. the worst-case in terms of constraint checks is when: 1  only one value is removed from dominit y   between two calls to revise c x   1  values of dominit y   are ordered in such a way that the c first values correspond to values which do not support a and the s last values correspond to values which support a  1  the first s values removed from dominit y   systematically correspond to the last found supports recorded by ac1rm  until a domain wipe-out is encountered . for these s + 1 calls  note the initial call  to seeksupport c x a   we obtain s    c + 1  + c constraint checks. on the other hand  the number of other operations  validity checks and updates of the supp structure  in revise performed with respect to a is bounded by d. then  we have a worst-case cumulated complexity in o sc + s + c + d  = o cs + d . 
모what is interesting with ac1rm is that  even if this algorithm is not optimal  it is adapted to instances involving constraints of low or high tightness. indeed  when the constraint tightness is low  more precisely  when c is o 1   or high  when s is o 1    the worst-case cumulated time complexity becomes o d   what is optimal. on the other hand  sc is maximized when c = s = d/1  what corresponds to a medium constraint tightness. however  ac1rm can also be expected to have a good  practical  behavior for medium constraint tightness since  on average  i.e. asymptotically   considering random constraints  1 constraint checks are necessary to find a support when the tightness is 1. we can deduce the following result.
proposition 1 the worst-case time complexity of ac1rm is:
o 
모table 1 indicates the overall worst-case complexities1to establish arc consistency with algorithms ac1  ac1rm  ac1 and ac1. it is also interesting to look at worstcase cumulated time complexities to seek successive supports for a given cn-value  c x a . even if it has not been introduced earlier  it is easy to show that optimal algorithms admit a cumulated complexity in o d . by observing table 1  we do learn that ac1 and ac1rm are optimal when the tightness is low  i.e. c is o 1    and that  unlike ac1  ac1rm is also optimal when the tightness is high  i.e. s is o 1  .
spacetimeac1o e + nd o 
	c x a	c x aac1rmo ed o 
c x aac1o ed o ed1 ac1o ed o ed1 table 1: worst-case complexities to establish ac.
tightnessanylowmediumhighac1o cd + s o d o d1 o d1 ac1rmo cs + d o d o d1 o d ac1o d o d o d o d ac1o d o d o d o d table 1: cumulated worst-case time complexities to seek successive supports for a cn-value  c x a . we have c + s = d.
모remark that the complexities given for ac1rm also hold for ac1r. the advantage of ac1rm is the fact that as we always record the most recent found supports  by exploiting multi-directionality   there is a greater probability that a residue be valid. finally  note that it should be possible to extend the ac-* framework  re뫣gin  1  in order to include the concept of residues.
1 maintaining arc consistency
in this section  we focus on maintaining arc consistency during search. more precisely  we study the impact  in terms of time and space  of embedding some ac algorithms in mac. the mac algorithm aims at solving a csp instance and performs a depth-first search with backtracking while maintaining arc consistency. at each step of the search  a variable assignment is performed followed by a filtering process that corresponds to enforcing arc-consistency. mac is based on a binary branching scheme. it means that  at each step of the search  a pair  x a  is selected where x is an unassigned variable and a a value in dom x   and two cases are considered: the first one corresponds to the assignment x = a and the second one to the refutation.
모on the other hand  it is important to remark that all known ac algorithms  including ac1rm  are incremental. an arcconsistency algorithm is incremental if its worst-case time complexity is the same when it is applied one time on a given network p and when it is applied up to nd times on p where between two consecutive executions at least one value has been deleted. by exploiting incrementality  one can get the same complexity  in terms of constraint checks  for any branch of the search tree as for only one establishment of ac. for ac1 and ac1rm  the  non optimal  worst-case time complexity for any branch of the search tree is guaranteed  by incrementality  even if  meanwhile  sub-trees have been explored and then backtracking has occurred. however  for optimal algorithms ac1 and ac1  it is important to manage the data structure  denoted last  in order to restart search  after exploring a sub-tree  as if backtracking never occurred. in this paper  mac1 and mac1 correspond to the algorithms that record the smallest supports that have been successively found all along the current branch. note
spacetime  per branch mac1o e+ nd o 
c x amac1rmo ed o 
c x amac1o min n d ed o ed d + 뷃  mac1o min n d ed o ed d + 뷃  table 1: worst-case complexities to run mac. time complexity is given for a branch involving 뷃 refutations.
that it is at the price of a space complexity in o min n d ed   van dongen  1 .
proposition 1 in mac1 and mac1  the worst-case cumulated time complexity of reinitializing the structure last is o 뷃ed  for any branch involving 뷃 refutations.
모proof. for any refutation occurring in a branch  we need to restore the data structure last. in the worst-case  we have at most e   1   d operations since for each cn-value  c x a   we have to reinitialize last c x a  to a stacked value  or  for variants  to 뫐 or a new recomputed value . hence  we obtain  뷃ed . 
모if 뷃 = 1  it means that a solution has been found without any backtracking. in this case  there is no need to restore the structure last as the instance is solved. at the opposite  we know that the longest branch that can be built contains nd edges as follows: for each variable x  there are exactly d   1 edges that correspond to refutations and only one edge that corresponds to an assignment. then  we obtain a worstcase cumulated time complexities of reinitializing the structure last in o end1  and although it is omitted here  we can also show that it is 붲 end1 .
모one nice feature of ac1rm is that  when they are embedded in mac  no initialization is necessary at each step since the principle of this algorithm is to record the last found support which does not systematically correspond to the last smallest one. in fact  it was reported in  lecoutre et al.  1  that it is worthwhile to leave unchanged last found supports  using ac1  while backtracking  having the benefit of a socalled memorization effect. it means that a support found at a given depth of the search has the opportunity to be still valid at a weaker depth of the search  after backtracking . in other words  it is worthwhile to exploit residues during search. the importance of limiting in mac the overhead of maintaining the data structures employed by the embedded ac algorithm was pointed out in  likitvivatanavong et al.  1   but no complexity result was given . in fact  mac1r corresponds to the algorithm mac1residue introduced in  likitvivatanavong et al.  1 .
모by taking into account proposition 1 and table 1  we obtain the results given in table 1. it appears that  for the longest branch  when 뷃   d1  mac1 and mac1rm have a better worst-case time complexity than other mac algorithms based on optimal ac algorithms since we know that  for any branch  due to incrementality  mac1 and mac1rm are o ed1 . also  if the tightness of any constraint is either low or high  more precisely  if for any cn-value  c x a   either c c x a  is o 1  or s c x a  is o 1    then mac1rm admits an optimal worst-case time complexity in o ed1  per
mac embeddingac1ac1rmac1ac1classes of random instances  mean results for 1 instances 
cpu ccks1
1m1
1m1
1m1
1mcpu ccks1
1m1
1m1
1m1
1mcpu ccks1
1m1
1m1
1m1
1mcpu ccks1
1m1
1m1
1m1
1mcpu ccks1
1m1
1m1
1m1
1mcpu ccks1
1m1
1m1
1m1
1mcpu ccks1
1m1
1m1
1m1
1macademic instances
ehi-1cpu ccks1
1m1
1m1
1m1
1mgeo-1-1cpu ccks1
1m1
1m1
1m1
1mqa-1cpu ccks1
1m1
1m1
1m1
1mqcp-1cpu ccks1
1m1
1m1
1m1
1mreal-world instances
fapp1-1cpu ccks1
1k1
1k1
1k1
1kjs-enddr1cpu ccks1
1m1
1m1
1m1
1mscen-1cpu ccks1
1m1
1m1
1m1
1mgraph-1cpu ccks1
1k1
1k1
1k1
1ktable 1: cost of running mac
branch. in this case  mac1rm outperforms mac1 as soon as 뷃   d. these observations suggest that mac1rm should be very competitive.
1 experiments
to compare the different algorithms mentioned in this paper  we have performed a vast experimentation  run on a pc pentium iv 1ghz 1mb under linux  with respect to random  academic and real-world problems. performances have been measured in terms of the cpu time in seconds  cpu  and the number of constraint checks  ccks .
모to start  we have tested mac  equipped with dom/deg  by considering 1 classes of binary random instances situated at the phase transition of search. for each class   defined as usually  1 instances have been generated. the tightness t denotes the probability that a pair of values is allowed by a relation. what is interesting here is that a significant sampling of domain sizes  densities and tightnesses is introduced. in table 1  we can observe the results obtained with mac embedding the various ac algorithms. as expected  the best embedded algorithms are ac1 and ac1rm when the tightness is low  here 1  and ac1rm when the tightness is high  here  1 . also  ac1rm is the best when the tightness is medium  here 1  as expected on random instances. all these results are confirmed for some representative selected academic and real-world instances. clearly  mac1rm outperform all other mac algorithms in terms of cpu while mac1 is the best  although beaten on a few instances by
sac   1embeddingac1ac1rmac1ac1academic instances
domino-1cpu ccks 1 1m1
1m1
1m1
1mdomino-1cpu ccks1
1m   1 1k   1 1k   1 1kgeo-1-1cpu ccks   1 1k   1 1k   1 1k   1 1kqa-1cpu ccks1
1m   1 1k   1 1k   1 1kreal-world instances
fapp1-1cpu ccks     1m   1m모모1m   1mjs-enddr1cpu ccks1
1m1
1m1
1m1
1mgraph-1cpu ccks     1m모모1m모모1m모모1mscen-1cpu ccks1
1m1
1m1
1m1
1mtable 1: cost of establishing sac-1
mac1rm  in terms of constraint checks. interestingly  in an overall analysis  we can remark that mac1rm and mac1 roughly perform the same number of constraint checks. as  on the other hand  mac1rm do not require any data structure to be maintained  it explains why it is the quickest approach. these results confirm the results obtained for mac1r  mac1residue in  likitvivatanavonget al.  1  which has a behaviour similar to mac1rm  due to lack of space  results for mac1r are not presented .
모we have then embedded ac algorithms in sac-1. in table 1  one can observe that  for domino instances which involve constraints of high tightness  ac1rm clearly shows its superiority to ac1. for real-world instances  the gap between ac1rm and the other algorithms increases. for example  sac-1 embedding ac1rm is about 1 times more efficient than sac-1 embedding ac1 on scen1 and 1 times more efficient than sac-1 embedding ac1 on fapp1-1.
1 residues for non binary constraints
one can wonder what is the behaviour of an algorithm that exploits residues when applied to non binary instances. first  it is important to remark that seeking a support of a cn-value from scratch requires iterating o dr 1  tuples in the worstcase for a constraint of arity r. we then obtain a worst-case cumulated time complexity of seeking a support of a given cn-value in o r1dr  for gac1 and o rdr 1  for gac1  bessie`re et al.  1  since we consider that a constraint check is o r  and since there are o rd  potential calls to the specific seeksupport function. then  we can observe that there is a difference by a factor dr. it means that the difference between the two algorithms grows linearly with r.
모on the other hand  if we assume that c   1 and s   1 respectively denote the number of forbidden and allowed tuples of the constraint  then we obtain  by generalizing our results of section 1  a complexity in o crdr 1  for gac1 and in o cs  for gac1rm. we can then deduce that the worst-case cumulated time complexity of seeking a support is o min c rd .rdr 1  for gac1 and o min csr r1dr   for gac1rm. if c = o 1  or s = o 1   we obtain o rdr 1  for
gac1rm as c+s = dr 1  that is to say optimality. however 
mgac embeddinginstancegac1gac1rgac1rmgac1random instances  mean results for 1 instances - constraints are of arity 1 
cpu ccks1
1m모모1 1k모모1 1k   1 1kcpu ccks1
1m1
1m1
1m1
1mcpu ccks모1m모1m모1m모1mcpu ccks모모1m모모1m모1m모1mstructured instances
tsp-1cpu ccks모1m1
1모1m모1mgr-1-a1cpu ccks1
1m1
1m1
1m1
1mgr-1-a1cpu ccks모1m모1m모1m모1mseries-1cpu ccks모모1m모1m모1m모1mrenaultcpu ccks1
1m1
1m1
1m1
1mtable 1: cost of running mgac
in practice  the likelihood of having small  bounded  values of c or s when dealing with non binary constraints is weak.
모we have performed a preliminary experimentation by maintaining gac algorithms during search on series of random non binary instances. here  we chose constraints of arity 1 and studied the behaviour of the algorithm for a tightness t 뫍 {1 1 1 1}. for small values of t  we observed  as in the binary case  that the difference between all algorithms was limited. on these random instances  one can observe in table 1 that gac1rm and gac1 are the most efficient embedded algorithms. of course  when the tightness is high  gac1 is penalized and gac1r is less efficient then gac1rm as exploiting multi-directionality pays off. on non binary structured instances of the 1 csp solver competition  one can see the good behaviour of gac1r and gac1rm.
1 conclusion
in this paper  we have introduced some theoretical results about the use of residual supports  or residues  in arc consistency algorithms. the concept of residue has been introduced under its multi-directional form in  lecoutre et al.  1  and under its uni-directional form in  likitvivatanavong et al.  1 . we have first proved that the basic algorithm ac1 which is optimal for low constraint tightness  also becomes optimal for high constraint tightness when it is extended to exploit uni-directionalor multi-directionalresidues. furthermore  these extensions to ac1  respectively called ac1r and ac1rm  can be expected to have a good  practical  behavior for medium tightness as asymptotically  for random constraints  1 constraint checks are necessary to find a support when the tightness is 1. then  we have shown that mac1rm admit a better worst-case time complexity than mac1 for a branch of the binary search tree when either 뷃   d1 or 뷃   d and the tightness of any constraint is low or high  with 뷃 denoting the number of refutations of the branch.
모on the practical side  we have run a vast experimentation including mac and sac-1 algorithms on binary and non binary instances. the results that we have obtained clearly show the interest of exploiting residues as ac1rm  embedded in mac or sac-1  were almost always the quickest algorithms  only beaten by ac1 on some non binary instances . it confirms for mac1r  mac1residue  the results presented in  likitvivatanavonget al.  1 . in terms of constraint checks  it appears that ac1rm is quite close to ac1  but usually beaten by ac1 . we also noted that ac1rm was more robust than ac1r on non binary instances and constraints of high tightness.
모finally  residues can be seen as a lazy structure related to the concept of watched literals  moskewicz et al.  1 . in both cases  no maintenanceof data structures upon backtracking is required. we also want to emphasize that implementing  g ac1rm  and embeddingit in mac or sac  is a quite easy task. it should be compared with the intricacy of fine-grained algorithms which requires a clever use of data structures  in particular when applied to non binary instances. the simplicity of ac1rm offers another scientific advantage: the easy reproducibility of the experimentation by other researchers.
acknowledgments
we would like to thank christian bessie`re and romuald debruyne for their useful comments. this paper has been supported by the cnrs and the anr  planevo  project.

 
we present an approach to automatically learning strategies for natural language question answering from examples composed of textual sources  questions  and answers.  our approach formulates qa as a problem of first order inference over a suitably expressive  learned representation.  this framework draws on prior work in learning action and problem-solving strategies  as well as relational learning methods.  we describe the design of a 
system implementing this model in the framework of natural language question answering for story comprehension.  finally  we compare our approach to three prior systems  and present experimental results demonstrating the efficacy of our model.  
1  introduction 
this paper presents an approach to automatically learning strategies for natural language question answering from examples composed of textual sources  questions  and answers.  our approach is focused on one specific type of text-based question answering known as story comprehension.  most trec-style qa systems are designed to extract an answer from a document contained in a fairly large general collection  voorhees  1 .   they tend to follow a generic architecture  such as the one suggested by  hirschman and gaizauskas  1   that includes components for document pre-processing and analysis  candidate passage selection  answer extraction  and response generation.  story comprehension requires a similar approach  but involves answering questions from a single narrative document.  an important challenge in text-based question answering in general is posed by the syntactic and semantic variability of question and answer forms  which makes it difficult to establish a match between the question and answer candidate.  this problem is particularly acute in the case of story comprehension due to the rarity of information restatement in the single document. 
   several recent systems have specifically addressed the task of story comprehension.  the deep read reading comprehension system  hirschman et al.  1  uses a statistical bag-of-words approach  matching the question with the lexically most similar sentence in the story.  quarc  riloff and thelen  1  utilizes manually generated rules that selects a sentence deemed to contain the answer based on a combination of syntactic similarity and semantic correspondence  i.e.  semantic categories of nouns .  the brown university statistical language processing class project systems  charniak  et al.  1  combine the use of manually generated rules with statistical techniques such as bag-of-words and bag-of-verb matching  as well as deeper semantic analysis of nouns.  as a rule  these three systems are effective at identifying the sentence containing the correct answer as long as the answer is explicit and contained entirely in that sentence.  they find it difficult  however  to deal with semantic alternations of even moderate complexity.  they also do not address situations where answers are split across multiple sentences  or those requiring complex inference. 
   our framework  called qable  question-answering behavior learner   draws on prior work in learning action and problem-solving strategies  tadepalli and natarajan  1; khardon  1 .  we represent textual sources as sets of features in a sparse domain  and treat the qa task as behavior in a stochastic  partially observable world.  qa strategies are learned as sequences of transformation rules capable of deriving certain types of answers from particular text-question combinations.  the transformation rules are generated by instantiating primitive domain operators in specific feature contexts.  a process of reinforcement learning  kaebling  et al.  1  is used to select and promote effective transformation rules.  we rely on recent work in attribute-efficient relational learning  khardon et al.  1; cumby and roth  1; even-zohar and roth  1  to acquire natural representations of the underlying domain features.  these representations are learned in the course of interacting with the domain  and encode the features at the levels of abstraction that are found to be conducive to successful behavior.  this selection effect is achieved by a fusion of abstraction space generalization  sacerdoti  1; knoblock  1  and reinforcement learning elements.  
   the rest of this paper is organized as follows.  section 1 presents the details of the qable framework.  in section 1 we describe preliminary experimental results which indicate promise for our approach.  in section 1 we summarize and draw conclusions.    
1  qable - learning to answer questions 
1  overview 
figure 1 shows a diagram of the qable framework.  the bottom-most layer is the natural language textual domain.  it represents raw textual sources  questions  and answers.  the intermediate layer consists of processing modules that translate between the raw textual domain and the top-most layer  an abstract representation used to reason and learn. 
   this framework is used both for learning to answer questions and for the actual qa task.  while learning  the system is provided with a set of training instances  each consisting of a textual narrative  a question  and a corresponding answer.  during the performance phase  only the narrative and question are given. 
   at the lexical level  an answer to a question is generated by applying a series of transformation rules to the text of the narrative.  these transformation rules augment the original text with one or more additional sentences  such that one of these explicitly contains the answer  and matches the form of the question. 
   on the abstract level  this is essentially a process of searching for a path through problem space that transforms the world state  as described by the textual source and question  into a world state containing an appropriate answer.  this process is made efficient by learning answergeneration strategies.  these strategies store procedural knowledge regarding the way in which answers are derived from text  and suggest appropriate transformation rules at each step in the answer-generation process.  strategies  and the procedural knowledge stored therein  are acquired by explaining  or deducing  correct answers from training examples.  the framework's ability to answer questions is tested only with respect to the kinds of documents it has seen during training  the kinds of questions it has practiced answering  and its interface to the world  domain sensors and operators . 
in the next two sections we discuss lexical pre-
processing  and the representation of features and relations over them in the qable framework.  in section 1 we look at the structure of transformation rules and describe how they are instantiated.  in section 1  we build on this information and describe details of how strategies are learned and utilized to generate answers.  in section 1 we explain how candidate answers are matched to the question  and extracted. 
1  lexical pre-processing 
several levels of syntactic and semantic processing are required in order to generate structures that facilitate higher order analysis.  we currently use montytagger 1  an offthe-shelf pos tagger based on  brill  1   for pos tagging.  at the next tier  we utilize a named entity  ne  tagger for proper nouns a semantic category classifier for nouns and noun phrases  and a co-reference resolver  that is limited to pronominal anaphora .  our taxonomy of semantic categories is derived from the list of unique beginners for wordnet nouns  fellbaum  1 .  we also have a parallel stage that identifies phrase types.  table 1 gives a list of phrase types currently in use  together with the categories of questions each phrase type can answer.  in the near future  we plan to utilize a link parser to boost phrase-type tagging accuracy.  for questions  we have a classifier that identifies the semantic category of information requested by the question.  currently  this taxonomy is identical to that of semantic categories.  however  in the future  it may be expanded to accommodate a wider range of queries.  a separate module reformulates questions into statement form for later matching with answer-containing phrases. 
1  representing the question-answering domain 
in this section we explain how features are extracted from 
instantiate rule given:  
  set of primitive operators 
  current state specification 
  goal specification 
 
1. select primitive operator to instantiate 
1. bind active state variables & goal spec to existentially quantified condition variables   
1. execute action in domain 
1. update expected effect of new rule according to change in state variable values 
 
figure 1.  procedure for instantiating transformation phrase type comments subj   who  and nominal  what  questions verb event  what  questions dir-obj   who  and nominal  what  questions indir-obj   who  and nominal  what  questions elab-subj descriptive  what  questions  eg. what kind  elab-verb-time  elab-verb-place  elab-verb-manner  elab-verb-cause   why  question elab-verb-intention    why  as well as  what for  question elab-verb-other smooth handling of undefined verb phrase types elab-dir-obj descriptive  what  questions  eg. what kind  elab-indir-obj descriptive  what  questions  eg. what kind  verb-compl where/when/how 
questions concerning state or status  table 1.  phrase types used by qable framework. raw textual input and tags which are generated by preprocessing modules. 
   a lexical sentence is represented as a sequence of words   w1  w1 ...  wn   where word wi  word  binds a particular word to its position in the sentence.  the kth sentence in a passage is given a unique designation sk.  several simple functions capture the syntax of the sentence.  the sentence main  e.g.  main verb  is the controlling element of the sentence  and is recognized by main wm  sk .  parts of speech are recognized by the function pos  as in pos wi  nn  and pos wi  vbd .  the relative syntactic ordering of words is captured by the function before wi  wj .  it can be applied recursively  as before wi  before wj  wk   to generate the entire sentence starting with an arbitrary word  usually the sentence main.  thus for each word wi  in the sentence  insentence wi  si    main wm  sk  ¡Ä  before wi  wm  ¡Å before wm  wi  .  a consecutive sequence of words is a phrase entity or simply entity.  it is given the designation ex  and declared by a binding function  such as entity ex  ne  for a named entity  and entity ex  np  for a syntactic group of type noun phrase.  each phrase entity is identified by its head  as head wh  ex   and we say that the phrase head controls the entity.  a phrase entity is defined as head wh  ex  ¡Ä inphrase wi  ex  ¡Ä ... ¡Ä inphrase wj  ex . 
   we also wish to represent higher-order relations such as functional roles and semantic categories.  functional dependency between pairs of words is encoded as  for example  subj wi  wj  and aux wj  wk .  functional groups are represented just like phrase entities.  each is assigned a designation rx  declared for example  as func role rx  subj   and defined in terms of its head and members  which may be individual words or composite entities .  semantic categories are similarly defined over the set of words and syntactic phrase entities - for example  sem cat cx  person  ¡Ä  head wh  cx  ¡Ä pos wh  nnp  ¡Ä word wh   john  . 
    semantically  sentences are treated as events defined by their verbs.  a multi-sentential passage is represented by tying the member sentences together with relations over their verbs.  we declare two such relations - seq and cause.  the seq relation between two sentences  seq si  sj    prior main si   main sj    is defined as the sequential ordering in time of the corresponding events.  the cause relation cause si  sj    cdep main si   main sj   is defined such that the second event is causally dependent on the first.   
1  primitive operators and transformation rules the system  in general  starts out with no procedural knowledge of the domain  i.e.  no transformation rules .  however  it is equipped with 1 primitive operators that define basic actions in the domain.  primitive operators are existentially quantified.  they have no activation condition  but only an existence condition - the minimal binding condition for the operator to be applicable in a given state.  a primitive operator has the form ce ¡úa    where ce is the existence condition and a  is an action implemented in the domain.  an example primitive operator is  
   primitive-op-1 :       wx  wy ¡ú  add-word-after-word wy  wx  other primitive operators delete words or manipulate entire phrases.  figure 1 lists all nine primitive operators.  note that primitive operators act directly on the syntax of the domain.  in particular  they manipulate words and phrases.  a primitive operator bound to a state in the domain constitutes a transformation rule.  the procedure for instantiating transformation rules using primitive operators is given in figure 1.  the result of this procedure is a universally quantified rule having the form c¡Ägr ¡úa.  a may represent either the name of an action in the world or an internal predicate.  c represents the necessary condition for rule activation in the form of a conjunction over the 
1.   wx  wy ¡ú  add-word-after-word wy  wx  
1.   wx  wy ¡ú  add-word-before-word wy  wx  
1.   wx ¡ú  delete-word wx  
1.   wx  py ¡ú  add-word-after-phrase py  wx  
1.   wx  py ¡ú  add-word-before-phrase py  wx  
1.   px  wy ¡ú  add-phrase-after-word wy  px  
1.   px  wy ¡ú  add-phrase-before-word wy  px  
1.   px  py ¡ú  add-phrase-after-phrase py  px  
1.   px  py ¡ú  add-phrase-before-phrase py  px  
 
figure 1.  primitive operators used to instantiate transformation rules. relevant attributes of the world state.  gr represents the expected effect of the action.  gr is inductively acquired from prior applications of the rule.  for example   
before w1 w1 ¡Äbefore w1 w1 ¡Ägr before w1 w1  ¡ú add   word   after   word w1 w1  
indicates that when the phrase  w1 w1 w1  is found in the text  this operator is expected to attach w1 to the end  generating the phrase  w1 w1 w1 w1 .   for the rule to be effective in a given state  gr must match all or part of the system's goal specification in that state.   an instantiated rule is assigned a rank composed of: 
¡¡¡¡  priority rating  p  
¡¡¡¡  level of experience with rule  f  
¡¡¡¡  confidence in current parameter bindings  c  the first component  priority rating  is an inductively acquired measure of the rule's performance on previous instances.  the second component modulates the priority rating with respects to a frequency of use measure.  the third component captures any uncertainty inherent in the underlying features serving as parameters to the rule.  the rank of a rule is computed by the following function: 
 
rank = p¡Ác¡Á 1+ log 1+ f    
 
   each time a new rule is added to the rule base  an attempt is made to combine it with similar existing rules to produce more general rules having a wider relevance and applicability. 
   given a rule ca ¡Äcb ¡Ägxr ¡Ägyr ¡ú a1covering a set of example instances e1 and another rule cb ¡Äcc ¡Ägyr ¡Ägzr ¡úa1covering a set of examples e1   we add a more general rule cb ¡Ägyr ¡úa1 to the strategy.  the new rule a1 is consistent with e1and e1.  in addition it will bind to any state where the literal cb is active.  therefore the hypothesis represented by the triggering condition is likely an overgeneralization of the target concept.  this means that rule a1 may bind in some states erroneously.  however  since all rules that can bind in a state compete to fire in that state  if there is a better rule  then a1 will be preempted and will not fire. 
1  generating answers 
returning to figure 1  we note that at the abstract level the process of answer generation begins with the extraction of features active in the current state.  these features represent low-level textual attributes and the relations over them described in section 1. 
   immediately upon reading the current state  the system checks to see if this is a goal state.   a goal state is a state whose corresponding textual domain representation contains an explicit answer in the right form to match the questions.  in the abstract representation  we say that in this state all of the goal constraints are satisfied.  
   if the current state is indeed a goal state  no further inference is required.  the inference process terminates and the actual answer is identified by the matching technique described in section 1 and extracted.   
   if the current state is not a goal state and more processing time is available  qable passes the state to the inference engine  ie .  this module stores strategies in the form of decision lists of rules.  for a given state  each strategy may recommend at most one rule to execute.  for each strategy this is the first rule in its decision list to fire.  the ie selects the rule among these with the highest relative rank  and recommends it as the next transformation rule to be applied to the current state.  
if a valid rule exists it is executed in the domain.  this 
modifies the concrete textual layer.  at this point  the preprocessing and feature extraction stages are invoked  a new current state is produced  and the inference cycle begins anew. 
   if a valid rule cannot be recommend by the ie  qable passes the current state to the search engine  se .  the se uses the current state and its set of primitive operators to instantiate a new rule  as described in section 1. this rule is then executed in the domain  and another iteration of the process begins.   
   if no more primitive operators remain to be applied to the current state  the se cannot instantiate a new rule.  at this point  search for the goal state cannot proceed  processing terminates  and qable returns failure. 
   when the system is in the training phase and the se instantiates a new rule  that rule is generalized against the existing rule base.  this procedure attempts to create more general rules that can be applied to unseen example instances.   
	once 	the 	inference/search 	process 	terminates 
 successfully or not   a reinforcement learning algorithm is applied to the entire rule search-inference tree.  specifically  rules on the solution path receive positive reward  and rules that fired  but are not on the solution path receive negative reinforcement.   
1  candidate answer matching and extraction as discussed in the previous section  when a goal state is generated in the abstract representation  this corresponds to a textual domain representation that contains an explicit answer in the right form to match the questions.  such a candidate answer may be present in the original text  or may be generated by the inference/search process.  in either case  the answer-containing sentence must be found  and the actual answer extracted.  this is accomplished by the answer matching and extraction procedure. 
   the first step in this procedure is to reformulate the question into a statement form.  this results in a sentence containing an empty slot for the information being queried.  for example   how far is the drive to chicago   becomes  the drive to chicago is       .   recall further that qable's pre-processing stage analyzes text with respect to various syntactic and semantic types.  in addition to supporting abstract feature generation  these tags can be used to analyze text on a lexical level.  thus  the question above is marked up as  elab-verb  quantity-distance   wrb how   rb far    verb  vbz is    subj  action   dt the   nn drive    verb-compl  to to   nnp  place  chicago  .  once reformulated into statement form  this becomes  elab-verb  quantity-distance            verb  vbz is    subj  action   dt the   nn drive    verb-compl  to to   nnp  place  chicago  .  the goal now is to find a sentence whose syntactic and semantic analysis matches that of the reformulated question's as closely as possible.  thus  for example the text may contain the sentence  the drive to chicago is 1 hours  with the corresponding analysis  subj  action   dt the   nn drive    verb-compl  to to   nnp  place  chicago    verb  vbz is    verb-compl  quantity-time   cd 1   nns hours  .  notice that all of the elements of this candidate answer match the corresponding elements of the question  with the exception of the semantic category of the elab-verb phrase.  this is likely not the answer we are seeking.  the text may contain a second sentence  the drive to chicago is 1 miles   that analyses as  subj  action   dt the   nn drive    verb-compl  to to   nnp  place  chicago    verb  vbz is    verb-compl  quantity-distance   cd 1   nns miles  .  in this case  all of the elements match their counterparts in the reformulated question.  thus  the second sentence can be matched as the correct answer with high confidence. 
1  experimental evaluation 
1  experimental setup 
we evaluate our approach to open-domain natural language question answering on the remedia corpus.  this is a collection of 1 children's stories provided by remedia publications for reading comprehension.  the comprehension of each story is tested by answering five who  what  where  and why questions.   
   the remedia corpus was initially used to evaluate the deep read reading comprehension system  hirschman et al.  1   and later also other systems  including quarc  riloff and thelen  1  and the brown university statistical language processing class project  charniak  et al.  1 .   
   the corpus includes two answer keys.  the first answer key contains annotations indicating the story sentence that is lexically closest to the answer found in the published answer key  autsent .  the second answer key contains sentences that a human judged to best answer each question  humsent .  examination of the two keys shows the latter to be more reliable.  we trained and tested using the humsent answers.  we also compare our results to the humsent results of prior systems.  in the remedia corpus  approximately 1% of the questions lack an answer.  following prior work  only questions with annotated answers were considered.     
system who what when where why overall deep read 1% 1% 1% 1% 1% 1% quarc 1% 1% 1% 1% 1% 1% brown 1% 1% 1% 1% 1% 1% qable-n/l 1% 1% 1% 1% 1% 1% qable-l 1% 1% 1% 1% 1% 1% qable-l+ 1% 1% 1% 1% 1% 1% table 1.  comparison of qa accuracy by question type. 
 
system total # rules learned total # rules on all solution paths average # rules on solution path per correct answer qable-l 1 1 1 qable-l+ 1 1 1 table 1.  analysis of transformation rule learning and use.    we divided the remedia corpus into a set of 1 tests used for development  and 1 tests used to evaluate our model  employing the same partition scheme as followed by the prior work mentioned above.  with five questions being supplied with each test  this breakdown provided 1 example instances for training  and 1 example instances to test with.  however  due to the heavy reliance of our model on learning  many more training examples were necessary.  we widened the training set by adding storyquestion-answer sets obtained from several online sources1.  all of these additional stories are supplied with questions  but few have answers.  to complete the training set  a human generated reasonable answers to the questions.  with the extended corpus  qable was trained on 1 stories with 1 questions each  corresponding to 1 example instances.   
1  discussion of results 
table 1 compares the performance of different versions of qable with those reported by the three systems described above.  we wish to discern the particular contribution of transformation rule learning in the qable model  as well as the value of expanding the training set.  thus  the qablen/l results indicate the accuracy of answers returned by the qa matching and extraction algorithm described in section 1 only.  this algorithm is similar to prior answer extraction techniques  and provides a baseline for our experiments. the qable-l results include answers returned by the full qable framework  including the utilization of learned transformation rules  but trained only on the limited training portion of the remedia corpus.  the qable-l+ results are for the version trained on the expanded training set.    
   as expected  the accuracy of qable-n/l is comparable to those of the earlier systems.  the remedia-only training set version  qable-l  shows an improvement over both the baseline qable  and most of the prior system results.  this is due to its expanded ability to deal with semantic alternations in the narrative by finding and learning transformation rules that reformulate the alternations into a lexical form matching that of the question.   
   the results of qable-l+  trained on the expanded training set  are for the most part noticeably better than those of qable-l.  this is because training on more example instances leads to wider domain coverage through the acquisition of more transformation rules.  table 1 gives a break-down of rule learning and use for the two learning versions of qable.   the first column is the total number of rules learned by each system version.  the second column is the number of rules that ended up being successfully used in generating an answer.  the third column gives the average number of rules each system needed to answer an answer  where a correct answer was generated .  note that qable-l+ used fewer rules on average to generate more correct answers than qable-l.   this is because qable-l+ had more opportunities to refine its policy controlling rule firing through reinforcement and generalization. 
   note that the learning versions of qable do significantly better than the qable-n/l and all the prior systems on why-type questions.  this is because many of these questions require an inference step  or the combination of information spanning multiple sentences.  qable-l and qable-l+ are able to successfully learn transformation rules to deal with a subset of these cases. 
1  conclusion  
in this paper we present an approach to automatically learn strategies for natural language questions answering from examples composed of textual sources  questions  and corresponding answers.   the strategies thus acquired are composed of ranked lists transformation rules that when applied to an initial state consisting of an unseen text and question  can derive the required answer. we compare our approach to three prior systems  and present experimental results demonstrating the efficacy of our model. in particular  we show that our approach is effective given a sufficiently large training corpus  and reasonably accurate pre-processing of raw input data. 

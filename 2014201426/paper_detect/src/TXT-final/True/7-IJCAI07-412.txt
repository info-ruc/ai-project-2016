
many interesting human actions involve multiple interacting agents and also have typical durations. further  there is an inherent hierarchical organization of these activities. in order to model these we introduce a new family of hidden markov models  hmms  that provide compositional state representations in both space and time and also a recursive hierarchical structure for inference at higher levels of abstraction. in particular  we focus on two possible 1-layer structures - the hierarchical-semi parallel hidden markov model  hspahmm  and the hierarchical parallel hidden semi-markov model  hpahsmm . the lower layer of hspahmm consists of multiple hmms for each agent while the top layer consists of a single hsmm. hpahsmm on the other hand has multiple hsmms at the lower layer and a markov chain at the top layer. we present efficient learning and decoding algorithms for these models and then demonstrate them first on synthetic time series data and then in an application for sign language recognition.
1	introduction
our goal is to develop methods for inferring activities given observations from visual and other sensory data. activities have a natural hierarchical structure where combinations of simpler activities form higher level  more complex activities. in general  multiple agents may be involved who take parallel actions but whose temporal  and spatial  relations are important for inference of higher level activities. we present a mathematical formalism for recognizing such multi-agent activities that can take advantage of both their inherent hierarchical organization and typical durations. such models can have a wide range of applications such as surveillance  assistive technologies like sign language recognition and intelligent environments.
모a key challenge faced by researchers in activity recognition is to bridge the gap between the observations  such as limb joints  and the high level semantic concepts  such as gestures  that need to be recognized and to handle the large variations in the duration and styles of these activities when performed by different people or even the same person at different times. due to uncertainty inherent in sensory observations  probabilistic reasoning offers a natural approach. while several probabilistic models have been proposed over the years in various communities for activity recognition  hidden markov models  hmms  and their extensions have by far been the most widely used ones. they offer advantages such as clear bayesian semantics  efficient learning and inferencing algorithms  and a natural way to introduce domain knowledge into the model structure.  bui et al.  1  presented an extension of the hierarchical hidden markov model  hhmm  for inferring activities at different levels of abstraction.  hongeng and nevatia  1  used the hidden semi-markov model  hsmm  for modeling activity durations  while  duong et al.  1  presented the switching hidden semi-markov model  s-hsmm  to exploit both the hierarchical structure as well as typical durations for activity recognition.  vogler and metaxas  1  introduced the parallel hidden markov model  pahmm  for recognizing complex 1-handed gestures in asl while  brand et al.  1  introduced the coupled hidden markov model  chmm  and applied it to recognize tai chi gestures as well as multi-agent activities.
모we believe that in most real applications we need models that combine the features of all of these models and introduce a new class of models  namely the hierarchical multichannel hidden semi-markov models. in particular we focus on two model structures - the hierarchical semi parallel hidden markov model  hspahmm  and the hierarchical parallel hidden semi-markov model  hpahsmm  and present efficient decoding and learning algorithms for them. we validate the utility of these models by testing on simulated data as well as for the real task of continuous sign language recognition.
모the rest of the paper is organized as follows - in the next section we define the parameters of hspahmm and hpahsmm formally. then in the sections 1 and 1 we present efficient decoding and learning algorithms for them. finally in section 1 we present the experimental results.
1 model definition and parameters we begin by defining a standard hmm model 뷂 by the tuple  q o a b 뷇  where  q is the set of possible states  o is the set of observation symbols  a is the state transition probability matrix  aij = p qt+1 = j|qt = i    b is the observation probability distribution  bj k  = p ot = k|qt = j   and 뷇 is the initial state distribution. it is straightforward to generalize this model to continuous  like gaussian  output models.
모this can be extended to a hierarchical hidden markov model  hhmm  by including a hierarchy of hidden states. a hhmm can be formally specified by the tuples- 
 qd od ad bd 뷇d  where d 뫍 1..h indicates the hierarchy index.
모in traditional hmms  the first order markov assumption implies that the duration probability of a state decays exponentially. the hidden semi-markov models  hsmm  were proposed to alleviate this problem by introducing explicit state duration models. thus a hsmm model can be specified by the tuple- where  d contains a set of parameters of the form p di = k   i.e. the probability of state i having a duration k.
모in the basic hmm  a single variable represents the state of the system at any instant. however  many interesting activities have multiple interacting processes and several multi-channel hmms have been proposed to model these. these extensions basically generalize the hmm state to be a collection of state variables  st = st1  stc . in their most general form  such extensions can be represented as-  where qc and oc are the possible states and observations at channel c respectively and 뷇c represents the initial probability of channel c's states. ac contains the transition probabilities over the composite states     and bc contains the observation probabilities over the composite states  p  o1t .. oct  | qt1 .. qtc   . in this form  the learning as well as inferencing algorithms are exponential in c  and also result in poor performance due to over-fitting and large number of parameters to learn. the various multi-channel extensions typically introduce simplifying assumptions that help in factorizing the transition and observation probabilities. parallel hidden markov models  pahmm  factor the hmm into multiple independent chains and hence allow factorizing both ac and bc. coupled hidden markov models  chmm  factor the hmm into multiple chains where the current state of a chain depends on the previous state of all the chains.
모the hierarchical multi-channel hidden semi-markov models that we propose try to combine all the above characteristics into a single model structure. in the most general form  they can be described by a set of parameters of the form where  d 뫍 1..h is the hi-
erarchy index and c is the number of channels at level d  and the parameters have interpretations similar to before. each channel at a higher level can be formed by a combination of channels at the lower level. also  the duration models at each level is optional. further  the channels at each level in the hierarchy maybe factorized using any of the methods discussed above  pahmm  chmm etc . it can be seen that 뷂 presents a synthesis of. hspahmm has 1 layers with multiple hmms at the lower layer and hsmm at the upper layer and has the following set of parameters-
모모모모뷂hspahmmlower =  qclower olowerc  aclower blowerc  뷇lowerc   뷂hspahmmupper =  qupper oupper aupper bupper dupper 뷇upper 
hpahsmm contains multiple hsmms at the lower layer and a single markov chain at the upper layer and hence has the following set of parameters-
뷂hpahsmmlower =  qclower olowerc  aclower blowerc  dlowerc  뷇lowerc   뷂hpahsmmupper =  qupper oupper aupper bupper 뷇upper 
figure 1 illustrates the various hmm extensions dis-

figure 1: structure of a hmm b hsmm c pahmm d pahsmm e hspahmm f hpahsmm cussed. the key difference between hspahmm and hpahsmm is that hspahmm models the duration for the entire low-level pahmm with the top-level hsmm state while hpahsmm models the duration of each state in each low-level hsmm. thus hspahmm requires fewer parameters  while hpahsmm is a richer structure for modeling real events.
1	decoding algorithm
in this section  we use the following notations - let c be the number of channels in lower layer  t the number of frames or observations in each channel  n the number of states in each channel of the lower layer1 and w the number of lower level hmms. then  the top-level hmm will have one state for every lower level hmm as well as a state for every possible transition between lower level hmms. this is because in applications like sign language recognition where each word is modeled by a multi-channel hmm/hsmm each transition between the words in the lexicon is distinct. each of the w hmms can transition to any of the w hmms giving a total of w1 transition states. thus the top-level hmm has a total of w    w + 1  states.
1	hspahmm decoding
the decoding algorithm for hspahmm works by traversing the top-level hsmm and at each time segment finding the maximum likelihood path through the low-level pahmm corresponding to the upper hsmm's state. traversing the top-level hsmm states takes o w1 w + 1t1  time and each call to the lower pahmm takes o cn1t  time giving a total complexity of o w1 w + 1n1 . we can reduce this complexity if the duration models for the top-level hsmm are assumed to be uniform or normal. in this case  we can define parameters m and  for each state in the toplevel hsmm such that we only need to consider state durations in the range  m    m +  . the values of m and  can be obtained from the lower and upper thresholds in the case of uniform distributions or from the mean and variance in normal distributions. in this case since we need to check only 1 durations at each instant and each low-level pahmm has m observations on average  traversing the toplevel hsmm takes o w1 w +1t  and each lower level pahmm takes o cn1m  giving a total inference complexity of o cw1 w + 1n1tm . still  even for small values of w the inference complexity become prohibitively large as it varies with w1 w + 1. we can get around this by storing only the top k states of the upper-hsmm at each instant. then  since each state can only transfer to o w  states  transition states can transfer only to the destination states while states corresponding to lower-level pahmms can transfer to w transition states   the overall inference complexity becomes o cwkn1tm . figure 1 illustrates the decoding algorithm and algorithm 1 presents the pseudocode.

figure 1: decoding hspahmm
1	hpahsmm decoding
for decoding hpahsmms  we have to traverse the top-level markov chain and at each state call the corresponding lowlevel pahsmm. this procedure can be simplified by stringing together the low-level pahsmms and also the transition states into one large compound pahsmm and then traversing it. since the w low-level pahsmms have n states each and there are w1 transition states in the top level  the compound pahsmm has w    w + n  states. note that the transition states can have their own duration and output models. since each channel of the compound pahsmm is a hsmm taking o w1 w + n 1  1 time  the entire decoding algorithm algorithm 1 hspahmm decoding
1: top-level hsmm has w* w+1  states
1: we use the following indices for states-
- top-level states 1..w-1 have low-level pahmms corresponding to them.
- top-level state w + w1w + w1 is the transition state for the w1 뫸 w1 transition where w1 w1 뫍  1..w   1 
1: beam t =top k states at time t.
1: state i's duration 뫍  m i     i  m i  +  i  
1: 붻ti = probability of max-likelihood path to state i at time t.
1: pt m|l  = probability of transitioning to state m from state l. 1: po ot1..ot1|m  = probability of observing ot1..ot1 in state
1:	= probability of spending duration d in state m.
1: maxpath m t1 t1  = function to calculate probability of max-likelihood path through low-level pahmm of state m from time t1 to t1. see  vogler and metaxas  1  for details.
1: for i = 1 to t do
1:	for j = 1 to k do
1:	l 뫹 jth state in beam i 
1:	if l   w then
1:	for m =  l + 1    w to  l + 1    w + w do
1:	fordo
1:		 	 	 n|m   
1:	ifpaths at time i + n then
1:add m to beam i + n 1:end if1:end for1:end for1:else1:	m	remainder l/w 뫹
1:	fordo
1:	i n	i	 	 	 	+1 i+n 
1:in top k paths at time i + n then
1:	add m to beam i + n 
1:	end if
1:	end for
1:	end if
1:	end for
1: end for
1: return 붻 of maximum probability state in beam t 

takes o cw1 w +n 1 . if the duration models are normal or uniform we only need to consider state durations in the range  m  m+  where the values of m and  are defined for each state of every pahsmm. the time complexity then becomes o cw1 w + n 1tm . further by storing only the top k states in the compound pahsmm at each instant  we can reduce the complexity to o ckw w + n tm . figure 1 illustrates the decoding algorithm and algorithm 1 presents the pseudocode for hpahsmm.
1	embedded viterbi learning
in many applications like sign language recognition and event recognition the training samples typically contain a sequence of words/events which are not segmented. in such cases  we string together the individual word/event hmms and then reestimate the parameters of the combined hmm using the traditional baum-welch algorithm. thus the individual events are segmented automatically during the re-estimation profigure 1: decoding hpahsmm
cess. in constrained hmm structures like the the left-right hmm  where each state can transition only to itself or to one state higher   the re-estimation procedure can be simplified by calculating the viterbi path through the hmm at each iteration and re-estimating the parameters by a histogram analysis of the state occupancies. since in our applications we are primarily interested in left-right hmms  we adopted a viterbi-like embedded training algorithm for hspahmm and hpahsmm. algorithm 1 presents the pseudocode for the learning algorithm where at each iteration we call the corresponding decoding algorithm and then re-estimate the parameters using a simple histogram analysis of state occupancies.
1	experiments
to evaluate learning and decoding in hspahmm and hpahsmm we conducted two experiments: one with synthetic data  other with real data for a sign language  asl  recognition task. in both cases  we compare our results with pahmm without any duration models and beam search on the states. all run time results are on a 1ghz pentium 1 windows platform with 1gb ram  running java programs.
1	benchmarks on synthetic data
in this experiment  we used a discrete event simulator to generate synthetic observation sequences. each event can have c=1 channels/agents  and each channel can be in one of n=1 states at any time. state transitions were restricted to be leftto-right so that each state i can transition only to state  i+1 . the states had 1-dimensional gaussian observation models with the means uniformly distributed in  1  and the covariances were set to i/1. further  each state had gaussian duration models with means in the range  1  and variances set to dparam=1. we then built a top-level event transition graph with uniform inter-event transition probabilities. continuous observation sequences were then generated by random walks through the event transition graph and the corresponding low-level event models. random noise was added in between the event sequences as well as at the beginning and end of the observation sequence. figure 1 illustrates this procedure for a 1 event top-level transition graph. as can be seen  this setup corresponds to the hpahsmm model structure. observation sequences were generated using the setup described above using a 1-event top-level transition graph such that each sequence had 1 individual events and each event occurred at least 1 times in the entire set of
1:for j = minth to maxth do1:for l = 1 to c do1: 1:for m = 1 to w    w + n  do
for n = 1 to k do1:	p	th
1:	
1:	if	in top k paths at time i + j then
1:	add m to beam l i + j 
1:	end if
1:	end for
1:	end for
1:	end for
1:	end for
1: end for
1: return  of maximum probability state in beam c t 

sequences producing in total 1 sequences. we then randomly chose a set of training sequences such that each word occurred at least 1 times in the training set and used the rest as test sequence. thus the training set contained 1 sequences and the test set contained 1 sequences. the data generators were then discarded and then the following models were trained - 1 hpahsmm with randomly initialized output models  left-right low-level pahsmms and low-level duration models  parameters m   - see section 1  set accurately using the corresponding simulator parameters. the beamsize k was set manually. 1  hspahmm with randomly initialized output models  left-right low-level pahmms and toplevel duration models whose means  m  were set by summing over the means of the corresponding low-level pahsmms in the simulator and set the parameters k and   see section 1  manually. 1  pahmm with the output models initialized randomly and decoding performed by a viterbi beam search. each model was trained by re-estimating the output models using embedded viterbi learning described in section 1 until the slope of the log-likelihood curve fell below 1 or when 1 training iterations were completed. we then ran the learned models on the test sequences and obtained accuracy measures using the metric  n   d   s   i /n where
n=number of events in test set  d=no. of deletion errors  s=no. of substitution errors  i=no. of insertion errors.
since the accuracy as well as complexity of the decoding algorithms depend on manually set parameters  k  for hspahmm and k for hpahsmm  we first investigated their algorithm 1 embedded viterbi learning
1: numtrain = number of training samples
1: pct j|i  = probability of transitioning from state i to state j in channel c.
1: pco oi|j  = probability of observing symbol oi in state j in channel c.
1: pcd d|i  = probability of spending a duration d in state i in channel c.
1: for i = 1 to numtrain do
1:	jointhmm 뫹 string together hmms of words/events forming training sequence i.
1:	repeat
1:	maxpath 뫹 state sequence of maximum probability path through jointhmm obtained using decoding algorithm.
1:	nci 뫹 no. of times channel c is in state i in maxpath.
1: nci j 뫹 no. of times channel c transitions from state i to state j in maxpath. c oj
1: ni 뫹 no. of times oj is observed in state i channel c in maxpath.
1: nc di 뫹 no. of times state i in channel c spends duration d in maxpath.
1:	re-estimate parameters using the following equations 1:
1:	pc  oi|j  뫹 nc oj i/nj
1:	pcd d|i  뫹 nc di /nci
1:	until convergence
1:	split hmms and update corresponding word/event hmms.
1: end for

effects. to do this  we varied the parameters and ran 1 iterations of the train-test setup described above for hspahmm and hpahsmm for each parameter value. figures 1 show these variations.
모as can be seen  while increasing  in hspahmm produces a significant drop in frame rate  it does not affect the accuracy. on the other hand  increasing the beam size k  produces a significant increase in accuracy at the cost of slower speed. for hpahsmm  increasing the beam size does not improve accuracy. based on these observations we ran a set of 1 tests comparing hspahmm  with  = 1  k = 1   hpahsmm  with k = 1  and pahmm. table 1 summarizes the average accuracies and speeds. thus  hspahmm pro-
modelaccuracyspeedhpahsmm1% n=1  d=1  s=1  i=1 1hspahmm1% n=1  d=1  s=1  i=1 1pahmm1% n=1  d=1  s=1  i=1 1table 1: model accuracy %  and speed fps 
duces a huge jump in performance when compared to plain pahmm without affecting the speed. while hspahmm's accuracy is still lower than hpahsmm  it is 1 times faster and thus serves as a good mean between hpahsmm and pahmm.
1	application to continuous sign language recognition
sign language recognition  besides being useful in itself  provides a good domain to test hierarchical multi-agent activi-

figure 1: structure of event simulator

figure 1: variation of hspahmm speed frames/sec or fps  and accuracy %  with a sigma  beam size=1 b beam size  sigma=1
ties; both hands go through a complex sequence of states simultaneously  each sign has distinct durations  and there is hierarchical structure at the phoneme  word and sentence level. we experimented with a set of 1 test sentences from a larger dataset used in  vogler and metaxas  1  provided by dr.vogler ; the sequences were collected using a motionstartm system at 1 frames per second. vocabulary is limited to 1-words; each sentence is 1 words long for a total of 1 signs. the input contains the  x y z  location of the hands at each time instant; from these we calculate the instantaneous velocities which are used as the observation vector for each time instant.
모we model each word as 1-channel pahmm  for hspahmm  or pahsmm  for hpahsmm  based on the movement-hold mh  model  liddell and johnson  1  which breaks down each sign into a sequence of  moves  and  holds . during a  move  some aspect of the hand is changed while during a  hold  all aspects are held constant. the mh model also identifies several aspects of hand configuration like location  chest  chin  etc   distance from body  hand shape  kind of movement  straight  curved  round  etc. with these definitions  we can encode the signs for various words in terms of constituent phonemes. for example  in the word  i   a right-handed signer would start some distance from his chest with all but his index finger closed and end at the chest. this can be encoded in the mh model as  h p1ch m strtoward h ch    where p1ch indi-

figure 1: variation of hpahsmm speed fps  and accuracy %  with beam size
cates that the hand is within a few inches in front of the chest at the start  strtoward indicates that hand moves straight perpendicular to the body and ch indicates that the hand ends at the chest. similar transcriptions can be obtained for more complex 1 handed signs by considering both hands as well as hand shape.
모we model the observation probabilities in the hold states as a normal distribution with 뷃 = 1 while the move states are modeled as a signum function. further  we set the inflection point of the signum to be the same as the gaussian's variance. the intuition behind this choice is that during the hold states the configuration of the hand remains constant with some random noise  while we have a  move  whenever the hand's position changes above the noise threshold during an instant.
모we specified the duration models for the move states based on the distance between the starting configuration and the ending configuration and the frame rate. in order to do this we separated the possible hand locations into 1 clusters - those around the abdomen ab   those around the chest ch  and those around the face/forehead fh . we approximately initialized the hold state and intra-cluster transition times by looking at a few samples and set the inter-cluster transition time to be twice the intra-cluster transition time. we modeled the duration as normal distribution centered around these means and variance = 1 so that the th in the decoding algorithm is reasonably small. for the upper level hsmm in hspahmm  we set the means m  by adding the means of the individual states and set  = 1. thus  we approximately set a total of 1 parameters for the entire set up. table 1 shows the word accuracy rates. these results indicate
modelaccuracyspeedhpahsmm1% n=1  d=1  s=1  i=1 1hspahmm1% n=1  d=1  s=1  i=1 1pahmm1% n=1  d=1  s=1  i=1 1table 1: word accuracy rates %  and speed fps 
that including duration models significantly improves the results. hspahmm provides a good high-speed alternative to hpahsmm. further  hspahmm produces better results than pahmm because the top-level hsmm restricts the number of word transitions and hence reduces the number of insertion errors. these results were obtained without requiring any additional training data using very simple features. for comparison  existing algorithms for continuous sign language recognition  vogler and metaxas  1   starner et al.  1  require training sets with 1 signs for a test set of 뫘 1 signs.  bowden et al.  1  reports good results on isolated word recognition with a 1 word lexicon that uses just one training sequence per word  but the words in both the test and train sequences are pre-segmented; this is a much easier task than continuous sign language recognition demonstrated here.
1	conclusion
we have presented a new class of hmms that provides a hierarchical multi-channel structure with explicit duration models; we focused on two instances - hspahmm and hpahsmm and presented efficient decoding and learning algorithms for them. we rigorously analyzed their performance on synthetic multi-channel time series data and also presented a real application. the methods are not specific for a task domain and should apply to a wide variety of multi-agent activity recognition.

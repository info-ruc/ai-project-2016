: 
           this raport outlines the problem of intelligent failure recovery in   problem-solver for electrical design. we want our problem solver to learn as much as it can from its mistakes. thus we cast the engineering design process in terms of problem solving by debugging almost-right plans  a paradigm for automatic problem solving based on the belief that creation and removal of  bugs  is an unavoidable part of the process of solving a complex problem. the process of localization and removal of bugs called for by the psboarp theory requires an approach to engineering analysis in which every result has a justification which describes the exact set of assumptions it depends upon. we have developed a program based on analysis by propagation of constraints which can explain the basis of its deductions. in addition to being useful to a psbdarp designer  these justifications are used in dependency-directed backtracking to limit the combinatorial search in the analysis routines. 
           although the research we will describe is explicitly ebout electrical circuits  we believe that similar principles and methods ere employed by other kinds of engineers  including computer programmers. 
introduction: 
           engineers combine  analyze  debug  and explain structures in the course of design. they decide how simple structures may be combined to achieve particular goals. they can predict the behavior of complex structures by combining the behaviors of the substructures out of which they were formed. this analysis is critical for debugging plausible designs which do not quite work  for constraining the possible design decisions  and for ruling out unfeasible plans. finally  an engineer must be able to explain the devices which he has designed. an explanation is often a description of how the behavior of the composite device can be attributed to the combined behaviors of its parts. the ability to explain is crucial to analysis and design. it is much easier to analyze a system if we know the intended operation of the parts. 
           this paper outlines our project to construct an electrical circuit designer program as part of an effort to understand the fundamental mechanisms involved in reasoning about complex  deliberately constructed systems. parts of this program already exist  other parts are being developed and others ere still in the planning stage. essential ideas from the recent theses of allen brown on the localization of failures in radio circuits  brown 1  and drew mcdermott on a rulebased system of hierarchical design  mcdermott 1  are being incorporated into this project. 
a theory of the engineering design process: 
           innumerable hours can be spent tracking down a  bug  in a computer program  an electronic device  or a mathematical proof. at such times it may seem that a bug is at best a nuisance and at worst a disaster. we believe that many bugs are just manifestations of powerful strategies of creative thinking - that creation and removal of bugs are necessary steps in the normal process of solving a complex problem. following the work of poly a  polya 1   recent research  fahlman 1   sussman 1   gold$tein 1  predicated on this belief has resulted in the development of a paradigm for problem solving which we cell problem solving by debugging almost-right plans  psbdarp . we believe that the psbdarp theory is a good foundation for building expert problem-solving systems for such diverse kinds of engineering as circuit design and computer programming. 
the psbdarp theory: 
           figure 1 displays the structure of a psbdarp problem solver. when the problem solver is given a problem it first checks its answer library to determine if there is an answer available whose pattern of applicability matches the problem 


a p p l i c a t i o n s - 1 : 	sussman 
1 

statement. if so  the proposed answer is tested make sure that it really works and if it passes the test it is returned as the answer to the problem posed. but suppose the answer is not immediately available. the problem solver next examines a set of problem decompositions to see if any are appropriate for breaking the problem into more manageable chunks. if so  the problem solver remembers the decomposition rule chosen and recursively calls itself to solve each subproblem separately. if this is possible  the solutions returned are combined according to the decomposition rule used to break the problem up and the resulting proposal is sent off to be tested. if there are no decomposition rules available which match the problem statement  the problem solver next checks to see if there are any changes of representation which can be applied to the problem statement to put it into a form more amenable to solution. if so  the problem is considered in terms of the alternate representation. if no representation changes are appropriate  the problem solver has failed on this problem and reports its failure. a failure may cause backtracking and search. 
           suppose that a composite solution is eventually proposed and tested. if it is found to work it is returned as the answer  but often the proposal has a bug. a bug may manifest by a contradiction among the constraints of the modules which are the solutions to the subproblems. the composite solution is also analyzed to see if it actually achieves the goal. if there is a bug the next step is to localize the cause of the failure. since the solution is a composite of correct solutions to subproblems  the bug must be the result of some unanticipated interaction between the parts of the proposed solution. in any case the problem solver must construct a subproblem whose solution would fix the bug. this problem is then solved  by a recursive call to the problem solver  and the resulting patch is installed in the proposed solution. the corrected solution must then be retested against the original criteria. 
why are there bugs  
           one might imagine a problem-solver based on figure 1 which produced only correct solutions to problems -- that is  one in which the question  does it work   is always answered  yes . the. problem with this idea is that a crucial part of the problemsolving strategy is the decomposition of problems into presumably independent subproblems. there is no guarantee that this is possible in general  but even when it is not possible  there are often general strategies for approximating a solution to a problem by composing the solutions to almost independent subproblems. often one can make progress on the solution to a hard problem by considering the solution of a simplified version of the problem which is similar in some essential aspect to the original one but which differs from it in detail. but even in those cases where a decomposition into completely independent subproblems is possible  it is not always feasible. in order to be sure that the solutions to the subproblems are really independent it is necessary to understand the problem and the possible implementations of subsolutions so completely that one must effectively solve the entire problem before choosing the correct 
decomposition. this compromises the decomposition strategy. another difficulty is that in order to allow  perfect  solutions  the decompositions and possible answers to problems must be specified more precisely. this leads to a proliferation of stored answers and decompositions which differ in only some minor aspect and thus hide the power of generalization. 
           superficially  psbdarp is a kind of means-ends analysis  ernst & newell 1  but it is not profitable to merge the concepts. in means-ends analysis the problem solver considers the current state of the problem solution and the goal being approached and attempts to apply an operator which will move the solution in the direction of the goal. often the operator will decompose the problem into subproblems which can be achieved separately  to be combined into a solution of the overall problem. at this point the psbdarp philosophy diverges. in means-ends analysis the process is now iterated. in debugging  the original goal may be ignored because many bugs manifest in terms of destructive interactions among the solutions of subprobiems. 
           in psbdarp there is a specific phase of the solution process where debugging knowledge is applied. this knowledge is relatively domain independent and is concerned with notions of causality  teleology and simultaneous constraints. the debugging phase is far more concerned with the structure of the plan produced by the decomposition phase than it is with the goal that evoked the plan. for example  localization of a bug in an electrical circuit or in a computer program may involve such strategies as  tracing  - examination of the conditions at various module boundaries to determine how the expected conditions compare with those that actually occur. 
an example of synthesis: 
           consider a concrete problem of engineering synthesis. suppose we want an electrical network with a specified system function; perhaps a network having a voltage-transfer ratio whose magnitude varies with frequency as follows: 

we recognize that the encoding of these requirements is not obvious - part of the research is to determine appropriate languages for such description. the designer first checks the bag of tricks for a plan fragment  an answer or decomposition  whose pattern of applicability matches the goal.  an expert engineer would probably have an answer on tap for so simple a problem.   matches  is a rather complex idea - features must be extracted such as the  flat response  between wl and w1  the fall off at frequencies above w1 and below w l   the positions of the  elbows   etc. in this case we assume that the designer does not have a plan fragment for synthesis of the required network  so it has to look for a transformation of the problem.  in mcdermott's terminology  we enter the  rephrasing protocol .  in this case  there is a good transformation available ~ from a magnitude graph to a pole - zero plot.  this is an algorithmic transformation which requires careful measurement of the parameters of the magnitude plot.  we get: 


applications-1: sussman 
1 

       in this case analysis discovers a bug. our analysis of nl as a voltage divider was contingent on the assumption that no current would be drawn from the midpoint of the divider. our analysis of n1 was contingent on it drawing a significant current. these assumptions are contradicted by connecting the output of 
in fact  if our  bag of tricks  includes some techniques of elgebreic manipulation we can turn our product into a sum by a partial-fraction expansion. 
we next try to expand and instantiate the plan 
fragment's parts. we are forced to solve 1 subproblems: nl to the input of n1. this contradiction is apparent from local evidence in the structure of the proposed solution independent of the goal of the overall circuit. we have caught ttr  unanticipated destructive interaction between the subproblem solution modules. this particular kind of bug  called loading is common and should be considered whenever ports are connected together. 
the statement of this bug - that we have a port 
voltage which we cant draw a current from  connected to a port which wants to draw a current at that voltage -- can easily be turned into a statement of a problem whose solution is an appropriate patch for this bug. wishful thinking tells us that if we hed e voltage-controlled voltage source inserted between nl end n1 everything would be ok. 
applicatlons-1: sussman 
1 

we now have e good place to absorb our constant k  thus solving the problem given: 

           suppose we were using pure means-ends analysis rather then a debugging strategy. at point *** above we would then analyze our current circuit and compere it with the result we expected  the goat . in this case  analysis leads to the following result: 

the difference between the answer we got and the answer we wanted is just that there is an extra term  r1  in the second coefficient of the denominator. why is this term present  allen brown  brown 1  has developed methods for localizing bugs using causal and tepeological reasoning about a circuit but it is certainly a more difficult problem to pursue this path than the one we have. 
the propagation theory of engineering analysis: 
           it is important that the bug localization process have access to the assumptions on which the bug manifestation is based. this depends upon analysis being able to explain its answers. in this section we will describe progress that has been made on an analysis program that reasons qualitatively about circuits and can explain its results. 
           as part of the development of the psbdarp circuit designer  we have developed el  a new kind of electrical network enalysis program  sussman ft staliman 1 . the literature is full of powerful and useful circuit analysis systems which implement the formal methods. what is novel about this program it its rule-based approach to network analysis and its consequent ability to explain the basis of its deductions. 
           el is implemented in ars  antecedent reasoning system   a problem-solving language which implements rules as demons with multiple patterns of invocation monitoring an associative data base  stallman & sussman 1 . it performs ell deductions in an antecedent manner  threading the deduced facts with justifications which mention the antecedent facts used end the rule of inference applied. these justifications may be 
examined by the user to gain insight into the operation of the system of rules as they epply to a problem. the same justifications are employed by the system to determine the currently active data-base context for reasoning in hypothetical situations. justifications are also used in the analysis of blind alleys to extract information which will limit future search. 
           el is a set of ars rules for electronic circuit analysis. this set of rules encodes familiar approximations to physical laws such as kirchoff's laws and ohm's law as well as models for more complex devices such as transistors. facts  which may be given or deduced  represent data such as the circuit topology  device parameters  voltages and currents. the antecedent reasoning of ars gives analysis by el a  cetch-es-catch-can  flavor suggestive of the behavior of a circuit expert. the justifications prepared by ars allow an el user to examine the basis of its conclusions. this is useful in understanding the operation of the circuit as well as in debugging the el rules. for example  a device parameter not mentioned in the derivation of a voltage value has no part in determining that value. if a user changes some part of the circuit specification  a device parameter or an imposed voltage or current   only those facts depending on the changed fact need be  forgotten  and re-deduced  so small changes in the circuit may need only a small amount of new analysis. finally  the search-limiting combinatorial methods supplied by ars lead to efficient analysis of circuits with piecewise-linear models. 
           the style of analysis performed by el  which we call the method of propagation of constraints  requires the introduction and manipulation of some symbolic quantities. though the system has routines for symbolic algebra  they can handle only linear relationships. nonlinear devices such as transistors are represented by piecewise-linear models that cannot be used symbolically; they can be applied only after one has guessed a particular operating region for each nonlinear device in the circuit. trial and error can find the right regions  but this method of assumed states is potentially combinatorially explosive. ars supplies dependency-directed backtracking  a scheme which limits the search as follows: the system notes a 
           contradiction when it attempts to solve an impossible algebraic relationship  or when discovers that a device's operating point is not within the possible range for its assumed region. the antecedents of the contradictory facts are scanned to find which nonlinear device state guesses  more generally  which backtrackable choicepoints  are relevant  ars nenr tries that combination of guesses again. a short list of relevant choicepoints eliminates from consideration a large number of combinations of answers to all the other  irrelevant  choices. the fact that the set of assumptions leading to the contradiction is inconsistent is summarized and recorded with antecedents being that part of the support of the contradiction which are independent of the assumptions. these summaries are examined whenever a choice has to be made  thus preventing rechoosing of an inconsistent set of assumptions. thus the justifications  or dependency records  are used to extract and retain more information from each contradiction than a chronological backtracking system. a chronological backtracking system would often have to try many more combinations  each time wasting much labor rediscovering the original contradiction. 
           jon doyle is now engaged in further research on the uses of dependency information in the control of reasoning  doyle 1 . 1 de kleer  jon doyle  guy steele and this author have been developing an even more powerful rule-besed language we call amord in which the el rules can be expressed in e more hierarchical form. 
history of this project and relation to other work: 
　　　　　　the psbdarp theory of design has many antecedents. the idea of successive refinement of plans appears as a key dogma of  structured programming   dijkstra 1   wirth 1   dahl et el 1   although it also appears in the artificial intelligence problem-solving literature. the idea of relaxation of a hierarchy of constraints comes from  freeman ft 
newell 1  	there are also versions of gps  ernst ft newell 
1  which were purported to do reasoning in a hierarchy of 

a p p l i e a t i o n s - 1 : 	sussman 
1 

abstraction spaces. abstrips  sacerdoti 1  showed how refinement of abstract plans could be used to guide a problem solver past problems which would otherwise be combinatorially explosive. recently the noah system  sacerdoti 1  has developed this idea to great depth. the major difference we have with successive refinement is our emphasis on engineering analysis and debugging. we are sure that it is impossible to build systems which can deal with complex real world problems without making and removing bugs. psboarp is a descendent of the hacker  sussman 1  and mycroft  goldstein 1  debugging systems. one might consider that gps already embodied the idea of debugging in that one may take a problem solver with a debugging strategy to be a special case of a problem solver which first attempts to eliminate the main difference between the given and the goal and then reevaluates the situation after a step. this is true in principle  but gps was never used for debugging. poly a  polya 1  had developed a 
theory of problem solving which included debugging but gps only captured the reduction and rephrasing aspects of polya's theory. 
           recently allen l brown jr. finished a phd thesis at mit  brown 1  which explored the use of causal and teleologies! reasoning in the troubleshooting of complex electrical systems. in this thesis brown developed a set of linguistic conventions for the representation of the plan of a complex  hierarchically-structured system. brown's methods depend on  and inspired the construction of the el analysis system  sussman & stallman 1  which uses constraint propagation and can explain how a result depends on assumptions. brown needed analysis by propagation of constraints to predict the consequences of a hypothesized fault in a component. these consequences are compared with the measured values as a test of the fault theory. the explanations are critical in determining the faulty assumptions. johan de kleer also uses this technique in his debugging program inter  de kleer 1 . a related process of relaxation of symbolic constraints has been applied to the labelling of line drawings of visual scenes  muffman 1 . a beautiful exposition of this technique can be found in  waltz 1 . some theoretical analysis of this technique appears in  freuder 1 . 
           tople  mcdermott 1  was an early attempt to record the interactions among deductions for the purpose of deciding what is currently believed to be true. mcdermott used this information to help decide which of several assumptions must be thrown out in order to keep a consistent data base when a new fact conflicted with existing ones. mycin  shortliffe 1   davis 1  use dependency information to produce explanations but do not use it for any control purposes. the sri computer based consultant  fikes 1  makes use of dependencies to determine the logical support of facts in a manner similar to ars but does not use them to control search. 
           two other recent research efforts at mit have developed these ideas further. drew v. mcdermott finished a phd thesis  mc dermott 1  concerning the design of such systems. drew developed a rule-based language  called nasl  in which it is possible to express strategies  tactics  and advice for design. he used this language to encode some general design strategies and some specific strategies for the design of electrical systems. howie shrobe and charles rich  rich & shrobe 1  designed and mostly implemented a system which  understands  a limited class of lisp programs. they have developed set of linguistic constructs for attaching a set of structured comments to a program which relate it to its plan. these plans look very much like the plans of brown. they have also developed a system which reasons about the program in terms of its plan  and which can check that a program in fact implements its goals. in effect their system employs the teleological information in the plan about the parts of the program being checked  as an outline for the verification of the program. 
           finally  there have been many books about the strategies of the design process  for example  alexander 1    asimow 1    buhl 1    glegg 1   but these are mostly simple advice about how to avoid overlooking a good approach when working out a hard problem. they offer little help in how to propose new solutions to new problems. artificial intelligence researchers have been interested in the design process as a model of creativity. computer science in general has been interested in design because of the  complexity barriers  apparent in the design of large systems. herbert simon  simon 1  wrote a delightful and insightful book which relates computer science to general engineering design and to cognitive theory. at carnegie-mellon university  for example  grason  grason 1  wrote a phd thesis on the relaxation of architectural constraints  and hanley  hanley 1  wrote a phd thesis on computer-aided design of computer instruction sets. 
           one would expect the cad literature to deal extensively with systems to save an engineer time and effort. a survey of this literature  see  kuo & magnuson 1   furman 1   dertouzos 1   vlietstra & wielinga 1   rosenbrock 1   shows that the thrust of cad development has been in the development of interactive graphics packages  libraries of special purpose programs  and mathematically sophisticated programs aimed at analysis or optimization of synthesis. only a small amount of work has been done in the field of synthetic reasoning  and then only in restricted domains where algorithms are available to solve a small class of problems. such approaches have been partially successful in the problem of printed-circuit layout  e.g.  fletcher 1   and filter design  e.g.  chohan a fidler 1  . director  director 1  describes a circuit design program which assumes a full-graph impedance network and then optimizes the network for the behavior desired. in the process  many component values become zero and are thus discarded  the cad literature is almost completely ignorant of non-numerical techniques  except  powers 1   and would benefit from an infusion of these new ideas. besides our work  the tropic system  latombe 1  is one other application of artificial intelligence ideas to cad. john s. brown 
 brown & burton 1   at bolt  beranek and newman  cambridge  massachusetts  has been applying both artificial intelligence ideas and cad ideas to the problem of computeraided instruction of circuit debugging skills for technicians. 	we expect that the work of his group will contribute to the understanding of ai issues in cad. 
conclusions: 
           a major problem confronting builders of automatic problem-solving systems is that of the combinatorial explosion of search-spaces. one way to attack this problem is to build systems that effectively use the results of failures to reduce the search space - that learn from their exploration of blind alleys. in simple cases  as in analysis of circuits  various automatic techniques such as the dependency-directed backtracking of ars can go a long way toward controlling the search. in more complex situations  as in design  it is necessary to constrain the search as rapidly as possible - even if that sometimes overconstrains the problem and causes a bug. at least we can hope that the debugging problem is easier than the search problem. in either case it is necessary to build problem solvers so that they can remember and explain their reasoning. both dependency-directed backtracking and problem solving by debugging almost-right plans depend on the ability to manipulate the justification of a conclusion as well as the ability to deduce it. 
           saving justifications for the intermediate results of a computation has other merits. it is very difficult to debug programs containing large amounts of knowledge. the complexity of the interactions between the  chunks  of knowledge makes it difficult to ascertain what is to blame when a bug manifests itself. a program which can explain the reasons for its beliefs is more convincing when right  and it is easier to debug when wrong. 

a p p l i c a t i o n s - 1 : 	sussman 
1 

acknowledgement: 
           1 would like to thank the many people who have contributed to this project. richard  rms  stallman  drew mcdermott  allen brown  guy  quux  steele  jon doyle  johan de kleer  marilyn matz and gerald roylance have worked with me on it. chuck rich  howie shrobe  scott fahlman  marvin minsky  seymour papert  louis braida  paul penfield  kurt vanlehn  richard fikes  john allen  david marr  pat winston  and earl sacerdoti provided good advice and important ideas. 
bibliography: 
alexander  c.  1  notes on the synthesis of form  cambridge: harvard university press. 
asimow  m.  1  introduction to design  englewood cliffs  nj: prentice-hall  inc. 
brown  allen  1  qualitative knowledge  causal reasoning  and the localization of failures  cambridge: unpublished mit ph.d. thesis. 
brown  john seely and richard r. burton  1   multiple 
representations of knowledge for tutorial reasoning  in daniel bobrow and allan collins  eds.   representation and understanding: studies in cognitive science  new york: academic press. 
buhl  h.r.  1  creative engineering design  ames  iowa: the iowa state university press. 
chohtn  v.c and ik. fidler  1   computer aided design of 
filters for data transmission using frequency modulation  proceedings of the international conference on computer aided design  1. 
dahl  oj.  e.w. dijkstra and car. hoare  1  structured programming  london: academic press. 
davis  randall  1  applications of meta level knowledge to the 
construction  maintenance  and use of large knowledge bases  stanford  ca: stanford university artificial intelligence laboratory memo 1. 
de kleer  johan  1  local methods for localization of faults in electronic circuits  cambridge: mit artificial intelligence laboratory memo 1. 
dertouzos  michael  1   circal-1: general-purpose on-line circuit design   proceedings of the ieee  vol. 1  pp. 1  jan. 1. 
dijkttra  edsgar  1   structured programming  in software 
engineering techniques  jln. buxton and b. randell  eds.   nato scientific affairs division  bruseels  belgium  1. 
director  s.w.  1  towards automatic design of integrated 
circuits   in william r. spiders  ed.  basic questions of design theory  new york: american elsevier publishing company  inc.  p. 1. 
doyle  jon  1  the use of dependency relationships in the control of reasoning  cambridge: mit artificial intelligence laboratory working paper1. 
ernst  george w. and allen newell  1  gps: a case study in 
generality end problem-solving  new york: academic press. 
fahlman  scott  1  a planning system for robot construction tasks  cambridge: mit master's thesis. 
fikes  richard  1  deductive retrieval mechanisms for state 
description models  menlo park  ca: stanford research institute artificial intelligence center technical note 1. 
fletcher  a.j.  1   eureka - a system for the automatic 
layout of single-sided printed circuit boards   proceedings of the ziinternational conference on computer aided design  1. 
freeman  p. and allen newell  1   a model for functional reasoning in design   proceedings of international joint conference on artificial intelligence ii  p. 1. 
freuder  eugene  1  synthesizing constraint expressions  cambridge: mit artificial intelligence lab memo 1. 
furman  ta  1   ed.  the use of computers in engineering design  london: english universities press. 
glegg  gordon lindsay  1  the science of design  cambridge  eng.: cambridge university press. 
goldstein  ira  1   summary of mycroft: a system for 
understanding simple picture programs   artificial intelligence  vol. 1  no. 1  fall  1  pp. 1. 
grason  jason  1  methods for the computer-implemented solution of a class of  floor plan  design problems  unpublished ph.d. dissertation  pittsburgh: carnegiemellon university. 
hanley  frederick  1  using a computer to design computer instruction sets  pittsburgh: carnegie-mellon university computer science department ph.d. thesis. 
hewitt  carl and brian smith  1  towards a programming 
apprentice  cambridge: mit artificial intelligence laboratory working paper 1. 
huffman  david  1   impossible objects as nonsense sentences   in machine intelligence 1  edinburgh  uk.: edinburgh university press  1 . 
kuo  f.f. and w.g. magnuson  1   eds.  computer-oriented circuit design  englewood cliffs  nj: prentice-hall  inc. 
latombe  jean-claude  1  artificial intelligence in computer aided design: the tropic system  menlo park  ca: stanford research institute artificial intelligence center technical note 1. 
mcdermott  drew  1  assimilation of new information by a 
natural language understanding system  cambridge: mit department of electrical engineering and computer science master's thesis. 
mcdermott  drew  1  flexibility and efficiency in a computer 
program for designing circuits  cambridge: mit department of electrical engineering and computer science ph.d. thesis. 
polyt  george  1  how to solve it  princeton  nj: princeton university press  
polya  george  1  mathematical discovery: on understanding. 
learning  and teaching problem solving  vols. i and ii. 
new york: john wiley and sons  inc. 

applications-1: sussman 1 

1. the status transition  if any  e.g.   prl.xm.s  can occur only if the defendant is in the  magistrate's proceedings  status  and the event w i l l not cause a status change   
1. the formal parameters necessary to specify the data contents of the event  e.g.   prl.xm.s  requires that the scheduled date of the examination be supplied   
1. the speedy trial time accounting actions necessary as a result of posting the event  
1. any special preconditions that must be satisfied in order for the event to be posted  
1. any special semantic actions that must be performed upon posting the event  
1. the text that is to be printed on a docket sheet when this event is reported. 
　　　in addition to the event sequencing constraints represented by the status diagram  a r b i t r a r y sequencing relationships may be specified to control the order in which events may be posted w i t h i n any given status. these r e l a t i o n s h i p s are represented graphically as sequence diagrams and extend the f i n i t e state nature of the status diagram. in addition to s t r i c t event sequences  sequence diagrams may denote forks and joins  optional sequences  and parallel paths. the state of any given subject with respect to the progress of a case may be described as the status containing the subjectplus a vector of  program counter  values i n d i c a t i n g the subject's position along each possible parallel path in the sequence diagram 
which further defines the status. 

　　　figure 1 depicts a simplified event sequence diagram for defendant subjects in the  magistrate's proceedings  status  showing the allowable sequences for setting  holding  and continuing preliminary examinations. the { } indicate that the enclosed sequence may be repeated zero or more times. the vertical bars denote a fork and join operation on the enclosed independent event sequences. the dotted line indicates that the dismiss event may be posted at any time between the fork and join to interrupt and curtail the parallel sequences. according to figure 1  before an indict event can be posted  a preliminary examination must f i r s t be set  prl.xm.s  and then held  prl.xm.h   and optionally continued  prl.xm.c  and re-held  prl.xm.h  an arbitrary number of times. however  at any time during this preliminary examination sequence  dismiss may be posted  thereby escaping from the sequence and causing a status change to the  post-trial  status  see figure 1 . 
　　　the event dictionary  status diagrams  and sequence diagrams represent the court-oriented knowledge of the cr1mnl system and are declaratively specified in tables rather than being  for example  procedurally embedded. the system acts essentially as an i n t e r a c t i v e interpreter which accepts proposed events from the user and tries to apply the semantic actions of each event to transform the current state of its subject. the i n t e l l i g e n c e of the system is exhibited by its responses to proposed events and the reports produced for e f f e c t i v e case monitoring. not only can crimnl detect when an event is invalid based on the current state of its subject  but the system can also offer diagnostic advice as to which events are allowable at that time and which events need to be posted f i r s t in order that the attempted event become valid. this model-based v a l i d i t y checking and diagnostic advice allows the detection of clerical errors and results in increased data base integrity. this same model-based system also provides the courts with a valuable training tool for the instruction of docket clerks in criminal procedure. furthermore  as a result of explicitly defining each subject's state with respect to i t s progress in the criminal proceedings  it is possible to generate exception reports which monitor case progress and warn of approaching procedural time constraints  an especially complex clerical task imposed on the courts by the speedy trial act. 
　　　the system is programmed in sail using dbms-1 and runs on a decsystem-1 computer in 
washington  d.c.  accessible from terminals located in the various user courts via a value-added network. the i n i t i a l   p i l o t   group of federal courts are located in los angeles  san 
francisco  chicago  d e t r o i t   new york  and washington  d.c. 

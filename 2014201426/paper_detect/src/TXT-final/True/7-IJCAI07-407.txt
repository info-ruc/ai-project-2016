
while conditional random fields  crfs  have been applied successfully in a variety of domains  their training remains a challenging task. in this paper  we introduce a novel training method for crfs  called virtual evidence boosting  which simultaneously performs feature selection and parameter estimation. to achieve this  we extend standard boosting to handle virtual evidence  where an observation can be specified as a distribution rather than a single number. this extension allows us to develop a unified framework for learning both local and compatibility features in crfs. in experiments on synthetic data as well as real activity classification problems  our new training algorithm outperforms other training approaches including maximum likelihood  maximum pseudo-likelihood  and the most recent boosted random fields.
1 introduction
conditional random fields  crfs  are undirected graphical models that were developed for labeling relational data  lafferty et al.  1 . by directly modeling the conditional distribution over hidden states given the observations  crfs make no assumptions on the dependency structure between observations. crfs are thus especially suitable for classification tasks with complex and overlapped observations. however  training crfs with very large numbers of features  especially continuous features  is still very challenging. standard training algorithms based on maximum likelihood  ml  require running inference at each iteration of the optimization  which can be very expensive. moreover  since exact inference can easily become intractable in large and dense networks  people often have to resort to approximate inference techniques such as loopy belief propagation and markov chain monte carlo. as a consequence  the ml learning procedure could converge to suboptimal results or even diverge.
¡¡an alternative is to maximize the pseudo-likelihood of the training data  mpl   besag  1 . the essential idea of mpl is to convert a crf into a set of independent patches; each patch consists of a hidden node and the true values of its direct neighbors. by applying ml on this simplified model  mpl is usually very efficient and has been successful in several domains. however  no general guidance has been given on when mpl can be safely used  and indeed mpl has been observed to over-estimate the dependency parameters in some experiments  geyer and thompson  1 .
¡¡in addition  neither ml nor mpl performs feature selection explicitly  and neither of them is able to adequately handle continuous observations. these limitations make them unsuitable for some tasks  such as activity recognition based on real sensor data and identifying the set of features that are most useful for classification. alternatively  boosting has been successfully used for feature selection in the context of classification problems  viola and jones  1 . however  its application to relational data remains an unsolved problem since it assumes the independence of hidden labels.
¡¡in this paper  we show how to seamlessly integrate boosting and crf training  thereby combining the capabilities of both paradigms. the integration is achieved by cutting a crf into individual patches  as done in mpl  and using these patches as training instances for boosting. the key difference to mpl  however  is that in our framework the neighbor labels are not treated as observed  but as virtual evidences or beliefs. therefore  our approach can be seen as a  soft  version of mpl  and is able to avoid over-estimating the neighborhood dependencies  as often happens in mpl.
¡¡this paper has three main contributions. first  we extend the standard boosting algorithm to handle input features that are either virtual evidences in the form of likelihood values or deterministic quantities. second  based on the extended boosting algorithm  we present a general approach to training crfs. this approach is able to   perform feature selection and parameter estimation in a unified and efficient manner 
  select compatibility features and thus learn dependency structures in the relational data  and
  handle both discrete and continuous observations.
third  we perform experimental validation of our algorithm on real world activity classification tasks as well as synthetic data using crfs with different degrees of complexity. in the comparison  our approach consistently outperforms other training techniques.
¡¡the rest of this paper is organized as follows. we discuss related work in the next section. in section 1  we extend boosting with virtual evidence. then  in section 1  we apply this extension to training crfs. finally  we show experimental results and conclude.
1 related work
several techniques have been presented that perform feature selection during crf training.
¡¡for discrete features  mccallum  suggested an efficient method of feature induction by iteratively increasing conditional log-likelihood. dietterich et al.  applied gradient tree boosting to select features for crfs; their algorithm combines boosting with parameter estimation for 1d linear-chain models.
the work closest to ours is boosted random fields
 brfs   torralba et al.  1   developed specifically for vision tasks in which graphs are often very densely connected. both brfs and our approach combine boosting and belief propagation  and both can select compatibility dependencies as well as local features. however  there are a few key differences. first  for learning compatibility dependencies  brfs use linear combinations of beliefs as weak learners instead of combinations of crf features. so their models are not compatible with standard inference techniques. second  brfs assume densely-connected graphs with weak pairwise connections. as we will show in our experiments  when the dependencies are strong  brfs could perform poorly. third  since brfs formulate the inductions of local and compatibility features differently  they have to specify the number of each type of features separately. in contrast  our approach treats both types of features in a consistent manner and thus the algorithm can determine which type is better at a given iteration. in our experiments  our algorithm automatically picks reliable local features at the beginning and starts selecting compatibility features after accumulating enough local evidence.
1 boosting with virtual evidence
boosting is a general approach for supervised learning  freund and schapire  1 . given the training data  x1 y1   ...   xn yn   where xi is a feature vector and yi is the label  boosting works by sequentially learning a set of weak classifiers and combining them for final decisions. while traditional boosting algorithms assume feature values be deterministic  in this section we extend them with virtual evidence  pearl  1   i.e.  a feature could be a distribution over its domain rather than a single  observed value. specifically  we generalize the logitboost algorithm  friedman et al.  1   which directly handles probabilities and is closely related to random field models. for simplicity  we will explain logitboost and our extension only for the binary classification case  i.e.  yi ¡Ê {1}  but both can be easily extended to multi-class problems  friedman et al.  1 .
1 logitboost algorithm
logitboost minimizes the negative log-likelihood
xi    1 
where the right term follows from the independence between labels. using a logistic regression model  p yi | xi  can be computed as  = 1;
 1 
= 1.
where ef xi  and e f xi  represent the potentials for yi = 1 and 1  respectively  and  refers to the sum of feature functions or ensemble of weak learners. logitboost minimizes the objective function  1  with respect to f in a stepwise way. specifically  given the current ensemble f  logitboost selects the next weak learner fm x  using a newton step and adds fm x  to the ensemble. it has been shown that computing the newton step is equivalent to solving the following weighted least-square-error  wlse  problem:
n
	fm x 	=	argmin	 	 1 
where and are the weight and working response for sample i.
1 extension with virtual evidence
in this section we extend logitboost to handle virtual evidences or beliefs. that is  for each feature in the feature vector xi  the input to boosting could be a probabilistic distribution over that feature's domain  as opposed to a single  observed value 1. we denote a distribution over the cross-product of feature values as ve xi  with domain {1 ... xi}. we again aim to minimize the negative log-likelihood ve xi    where p yi|ve xi   represents the posterior probability of a true label conditioned on its virtual evidence. we can compute this term as follows:
= 1;
	xi	i  	 1 
	p =1ve x  e	if yi = 1.
here computes the expected potentials  which replace the potentials in  1 . it is also helpful to think of ve xi  as a message in random field models; thus  1  is consistent with the belief update in belief propagation.
¡¡to determine the next weak learner fm x   we modify the logitboost error criterion  1  by taking the expectation w.r.t. the virtual evidence:
n
fm x 	=	argmin
	=	argmin
                           =1 i=1 where wi and zi can be computed as in logitboost  using p yi|ve xi   obtained from  1 .
¡¡the algorithm is described in alg. 1  which constructs f in m iterations. within each iteration  the algorithm first formulates the wlse problem  line 1 to 1   and then solves it to
inputs: training data	 
  and
output: f that approximately minimizes eq.  1 
1 for m = 1 ¡¤¡¤¡¤ m do
1 for i = 1 ¡¤¡¤¡¤ n do
1 compute likelihood p yi|ve xi   using eq.  1 ;
1 compute weight wi = p yi|ve xi   1   p yi|ve xi  ;
1 compute working response;
1 end
1 obtain  best  fm x  by solving eq.  1 ;
1 update f x  = f x  + fm x  ;
1 endalgorithm 1: extending logitboost with virtual evidence
obtain the next weak learner  line 1 . when ve xi  is a deterministic value  eq.  1  becomes  1  and eq.  1  becomes  1 ; thus we get exactly the original logitboost algorithm. so our extension is a generalization of the original logitboost and is able to handle deterministic evidence as well. it can be shown to have the same property as standard logitboost  i.e.  it minimizes the objective function using newton steps 
1 virtual evidence boosting for training conditional random fields
the boosting algorithm in previous section assumes independence between training examples. how can they be applied to crfs in which the labels are dependent  similar to the mpl algorithm  we first convert a crf into a set of individual patches; each patch consists of a hidden node  its direct neighbors  and the observations. the key difference with mpl is that  instead of using the true labels of neighbors  we use the messages from the neighbors as virtual evidences. then we apply extended boosting to these independent patches for feature selection and parameter estimation. based on these ideas  we develop a new training algorithm for crfs  called virtual evidence boosting  veb . veb is a very general technique: it can handle both continuous and discrete observations  and can be used in crfs with arbitrary structures. we will explain veb in the context of binary classification; the algorithm can be readily extended to multi-class labeling  and we have done that for our experiments.
1 the veb algorithm
the veb algorithm is described in alg. 1. the crucial difference between the veb and extended logitboost algorithm lies in the way virtual evidences are handled. the veb considers two types of evidences for a node yi. the first type is the hard evidence given as input to the algorithm  which corresponds to the observations xi in the training data. the second type is the soft evidence  corresponding to the messages from neighboring nodes n yi ; these messages are obtained by running belief propagation with the current ensemble  i.e.  linear combination of feature functions  f. our extension to boosting allows us to treat both types as virtual evidence  denoted as ve xi n yi    so that we can learn the crf's local features and compatibility features in a unified framework.
inputs: structure of crf and training data  xi yi   with
       yi ¡Ê {1}  1 ¡Ü i ¡Ü n  and f = 1 output: learned f
1 for m = 1 ¡¤¡¤¡¤ m do
1 run bp using f to get virtual evidences ve xi n yi  ; 1 for i = 1 ¡¤¡¤¡¤ n do
1 compute likelihood p yi|ve xi n yi    using eq.  1 ;
1 compute weight
wi = p yi|ve xi n yi    1   p yi|ve xi n yi   ;
1 compute working response	;
1 end
1 obtain  best  fm by solving eq.  1 ;
1 update f = f + fm ; end1
algorithm 1: training crfs using veb
¡¡note that while virtual evidences are provided as inputs to alg. 1  veb must update ve xi n yi   at each iteration  because the messages from n yi  keep changing as veb updates f. specifically  to compute the virtual evidence of yi from a neighbor yk  vei yk   we distinguish messages before and after multiplying the compatibility potentials ef yk yi . we denote these messages as ¦Ëk¡úi yk  and ¦Ìk¡úi yi   respectively. these messages are computed iteratively during belief propagation  
and
	 	 1 
where ¦Á and ¦Â are used for normalization. as can be seen  ¦Ë-messages contain information about the distribution of the sending node yk  and ¦Ì-messages contain information about which values the recipient node yi should prefer. while the ¦Ì-messages correspond exactly to the messages sent in regular belief propagation  we use each ¦Ëk¡úi yk  message as virtual evidence vei yk . at the end of belief propagation  we generate the combined virtual evidence ve xi n yi   for node yi by  stacking  the observations  xi  and the received virtual evidence messages vei yk . the combined virtual evidence can then be used to compute the posterior distribution p yi|ve xi n yi    using  1 . equivalently  from belief propagation we have

where ¦Ã is used for normalization.
¡¡to summarize  at each iteration  veb updates the virtual evidences via belief propagation using only those local features and compatibility potentials already contained in f. initially  when f = 1  all posterior distributions p yi|ve xi n yi    are uniform. it then proceeds exactly as the extended logitboost algorithm in order to add one more weak learner fm. in our experiments we found it sufficient to run belief propagation for only one iteration per learning cycle  which greatly increases the efficiency of the approach.
1 feature selection in veb
a key step in alg. 1 is step 1  which finds the  best  weak learner fm by solving the wlse problem. note that since a weak learner in crfs is a certain kind of combination of features  the algorithm is essentially performing feature selection and parameter estimation. in this paper we only consider weak learners that are linear combinations of features and involve one single type of local attribute or neighbor 1. in a nutshell  to determine the  best  weak learner  our approach enumerates all types of local attributes and neighbor relations. for each type  it computes the optimal parameters of the weak learner and the least square error. then it picks the one with the overall least square error as well as its optimal parameters. in this section  we discuss how to formulate weak learners for crfs with binary labels and how to estimate the optimal parameters efficiently. specifically  we consider three different cases: when the weak learner involves a continuous attribute  a discrete attribute  or a neighbor relationship. while the first two cases can be treated just like in regular logitboost  we apply extended boosting for the neighbor relationships to handle virtual evidences  with the evidences provided by belief propagation.
¡¡first  for a continuous attribute x k   the weak learner is a linear combination of decision stumps:
	f x k  	=	¦Á1¦Ä x k  ¡Ý h  + ¦Á1¦Ä x k    h  
 where h is the threshold  and ¦Á1 and ¦Á1 are the feature weights. we get their  approximately  optimal values by solving the wlse problem in  1 . specifically  h is determined using some heuristic  e.g.  to maximize the information gain. then we compute the optimal ¦Á1 and ¦Á1 analytically by setting the first-order partial derivative of the square error equal to zero. thus we get
 and 
 second  given a discrete attribute x k  ¡Ê {1 ¡¤¡¤¡¤ d}  the weak learner is expressed as
 
where ¦Ád is the weight for feature ¦Ä x k  = d   an indicator function which is 1 if x k  = d and 1 otherwise. the optimal weights can be calculated similarly as:

¡¡third  given a certain type of neighbor and corresponding virtual evidence vei yk   the weak learner is the weighted sum of two indicator functions  compatibility features :
1
f yk  = x¦Ád¦Ä yk = d .
d=1
¡¡solving the wlse problem with virtual evidence  as in  1   we get the optimal weights:

¡¡we can unify the three cases for computing optimal feature weights as follows:
		 1 
here cdi is the count of feature d in data instance i  assume we have cut crfs into individual patches . cdi can be 1 and 1 for local features  or a real number between 1 and 1 for compatibility features. it can also be greater than 1 if we allow parameter sharing within an instance  for example  when a node is connected with more than one neighbor of the same type. thus in our approach parameter estimation is solved by simply performing feature counting  which makes the whole algorithm very efficient.
¡¡it is important to notice that the algorithm typically first picks reliable local attributes since messages from neighbors are close to uniform at the beginning. then  after some iterations  it starts picking compatibility features as those messages provide more information.
1 experiments
we evaluate the performance of veb and compare it with other alternatives: boosted random fields  brf   maximum likelihood  ml   and maximum pseudo-likelihood  mpl . we perform experiments using both synthetic data and two different activity recognition datasets. in all these experiments  we run veb as well as brf for 1 iterations  and in each iteration we run one iteration of belief propagation. in ml and mpl learning  we use a shrinkage prior with zero mean and unit variance. ml and mpl optimization are implemented using a quasi-newton procedure. for ml we evaluate the likelihood using the bethe method  yedidia et al.  1  and its gradient using belief propagation. all the learned models are tested using the map belief propagation  except that we have to use a specific inference algorithm for brf  as described in  torralba et al.  1 . all accuracies are calculated based on the map labels. all experiments were run on a standard desktop pc with 1ghz cpu and 1gb of memory.
1 synthetic data
veb versus brf
veb and brf are similar. however  brf assumes the graphs are densely connected and thereby each individual message is not very informative  while veb does not make any assumption about the connectivity structure. this difference is significant because although their assumption is often true for the vision applications discussed in  torralba et al.  1   it may be invalid for many other applications. in this experiment  we examine the performance of veb and brf as the dependencies between nodes get stronger.
¡¡the synthetic data is generated using a first-order markov chain with binary labels. to emphasize the difference on learning compatibility features  we intentionally use weak observation models: each label is connected to 1 binary observations and the conditional probabilities in the observation models are uniformly sampled from the range  1 1 . we adjust the transition probabilities  from label 1 to 1 and

figure 1: classification accuracies in experiments using synthetic data  where the error bars indicate 1% confidence intervals.  a  veb vs. brf when the transition probabilities  pairwise dependencies  turn from weak to strong.  b  comparison of different learning algorithms for feature selection.
from label 1 to 1  from 1 to 1. for each given transition and observation model  we generate ten 1-labels chains and perform leave-one-out cross-validation using a linearchain crf. we additionally run the experiments several times by randomly generating different observation models.
¡¡the running durations of both algorithms are very similar  so we only compare the accuracies. the average accuracies using veb and brf and their confidence intervals are shown in fig. 1 a . it is clear that when the compatibility dependencies are not strong  transition probabilities range from 1 to 1   both methods give very similar accuracies. however  as the dependencies get stronger  from 1 to 1   veb dramatically outperforms brf  mainly because the weak interaction assumption underlying brf does not hold any more.
feature selection in complex models
many real sequential estimation problems have long-range dependencies  which can be modeled using high-order markov models. however in practice it is often impossible to know the exact order  so people may have to use markov models that have longer dependencies than the actual data. in this experiment  we simulate this scenario by generating synthetic data using a high-order markov model  whose transition probability p yn | y1:n 1  = p yn | yn k   where k is a constant  the observation model is similar as the one in the previous experiment . that is  a label yn only depends on one past label yn k  but the value of k is unknown to the crf model. specifically  we pick k from 1 to 1  and we set the transition probability p yn | yn k  as 1 if yn = yn k and 1 otherwise. for a given k  we generate ten 1-long chains and perform leave-one-out cross-validation. we repeat the experiment for different k's and compute the average.
¡¡since the exact value of k is unknown to the crf model  we generate a densely-connected crf that has connections between each pair of nodes whose distance is less than or equal to 1; then the crf was trained using different algorithms. in our experiments  veb can reliably identify the correct values of k  i.e.  picking only pairwise features whose distance is k or multiples of k. although brf also performs feature selection and structure learning  it does not perform as well as veb. the average classification accuracies are shown in fig. 1 b . because veb can robustly extract the sparse structures  it significantly outperforms other approaches. as to the running time  veb  brf  and mpl are all quite efficient; each training takes only tens of seconds. in contrast  the training using ml takes about 1 minutes.
training algorithmaverage accuracyveb1%brf1%ml + all observations1%ml + boosting1%mpl + all observations1%mpl + boosting1%table 1: average accuracy for indoor activities
1 real activity recognition data
crfs are well-suited for the tasks of activity recognition using real sensor data  because of the overlaps between measurements and the strong relationships between activities. in this section  we compare different training approaches on such crfs. although veb and brf can handle continuous sensor measurements directly  doing that in ml and mpl is not straightforward. the performance of ml and mpl is terrible if we simply use the continuous measurements as feature values. this is due to the fact that such features correspond to a zero-mean gaussian assumption  which could be far from the truth. we try two tricks to circumvent this difficulty. one is to learn decision stumps for all observations  using the heuristics as in veb and brf. the other is to use boosting  e.g.  logitboost in our experiment  to select a set of decision stump features and these decision stumps are then fed into ml and mpl for weight estimation  as done in  friedman et al.  1  .
indoor activity recognition
in the first experiment  one person collected audio  acceleration  and light sensor data as he stayed indoors using a small wearable device. the total length of the data set is about 1 minutes  recorded over a period of 1 days. the goal is to recognize the person's major indoor activities including computer usage  meal  meeting  tv watching and sleeping. we segmented the data into one-minute chunks and manually labeled the activity at each minute for the purpose of supervised learning and testing. for each chunk of data  we computed 1 feature values  which included energy in various frequency bands  log and linear  of the signal  autocorrelation  different entropy measures  etc. these features are fed into the crf as observations  and one linear chain crf is created per day. we evaluate our algorithm using leave-one-out cross-validation. because the person performs different activities in different days  the accuracies can vary significantly from day to day. some activities  such as meals  are hard to recognize  while other activities  such as sleeping  are relatively easy to recognize. as a result  in the leave-one-day-outcross-validation  the accuracies for different days vary significantly and the standard deviation is rather large. the overall average accuracies using the different methods are shown in table 1  in which veb is about 1% to 1% better than ml and mpl  no matter how they incorporate the continuous observations. even though the error bars of the different techniques overlap  our approach is significantly  1 level  better than its competitors when we evaluate the combination of the different experiments reported in the paper.

figure 1: the crf model for simultaneously inferring motion states and spatial contexts  observations are omitted for simplicity .
training algorithmaverage overall accuracyveb1 ¡À 1%mpl + all observations1 ¡À 1%mpl + boosting1 ¡À 1%hmm + adaboost	1	1%¡À
table 1: accuracy for inferring states and contexts
recognizing motions and spatial contexts
subramanya et al.  proposed a model for simultaneously recognizing motion states  e.g.  stationary  walking  running  driving  and going up/down stairs  and spatial contexts  e.g.  indoors  outdoors  vehicle  from wearable sensors. they train local features using adaboost and incorporate the boosted classifiers as observation into an hmm that infers jointly the states and contexts. their data set consists of 1 episodes and about 1 labels. in our experiment  we perform the same task with the same data set  but using a crf instead of an hmm. as shown in fig. 1  the crf captures the pairwise relations between states and contexts. we perform leave-one-out cross-validation using different learning approaches. in such large and loopy crfs  ml becomes completely intractable and does not finish in two days. mpl and veb take about 1 hours for training 1. the overall average accuracies and confidence intervals are shown in table 1. our veb clearly outperforms mpl  as well as the result in the original paper.
1 conclusions and future work
we presented a novel and unified training algorithm for crfs  called virtual evidence boosting  which can simultaneously select informative features  both discrete and/or continuous  and estimate optimal parameters. as part of this training algorithm  we generalized the logitboost algorithm to handle virtual evidence. by treating neighborhood relations as features  our approach also learns the connectivity structure of crfs.
¡¡our experimental results demonstrate that virtual evidence boosting significantly outperforms other training approaches in both synthetic data and real world applications such as activity recognition. in future work  we want to compare our approach with max-margin techniques  taskar et al.  1  and explore the possibility of learning feature conjunctions.
acknowledgments
we thank benson limketkai for the help on preparing the last dataset. this work was supported by the nsf under grant numbers iis 1 and iis-1  and the uw cse educator's fellowship. it has also been supported by darpa's assist and calo programs  contract numbers: nbch-c1  sri subcontract 1 .

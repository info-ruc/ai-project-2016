
we present in this paper a new  complete method for distributed constraint optimization  based on dynamic programming. it is a utility propagation method  inspired by the sum-product algorithm  which is correct only for tree-shaped constraint networks. in this paper  we show how to extend that algorithm to arbitrary topologies using a pseudotree arrangement of the problem graph. our algorithm requires a linear number of messages  whose maximal size depends on the induced width along the particular pseudotree chosen.
we compare our algorithm with backtracking algorithms  and present experimental results. for some problem types we report orders of magnitude fewer messages  and the ability to deal with arbitrarily large problems. our algorithm is formulated for optimization problems  but can be easily applied to satisfaction problems as well.
1	introduction
distributed constraint satisfaction  discsp  was first studied by yokoo  yokoo et al.  1  and has recently attracted increasing interest. in distributed constraint satisfaction each variable and constraint is owned by an agent. systematic search algorithms for solving discsp are generally derived from depth-first search algorithms based on some form of backtracking  silaghi et al.  1; yokoo et al.  1; meisels and zivan  1; hamadi et al.  1 .
모recently  the paradigm of asynchronous distributed search has been extended to constraint optimization by integrating a bound propagation mechanism  adopt -  modi et al. 
1  .
모in general  optimization problems are much harder to solve than discsp ones  as the goal is not just to find any solution  but the best one  thus requiring more exploration of the search space. the common goal of all distributed algorithms is to minimize the number of messages required to find a solution.
모backtracking algorithms are very popular in centralized systems because they require very little memory. in a distributed implementation  however  they may not be the best basis since in backtrack search  control shifts rapidly between different variables. every state change in a distributed backtrack algorithm requires at least one message; in the worst case  even in a parallel algorithm there will be exponentially many state changes  kasif  1   thus resulting in exponentially many messages. so far  this has been a serious drawback for the application of distributed algorithms in the real world  especially for optimization problems  also noted in  maheswaran et al.  1  .
모this leads us to believe that other search paradigms  in particular those based on dynamic programming  may be more appropriate for discsp. for example  an algorithm that incrementally computes the set of all partial solutions for all previous variables according to a certain order would only use a linear number of messages. however  the messages could grow exponentially in size  and the algorithm would not have any parallelism.
모recently  the sum-product algorithm  kschischang et al.  1  has been proposed for certain constraint satisfaction problems  for example decoding. it is an acceptable compromise as it combines a dynamic-programming style exploration of a search space with a fixed message size  and can easily be implemented in a distributed fashion. however  it is correct only for tree-shaped constraint networks.
모in this paper  we show how to extend the algorithm to arbitrary topologies using a pseudotree arrangement of the problem graph  and report our experimental results. the algorithm is formulated for optimization problems  but can be easily applied to satisfaction problems by having relations with utility either 1  for allowed tuples  or negative values  for disallowed tuples . utility maximization produces a solution if there is an assignment with utility 1.
모the rest of this paper is structured as follows: section 1 presents the definitions and the notation we use  section 1 presents an optimization procedure for trees  section 1 the optimization for graphs  section 1 proves the complexity to be equal to the induced width  section 1 compares theoretically our algorithm with other aproaches  section 1 presents experimental results  and we conclude in section 1.
1	definitions & notation
a discrete multiagent constraint optimization problem  mcop  is a tuple   x d r   such that:
  x = {x1 ... xm} is the set of variables/agents;
  d = {d1 ... dm} is a set of domains of the variables  each given as a finite set of possible values.
  r = {r1 ... rp} is a set of relations  where a relation ri is a function di1 뫄 .. 뫄 dik 뫸  + which denotes how much utility is assigned to each possible combination of values of the involved variables.
모in this paper we deal with unary and binary relations  being well-known that higher arity relations can also be expressed in these terms with little modifications. in a mcop  any value combination is allowed; the goal is to find an assignment x  for the variables xi that maximizes the sum of utilities.
모for a node xk  we define rk xj  = the relation s  between xk and its neighbor xj.
1	distributed constraint optimization for tree-structured networks
for tree-structured networks  polynomial-time complete optimization methods have been developed  e.g. the sum-product algorithm  kschischang et al.  1  and the dtree algorithm from  petcu and faltings  1  .
모in dtree  the agents send util messages  utility vectors  to their parents. a child xl of node xk would send xk a vector of the optimal utilities ux  l vkj  that can be achieved by the subtree rooted at xl plus rl xk    and are compatible with each value vkj of xk  such a vector has |dom xk | values .
모for the leaf nodes it is immediate to compute these valuations by just inspecting the constraints they have with their single neighbors  so they initiate the process. then each node xi relays these messages according to the following process:
  wait for util messages from all children. since all of the respective subtrees are disjoint  by summing them up  xi computes how much utility each of its values gives for the whole subtree rooted at itself. this  together with the relation s  between xi and its parent xj  enables xi to compute exactly how much utility can be achieved by the entire subtree rooted at xi  taking into account compatibility with each of xj's values. thus  xi can send to xj its util message. xi also stores its optimal values corresponding to each value of xj.
  if root node  xi can compute the optimal overall utility corresponding to each one of its values  based on all the incoming util messages   pick the optimal one  and send a value message to its children  informing them about its decision.
upon receipt of the value message from its parent  each node is able to pick the optimal value for itself  as the previously stored optimal value corresponding to the value its parent has chosen   and pass it on to its children. at this point  the algorithm is finished for xi.
모the correctness of this algorithm was shown in the original paper  as well as the fact that it requires a linear number of messages  and linear memory.

figure 1: example of a pseudotree arrangement.
1	distributed constraint optimization for general networks
to apply a dtree-like algorithm to a cyclic graph  we first need to arrange the graph as a pseudotree  it is known that this arrangement is possible for any graph .
1	pseudotrees
definition 1 a pseudo-tree arrangement of a graph g is a rooted tree with the same vertices as g and the property that adjacent vertices from the original graph fall in the same branch of the tree  e.g. x1 and x1 in figure 1 .
모pseudotrees have already been investigated as a means to boost search   freuder  1; freuder and quinn  1; dechter  1; schiex  1  . the main idea with their use in search  is that due to the relative independence of nodes lying in different branches of the pseudotree  it is possible to perform search in parallel on these independent branches.
모figure 1 shows an example of a pseudotree that we shall refer to in the rest of this paper. it consists of tree edges  shown as solid lines  and back edges  shown as dashed lines  that are not part of the spanning tree  e.g. 1  1  1 . we call a path in the graph that is entirely made of tree edges  a tree-path. a tree-path associated with a back-edge is the tree-path connecting the two nodes involved in the back-edge  please note that since our arrangement is a pseudotree  such a tree path is always included in a branch of the tree . for each back-edge  the higher node involved in that back-edge is called the back-edge handler  e.g. the dark nodes 1  1 and 1 . we also define:
  p x  - the parent of a node x: the single node higher in the hierarchy of the pseudotree that is connected to the node x directly through a tree edge  e.g. p x1  = x1 
  c x  - the children of a node x: the set of nodes lower in the pseudotree that are connected to the node x directly through tree edges  e.g. c x1  = {x1 x1} 
  pp x  - the pseudo-parents of a node x: the set of nodes higher in the pseudotree that are connected to the node x directly through back-edges  pp x1  = {x1} 
  pc x  - the pseudo-children of a node x: the set of nodes lower in the hierarchy of the pseudotree that are connected to the node x directly through back-edges
 e.g. pc x1  = {x1 x1} 
모as it is already known  a dfs  depth-first search  tree is also a pseudotree  although the inverse does not always hold . so  a dfs tree obtained from the dfs traversal of the graph starting from one of the nodes  chosen through a distributed leader election algorithm  will do just fine. due to the lack of space we do not present here a procedure for the creation of a dfs tree  and refer the reader to techniques like  barbosa  1; hamadi et al.  1 .
1	the dpop algorithm
our algorithm has 1 phases. first  the agents establish the pseudotree structure  see section 1  to be used in the following two phases. the next two phases are the util and value propagations  which are similar to the ones from dtree - section 1. please refer to algorithm 1 for a formal description of the algorithm  and to the rest of this section for a detailed description of the util and value phases.
util propagation
as in dtree  the util propagation starts from the leaves of the pseudotree and propagates up the pseudotree  only through the tree edges. it is easy for an agent to identify whether it is a leaf in the pseudotree or not: it must have a single tree edge  e.g. x1 to x1 in figure 1 .
모in a tree network  a util message sent by a node to its parent is dependent only on the subtree rooted at the respective node  no links to other parts of the tree   and the constraint between the node and its parent. for example  consider the message  x1 뫸 x1 . this message is clearly dependent only on the target variable x1  since there are no links between x1 or x1 and any node above x1.
모in a network with cycles  each back-edge in the pseudotree produces a cycle   a message sent from a node to its parent may also depend on variables above the parent. this happens when there is a back-edge connecting the sending node with such a variable. for example  consider the message  x1 뫸 x1  in figure 1. we see that the utilities that the subtree rooted at x1 can achieve are not dependent only on its parent x1  as for x1 뫸 x1 . as x1 is connected with x1 through the backedge x1 뫸 x1  x1 must take into account this dependency when sending its message to x1.
모this is where the dynamic programming approach comes into play: x1 will compute the optimal utilities its subtree can achieve for each value combination of the tuple hx1 x1i. it will then assemble a message as a hypercube with 1 dimensions  one for the target variable x1 and one for the backedge handler x1   and send it to x1  see table 1 .
모this is the key difference between dtree and dpop: messages travelling through the network in dtree always have a single dimension  they are linear in the domain size of the target variable   whereas in dpop  messages have multi-
ple dimensions  one for the target variable  and another one for each context variable .
combining messages - dimensionality increase
let us consider this example: x1 receives 1 messages from its children x1 and x1; the message from x1 has x1 as context  and the one from x1 has x1 as context. both have one dimension for x1  target variable  and one dimension for their context variable  x1 and x1 respectively   therefore  algorithm	1:	dpop	-	distributed	pseudotreeoptimization procedure for general networks.

1: dpop x d r 
each agent xi executes:
1:
1: phase 1: pseudotree creation
1: elect leader from all xj 뫍 x
1: elected leader initiates pseudotree creation
1: afterwards  xi knows p xi   pp xi   c xi  and pc xi 
1: phase 1: util message propagation
1: if |children xi | == 1  i.e. xi is a leaf node  then
	1:	utilxi p xi   뫹 compute utils p xi   pp xi  
	1:	send message p xi   utilxi p xi   
1: activate util message handler  
1: phase 1: value message propagation
1: activate value message handler  
1: end algorithm
1:
1: utilmessage handler xk utilxk xi  
1: store utilxk xi 
1: if util messages from all children arrived then
	1:	ifis the root  then
	1:	i 뫹
	1:	send v alue xi vi   to all c xi 
	1:	else
	1:	utilxi p xi   뫹 compute utils p xi   pp xi  
	1:	send message p xi   utilxi p xi   
1: return 1: value message
1:
1:  to agent view
1: xi 뫹 vi  = choose optimal agent view 
1: send to all xl 뫍 c xi 
1:
1: choose optimal agent view 
1:

1: return vi 
1:
1: compute utils p xi   pp xi  
1: for all combinations of values of xk 뫍 pp xi  do
	1:	let xj be parent xi 
1: similarly to dtree  compute a vector utilxi xj  of all {utilxi vi  vj  vj |vj 뫍 dom xj }
1: assemble a hypercube utilxi xj  out of all these vectors  totaling |pp xi | +1 dimensions .
1: return utilxi xj 

x1 뫸 x1x1 = v1x1 = v1...x1 = v1u x1 v1 u x1 v1 ...u x1 v1 ..................table 1: util message sent from x1 to x1  in figure 1
their dimensionality is 1. x1 needs to send out its message to its parent  x1 . x1 considers all possible values of x1  and for each one of them  all combinations of values of the context variables  x1 and x1  and x1 are considered; the values of x1 are always chosen such that the optimal utilities for each tuple   x1 뫄 x1 뫄 x1   are achieved. note that since x1 is both a context variable and the target variable  the message collapses to 1 dimensions  not 1.
모one can think of this process as the cross product of messages x1 뫸 x1 and x1 뫸 x1 resulting in a hypercube with dimensions x1  x1 and x1  followed by a projection on the x axis  which retains the optimal utilities for the tuples
  optimizing w.r.t. x1 given x1 and x1 .
collapsing messages - dimensionality decrease
whenever a multi-dimensional util message reaches a target variable that occupies one dimension in the message  a back-edge handler   the target variable optimizes itself out of the context  and the outgoing message looses the respective dimension.
모we can take the example of x1  which is initially present in the context of the message x1 뫸 x1: once the message arrives at x1  since x1 does not have any more influence on the upper parts of the tree  x1 can  optimize itself away  by simply choosing the best value for itself  for each value of its parent x1  the normal dtree process . thus  one can see that a back edge handler  x1 in our case  appears as an extra dimension in the messages travelling from the lower end of the back edge  x1  to itself  through the tree path associated with the back edge  x1 뫸 x1 뫸 x1 .
value propagation
the value phase is similar to dtree. now  in addition to its parent's value  the message a node xj receives from its parent also contains the values of all the variables that were present in the context of xj's util message for its parent. e.g.: x1 sends x1 v alue1 x1 뫹 v1    then
x1 sends  and x1 sends
x1 v alue1 x1 뫹 v1  x1 뫹 v1  .
1	complexity analysis
by construction  the number of messages our algorithm produces is linear: there are n   1 util messages - one through each tree-edge  n is the number of nodes in the problem   and m linear size value messages - one through each edge  m is the number of edges . the dfs construction also produces a linear number of messages  good algorithms require 1 뫄 m messages . thus  the complexity of this algorithm lies in the size of the util messages.
theorem 1 the largest util message produced by algorithm 1 is space-exponential in the width of the pseudotree induced by the dfs ordering used.
proof. dechter   dechter  1   chapter 1  pages 1  describes the fill-up method for obtaining the induced width. first  we build the induced graph: we take the dfs traversal of the pseudotree as an ordering of the graph and process the nodes recursively  bottom up  along this order. when a node is processed  all its parents are connected  if not already connected . the induced width is the maximum number of parents of any node in the induced graph.
모it is shown in  dechter  1  that the width of a tree  no back-edges  is 1. actually the back-edges are the ones that influence the width: a single backedge produces an induced width of 1. from the construction of the induced tree  it is easy to see that several backedges produce increases in the width only when their tree-paths overlap on at least one edge  and their respective handlers are different; otherwise their effects on the width do not combine. thus  the width is given by the size of the maximal set of back-edges which have overlapping tree-paths and distinct handlers.
모during the util propagation  the message size varies; the largest message is the one with the most dimensions. we have seen that a dimension xi is added to a message when a backedge with xi as a handler is first encountered in the propagation  and travels through the tree-path associated with the back-edge. it is then eliminated by projection when the message arrives at xi. the maximal dimensionality is therefore given by the maximal number of overlaps of tree-paths associated with back-edges with distinct handlers.
we have thus shown that the maximal dimensionality is
equal to the induced width.	1
모exponential size messages are not necessarily a problem in all setups  depending on the resources available and on the induced width - low width problems generate small messages!  however  when the maximum message size is limited  one can serialize big messages by letting the back-edge handlers ask explicitly for valuations for each one of their values sequentially  so each message can have customizable size.
모a workaround against exponential memory is possible by renouncing exactness  and propagating valuations for the best/worst value combinations  upper/lower bounds  instead of all combinations.
1	comparison with other approaches
schiex  schiex  1  notes the fact that so far  pseudotree arrangements have been mainly used for search procedures  essentially backtrack-based search  or branch-and-bound for optimization . as good examples  see the distributed depth-first branch and bound  ddbb   distributed iterative deepening  did   adopt  synchronous branch and bound  sbb  and iterative distributed breakout  idb . all these procedures have a worst case complexity exponential in the depth of the pseudotree arrangement  basically because all the variables on the longest branch from root to a leaf have to be instantiated sequentially  and all their value combinations tried out . it was shown in  bayardo and miranker  1  that there are ways to obtain shallow pseudotrees  within a logarithmic factor of the induced width   but these require intricate heuristics like the ones from  freuder and quinn  1; maheswaran et al.  1   which have not yet been adapted to a distributed setting  as also noted by the authors of the second paper.
모in contrast  our approach exhibits a worst case complexity exponential in the width of the graph induced by the pseudotree ordering. arnborg shows in  arnborg  1  that finding a min-width ordering of a graph is np-hard; however  the dfs traversal of the graph has the advantage that it produces a good approximation  and is easy to implement in a distributed context. this  coupled with the fact that the depth of the pseudotree is irrelevant to the complexity  means that our algorithm works well with a simple dfs ordering. to see this fundamental difference between the two approaches  consider a problem that is a ring with n nodes. a dfs ordering of such a graph would yield a pseudotree with height n  and one back edge  thus the induced width is 1. a backtracking algorithm is time exponential in n  whereas our algorithm is linear  with message size o |d|1 . since the exponential complexity translates directly in the explosion of the number of messages exchanged  these backtracking-based algorithms have not yet been applied to large systems.
모furthermore  it was shown by dechter in  dechter and fattah  1  that the induced width is always less than or at most equal with the pseudotree height; thus we can conclude theoretically that our algorithm will always do at least as well as a pseudotree backtrack-based algorithm on the same pseudotree ordering. however  it is only fair to say that our aproach can generate very big messages in the worst case  so one has to find a proper tradeoff between the number and the size of the messages transmitted through the system.
1	experimental evaluation
usual performance metrics for distributed algorithms are the number of messages and the number of synchronous cycles required to find the optimal solution. both are linear in our case. for the number of messages  see section 1; the number of synchronous cycles is two times the height of the pseudotree  one util propagation  and one value propagation . we also introduce the maximal message size as a metric.
1	sensor networks
one of our experimental setups is the sensor grid testbed from  bejar et al.  1 . briefly  there is a set of targets in a sensor field  and the problem is to allocate 1 different sensors to each target. this is a np-complete resource allocation problem.
모in  bejar et al.  1   random instances are solved by awc  a complete algorithm for constraint satisfaction . the problems are relatively small  1 sensors and maximum 1 targets  beyond which the problems become intractable . our initial experiments with this setup solve to optimality problems in a grid of 1 sensors  with up to 1 targets.
모another setup is the one from  maheswaran et al.  1   where there are corridors composed of squares which indicate areas to be observed. sensors are located at each vertex of a square; in order for a square to be  observed   all 1 sensors in its vertices need to be focused on the respective square. depending on the topology of the grid  some sensors are shared between several squares  and they can observe only one of them at a time. the authors test 1 improved versions of adopt  current state of the art for mcop  on 1 different scenarios  where the corridors have the shapes of capital letters l  z  t and h. their results and a comparison with dpop are in table 1. one can see the dramatic reduction of the number of messages required  in some cases orders of magnitude   even for these very small problem instances  1
algo/scenariotest ltest ztest ttest hmcn   no pass1111mlsp  no pass1111mcn   pass1111mlsp   pass1111dpop11table 1: dpop vs 1 adopt versions: number of messages in sensor allocation problems.
variables . the explanation is that our algorithm always produces a linear number of messages.
모regarding the size of the messages: these problems have graphs with very low induced widths  1   basically given by the intersections between corridors. thus  our algorithm employs linear messages in most of the parts of the problems  and only in the intersections are created 1 messages with 1 dimensions  in this case with 1 values each .
모this fact gives our algorithm the ability to solve arbitrarily large instances of this particular kind of real-world problems.
1	meeting scheduling
we experimented with distributed meeting scheduling in an organization with a hierarchical structure  a tree with departments as nodes  and a set of agents working in each department . the csp model is the peav model from  maheswaran et al.  1 . each agent has multiple variables: one for the start time of each meeting it participates in  with 1 timeslots as values. mutual exclusion constraints are imposed on the variables of an agent  and equality constraints are imposed on the corresponding variables of all agents involved in the same meeting. private  unary constraints placed by an agent on its own variables show how much it values each meeting/start time. random meetings are generated  each with a certain utility for each agent. the objective is to find the schedule that maximizes the overall utility.
모table 1 shows how our algorithm scales up with the size of the problems. notice that the total number of messages includes the value messages  linear size   and that due to the fact that intra-agent subproblems are denser than the rest of the problem  high-dimensional messages are likely to be virtual  intra-agent messages  not actually transmitted over the network . to our knowledge  these are by far the largest optimization problems solved with a complete  distributed algorithm  1 agents  1 meetings  1 variables  1 constraints . the largest reported previous experiment is  maheswaran et al.  1   with 1 agents  1 meetings  1 variables  1 constraints  solved using adopt.
1	conclusions and future work
we presented in this paper a new complete method for distributed constraint optimization. this method is a utilitypropagation method that extends tree propagation algorithms like the sum-product algorithm or dtree to work on arbitrary topologies using a pseudotree structure. it requires a linear number of messages  the largest one being exponential in the induced width along the particular pseudotree cho-
agents111meetings111variables111constraints111messages111max message size11k1k1kcycles111table 1: dpop tests on meeting scheduling.
sen. this method reduces the complexity from domn  standard backtracking  to domw  where n=number of nodes in the problem  dom bounds the domain size and w=the induced width along the particular pseudotree chosen. for loose problems holds and our method retains the advantage of a linear number of messages  in practice even orders of magnitude fewer messages than the other aproaches   while preserving a small message size. in real world scenarios  sending a few larger messages is preferable to sending a lot of small messages because of the much lower overheads implied  differences can go up to orders of magnitude speedups . our experiments show that our method is the first one to be able to handle effectively arbitrarily large instances of a number of practical problems while using a linear number of messages.
모finding the minimum width pseudotree is an np-complete problem  so in our future work we will investigate heuristics for finding low width pseudotrees.
1	acknowledgements
we would like to thank rina dechter and radu marinescu for insightful discussions  jonathan pearce/teamcore for experimental data from sensor networks and meeting scheduling simulations  and michael schumacher for valuable comments on an early version of this paper. this work has been funded by the swiss national science foundation under contract no. 1/1.

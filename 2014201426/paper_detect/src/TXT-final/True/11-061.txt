 
a program called  am  is described which cairies on simple mathematics research: defining  and studying new concepts under the guidance of a large body of heuiistic rules. the 1 heurktus communicate via an agenda mechanism  a global priority queue of small bisk'  for the program to pei foim and teasons why each task is plausible  e.g.   find pencrahztion. of 'prnes'  because turued out to be so useful a conccpi  . fach concept is an active  structured knowledge module. one bundled vei y incomplete modules are initially supplied  each one corresponding to an elementary set theoretic concept  e.g.  union . this provides a definite but immense space which am begins to explore. in one boor  am rediscovers hundreds of common concepts  including singleton sets  natural numbers  arithmetic  and theorems  e.g.  unique factorization . 
of fully automatic theory formation in some scientific field.  1 his includes two activities:  i  discovering relationships among known concepts  e.g.  by formal manipulations  or by noticing regularities in empirical data   and  ii  defining new concepts for investigation. meta-dendral  buchanan 1  performs only the first of these; most domain-independent concept learning programs  winston 1  perform only the latter of these: while they do create new concepts  the initiative is not theirs but rather is that of a human  teacher  who already has the concepts in mind. 
	entire process. 	this paper describes such a program: am. 
1. introduction 	1. choice of domain what we are describing is a computet program which defines new concepts  investigates them  notices regularities in the data about them  and conjectures relationships between them. this new information is used by the program to evaluate the newly-defined concepts  concentrate upon the most interesting ones  and iterate the 

1. historical motivation 
scientists often face the difficult task of formulating nontrivial research problems which are soluble. in most brandies of science  it is usually easier to tackle a specific given problem than to propose interesting yet managable new questions to investigate. for example  contrast solving the missionaries and cannibals problem with the more ill-defined reasoning which led to inventing! it. the first type of activity is formalizable and admits a deductive solution; the second is inductive and judgmental. as another example  contrast proving a given theorem versus proposing it in the first place. 
a wealth of ai research has been focussed upon the former type of activity: deductive problem solving  see  e.g.   bledsoe 1    nilsson 1    newell & simon 1  . approaches to inductive inference have also been made. 
some researchers have tried to attack the problem in a completely domain-independent way  see  e.g.   winston 1  . other ai researchers believe that  expert knowledge  must be present if inductive reasoning is to be done at the level which humans are capable of. indeed  a few recent ai programs have incorporated such knowledge  in the form of judgmental rules gleaned from human experts  and successfully carried out quite complex inductive tasks: medical diagnosis  shortliffe 1   mass spectra identification  feigenbaum 1   clinical dialogue 
 davis 1   discovery of new mass spectroscopy rules  buchanan 1 . 
research in distinct fields of science and mathematics often proceeds slightly differently. not only are the concepts different  so are most of the powerful heuristics. so it was reasonable that this first attempt should be limited to one narrow domain. elementary mathematics was chosen  beeausc : 
1. there are no uncertainties in the raw data  e.g.  arising from errorful measuring devices . 
1. reliance on exports' introspection is a powerful technique for codifying the judgmental rules needed to work effectively in a field. by choosing a familiar field  it was possible for the author to rely primarily on personal introspection for such heuristics. 
1. the more formal a science is  the easier it is to automate  e.g.  the less one needs to use natural language to communicate information . 
1. a mathematician has the freedom to explore -- or to give up on -- whatever he wants to. there is no specific problem to solve  no fixed  goal . 
1. unlike some fields  e.g.  propositional logic   elementary math research has an abundance  many hundreds  of powerful heuristic rules available. 
the  next step  in this progression of tasks would be that 	1 	i n i t i a l assumptions and hypotheses the limitations of math as a domain are closely intertwined with its advantages. having no ties to real world data can be viewed as a liability  as can having no clear  right  or  wrong  behavior. since math has been worked on for millcnia by some of each culture's greatest minds  it is unlikely that a small effort like am would make many startling new discoveries. nevertheless  it was decided that the advantages outweighed the limitations. 

t hie 	work was 	supported 	in part by the defense advanced research 
projects 	agency 	 m1-c-1  and monitored by 	the air rorce 
office of scientific research 
the am program  got off the ground  only because a number of sweeping assumptions were made about how math research could be performed by a computer program: 
1. very little natural language processing capabilities are 

specialized 	systems-1 lenat 

	required. 	as it runs  am is monitored by a human 
 user . am keeps the user informed by instantiating english sentence templates. 1 he user's input is rare and can be successfully stereotyped. 
1 formal reasoning  including proof  is not indispensable when doing theory formation in elementary mathematics. in the same spirit  we need not worry in advance about the occurence of contradictions. 
1. each mathematical concept can be represented as a list of facets  aspects  slots  parts  property/value pairs . tor each new piece of knowledge gained  there will be no trouble in finding which facet of which concept it should he stored in. 
1. the basic activity is to choose some facet of some concept  and then try to fill in new entries to store there; this will occasionally cause new concepts to be defined. the high-level decision about which facet of which concept to work on next can be: handled by maintaining an  ordered agenda  of such tasks. the techniques for actually carrying out a task are contained within a large collection of heuristics. 
b. each heuristic has a well defined domain of applicability  which coincides perfectly with one of am's concepts. we say the heuristic  belongs to  that concept 
1. heuristics superimpose; they never interact strongly with each other. if one concept ci is a specialization of concept c   then cl's heuristics are more powerful and should he tried first. 
1. the reasons supporting a task  on the agenda of facet/concept tasks to be carried out  superimpose peifectly.  they never change with time  and it makes no difference in what order they were noticed. it suffices to have a single  positive number which characterizes tire value of the reason. 
1. the tasks on the agenda are completely independent. no task  wakes up  another. only the general position  near the top  near the bottom  is of any significance. 
1. the set of heuristics need not grow  as new concepts are discovered. all common-sense knowledge required is assumed to be already present within the initially-given body of heuristic rules. 
it is worth repeating that all the above points are merely convenient falsehoods. their combined presence made am doable  by one person  in one year . 
one point of agreeement between wei/enbaum and l e d e r b e i g  iederberg 1  is that ai can succeed in automating only those activities for which there exists a  strong theory  of how that activity is done by people. point #1 above is a claim that such a clean  simple model exists for math research: a search process governed by a large collection of houristic rules. here is a simplified summary of that model: 
1. the order in which a math textbook presents a theory is almost the exact opposite of the order in wheh it war. actually developed. in a text  definitions and lemmata are given with no motivation  and they turn out to be just the ones required for the next big theorem  whose proof 
magically follows. but in real life  a mathematician would begin by examining some already-known concepts  trying to find some regularity involving them  formulating those as conjectures to investigate further  and using them to motivate some simplifying new definitions. 
1. each step the researcher takes  see #1  involves choosing from a huge set of alternatives -- that is  searching. he uses judgmental criteria  heuristics  to choose the  best  alternative. this saves his search from the combinatorial explosion. 
1. non-formal 	criteria 	 aesthetic 	interestingness  empirical induction  analogy  utility estimates  are much more important than formal methods. 
1. all such heuristics can be viewed as situation/action  if/ihln  rules. there is a common core of  a few hundred  heuristics  basic to all fields of math at all levels. in addition to these  each field has several specific  powerful rules. 
1. nature is metaphysically pleasant: it is fair  uniform  regular. statistical considerations are valid and valuable when trying to find regularity in math data. simplicity and synergy and symmetry abound. 
1. design of the 'am' program 
a pure production system may be considered to consist of thtee components: data memory  a set of rules  and an interpreter. since am is more or less a rule-based system  it too can be considered as having three main design components: how it represents math knowledge  its framelike concept/facets scheme   how it enlarges its knowledge base  its collection of heuristic rules   and how it controls the firing of these rules  via the agenda mechanism . these form the subjects of the following three subsections. 
1. representation of concepts 
the task of the am program is to define plausible new mathematical concepts  and investigate them  each concept is represented internally as a bundle of slots or  facets . each facet corresponds to some aspect of a concept  to some question we might want to ask about the concept. since each concept is a mathematical entity  the kinds of questions one might ask are fairly constant from concept to concept. a set of 1b facets was therefore fixed once and for all. below is that list of facets which a concept c may have. for each facet  we give a typical question about c whic h it answers. 
name: what shall wo call c when talking with the user  
generalizations: which other concepts have less restrictive  i.e.  weaker  definitions than c  
specialisations: which concepts satisfy c's definition plus some additional constraints  
examples; what things that satisfy c's definition  isa's: which concepts' definitions does c itself satisfy  ln-domain of: which operations can operate on c's  
in-range of: which operations result in c's. when run  
views: how can we view some x as if it were a c  
intuitions: what abstract  analogic representations are known for c  
analogies: are there any similar concepts  
conjec's : what are some potential theorems involving c  
definitions: how can we tell if x is an example of c  
algorithms: what exactly do we do if we want to execute the operation c on a given argument  
domain/range: what kinds of arguments can operation c be executed on  what kinds of values will it return  
worth: how valuable is c   overall  aesthetic  utility  etc.  
interestingness: what special features can make a c especially interesting  especially boring1 
in addition  each facet f of concept c can possess a few little subfacets which contain heuristics for dealing with that facet of c's: 
f.fillin: what are some methods for filling in new entries for facet f of a concept which is a c  
f.check: how do we verify/debug potential entries  
f.suggest: if am bogs clown  what are some new tasks  related to facet f of concept c  to consider doing  

sppcialized 	systems-1: lennt 

in the lisp implementation of am  each  oncopt is maintained as an atom with an attribute/value list  property list . each facet  and its list of entries is just a property and its associated value. as an example  here is a rendition of the sets concept. it is meant to correspond to the notion of a collection of elements. 

to decipher the definitions facet  there are a few things you must know. facet f of concept c will occasionally be abbreviated as c.f. in those cases where f is  executable   the notation c.f will refer to applying the corresponding function. go the first entry in the definitions facet is recursive because it contains an embedded call on the function set.definition. since there are three separate but equivalent definitions  am may choose whichever one it wants when it recurs. am can choose one via a random selection scheme  or always try to recur into the same definition as it was just in  or perhaps suit its choice to the form of the argument at the moment. all concepts possess executable definitions  lisp predicates   though not necessarily effective ones. when given an argument x  set.definition will return true  false  or will eventually be interrupted by a timer  indicating that no conclusion was reached about whether or not x is a set . 
the views  intuitions  and analogies facets must be distinguished from each other. views is concerned with transformations between two specific concepts  e.g.  how to view any predicate as a set  and vice versa . an entry on the analogies facet is a mapping from a set of concepts to a sef of concepts  e.g.  between {bags  hag-union  bagintersection ...} and {numbers  addition  minimum ...!; or between {primes  factoring  numbers...} and {simple groups  factoring into subgroups  groups...} . intuitions deals with transformations between a bunch of concepts and one of a few large  standard scenarios  e.g.  intuit the relation     as playing on a see-saw; intuit a set by drawing a venn diagram . intuitions are characterized by being  i  opaque  am cannot introspect on them  delve into their code    ii  occasionally fallible   iii  very quick  and  iv  carefully handcrafted in advance  since am can not pick up new intuitions via metaphors to the real world  as we can . 
since  sets  is a static concept  it had no algorithms facet 
 as did  e.g.   set-union  . the algorithms facet of a concept 
snecialized 
contains a list of entries  a list of equivalent algorithms. 
each algorithm must have three separate parts: 
1. descriptors: recursive  linear  or iterative  quick or slow  opaque or transparent  destructive  
1. relators: is  this just a special case of some other concept's algorithm  which others does this one call on 1 is this similar to any other algorithms  
1. program: a small  executable piece of lisp code. it may be used for actually  running  the algorithm; it may also be inspected  copied  reasoned about  etc. there arc multiple algorithms because different ones have different properties: some are very quick in some cases  some are always slow but are very cleanly written and hence easier to reason about  etc. 
	another 	facet 	possessed 	only 	by 	active 	concepts 	is 
domain/range. it is a list of entries  each of the form  d1 d1... di --  r   which means that the concept takes a list of arguments  the first one being an example of concept d1  the second of d1 ...  the last argument being an example of concept di  and if the algouthm  any entry on the algorithms facet  is run on this argument list  then the value it returns will be an example of concept r. we may say that the domain of the concept is the cartesian product d1 xd1x...xdi  and that the range of the concept is r. for example  the domain/iange of set-union is * sets sets -* sets~ ; set-union takes a pair of sets as its argument list  and returns a set as its value. 
once the representation of knowledge is settled  there remains the actual choice of what knowledge to put into the program initially. one hundred elementary concepts wore selected  corresponding roughly to what piaget might have called  prenumerical knowledge . figure j presents a graph of these concepts  showing their interrelationships of genoralization/specialiation and fxamples/isa's. there is much static; structural knowledge  sets  truth-values  
conjectures...  and much knowledge about simple activities  boolean relations  composition of relations  set operations ... . notice that there is no notion of proof  of formal reasoning  or of numbers or arithmetic. 
1. top-level control: the agenda 
am's basic activity is to find new entries for some facet of some concept. but which particular one should it choose to develop next  initially  there are over one hundred concepts  each with about twenty blank facets; thus the  space  from which to choose is of size two thousand. as more concepts get defined  this number increases. ips worth having am spend some time deciding which basic task to work on next  for two reasons: most of the tasks will never get explored  and only a few of the tasks will appear  to the human user  rational things to work on at the moment. 
much informal expert knowledge is required to constrain the search  to quickly zero in on one of these few very good tasks to tackle next. this is done in two stages: 
1. a list of plausible facet/concept pairs is maintained. no task can get onto this  agenda  unless there is some reason why working on that facet of that concept would be worthwhile. 
1. fach task on this agenda is assigned a priority rating  based on the number  and strengths  of reasons supporting it. this allows the entire agenda to be kept ordered by plausibility. 
the first of these constrainings is much like replacing a legal move generator with a plausible move generator  in a heuristic search program  the second kind of constraint is akin to using a heuristic evaluation function to select the 
systems-1: lenat 


the actual top-level  ontrol policy is to pluck the top task 
 highest priority rating  from the agenda  and then execute it. while a task executes  some new bisks may he proposed  and merged into the agenda   some new concept'  may get created  and  hopefully  some entries for the specified facet of the specified concept will he found and filled in. once a task ir. chosen  the priority rating of that task now serves a new function: it is taken as an estimate of how much computational resource to devote to working on this task. 1 he task above  in the box  might he allotted 1 cpu seconds and 1 list cells  because its rating was 1. when either resource is exhausted  work on the task halts. 
the task is removed from the agenda  and the cycle begins anew  am starts working on whichever task is now at the top of the agenda . 
1. low-level control: the heuristics 
after 	a 	task 	is 	selected 	from 	the 	agenda  	how 	is 	it 
 executed   a concise answer would be: am selects relevant heuristics and executes them; they satisfy the task via side-effects. this really just splits our original question into two new ones: how are relevant heuristics located  what does it mean for a heuristic to be executed and to achieve something  
1.1 	how relevant heuristics are located 
each heuristic is represented as a condition/action rule. 
the condition or left-hand-side of a rule tests to see whether the rule is applicable to the task on hand. the action or right-hand-side of the rule consists of a list of actions to perform if the rule is applicable. eg.  
if the cunent task is to check examples of a concept x  and  forsome y  y is a generahzation of x  and y has al least 1 known examples and all examples of y are also examples of x  
thkn conjecture: x is really no more speciali/.ed than y  and add that conjecture as a new entry on the 
　　kxamples facet of the conjock concept  and add the following task to the agenda:  check examples of y  for this reason: y may analogously turn out to be equal to one of its supposed genetalizations. 
it is the heuristics  right hand sides which actually accomplish the selected task; that process will be described in the next subsection. the left sides are the relevancy checkers  and will be focussed on now: 
syntactically  the left side must be a predicate  a lisp function which always returns true or false. it must be a conjunction p 1 a p 1 a p 1 a   . of smaller predicates pi  each of which must be quick and must have no side effects. here are some typical conjucts which might appear inside a left hand side: 
over half of the current task's tunc allotment  is used up; 
there are some known examples of structures; 
some known generalization of the current concept  the concept mentioned as part o| the current task  has a completely empty kxamplcs facet; 
a task recently worked on had the form  fill in facet f of c   for any f  where c  is the current concept; the user has used this program at least once he fore; 
it turned out that the laxity of constraints on the form of the heuristic rules proved excessive: it made it very difficult for am to analyze and modify its own heuristics. 
f rom a  pure production system  viewpoint  we have answered the question of locating relevant heuristics. namely  we evaluate the left sides of all the rules  and see which ones respond  true . but am contains hundreds of heuristics  and repeatedly evaluating each one's condition would use up tremendous amounts of time. am is able to quickly select a set of potentially relevant rules  rules whose left sides are then evaluated to test for true relevance. the secret is that each rule is stored somewhere a propos to its  domain of applicability . the proper place to store the rule is determined by the first conjunct on its left hand side. consider this heuristic: 
if the riittr.nl ta k  * to find examples of activity f  and a fast algorithm for computing f is known  
t h e n one.way to get examples of f is to run f on landomly chosen examples of the domain of f. 
the very first conjunct of a rule's left side is always special. it specifics the domain of applicability  potential relevance  of the heuristic  by naming a particular facet of a particular concept to which this rule is relevant  in the above rule  the domain of relevance is therefore the examples facet of the activity concept . am uses such first conjuncts as pre-precondilions: a potentially relevant rule can be located by its first conjunct alone. then  its left hand side is fully evaluated  to indicate whether it's truly relevant. here are a few typical expressions which could be first conjuncts: 
the current task  the one just selected from the agenda  is of the form   duck the domain/range facet of concept x   where x is some surjectivc function; 
the current task matches  fill in boundary examples of 
x   where x is an operation on pairs of sets; 
the current task is  fill in examples of primes ; 
the key observation is that a heuristic typically applies to all examples of a particular concept c. the rule above has c = activity; it's relevant to each individual activity. 
when a task is chosen  it specifies a concept c and a facet f to be worked on. am then  ripples upward  to gather potentially relevant rules: it looks on facet f of concept c to see if any rules are tacked on there  it looks on facet f of each generalization of c  on each of their generalisations  etc. if the current task were  check the domain/range of union-o-union   then am would ripple upward from union-o-union  along the generalization facet entries  gathering heuristics as it went. the program would ascertain which concepts claim union-o-union as one of their examples. these concepts include compose-withself  compose  operation  active  any-concept  anything. am would collect heuristics that tell how to check the 
domain/range 	of 	any 	composition  	how 	to 	deal 	with 
domain/range facets of any concept  etc. 	of course  the 
　　this operation is the result of composing set-union with itself. it performs x  x y z  xu yuz . 

s p o c l a l i 	z e d s y s t e m s - 1 : 	l e n a t 
1 

further out it ripples  the more general  and hence weaker  the heuristics tend to be. here is one heuristic  tacked onto the domain/range facet of operation  which would be garnered if the selected task were  check domain/range of union o-union : 
if the ninnut task is  check the domain/range of f   and an entry on that facet has the form  d d...1  -  h   and concept r is a generalization of rnncrpl i   
t h k n it is worth spending time checking whether or not the range of f rnight he simply i   instcad of r. 
suppose one entry on union-o -union's domain/range facet was   nonempty-sets nonempty-sets nonempty-sets -+ sets  . then the above heuristic would be truly relevant 
 all three conjuncts on its left hand side would be satisfied   and it would pose the question: is the union of three nonempty sets always nonempty  empirical evidence would eventually confirm this  and the domain/range facet of union-o-union would then contain that fact  
merc is another way to look at the heuristic-gathering process. all the concepts known to am are arranged in a big hierarchy  via subsetof links  specializations  and element-of links  isa . since each heuristic is associated with one individual concept  its domain of applicability   there is a hierarchy induced upon the set of heuristics. heritability properties hold: a heuristic tacked onto concept c is applicable to working on all  lower  concepts. this allows us to efficiently analogically access the relevant heuristics simply by chasing upward links in the hierarchy. note that the task selected from the agenda provides an explicit pointer to the  lowest  -- most specific concept; am ripples upward from it. thus concepts are gathered in order of increasing generality; hence so are the heuristics. 
below are summarized the three main points that comprise 
am's scheme for finding relevant heuristics in a  natural  way and then using them: 
1. fach heuristic is tacked onto the most general concept for which it applies: it is given as large a 
. domain of applicability as possible. this will maximize its generality  while leaving its power untouched. 
1. when the current task deals with concept c  am ripples upward from c  tracing along generalization and isa links  to quickly find all concepts which claim c as one of their examples. heuristics attached to all such concepts are potentially relevant. 
1. all heuristics are represented as condition/action rules. once the potentially relevant rules are located  in step 1   am evaluates eacivs left hand side  in order of increasing generality. the rippling process automatically gathers the heuristics in this order. whenever a rule's left side returns true  the rule is known to be truly relevant  and its right side is immediately executed. 
1.1 what happens when heuristics are executed 
when a rule is recognized as relevant  its right side is executed. how does this accomplish the chosen task  
the right side  by contrast to the left  may take a great deal of time  have many side  effects  and the value it returns is always ignored. the right side of a rule is a series of little lisp functions  each of which is called an action. semantically  each action performs some processing which is appropriate in some way to the kinds of situations in which the rule's left side would have been satisfied  returned true . the only constraint which each action must satisfy is that it have one of the following three kinds of side-effects  and no other kinds: 
   1. it suggests a new task to add to the agenda. 
   1. it dictates how some new concept is to be defined. 
   1. it adds some entry to some facet of some concept. dear in mind that the right side of a single rule is a list of such actions. let's now treat these three kinds of actions: 
1a heuristics suggest new tasks 
the left side of a rule triggers. scattered among the list of 
 things to do  on its right side are some suggestions for future tasks. these new tasks are then simply added to the agenda. the suggestion for the task includes enough information about the task to make it easy for am to assemble its parts  to find reasons for it  to numerically evaluate those reasons  etc. for example  here is a typical rule which proposes a new task. it says to generalize a predicate if it appears to be returning true very rarely: 
if the current task was  fill in examples of x   and concept x is a predicate  and over 1 items are known in the domain of x  and at least 1 cpu sees  have been spent so far  and x has returned true at least once  and x returned false over 1 times as often as true  t h k n add the following task to the agenda:  fill in gcneraltations of x  for the following reason: 
 x is rarely satisfied; a slightly iess restrictive concept might he much more ml cresting  
this reason has a rating which is the false/true ratio 
let's see one instance where this rule was used. am worked on the task  fill in examples of list-equality . one heuristic  displayed in sec. 1.1  and again in detail in sec. 1.1  said to randomly pick elements from that predicate's domain and simply run the predicate. thus am repeatedly plucked random pairs of lists  and tested whether or not they were equal. needless to say  not a high percentage returned true  in practice  1 out of 1 . this rule's left side was satisfied  and it executed. its right side caused a new task to be formulated:  fill in generalizations of list-equality . the reason was as stated above in the rule  and that reason got a numeric rating of 1 = 1. that task was then assigned an overall rating  in this case  just 1  and merged into the agenda. it sandwiched in between a task with a rating of 1 and one with a 1 priority rating. incidentally  when this task was finally selected  it led to the creation of several interesting concepts  including the predicate which we might call  same-length . 
1 1 heuristics create new concepts 
one of the three kinds of allowable actions on the right side of a heuristic rule is to create a specific new concept. for each such creation  the heuristic must specify how the new concept is to be constructed. the heuristic states the definition facet entries for the new concept  plus usually a few other facets' contents. after this action terminates  the new concept will  exist . a few of its facets will be filled in  and many others will be blank. some new tasks may exist on the agenda  tasks which indicate that am ought to spend some time filling in some of those facets in the near future. here is a heuristic rule which results in a new concept being created: 
if the current task was  fill in examples of f  and f is an operation  from domain a into range b  and more than 1 items are known examples of a  and more than 1 range items  examples of b  were found by applying f to these domain elements  
　　and at least one of these range items 'b' is a distinguished member  especially  an extremum  of b  t h k n for each such 'b'b  create the following concept: 

specialized systens-1: lenat 


and the reason for this neat ion is:  lt's worth 
investigating a's whieh havr unusual f-values  
and add five new tasks to the anemia  
of the form  kill in faeet x of f-inveisr-oi-h  where x is coinertures  generlions  
　　specialization  kxamples  and isa's; for the following reason: 
　　 this conecpt was newly synthesized; it is erurial lo find where it 'fits in' to the hierarehy  thr reason's rating is just worlh finverse-of-b . 
one use of this heuristic was when thr current task was 
 f ill in examples of divisors~of . the heuristics left side was satisfied because: divisors of is an operation  from numbers to sets of numbers   and far more than the required 1 different numbers are known  and more than 1 different sets of factors were located altogether  and some of them were in fact distinguished by being extreme kinds of sets  e.g.  singletons  empty sels  doubletons  tripletons ... . after its left side triggered  the right side of the rule was executed  four new concepts were created immediately. here is one of them: 
namk: divisors-ol - invrrseok ooubleton j okfinition: x  a  divisors of a  is a don melon 
g e n k k a u / a t i 1 n s : numbers worth: 1 
intkrkst: any conjecture involving both this eoneept and eilher divisors-of or times | 
this is a concept representing a certain class of numbers  in fact the numbers we call  primes . the heuristic rule is of course applicable to any kind of operation  not just numeric ones. as another instance of its use  consider what happened when the current task was 'till in examples of set-intersect . this rule caused am to notice that some pairs of sets were mapping over into the most extreme of all sets: the empty set. the rule then had am define the new concept we would call  disjointness : pairs of sets having empty intersection. 
there is just a tiny bit of  theory  behind how these concept-creating rules were designed. a facet of a new concept is filled in immediately iff both  i  it's trivial to fill in at creation-time  and  ii  it would be very difficult to fill in later on. the following facets are typically filled in right away: definitions  algorithms  domain/range  worth. each other facet is either left unmentionod by the rule  or else is explicitly made the subject of a new task which gets added to the agenda. for instance  the heuristic rule above would propose many new tasks at the moment that primes were created  including  fill in conjectures about primes    fill in specializations of primes   etc. 
1 heuristics fill in entries for a specific facet 
if the task plucked from the agenda were  fill in examples of set-union   it would not be too much to hope for that by the time all the heuristic rules had finished executing  some examples of that operation would indeed exist on the examples facet of the set-union concept. let's see how this can happen. 
am starts by rippling upward from set-union  looking for heuristics which are relevant to finding examples of setunion  there are no such rules   relevant to finding examples of set-operations  of operations  of any activity  of any concept  of anything. here is one rule applicable to any activity: 
if the curreut task is to fill in examples of f  and f is an operation  say with domain i   and there is a fast known algorithm for f  
t h k n one way to get examples of f is lo run f's algorithm on randomly chosen examples of i . 
of course  in the lisp implementation  this situation-action rule is not coded quite so neatly. it would be more faithfully translated as follows: 
if curr-task malehes  fillin examples f*-anything   and f isa aetivily  and l.he algorithms farel of f is not blank  thkn carry out the following proredure: 
1. find the domain of f  and rail it d; 
1. find examples of d  and rail them k; 1. find a fast algorithm to compute f; call it a; 
	1. 	repeatedly: 
1a. choose any member of e  and call it kl. 
1b. run a on e1  and call the result x. 
1e. check whether  e1 x  satisfies the definition of f. 
1d. if so  then add 'i'll -  x  to the kxarnples facet of f. 
1e. if not  then add  'k1 -  x  to the nonexamples facet of f. 
let's see exactly how this rule found examples of setunion. step  1  says to locate the domain of set-union. the facet labelled domain/range  on the set-union concept  contains the entry  set sft -  slt   which indicates that the domain is a pair of sets. that is  set-union is an operation which accepts  as its arguments  two sets. 
since the domain elements are sets  step     says to locate examples of sets. the facet labelled examples  on the sets concept  points to a list of about 1 different sets. this includes {1}  {a b c d f   {}  {a {fb}} ... 
step  1  involves nothing more than accessing some entry tagged with the descriptor  quick  on the algorithms facet of set-union. one such entry is a recursive lisp function of two arguments  which halts when the first argument is the empty set  and otherwise pulls an element out of that set  set-inserts it into the second argument  and then recurs on the new values of the two sets. for convenience  we'll refer to this algorithm as union. 
we then enter the loop of step  1 . step  1a  has us choose one pair of our examples of sets  say the first two  1} and  a b c d e . step  1b  has us run union on these two sets. the result is {a b c d f 1}. step  1c  has us grab an entry from the definitions facet of set-union  and run it. a typical definition is this formal one: 
 x  s1 s1 s1  
 and 
 for all x in si  x is in s1   for all x in s1  x is in s1  
 for all x in s1  x is in s1 or x is in s1     
it is run on the three arguments s1={z}  s1={a b c d e}  
s1~{a b c d e z}. 	since it returns  true   we proceed to 
step  1d . the construct  {z}  {a b c d e} -  {a b c d e z}  is added to the examples facet of set-union. 
at this stage  control returns to the beginning of the step 
specialized svstems-1: lenat 
1  1  loop. a new pair of sets is chosen  and so on. the loop ends when either the time or space allotted to this rule is exhausted. am would then break away at a  clean  point  just after finishing a cycle of the step  1  loop  and would move on to a new heuristic rule for filling in examples of set-union. 
1. results 
1. excerpt of the 'am' program running 
repeatedly  the top task is plucked from the agenda  and heuristics are executed in an attempt to satisfy it. am has a modest facility that prints out a description of these activities as they occur. here is a tiny excerpt: 
+
* task: ** 	fill in examples of the concept  divisors-of . 
1 reasons: 
　　　　　 1  no known examples of divisors-of yet. 
　　　　　 1  times  related to divisors-of  is now v. int. 
　　　　　 1  focus of attention: am just defined divisors-of. 1 examples found  in 1 secs  e.g.  divisors- of 1 ={ 1 1}. 
** taski ** 	consider nos. having small sets of divisors-of. 
1 reasons: 
　　　　　 1  worthwhile to look for extreme cases.  1  focus: am just worked on divisors-of. filing in examples of numbers with 1 divisors. 
1 examples found  in 1 seconds. 
conjecture: no numbers have precisely 1 divisors. 
filling in examples of numbers with 1 divisors. 
j examples found  in 1 sees  e.g.  divisors of l  = {1j. 
conjecture: 1 is the only number with exactly 1 divisor. 
filling in examples of numbers with 1 divisors. 
1 examples found  in 1 sees. divisors- of  1 ={ 1}. 
no obvious conjecture. may merit more study. 
creating a new concept:  numbers-with-1-divisors . 
filling in examples of numbers with 1 divisors. 
1 examples found  in 1 secs. divisors-of 1 ={ 1 1}. 
all nos. with 1 divisors are also squares. unexpected!. creating a new concept:  numbers-with-1-divisors . 
** task: ** consider square-roots of nos-with-1-divisors. 1 reasons: 
 1  numbers-with-1 divisors unexpectedly turned out to all be perfect squares as well. 
    focus: am just defined nos-with-1-divisors. 
all square-roots of numbers-with-1 -divisors seem to be numbers-with-1-divisors. 
	e.g.  	divisors 1  = divisors 1  = {1}. 
even the converse of this seems empirically to be true. 
     the chance of coincidence is below acceptable limits. boosting the worth rating of both concepts. 
** task:** consider the squares of nos-witlv-1-divisors. 
1 reasons: 
 1  squares of nos-with-1~divisors were v. int. 
 1  square-roots of nos-with-1-divisors were int. 
 1  focus: am just worked on nos-with-1-divisors. 
1. overall performance 
now that we've seen how am works  and we've been exposed to a bit of  local  results  let's take a moment to discuss the totality of the mathematics which am carried out. am began its investigations with scanty knowledge of a hundred elementary concepts of finite set theory  see fig. 1 . most of the obvious set-theoretic concepts and relationships were quickly found  e.g.  de morgan's laws; singletons   but no sophisticated set theory was ever done  e.g.  diagonalization . rather  am discovered natural numbers and went off exploring elementary number theory. arithmetic operations were soon found  as analogs to set-theoretic operations   and am made rapid progress in divisibility theory. see fig. 1. prime pairs  diophantine equations  the unique factorization of numbers into primes  goldbach's. conjecture -- these were some of the nice discoveries by am. many concepts which we know to be crucial were never uncovered  however: remainder  gcd  greater-than  infinity  proof  etc. these  omissions   could have been discovered by the existing heuristic rules in am. 1 he paths which would have resulted in their definition were simply never rated high enough to explore. 
all the discoveries mentioned  including those in fig. 1  were made in a run lasting one cpu hour  interlisp + 1k  sumex pop-1 kl . two hundred jobs in toto were selected from the agenda and executed. on the average  a job was granted 1 cpu seconds  but actually used only 1 seconds. f or a typical job  about 1 rules were located as potentially relevant  and about a dozen actually fired. am began with 1 concepts and ended up with three times that many. of the synthesized concepts  half were technically termed  losers   both by the author and by am   and half the remaining ones were only marginal. 
although am fared well according to several different measures of performance  see section 1   of great significance are its limitations. as am ran longer and longer  the concepts it defined were further and further from the primitives it began with. e.g.   prime-pairs  were defined using  primes  and  addition   the former of which was defined from  divisors-of   which in turn came from  multiplication   which arose from  addition   which was defined as a restriction of  union   which  finally!  was a primitive concept that we had supplied  with heuristics  to am initially. when am subsequently needed help with prime pairs  it was forced to rely on rules of thumb supplied originally about uniomng. although the heritability property of heuristics did ensure that those rules were still valid  the trouble was that they were too general  too weak to deal effectively with the specialized notions of primes and arithmetic. 
f or instance  one general rule indicated that aub would be interesting if it possessed properties absent both from a and from 1. this translated into the prime-pair case as  if p+q=r  and p q.r are primes. then r is interesting if it has properties not possessed by p or by q.  the search for categories of such interesting primes r was of course barren. it showed a fundamental lack of understanding about numbers  addition  odd/even-ness  and primes. 
the key deficiency was the lack of adequate mera-rules  'davis 1 : heuristics which reason about heuristics: keep track of their performance  modify them  create new ones  etc. 
aside from the preceding major limitation  most of the other problems pertain to missing knowledge: many concepts one might consider basic to discovery in math are absent from am; analogies were under-utilized; physical intuition was hand-crafted only; the interface to the user was far from ideal; etc. a large effort is underway this year at carnegie-mellon university  comprised of greg harris  doug lenat  elaine rich  jim saxe  and herbert simon  to overcome these limitations. 

specialized systens-1: lenat 
1 

1. 	experiments wjthjam' 	1.1 	can am work in the new domain of plane geometry  

one valuable aspect of am is that it is amenable to many kinds of experiments. although am is too ad hoc for numeric results to have much significance  the qualitative results of such experiment'  may have some valid implications for math research  for automating math research  and for designing  scientist assistant  programs. 
1.1 	must the worth numbers be finely tuned  
each of the 1 initial concepts had  supplied by the author  a rating number  1  signifying its overall worth. the worth ratings affect the overall priority values of tasks on the agenda. just how sensitive is am*s behavior to the initial settings of the worth numbers  
to test this  a simple experiment was performed. all the concepts' worth facets were set to 1 initially. by and large  the same discoveries were made as before. but there were now long periods of blind wanderings  especially near the beginning of the run . once am hooked into a line of productive developments  it advanced at the old rate. during such chains of discoveries  am was guided by massive quantities of symbolic reasons for the tasks it chose  not by nuances in numeric ratings. as these spurts of development died out  am would wander around again until the next one started. 
1.1 	how finely tuned is the agenda  
the top few candidates on the agenda almost always appear to be reasonable things to do at the time. but what if  instead of picking the top-rated task  am selected one randomly from the top 1 tasks on the agenda  in that case  am's rate of discovery is slowed only by about a factor of 1. but the apparent  rationality   of the program  as perceived by a human onlooker  disintegrates. 
1.1 	how valuable is the presence of symbolic 'reasons'  
only one effect of note was observed: when a task is proposed which already exists on the agenda  then it matters very much whether the task is being suggested for a new reason or not. if the reason is an old  alreadyknown one  then the priority of the task on the agenda shouldn't rise very much. but if it is a brand new reason  then the task's rating should be boosted tremendously. the importance of this effect argues strongly in favor of having symbolic justification of the rank of each task in a priority queue  not just  summarizing  each task's set of reasons by a single number. 
1.1 	what if certain concepts are excised  
as expected  eliminating certain concepts did seal off whole sets of discoveries to the system. for example  excising  quality prevented am from discovering cardinality. one surprising result was that many common concepts get discovered in several ways. for instance  multiplication arose in no fewer than four separate chains of discoveries. 
one demonstration of am's generality  e.g.  that its  activity  heuristics really do apply to any activity  would be to choose some new mathematical field  add some concepts from that domain  and then let am loose to discover new things. only one experiment of this type was actually carried out on the am program. 
twenty 	concepts 	from elementary plane geometry were 
defined for am  including point  line  angle  triangle   quality of points/lines/angles/triangles . no new heuristics were added to am. 
am was able to find examples of all the supplied concepts  
*md to use the character of such empirical data to determine reasonable directions to proceed in its research. am derived the concepts of congruence and similarity of triangles  plus many other well-known concepts. an unusual result was the repeated derivation of the concept of  timberline : this is a predicate on two triangles  which is true iff they share a common vertex and angle  and if their opposite sides are parallel. am also came up with a cute geometric interpretation of goldbach's conjecture: any angle  1 - 1＜  can be approximated to within 1＜ as the sum of two angles each of a prime number of degrees. 
1. 	evaluating the 'am' program 
we may wish to evaluate am using various criteria. some obvious ones  with capsule results  appear below: 
1. by am's ultimate achievements. besides discovering many well-known useful concepts  am discovered some which aren't widely known: maximally-divisible numbers  numbers which can be uniquely represented as the sum of two primes  timberline. 
 . by the character of the differences between initial and final states. am moved all the way from finite set theory to divisibility theory  from sets to numbers to interesting kinds of numbers  from skeletal concepts  none of which had any examples filled in  to completed concepts. 
'1  by the quality of the route am took to accomplish this mass of results. only about half of amy forays were dead-ends  and most of those looked promising initially. 
1. by the character of the human - machine interactions. am was never pushed far along this dimension. 
1. by its informal reasoning abilities. am was able to quickly  guess  the truth value of conjectures  to estimate the overall worth of each new concept  to zero in on plausible things to do each cycle  and to notice glaring analogies  sometimes . 
1. by the results of experiments -- and the fact that experiments could be performed at all on am. 
1. by future implications of this project. only time will tell whether this kind of work will impact on how mathematics is taught  e.g.  explicit teaching of heuristics    on how empirical research is carried out by scientists  on our understanding of such phenomena as discovery  learning  and creativity  etc. 
1. by comparisons to other  similar systems. some of the techniques am uses were pioneered earlier: e.g  prototypical models  gelernter 1   and analogy  evans 1    kling 1 . there have been many attempts to 

specialized 	systems-1: 	lenat 1 

incorporate heuristic knowledge  into a theorem prover  wang 1    guard 1    bledsoe 1    brolz -1    boyor & moore 1b . most of the apparent differences  between them and am vanish upon close examination: the goaldtiven control structure of these systems is a compiled form of am's; rudimentary  focus of attention  mechanism.  i he fact that their overall activity is typically labelled as deductive is a misnomer  since constructing a difficult proof is usually in practice quite inductive . even the character of the inference processes are analogous: the provers typically contain a couple binary inference rules  like modus ponens  which are relatively isky to apply but can yield hip results; am's few  binary  operators have the same characteristics: compose  canonize  logically-combine  disjoin and conjoin . the deep distinctions between am and the  heurstic theorem provers  are these: the underlying motivations  heuristic modelling vs. building tools for problem solving   the richness of the knowledge base  hundreds of heuristics vs. only a few   and the amount of emphasis on formal methods. 
theory formation systems in any field have been few. meta-dendral  buchanan 1b  represents pethaps the best of these. rut even this system is given a fixed set of templates for rules which it wishes to find  and a fixed vocabulary of mass spectral concepts to plug into those hypothesis templates; whereas am selectively enlarges its vocabulary of math concepts. also  am must gather its own data  but this is much easier in math than in organic c hem. 
there has been very little published thought about  discovery  from an algorithmic point of view; even clear thinkers like polya and poincate' treat mathematical ability as a sacred  almost mystic quality  tied to the unconscious. the writings of philosophers and psychologists invariably attempt to examine human performance and belief  which are far more managable than creativity in t1ro. amarel  j 1  notes it may be possible to learn from  theorem finding  programs how to tackle the general task of automating scientific research. am has been one of the first attempts to construct such a program. 
1. 	final conclusions 
-  am is a demonstration that a few hundred general heuristic rules suffice to guide an automated math researcher as it explores and expands a large but incomplete knowledge base of math concepts. am demonstrates that some aspects of creative research can be effectively modelled as heuristic search. 
-  this work has also introduced a control structure based upon an ordered agenda of small research tasks  each with a list of supporting reasons attached. 
-  the main limitation of am was its inability to synthesize powerful new heuristics for the new concepts it defined. 
-  the main successes were the few novel ideas it came up with  the ease with which a new task domain was fed to the system  and - most importantly - the overall rational sequences of behavior am exhibited. 
acknowledgement 
this research was initiated as my ph.d. 	thesis at stanford 
university  and i wish to deeply thank my advisers and committee members: bruce buchanan  paul cohen  edward feigenbaum  cordell green  donald knuth  and allen newell. 
in addition  i gladly acknowledge the ideas i have received in discussions with avra conn and with herbert simon. 

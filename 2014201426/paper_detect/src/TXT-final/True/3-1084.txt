
probabilistic planning with observability restrictions  as formalized for example as partially observable markov decision processes  pomdp   has a wide range of applications  but it is computationally extremely difficult. for pomdps  the most general decision problems about existence of policies satisfying certain properties are undecidable.
we consider a computationally easier form of planning that ignores exact probabilities  and give an algorithm for a class of planning problems with partial observability. we show that the basic backup step in the algorithm is np-complete. then we proceed to give an algorithm for the backup step  and demonstrate how it can be used as a basis of an efficient algorithm for constructing plans.
1 introduction
when the sequence of states that will be visited during plan execution cannot be exactly predicted  for example because of nondeterminism  it is necessary to produce plans that apply different actions depending on how the plan execution has proceeded so far. such plans are called conditional plans.
¡¡construction of conditional plans is particularly difficult when there is no full observability; that is  when during plan execution it is not possible to uniquely determine what the current state of the world is. planning problems having this property are said to be partially observable  and their solution requires that the sets of possible current world states - the belief states - are  implicitly  maintained during plan execution and  implicitly  represented by a plan.
¡¡the earliest work on planning with partial observability was in the framework of partially observable markov decision processes  pomdps   smallwood and sondik  1; kaelbling et al.  1 . planning with pomdps is computationally difficult. for unbounded horizon lengths an unbounded number of probability distributions corresponding to belief states needs to be considered  and finding optimal plans is not in general solvable  madani et al.  1 . a natural approach for easing the computational difficulty of pomdp planning is to consider horizons of a bounded length  mundhenk et

 
this research was partly supported by dfg grant ri 1-1.al.  1 . a second approach which has been pursued with algorithms for conditional planning  weld et al.  1; bonet and geffner  1; bertoli et al.  1   ignores probabilities and hence directly yields a finitary problem. main decision problems related to non-probabilistic planning with partial observability are 1-exp-complete  rintanen  1a .
¡¡a main difference between pomdps and corresponding non-probabilistic problems is that the latter do not use probabilistic notions like success probability or expected cost  and require that a plan must reach the goals with certainty. an implication of success probability 1 is that uncertainty about observations and sensing can be ignored: if an observation is correct with a probability strictly less than 1 then it is as good as no observation at all.
¡¡for this planning problem we present an iterative algorithm that has some resemblance to iterative algorithms for solving pomdps. the algorithm maintains a data structure representing those belief states for which a conditional plan has been shown to exist. initially this data structure represents those belief states consisting of goal states only. then this data structure is repeatedly extended by performing search backwards from the goal belief states.
¡¡the structure of the paper is as follows. section 1 defines the planning problem. sections 1 and 1 respectively describe the formal framework and analyze its properties. section 1 proposes a planning algorithm and section 1 presents experimental results obtained with an implementation of the algorithm. section 1 concludes the paper.
1 the planning problem
in this section we present a formalization of planning in which states are atomic objects without internal structure.
definition 1 a problem instance is hs i o g pi where s is the set of states  i   s is the set of initial states  o is the set of actions o   s ¡Á s  g   s is the set of goal states and p =  c1 ... cn  is a partition of s into classes of observationally indistinguishable states satisfying
s{c1 ... cn} = s and ci ¡É cj =   for all i j such that 1 ¡Ü i   j ¡Ü n.
¡¡making an observation tells which set ci the current state belongs to. distinguishing states in a given ci is not possible.
¡¡an action is a relation between states and their successor states. an action o is applicable in a state s if sos1 for some s1 ¡Ê s. define the image of a set b of states with respect to an action o as imgo b  = {s1 ¡Ê s|s ¡Ê b sos1}. the preimage is preimgo b  = {s ¡Ê s|  1= imgo {s}    b}  consisting of those states from which o is guaranteed to reach a state in b. an action o is deterministic if it is a partial function.
¡¡plans are directed graphs with two kinds of nodes: action nodes and observation nodes.
definition 1 let hs i o g  c1 ... cn i be a problem instance. a plan is a triple hn b li where
  n is a finite set of nodes 
  b ¡Ê n is the initial node 
  l : n ¡ú  o¡Án ¡È1s¡Án is a function that assigns each node an action and a successor node 
or a set of states and successor nodes hc ni ¡Ê 1 ¡Án wherefor some
{c1 ... cn}. in the first case the node is an action node and in the second an observation node.
for all n ¡Ê n and {hc mi hc1 m1i}   l n  the observations c and c1 may not intersect: c ¡É c1 =  .
nodes with l n  =   are terminal.
¡¡we restrict to acyclic plans. acyclicity means that the graph hn ei  where hn n1i ¡Ê e iff l n  = ho n1i for some o or hc n1i ¡Ê l n  for some c  is acyclic.1
¡¡plan execution starts from the initial node b and any of the initial states. for an action node with label ho ni in state s execute o and continue from n and a state in imgo s . for an observation node identify hc ni in the node label so that s ¡Ê c  and then continue from n and s. a plan solves a problem instance if all of its executions terminate in a terminal node and a goal state. execution of an acyclic plan can have at most as many steps as there are nodes in the plan.
1 problem representation
now we introduce the representation for sets of state sets for which a plan for reaching goal states exists.
¡¡in the following example states are viewed as valuations of state variables  and the observational classes correspond to valuations of those state variables that are observable.
example 1 consider the blocks world with the state variables clear x  observable  allowing to observe the topmost block of each stack. with three blocks there are 1 observational classes because there are 1 valuations of {clear a  clear b  clear c } with at least one block clear.
¡¡consider the problem of trying to reach the state in which all blocks are on the table. for each block there is an action for moving it onto the table from wherever it was before. if a block cannot be moved nothing happens. initially we only have the empty plan for the goal states.
a b c
ab  
ac  
bc  ¡¡then we compute the preimages of this set with actions that respectively put the blocks a  b and c onto the table  and split the resulting sets to the different observational classes.

¡¡now for these 1 belief states we have a plan consisting of one or zero actions. but we also have plans for sets of states that are only represented implicitly. these involve branching. for example  we have a plan for the state set consisting of the four states in which respectively all blocks are on the table  a is on c  a is on b  and b is on a. this plan first makes observations and branches  and then executes the plan associated with the belief state obtained in each case. because 1 observational classes each have 1 belief states  there are 1 maximal state sets with a branching plan. from each class only one belief state can be chosen because observations cannot distinguish between belief states in the same class.
¡¡we can find more belief states that have plans by computing preimages of existing belief states. let us choose the belief states in which respectively all blocks are on the table  b is on c  c is on b  and c is on a  and compute their union's preimage with a-onto-table. the preimage intersected with the observational classes yields new belief states: for the class with a and b clear there is a new 1-state belief state covering both previous belief states in the class  and for the class with a clear there is a new 1-state belief state.
 
 
¡¡computation of further preimages yields for each observational class a belief state covering all the states in that class  and hence a plan for every belief state. 
¡¡the above example shows how the exponential number of state sets  corresponding to the cartesian product of the observational classes  considered by rintanen  is represented only implicitly. the algorithm by rintanen  explicitly generates the state sets  the number of which in many cases is very high. with the new representation the computational complexity is shifted from the size of the representation to the time it takes to find a combination of belief states having a useful preimage. this shift is useful for two reasons. first  much of the space complexity  and the time complexity it implies  is traded to time complexity only: the state sets are not represented explicitly  except in the unobservable special case.  second  the succinct representation allows much better control on which belief states to produce  and although finding one new belief state and plan still takes worst-case exponential time  this may be performed by clever algorithms and be further sped up by heuristics.
next we formalize the framework in detail.
definition 1  belief space  let p =  c1 ... cn  be a partition of the set of all states. then a belief space is an n-tuple hg1 ... gni where gi   1ci for all i ¡Ê {1 ... n} and b  1 b1 for all i ¡Ê {1 ... n} and {b b1}   gi.
¡¡notice that in each component of a belief space we only have set-inclusion maximal belief states. the simplest belief spaces are obtained from sets b of states as b b  = h{c1 ¡É b} ... {cn ¡É b}i. a belief space is extended as follows.
definition 1  extension  let p =  c1 ... cn  be the partition of all states  g = hg1 ... gni a belief space  and t a set of states. define g¨’t as hg1d t ¡Éc1  ... gn d t ¡É cn i where the operation d adds the latter set of states to the former set of sets of states and eliminates sets that are not setinclusion maximal  defined as u d v = {r ¡Ê u ¡È {v }|r k for all k ¡Ê u ¡È {v }}.
¡¡a belief space g = hg1 ... gni represents the set of sets of states flat g  = {b1 ¡È ¡¤¡¤¡¤ ¡È bn|bi ¡Ê gi for all i ¡Ê {1 ... n}} and its cardinality is |g1| ¡¤ |g1| ¡¤ ... ¡¤ |gn|.
1 complexity of basic operations
the basic operations on belief spaces needed in planning algorithms are testing the membership of a set of states in a belief space  and finding a set of states whose preimage with respect to an action is not contained in the belief space. next we analyze the complexity of these operations.
theorem 1 for belief spaces g and state sets b  testing whether there is b1 ¡Ê flat g  such that b   b1  and computing g ¨’ b takes polynomial time. proof: idea: a linear number of set-inclusion tests suffices.

¡¡our algorithm for extending belief spaces by computing the preimage of a set of states  lemma 1  uses exhaustive search and runs in worst-case exponential time. this asymptotic worst-case complexity is very likely the best possible because the problem is np-hard. our proof for this fact is a reduction from sat: represent each clause as the set of literals that are not in it  and then a satisfying assignment is a set of literals that is not included in any of the sets  corresponding to the same question about belief spaces.
theorem 1 testing if for belief space g there is r ¡Ê flat g  such that preimgo r  1  r1 for all r1 ¡Ê flat g  is npcomplete. this holds even for deterministic actions o.
proof: membership is easy: for g = hg1 ... gni choose nondeterministically ri ¡Ê gi for every i ¡Ê {1 ... n}  compute r = preimgo r1¡È¡¤¡¤¡¤¡Èrn   and verify that r¡Éci 1  b for some i ¡Ê {1 ... n} and all b ¡Ê gi. each of these steps takes only polynomial time.
¡¡let t = {c1 ... cm} be a set of clauses over propositions a = {a1 ... ak}. we define a belief space based on states {a1 ... ak a 1 ... a k z1 ... zk z 1 ... z k}. the states a  represent negative literals. define
c1i
g=
= o={hai zii|1 ¡Ü i ¡Ü k} ¡È {ha i z ii|1 ¡Ü i ¡Ü k}.¡¡we claim that t is satisfiable if and only if there is b ¡Ê flat g  such that preimgo b  1  b1 for all b1 ¡Ê flat g .
¡¡assume t is satisfiable  that is  there is m such that m |= t. define m1 = {zi|ai ¡Ê a m |= ai} ¡È {z i|ai ¡Ê a m 1|= ai}. now m1   b for some b ¡Ê flat g  because from each class only one of {zi} or {z i} is taken. let m1 = preimgo m1  = {ai ¡Ê a|m |= ai} ¡È {a i|ai ¡Ê a m 1|= ai}. we show that m1  b for all b ¡Ê flat g . take any i ¡Ê {1 ... m}. because m |= ci  there is aj ¡Ê ci ¡É a such that m |= aj  or  aj ¡Ê ci  for which the proof goes similarly.  now zj ¡Ê m1  and therefore.
as there is such an aj  or  aj  for every i ¡Ê {1 ... m}  is not a subset of any  and hence m1  b for all ¡Ê flat   .
¡¡assume there is b ¡Ê flat g  such that d = preimgo b  1  b1 for all b1 ¡Ê flat g . now d is a subset of a¡È{a |a ¡Ê a} with at most one of ai and a i for any i ¡Ê {1 ... k}. define a model m such that for all a ¡Ê a  m |= a if and only if a ¡Ê d. we show that m |= t. take any i ¡Ê {1 ... m}
 corresponding to a clause.  as d 1  b for all b ¡Ê flat g   d 1  c1i. hence there is aj or a j in d c1i. consider the case with aj  a j goes similarly.  as . by definition of m  m |= aj and hence m |= ci. as this holds for all i ¡Ê {1 ... m}  m |= t. 
1 planning algorithms
based on the problem representation in the preceding section  we devise a planning algorithm that repeatedly identifies new belief states  and associated plans  until a plan covering the initial states is found. the algorithm in figure 1 tests for plan existence; further book-keeping is needed for outputting a plan. the size of the plan is proportional to the number of iterations the algorithm performs  and outputting the plan takes polynomial time in the size of the plan. the algorithm uses the subprocedure findnew  figure 1  for extending the belief space  this is the np-hard subproblem from theorem 1 . our implementation of the subprocedure orders sets f1 ... fm by cardinality in a decreasing order: bigger belief states are tried first. we also use a simple pruning technique for deterministic actions o: if preimgo fi    preimgo fj  for some i and j such that i   j  then we may ignore fi.
procedure findnew o a f h ;
if f = hi and preimgo a  1  b for all b ¡Ê flat h 
then return a;
if f = hi then return  ;
f is h{f1 ... fm} f1 ... fki for some k ¡Ý 1;
for i := 1 to m do
b := findnew o a ¡È fi hf1 ... fki h ;
if b 1=   then return b;
end;
return  
figure 1: algorithm for finding new belief states
procedure plan i o g ; h := b g ;
progress := true;
while progress and i 1  i1 for all i1 ¡Ê flat h  do progress := false;
for each o ¡Ê o do
b := findnew o   h h ;
if b 1=   then
begin h := h ¨’ preimgo b ;
¡¡progress := true; end;
end;
end;
if i   i1 for some i1 ¡Ê flat h  then return true
else return false;
figure 1: algorithm for planning with partial observability
lemma 1 let h be a belief space and o an action. the procedure call findnew o   f h  returns a set b1 of states such that b1 = preimgo b  for some b ¡Ê flat f  and b1  b1 for all b1 ¡Ê flat h   and if no such belief state exists it returns  .
proof: sketch: the procedure goes through the elements hb1 ... bni of f1 ¡Á ¡¤¡¤¡¤ ¡Á fn and tests whether preimgo b1 ¡È ¡¤¡¤¡¤ ¡È bn  is in h. the sets b1 ¡È ¡¤¡¤¡¤ ¡È bn are the elements of flat f . the traversal through f1 ¡Á ¡¤¡¤¡¤ ¡Á fn is by generating a search tree with elements of f1 as children of the root node  elements of f1 as children of every child of the root node  and so on  and testing whether the preimage is in h. the second parameter of the procedure represents the state set constructed so far from the belief space  the third parameter is the remaining belief space  and the last parameter is the belief space that is to be extended  that is  the new belief state may not belong to it.	
¡¡the correctness proof of the procedure plan consists of the following lemma and theorems. the first lemma simply says that extending a belief space h is monotonic in the sense that the members of flat h  can only become bigger.
lemma 1 assume t is any set of states and b ¡Ê flat h . then there is b1 ¡Ê flat h ¨’ t  so that b   b1.
¡¡the second lemma says that if we have belief states in different observational classes such that each is included in a belief state of a belief space h  then there is a set in flat h  that includes all these belief states.
lemma 1 let b1 ... bn be sets of states so that for every i ¡Ê {1 ... n} there is bi1 ¡Ê flat h  such that bi   bi1  and there is no observational class c such that for some {i j}   {1 ... n} both i 1= j and bi¡Éc 1=   and bj ¡Éc 1=  . then there is b1 ¡Ê flat h  such that b1 ¡È ¡¤¡¤¡¤ ¡È bn   b1.
¡¡the proof of the next theorem shows how the algorithm is capable of finding any plan by constructing it bottom up starting from the leaf nodes. the construction is based on first assigning a belief state to each node in the plan  and then showing that the algorithm reaches that belief state from the goal states by repeated computation of preimages.
theorem 1 whenever there exists a finite acyclic plan for a problem instance  the algorithm in figure 1 returns true.
proof: assume there is a plan hn b li for a problem instance hs i o g pi. label all nodes of the plan as follows. the root node b is labeled with i  that is  z b  = i. when all parent nodes of a node n have a label  we assign a label to n. let l n1  = ho1 ni ... l nm  = hom ni for action nodes n1 ... nm that have n as the child node  and let
{hc1 ni ...} ... l n1k  = {hck ni ...} for all observation nodes n1 ... n1k with n as one of the children. then z n  = imgo1 z n1  ¡È¡¤¡¤¡¤¡Èimgom z nm  ¡È z n1 ¡Éc1 ¡È¡¤¡¤¡¤¡È  z n1k ¡Éck . if the above labeling does not assign anything to a node n  then assign z n  =  . each node is labeled with those states that are possible in that node on some execution.
¡¡we show that if plans for z n1  ... z nk  exist  where n1 ... nk are children of a node n in a possible plan  then the algorithm determines that a plan for z n  exists as well.
¡¡induction hypothesis: for each plan node n such that all paths to a terminal node have length i or less  its label b = z n  is a subset of some b1 ¡Ê flat h  where h is the value of the program variable h after the while loop exits and h could not be extended further.
¡¡base case i = 1: terminal nodes of the plan are labeled with subsets of g. by lemma 1  there is g1 such that g   g1 and g1 ¡Ê flat h  because initially h = b g  and thereafter it was repeatedly extended.
¡¡inductive case i ¡Ý 1: let n be a plan node. by the induction hypothesis for all children n1 of n  z n1    b for some b ¡Ê flat h .
¡¡if n is an observation node with children n1 ... nk and respective observations c1 ... ck  then z n  ¡É c1  ...  z n  ¡É ck all occupy disjoint observational classes and superset of z n  ¡É ci for every i ¡Ê {1 ... k} is in flat h . hence by lemma 1 z n    b for some b ¡Ê flat h .
¡¡if n is an action node with action o and child node n1  then imgo z n     z n1   and by the induction hypothesis z n1    b1 for some b1 ¡Ê flat h . we have to show that z n    b1 for some b1 ¡Ê flat h . assume that there is no such b1. but now by lemma 1 findnew o   h h  would return b1 such that preimgo b1  1  b for all b ¡Ê flat h   and the while loop could not have exited with h  contrary to our assumption about h.	
theorem 1 let ¦° = hs i o g pi be a problem instance. if plan i o g  returns true  then ¦° has a solution plan.
proof: let h1 h1 ... be the sequence of belief spaces h produced by the algorithm. we show that for all i ¡Ý 1  for every b ¡Ê flat hi  there is a plan that reaches g.
¡¡induction hypothesis: hi contains only such state sets b ¡Ê flat hi  for which a plan reaching g exists.
¡¡base case i = 1: h1 = b g   and the only state set in h1 is g. the empty plan reaches g from g.
¡¡inductive case i ¡Ý 1: hi+1 is obtained as hi¨’preimgo b  where b = findnew o   hi hi .
¡¡because by lemma 1 b ¡Ê flat hi   by induction hypothesis there is a plan ¦Ð for b. the plan that executes o followed by ¦Ð reaches g from preimgo b .
¡¡let b be any member of flat hi+1 . we show that for b there is a plan for reaching g. the plan for b starts by a
¡¡branch1. we show that for every possible observation  corresponding to one observational class  there is a plan that reaches g. let cj be the jth observational class. when observing cj  the current state is in bj = b ¡É cj. now for bj there is bj1 ¡Ê hi+1 j with bj   bj1 where hi+1 j is the jth component of hi+1. now by induction hypothesis there is a plan for bj1 if bj1 ¡Ê hi j  and if bj1 ¡Ê hi+1 j hi j  then for the branch corresponding to cj we use the plan for preimgo b   as bj1 must be preimgo b  ¡É cj. 
¡¡until now we have used only one partition of the state space to observational classes. however  it is relatively straightforward to generalize the above definitions and algorithms to the case in which several partitions are used  each for a different set of actions. this means that the possible observations depend on the action that has last been taken.
1 experimentation with an implementation
we have implemented the algorithm from the previous section and call the resulting planning system bbsp. the only heuristic is the one described in the preceding sections: findnew chooses bigger belief states first. the implementation is based on representing sets of states and actions as bdds  burch et al.  1 . there is a small improvement in the belief space representation with bdds: all components of a belief space consisting of one belief state only are represented by one bdd.
¡¡we carried out a comparison to the mbp planner  bertoli et al.  1  which uses forward-search together with some heuristics for restricting branching. mbp starts search from the initial states  and proceeds forward by taking actions  leading to another set of states  or by using observations to split the current state set to several smaller ones. different choices of actions and observations induce a search tree.
runtime in secondsiterationsproblem|s|mbpbbspbbspbtcs1111btcs1111btcs1111btcs1111btcs1111medical1111medical1111medical1111medical1  1 m11medical1  1 m11emptyroom1111emptyroom1111emptyroom1111emptyroom1111emptyroom1111ring1111ring1111ring1111ring1111ring1111ring1111ring1  1 m11ring1  1 m11bw1fo1.1.1bw1fo1  1 m11bw1fo1  1 m11bw1fo1  1 m11bw1pfo1.1.1bw1pfo1.1.1bw1pfo1  1 m11bw1pfo1  1 m11bw1po1.1.1bw1po1.1.1bw1po1.1.1bw1po1.1.1table 1: runtime comparison bbsp vs. mbp
¡¡some of the mbp runtimes given by bertoli et al.  are much better than given by us in this paper  specifically on the medical and ring problems  because the branching heuristic used by bertoli et al. works well on their formulations of the benchmarks: branch only on one observable state variable if possible. we used a slightly different formulation where one many-valued observation is replaced by a small number of boolean observations.
¡¡runtimes of the planners are given in table 1. the runs were on a 1 mhz sun sparcstation under solaris. the problem instances are the same as in  rintanen  1  where mbp was shown in almost all cases to be faster than gpt  bonet and geffner  1  and much faster than the yka¡§ planner  rintanen  1  on most of the problems except the blocks worlds problems with full or almost full observability. btcs is the bomb-in-the-toilet problem with sensing. in the medical problems patients are cured by performing tests and medicating. the emptyroom problems are about navigating
from an unknown location to the center of the room. the ring problems are about closing and locking all the windows of a building consisting of a cycle of rooms. bw is the blocks world with increasing number of blocks with the goal to arrange them into one stack from any initial configuration under different degrees of observability: fo is full observability  pfo is with the on relation observable  and po is partial observability  clear and ontable are observable . the problems are solvable under partial observability because moving a block only requires that it is clear and a move action is applicable no matter where the block is.
¡¡the rightmost column gives the number of iterations bbsp needs for finding a plan. mbp runtimes in some cases grow faster because it performs more search. this is most obvious in some of the problems with more observations as the number of possible ways of branching becomes astronomical. in our algorithm  the dynamic programming character of plan generation better avoids this explosion in the number of belief states to be considered.
¡¡in forward search there is an inherent conflict between a  keeping the size of plans and search trees down by not branching on all possible observations and b  branching enough to be able to find a plan. in mbp a number of heuristics is used for controlling branching  and for these benchmarks the heuristics in most cases work very well. for backward plan construction no similar conflict exists  and plan construction by a form of dynamic programming leads to effective reuse of already constructed belief states and plans  and there is no separate problem of deciding how to branch.
1 conclusions and future work
we have presented a novel framework for non-probabilistic conditional planning with partial observability  proposed a backward search algorithm for finding plans  and shown that the basic backup step of the algorithm is np-hard. we have also demonstrated how an efficient implementation of the backup step leads to competitive planning.
¡¡for future work we propose considering the problem of finding plans with quality guarantees  for example  plans with optimal execution length  as well as planning under more general infinite-horizon executions. also  the use of more sophisticated heuristics for driving the planning algorithm should be considered  for example the ones proposed by rintanen  1b  generalized to partially observable problems.

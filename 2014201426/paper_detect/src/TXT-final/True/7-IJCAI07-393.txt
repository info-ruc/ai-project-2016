
compiling bayesian networks has proven an effective approach for inference that can utilize both global and local network structure. in this paper  we define a new method of compiling based on variable elimination  ve  and algebraic decision diagrams  adds . the approach is important for the following reasons. first  it exploits local structure much more effectively than previous techniques based on ve. second  the approach allows any of the many ve variants to compute answers to multiple queries simultaneously. third  the approach makes a large body of research into more structured representations of factors relevant in many more circumstances than it has been previously. finally  experimental results demonstrate that ve can exploit local structure as effectively as state-of-the-art algorithms based on conditioning on the networks considered  and can sometimes lead to much faster compilation times.
1 introduction
variable elimination  zhang and poole  1; dechter  1   ve  is a well-known algorithm for answering probabilistic queries with respect to a bayesian network. the algorithm runs in time and space exponential in the treewidth of the network. advantages of ve include its generality and simplicity. in this paper  we consider two aspects of ve. the first is how to effectively utilize local structure in the form of determinism  jensen and andersen  1  and context-specific independence  boutilier et al.  1  to perform inference more efficiently. the second consideration is how to answer multiple queries simultaneously. for example  given particular evidence  we would like to be able to simultaneously compute probability of evidence and a posterior marginal on each network variable. and we would like to be able to repeat this process for many different evidence sets.
¡¡many proposals have been extended to utilize local structure in the context of ve. although the standard version of the algorithm uses tables to represent factors  the algorithm can sometimes run more efficiently by using a more structured representation like adds  r.i. bahar et al.  1   affine adds  sanner and mcallester  1   representations composed of confactors  poole and zhang  1   sparse representations  larkin and dechter  1   and a collection of others. such a representation makes use of local structure to skip certain arithmetic operations and to represent factors more compactly. however  the effectiveness of these approaches has been sometimes limited in practice  because the overhead they incur may very well outweigh any gains.
¡¡there has been less work to answer multiple queries simultaneously using ve as is done by the jointree algorithm  jensen et al.  1; lauritzen and spiegelhalter  1 ; but see  cozman  1  for an exception. theoretical results in  darwiche  1  demonstrate that by keeping a trace  one can use ve as a basis for compilation. this algorithm  which we will refer to as tabular compilation  will compile a bayesian network offline into an arithmetic circuit  ac . tabular compilation runs in time and space exponential in treewidth; the resulting ac has size exponential in treewidth; and once offline compilation is complete  the ac can be used online to answer many queries simultaneously in time linear in its size. however  the applicability of this approach is limited  because tabular compilation provides no practical advantage over jointree.
¡¡an important observation is that when compiling using ve  we need not use tables  but can instead use one of the more structured representations of factors. this observation is seemingly innocent  but it has two critical implications. first  the usual cost incurred when using structured representations gets pushed into the offline phase  where it can be afforded. second  the usual advantage realized when using more structured representations means that the size of the resulting ac will not necessarily be exponential in treewidth. the smaller ac translates directly into more efficient online inference  where efficiency matters most. we see that the proposed approach is important for four key reasons. first  it exploits local structure much more effectively than previous techniques based on ve. second  the approach allows any of the many ve variants to compute answers to multiple queries simultaneously. third  the approach makes a large body of research into more structured representations of factors rele-
vant in many more circumstances than it has been previously. finally  experimental results demonstrate that on the considered networks  ve can exploit local structure as effectively as state-of-the-art algorithms based on conditioning as applied to a logical encoding of the networks  and can sometimes lead to much faster compilation times.
¡¡to demonstrate these ideas  we propose a new method of compiling based on ve and algebraic decision diagrams  adds . we will refer to this method of compiling as add compilation. it is well known that adds can represent the initial conditional probability distributions  factors  of a bayesian network more compactly than tables. however  it is not clear whether adds will retain this advantage when producing intermediate factors during the elimination process  especially in the process of compilation which involves no evidence. note that the more evidence we have  the smaller the adds for intermediate factors.
¡¡experimental results will demonstrate several important points with respect to add compilation. the first point deals with ac sizes. add elimination  no compilation  can outperform tabular elimination  no compilation  when there are massive amounts of local structure  but can dramatically underperform tabular elimination otherwise. however  add compilation produces acs that are much smaller than those produced by tabular compilation  even in many cases where there are lesser amounts of local structure. second  because of the smaller ac size  online inference time is capable of outperforming jointree by orders of magnitude. finally  add compilation can be much faster in some cases than a state-of- the-art compilation technique  which reduces the problem to logical inference  darwiche  1 .
¡¡this paper is organized as follows. we begin in section 1 by reviewing ve  elimination using adds  and compilation into acs. next  section 1 shows how a trace can be kept during elimination employing adds to compile a network into an ac. we then discuss in section 1 implications for compiling using structured representations of factors. we present experimental results in section 1 and conclude in section 1.
1 background
in this section  we briefly review ve  elimination using adds  and compilation into acs.
1 variable elimination
variable elimination is a standard algorithm for computing probability of evidence with respect to a given a bayesian network  zhang and poole  1; dechter  1 . for space reasons  we mention only a few points with regard to this algorithm. first  the algorithm acts on a set of factors. each factor involves a set of variables and maps instantiations of those variables to real-numbers. the initial set of factors are the network's conditional probability distributions  usually tables . elimination is driven by an ordering on the variables called an elimination order. during the algorithm  two factor operations are performed many times: factors are multiplied and a variable is summed out of a factor. these factor operations reduce to performing many multiplication and addition operations on real-numbers. although tables are the most common representation for factors  any representation that supports multiplication and summing-out can be used.

xyzf . x1y1z1.1x1y1z1.1x1y1z1.1x1y1z1.1x1y1z1.1x1y1z1.1x1y1z1.1x1y1z1.1figure 1: an add over variables x y z and the corresponding table it represents. dotted edges point to low- children and solid edges point to high-children.
1 elimination using adds
an add is a graph representation of a function that maps instantiations of boolean variables to real-numbers  r.i. bahar et al.  1 . figure 1 depicts an add and the corresponding table  function  it represents. in the worst case  an add has the same space complexity as a table representing the same function. moreover  the factor operations of multiplication and summing-out are implemented on adds in polynomial time. there are four points that are important with respect to adds. first  because multiplication and summing-out are available for adds  we can use adds during ve instead of tables. second  because adds can leverage local structure  an add can be much smaller than the corresponding table. third  for the same reason  when applied to adds  the factor operations of multiplication and summing-out can result in far fewer arithmetic operations on numbers than the same factor operations acting on tables. finally  the constants involved in using adds are much larger than those involved in using tables  so much so that elimination using adds will often take much longer than elimination using tables  even when the add performs fewer arithmetic operations on numbers  and so much so that we may run out of memory when using adds  even in cases where tabular elimination does not. we will discuss later how we can deal with many-valued variables within an add.
1 compiling into acs
the notion of using arithmetic circuits  acs  to perform probabilistic inference was introduced in  darwiche  1; 1 . with each bayesian network  we associate a corresponding multi-linear function  mlf  that computes the probability of evidence. for example  the network in figure 1-in which variables a and b are boolean  and c has three values-induces the following mlf: ¦Ëa1¦Ëb1¦Ëc1¦Èa1¦Èb1¦Èc1|a1 b1 + ¦Ëa1¦Ëb1¦Ëc1¦Èa1¦Èb1¦Èc1|a1 b1+ ... ¦Ëa1¦Ëb1¦Ëc1¦Èa1¦Èb1¦Èc1|a1 b1 + ¦Ëa1¦Ëb1¦Ëc1¦Èa1¦Èb1¦Èc1|a1 b1
¡¡the terms in the mlf are in one-to-one correspondence with the rows of the network's joint distribution. assume that all indicator variables ¦Ëx have value 1 and all parameter variables ¦Èx|u have value pr x|u . each term will then be a

figure 1: a bayesian network and a corresponding ac.
product of probabilities which evaluates to the probability of the corresponding row from the joint. the mlf will add all probabilities from the joint  for a sum of 1. to compute the probability pr e  of evidence e  we need a way to exclude certain terms from the sum. this removal of terms is accomplished by carefully setting certain indicators to 1 instead of 1  according to the evidence.
¡¡the fact that a network's mlf computes the probability of evidence is interesting  but the network mlf has exponential size. however  if we can factor the mlf into something small enough to fit within memory  then we can compute pr e  in time that is linear in the size of the factorization. the factorization will take the form of an ac  which is a rooted dag  directed acyclic graph   where an internal node represents the sum or product of its children  and a leaf represents a constant or variable. in this context  those variables will be indicator and parameter variables. an example ac is depicted in figure 1. we refer to this process of producing an ac from a network as compiling the network.
¡¡once we have an ac for a network  we can compute pr e  by assigning appropriate values to leaves and then computing a value for each internal node in bottom-up fashion. the value for the root is then the answer to the query. we can also compute a posterior marginal for each variable in the network by performing a second downward pass  darwiche  1 . hence  many queries can be computed simultaneously in time linear in the size of the ac. another main point is that this process may then be repeated for as many evidence sets as desired  without recompiling.
1 add compilation
we have seen how adds can be used in place of tables during ve and how compilation produces an ac from a network. in this section  we combine the two methods to compile an ac using a ve algorithm that employs adds to represent factors. the core technique behind our approach is to work with adds whose sinks point to acs  their roots  instead of pointing to constants. we will refer to these adds as symbolic adds. given a bayesian network  we convert each conditional probability table  cpt  into a symbolic add called a cpt add. to do so  we first convert the cpt into a normal add and then replace each constant n within a sink by a pointer to an ac consisting of a single node labeled with conalgorithm 1 multiply ¦Á1 : symadd ¦Á1 : symadd : returns symadd.

1: swap ¦Á1 and ¦Á1 if pos ¦Á1    pos ¦Á1 
1: then
1:	return cache ¦Á1 ¦Á1 
1: else if ¦Á1 and ¦Á1 are leaf nodes then
1:	¦Á ¡û new add leaf node
1:	ac ¦Á  ¡û new ac   node with children ac ¦Á1  and ac ¦Á1 
1: else if pos ¦Á1  = pos ¦Á1  then
1:	new internal node
1:	 ¦Á  ¡û	 ¦Á1 
1:	lo ¦Á  ¡û multiply lo ¦Á1  lo ¦Á1  
1:	hi ¦Á  ¡û multiply hi ¦Á1  hi ¦Á1  
1: else
1:	¦Á ¡û new internal node
1:	v ar ¦Á  ¡û v ar ¦Á1 
1:	lo ¦Á  ¡û multiply lo ¦Á1  ¦Á1 
1:	hi ¦Á  ¡û multiply hi ¦Á1  ¦Á1 
1: end if
1: cache ¦Á1 ¦Á1  ¡û ¦Á 1: return ¦Á

stant n. for each variable x in the network  we also construct an indicator add  which acts as a placeholder for evidence to be entered during the online inference phase. assuming that variable x is binary with values x1 and x1  the indicator add for x will consist of one internal node  labeled with variable x  and having two sink children. the child corresponding to x1 x1  will be a sink labeled with a pointer to a single-node ac that is itself labeled with indicator ¦Ëx1 ¦Ëx1 . figure 1 a  shows a simple bayesian network and figure 1 b  shows the corresponding symbolic adds.

xpr x x1.1x1.1
xypr y|x x1y1.1x1y1.1x1y1.1x1y1.1	for x	for y	add for x	add for y
	 a 	 b 
figure 1:  a  a simple bayesian network and  b  symbolic adds representing the network.¡¡working with symbolic adds requires a modification to the standard add operations  but in a minimal way. we first point out that add operations are typically implemented recursively  reducing an operation over two adds into operations over smaller adds  until we reach boundary conditions: adds that correspond to sinks. it is these boundary conditions that need to be modified in order to produce symbolic add operations. for example  algorithm 1 specifies how to multiply two symbolic adds. when applied to an internal add node  the functions pos  lo  and hi return the position of the variable labeling the node in the add variable order  the low-child  corresponding to false   and the high-child  corresponding to true   respectively. when applied to an add sink  the functions pos and ac return ¡Þ and a pointer to the ac that labels the sink  respectively. finally  cache is the standard computed table used in add operations. the main observation is that the algorithm is identical to that for multiplying normal adds  see  r.i. bahar et al.  1    except for line 1. when multiplying normal adds  this line would label the newly created sink with a constant that is the product of the constants labeling ¦Á1 and ¦Á1. when multiplying symbolic adds  we instead label the new sink with a pointer to an ac that represents an analogous multiplication. this ac will consist of a new multiply node having children that are the acs pointed to by ¦Á1 and ¦Á1. the algorithm for summing-out a variable from a symbolic add is constructed from the algorithm for summing-out a variable from a normal algorithm 1 compile n : bayesian network : returns ac.
1: ¦· ¡û the set of indicator and cpt adds for n
1: ¦Ð ¡û ordering on the variables  ¦Ð i  is ith variable in order 
1: for i in 1... number of variables in n do
1: mentions variable ¦Ð i } 1: ¦· ¡û  ¦·   p  ¡È{¦²¦Ð i  ¦Á¡Êp ¦Á}
1: ¡û ¦Á¡Ê¦· ¦Á
1: return ac ¦Â 

add in an analogous way  by modifying the code that labels newly created sinks. in this case  instead of labeling with a constant representing a sum  we instead label with a pointer to an new addition node.
¡¡we now describe the compilation process in algorithm 1. line 1 begins by representing the bayesian network using symbolic adds as described previously. we then generate an ordering on the variables using a minfill heuristic on line 1. lines 1 perform variable elimination in the standard way  using the multiply and sum-out operations of symbolic adds. afterward  we are left with a trivial symbolic add: a sink labeled with a pointer to an ac. this ac is a factorization of the network mlf and a compilation of the given network! each internal node of the ac is labeled with a multiplication or addition operation  and each leaf is labeled with a constant or an indicator variable. the ac represents a history or trace of all arithmetic operations performed during the elimination process.
¡¡for the above procedure to scale and produce the results we report later  it has to be augmented by a number of key techniques that we describe next.
¡¡add variable order: adds require a fixed variable order which is independent of the elimination order we have discussed. for that  we use the reverse order used in the elimination process. this ensures that when a variable is eliminated from an add  it appears at the bottom of the add. the sum- out operation on adds is known to be much more efficient when the summed out variable appears at the bottom.
¡¡unique table: we maintain a cache  called a unique table in the add literature  to ensure that we do not generate redundant ac nodes. each entry is an ac node that has been constructed  indexed the node's label and its children. before we ever construct a new ac node  we first consult the unique table to see if a similar node has been constructed before. if this is the case  we simply point to the existing node instead of constructing a duplicate node. as is standard practice  we also use a unique table for the add nodes.
¡¡multi-valued variables: when a network variable x has more than two values  we define its add variables as follows. for each value xi of x  we create add variable vxi. we translate instantiations of x in the straightforward way. for example  we translate x = x1 as vx1 = true and vxi = false for. moreover  we construct an add over vxi which enforces the constraint that exactly one vxi can be true. we multiply this add into every cpt and indicator add that mentions x. finally  when eliminating  summing-out  a multi-valued variable x  we sum out all corresponding add variables vxi simultaneously.
¡¡converting a cpt into an add: the straightforward way to construct the add of a cpt is to construct an add for each row of the cpt and then add the resulting adds. this method was extremely inefficient for large cpts  over a thousand parameters . instead  we construct a tree-structured add whose terminals correspond to the cpt rows  and then use the standard reduce operation of adds to produce a dag structure.
¡¡simplifications: in certain cases  simplifications are possible. for example  when multiplying two add nodes  if one of the nodes ¦Á is a sink labeled with a pointer to an ac node which which is itself labeled constant 1  then we can simply return ¦Á without doing more work. similar simplifications exist for constant 1 and for the summing-out operation.
¡¡figure 1 depicts the elimination process when applied to the symbolic adds of figure 1 b  using elimination order y x. the first step is to multiply the set of symbolic adds involving y   which consists of y 's cpt add and y 's indicator add. figure 1 a  shows the result. observe that each add sink points to an ac that represents the multiplication of two acs  one pointed to by a sink from y 's cpt add and one pointed to by a sink from y 's indicator add. also observe that when one of the acs involved in the multiplication is a sink labeled with 1 or 1  the resulting ac is simplified. figure 1 b  next shows the result of summing-out y from the symbolic add in figure 1 a . here  each add node labeled with y and its children have been replaced with a sink which points to an addition node. a simplification has also occurred. figure 1 c  shows the result of multiplying symbolic adds involving variable x in two steps: first figure 1 b  by x's indicator add and then the result by x's cpt add. finally  figure 1 d  shows the result of summing-out x from figure 1 c . at this point  since there is only one remaining symbolic add  we have our compilation.
1 implications
there has been much research into using alternatives to tabular representations of factors in ve. the motivation for such research is that tabular elimination makes use only of global network structure  its topology . it may therefore miss opportunities afforded by local structure to make inference more efficient. structured representations of factors typically exploit local structure to lessen the space requirements required for inference and to skip arithmetic operations on numbers  multiplications and additions  required for inference. in some cases  structured representations of factors have been successful in performing inference when tabular elimination runs out of memory  and in some cases  structured representations allow for faster inference than tabular elimination. however  the time and space overhead involved in using more structured representations of factors may very well outweigh the benefits. this is particularly true when there are not excessive amounts of local structure present in the network. table 1 demonstrates the performance of elimination  no compilation  using both tables and adds applied to the set of networks we will be considering later in the paper. all add operations were performed using the publicly available cudd add package  http://vlsi.colorado.edu/¡«fabio/cudd . we see that in only two cases does add elimination outperform tabular elimination. both of the networks involved  bm-1 and mm-1-1  contain massive amounts of determinism. in the remaining cases  add elimination is actually slower than tabular elimination  often by an order of magnitude or more. the large number of examples where structured representations of factors are slower than tabular elimination have limited their applicability.
¡¡the main observation behind this paper is that even when elimination using a more structured representation of factors is slower than tabular elimination  structured representations become very powerful in the context of compilation. compilation is an offline process  and so extra time can be afforded. in fact  the combination of structured representations with compilation is ideal  since the very purpose of compilation is to spend time offline in an effort to identify opportunities for savings that can be used repeatedly during online inference. hence  in the context of compilation  the disadvantages of using structured representations are much less severe  virtually disappearing  and the advantages are retained.1 although
tabularaddnetworktime  ms time  ms improvementalarm11barley1 1.1bm-111.1diabetes1 1.1hailfinder11link111mm-1-1 11mildew1 1.1munin111munin111munin111munin111pathfinder1 1.1pigs11st-111tcc1f11water1 1.1table 1: time to perform ve  no compilation  using tables and using adds.
overhead is incurred during the offline phase  each arithmetic operation saved makes the size of the resulting ac smaller  yielding more efficient online inference. these observations make research into structured representations of factors applicable in many more circumstances than it has been previously. another major advantage of adding compilation to elimination is that one can compute online answers to many queries simultaneously and very quickly as is done by the jointree algorithm; see  darwiche  1  for details.
1 experimental results

	 a 	 b 	 c 	 d 
figure 1: symbolic adds produced after  a  multiplying factors involving y    b  summing-out y    c  multiplying factorsin this section  we present experimental results of applying add compilation and compare add compilation to tabular compilation  ace compilation  and jointree. all add operations were performed using the cudd add package  http://vlsi.colorado.edu/¡«fabio/cudd   modified to work with symbolic adds. ace  http://reasoning.cs.ucla.edu/ace  is a state-of-the-art compiler that encodes bayesian networks as logical knowledge bases and then applies conditioning to the result. ace has been shown to be extremely effective on networks having large amounts of local structure  chavira et al.  may 1; 1   able to compile many networks with treewidths in excess of one-hundred. ace was also shown in  chavira and darwiche  1  to perform online inference orders of magnitude more efficiently than jointree when applied to networks having treewidth small enough for jointree to work and having lesser amounts of local structure. on these networks  ace online inference is very efficient  but some compile times are in excess of one thousand seconds. the networks with which we experimented are a superset of these networks from  chavira and darwiche  1 . experiments ran on a 1ghz core duo processor with 1gb of memory  using the networks in table 1 to make the experiments as fair as possible  for each network  we first involving x  and  d  summing-out x.
generated an elimination order ¦Ð  and all experiments were performed with respect to ¦Ð. the second column in table 1 shows the maximum cluster size of a jointree generated from ¦Ð  which gives an indication of difficulty with respect to structure-based methods. we compiled each network using jointree  ace 1  add ve  and tabular ve  in each case driven by ¦Ð. we evaluate a compilation algorithm based on compilation time  compilation size  and online inference time. we first discuss compilation time  which includes reading the network  compiling  and writing the ac to disk.
¡¡columns 1 compare ace compilation time to add compilation time. we see that on these networks  neither algorithm dominates the other. our experiments show that ace compilation often ran faster than add compilation in the following cases: when the networks had very low treewdith  alarm  hailfinder  tcc1f  and when the networks had massive amounts of determinism  bm-1  mm-1-1  and st-1 . we also found ace compilation times to be significantly lower on networks  not shown  having very high treewidth  e.g.  the blockmap and mastermind networks from  chavira et al.  may 1    many of which add compilation could not handle. however  add compilation times are significantly more efficient on precisely those networks on which ace has trouble. in particular  networks with treewidths in the range 1 having lesser amounts of local structure  barley  diabetes  link  mildew  and the munin networks . on these types of networks  ace compilation can require thousands of seconds and add compilation can run an order of magnitude faster. perhaps the most striking example is barley  on which ace required over two hours while add compilation required a little over two minutes. ace compilation also ran out of memory on link  which compiled successfully using adds.
¡¡we next discuss compilation sizes  which we measure using the number of edges of the ac produced. the ac size is important  because it determines the time and space requirements for online inference  which is linear in this size. the ac size also provides the main indicator for the extent to which local structure was exploited. ac sizes produced using adds and using ace turned out to be very close  showing that both methods seem to exploit local structure to a similar extent. columns 1 compare sizes of acs that would be produced using tabular compilation to those produced using add compilation  the size of the ac embedded in a jointree  park and darwiche  1  would be about equal to the size of the ac produced by tabular compilation . add compilation sizes can be multiple orders of magnitude smaller than those produced by tabular compilation. the difference is most pronounced on networks having massive amounts of local structure  bm-1  mm-1-1  st-1   but is also striking in some other cases. for example  on munin1  munin1  pathfinder  and water  add compilation sizes were over 1  1  1  and 1 times smaller  respectively. we see here the massive advantage of utilizing more structured representations of factors when compiling via ve.
¡¡because acs produced using ace were about the same size as those produced using adds  online inference times for the two compilation algorithms were also very similar. the last three columns in table 1 compare online inference using add compilations and jointree  tabular compilation online times would be about equal to jointree online times . for each network  we generated 1 sets of evidence. for each evidence set  we then computed probability of evidence and a posterior marginal on each network variable. note that answering these queries would be very difficult using standard ve  without compilation   because of the large number of queries involved. each reported number is the sum of times for all 1 evidence sets. here we see an online time advantage to add compilation about equal to its large space advantage over tabular compilation  which makes sense  since neither tabular compilation nor jointree make use of local structure. once again we see the massive advantage that can be achieved by utilizing structured representations of factors during compilation.
1 conclusion
in this paper  we combined three ideas: variable elimination  compilation  and structured representations of factors. the result is an algorithm that retains the advantages of these approaches while minimizing their shortcomings. the approach is important for the following reasons:  1  it utilizes local
table 1: comparing ace compilation times to add compilation times  tabular compilation size to add compilation size  and jointree online inference time to add online inference time. imp. stands for factor of improvement.
networkmaxoffline compile time  s ac edge countonline inference time  ms 
clust.ace
add-veimp.tabular-ve
add-veimp.jointreeadd-veimp.alarm111111111barley11.1.1.1 11 1.1 1 1.1bm-111111 1 1.1 11diabetes11.1.1.1 11 1.1 1 1.1hailfinder111111111link1-1-1 1 11111mildew11.1.1.1 11 1.1 1 1.1mm-1-1.1.1.1.1 11111.1munin1.1 1111 11 1.1 1 1.1munin1.1.1.1.1 11 1.1 1 1.1munin1.1.1.1.1 11 1.1 1 1.1munin1.1.1.1.1 11 1.1 1 1.1pathfinder111111111.1pigs11111 1 11111st-111111 1 1.1 11tcc1f111111111water11111 1 1.1 11structure more effectively than previous approaches based on ve;  1  it allows any variant of ve to answer multiple queries simultaneously;  1  it makes a large body of research into structured representations of factors more relevant than it had been previously; and  1  it demonstrates that variable elimination can utilize local structure as effectively as state-of- the-art approaches based on conditioning  applied to a logical encoding of the bayesian network   and can sometimes lead to much faster compilation times.

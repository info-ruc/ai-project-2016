 
this paper presents an analysis of static and dynamic organizational structures for naturally distributed  homogeneous  cooperative problem solving environments  exemplified by distributed sensor networks. we first show how the performance of any static organization can be statistically described  and then show under what conditions dynamic organizations do better and worse than static ones. finally  we show how the variance in the agents' performance leads to uncertainty about whether a dynamic organization will perform better than a static one given only agent a priori expectations. in these cases  we show when meta-level communication about the actual state of problem solving will be useful to agents in constructing a dynamic organizational structure that outperforms a static one. viewed in its entirety  this paper also presents a methodology for answering questions about the design of distributed problem solving systems by analysis and simulation of the characteristics of a complex environment rather than by relying on single-instance examples. 
1 	introduction 
organizational theorists have long held that the organization of a set of agents cannot be analyzed separately from the agents' task environment  that there is no single best organization for all environments  and that different organizations are not equally effective in a given environment  galbraith  1 . most of these theorists view the uncertainties present in the environment as a key characteristic  though they differ in the mechanisms that link environmental uncertainty to effective organization. in particular  the transaction cost economics approach  moe  1  focuses on the relative efficiencies of various organizations given an uncertain environment  while the modern contingency theory approach  stinchcombe  1  focuses on the need for an organization to expand toward the earliest available information that resolves uncertainties in the current environment. 
    this work was supported by darpa contract n1-j-1  office of naval research contract n1-j-1  and nsf contract cda 1. the content of the information does not necessarily reflect the position or the policy of the government and no official endorsement should be inferred. 
1 	distributed al 
   in this paper we use both of these concepts to analyze potential organizational structures for a class of naturally distributed  homogeneous  cooperative problem solving environments where tasks arrive at multiple locations  exemplified by distributed sensor networks  lesser and corkill  1 . previous approaches to analyzing organizations in distributed sensor networks have either not focused on the effectiveness of the organization  davis and smith  1   or have only analyzed organizational effectiveness in particular  single-instance examples  durfee et al.  1 . our approach is to model the task environment mathematically  using a formalism developed specifically to study distributed coordination and scheduling  decker and lesser  1b . we then develop expressions for the expected efficiencies of static and dynamic organizational structures  in terms of the cost of communication and time to complete a given set of tasks. finally  we validate these mathematical models by using simulations. 
   a dynamic organization is one in which the responsibilities of agents can be reassigned based on a developing view of the problem at hand. due to the uncertainties explicitly represented in the task environment model  there may not be a clear performance tradeoff between static and dynamic organizational structures when agents use just their own local views to make a reorganization decision. agents that have a dynamic organization have the option of meta-level communication- communicating about the current state of problem solving as opposed to communicating about solving the problem itself. in this way  information that resolves uncertainties about the current environment becomes available to the agents  allowing the agents to then create the most efficient organization for the situation. 
   section 1 describes the task environment model  the assumptions behind it  and analyzes the uncertainties present. section 1 describes static and dynamic organizational structures  and develops expressions for the expected performance of each organizational style. in section 1 we then show how the variance in performance without communication can lead to the efficient use of meta-level communication to customize a dynamic organizational structure. finally  we discuss how these results can be used by designers of distributed problem solvers  and how our methodology can be used by other researchers. throughout each section  we will illustrate and confirm the analytical results experimentally  using as an example a simulated distributed sensor network similar to the distributed vehicle monitoring testbed  dvmt   lesser and corkill  1 . 

1 	task environment model 
our task environment model of naturally distributed problems assumes that several independent groups of computational tasks arrive at multiple locations over a period of time called an episode. for example  in a distributed sensor network  dsn  episode the movements of several independent vehicles will be detected over a period of time by one or more distinct sensors  where each sensor is associated with an agent. the performance of agents in such an environment will be based on how long it takes them to process all the task groups necessary to interpret their sensed data  which will include the cost of communicating data  task results  and mcta-ievel communication  if any. the organizational structure of the agents will imply which subsets of which task groups are available to which agents and at what cost. for example  if dsn agents have overlapping sensors  either agent can potentially work on data in the overlapping area  from its own sensor  without any extra communication costs. we make several simplifying assumptions: that the agents are homogeneous  have the same capabilities with respect to receiving data  communicating  and processing tasks   that the agents are cooperative  interested in maximizing the system performance over maximizing their individual performance   that the data for each episode is available simultaneously to all agents as specified by their initial organization  and that there are only structural  precedence  constraints within the subtasks of each task group. 
   any single episode can be specified by listing the task groups  and what part of each task group was available to which agents  given the organizational structure. our analysis will be based on the statistical properties of episodes in an environment  not any single instance of an episode. the properties of the episodes in a dsn environment are summarized by the tuple where a specifies the number of agents  n the expected number of task groups   and o specify the structural portion of the organization by the range of each agent and the overlap between agents  and  specifies the homogeneous task group structure  section 1 and figure 1 describes how task group structures are specified . 
   our analysis initially focuses on what a priori knowledge agents have about the distribution of task groups in an episode. first we will look at the distribution of the lowest-level sensor subtasks of a single task group among multiple agents  deriving the maximum expected number of subtasks   and then we will look at the distribution of task groups themselves. these results will then be used in subsequent sections to derive the total amount of work  and therefore expected termination performance  under various organizational structures and control schemes. 
1 	task environment simulation 
in the next sections and for the rest of the paper  we will test the model we are developing against simulated dsn problems. each simulated dsn episode will take place on a grid where the concepts of length and size correspond directly to physical distances. for example  figure 1 illustrates several simple organizations imposed on such a grid in our simulation. 
in the simulation we assume that each vehicle is sensed at 
   'in general there arc usually more complex interrelationships between subtasks that affect scheduling decisions  such as facilitation  decker and lesser  1b . 
discrete integer locations  as in the dvmt   randomly entering on one edge and leaving on any other edge. in between the vehicle travels along a track moving either horizontally  vertically  or diagonally each time unit using a simple d d a line-drawing algorithm  see figure 1 . in an 1 x 1 grid  the  empirical  average length of a track is 1 units-the actual length of any one track will range from 1 to 1 units and is not distributed normally. given the organization  r  o  and a  and the geometry   we can calculate what locations are seen by the sensors of each agent. this information can then be used along with the locations traveled by each vehicle to determine what part of each task group is initially available to each agent. section 1 will detail what the structure of each task group is for the dsn simulation. 

figure 1: examples of dsn organizations on an 1 x 1 grid 
1 	expected number of sensor subtasks 
in order to analyze the performance of a particular organization  we will want to know what proportion of each task group each agent is likely to process. there will be some upper limit on this proportion  related to the agent's range r   and sometimes the agent will process less than this upper limit. especially in static organizational structures where tasks are not exchanged  the termination of the system as a whole can be tied to the completion of all tasks at the most heavily loaded agent. normally  we would use the average part of a task group to be seen  but since the focus of our analysis is the termination of problem solving  we need to examine the expected maximum portion of a task group to be seen. this section will develop an equation for the expected maximum workload at an agent by counting the expected number of low-level sensor subtasks  each individually associated with a sensed vehicle location  that the maximally loaded agent will have. 
　the amount of a single task group seen by an agent  which is the same as the number of sensor subtasks in the dsn example  can be viewed as a random variable s with a probability density function and corresponding cumulative distribution function. in the dsn environment  s is discrete  and its probability function  determined empirically  is heavily weighted toward r  the maximum . to simplify the analysis  instead of letting s correspond to the number of subtasks in a single task group seen by an agent  we have it equal 1 if the agent sees the maximum amount  and 1 otherwise. now s has a bernoulli  coin-tossing  distribution with parameter p corresponding to the chance of an agent seeing the maximum amount r of a task group. let's assume we know that n   n is the number of task groups at the maximally loaded agent  and that on average a   a agents see a single task group. the number of times an agent sees the maximum out of n task groups  n coin flips  then has a binomial distribution  1;v p *  - we need to know  given that a agents each flip n coins  what the distribution is of the 
decker and lesser 

1 	distributed a! 

　at the lowest level  each method  leaf task  m at time t can produce  if executed  some maximum quality q af  t  in some amount of time d   m   t   each method has an initial maximum quality qo af  and duration do m  . any task execution that starts before the execution of m completes may potentially affect m s execution through non-local effects. the effect is dependent on the relative timing of the two task executions  the quality of the task causing the effect  and whether information was transmitted between the two tasks. 
   this work considers a single non-local effect  precedence. if task a precedes task b  then the maximum quality q  1 t  = 1 until a is completed and the result is available  when the maximum quality will change to the initial maximum quality q b 1 = qo b . 
1.1 	execution model 
   for this paper we use an extremely simple model of execution. agents can perform three actions: method execution  communication  and information gathering. the control component of an agent determines the next action an agent will perform based on the agent's current set of beliefs  cohen and levesquc  1; shoham  1 . a method execution action  of method m  that is begun at time t will conclude at time t + d   m   t . an information gathering action has duration do 1  and updates the agents set of beliefs with any new information in the environment  for example  the arrival of data at the start of an episode  or communications from other agents. a communication action has duration  and  after a communication delay  makes information  such method execution results  available to other agents. the agent on the receiving side must perform an information gathering action before the communication can affect its local beliefs. 
1.1 	simple objective dsn model 
recall that the summary of a dsn environment was the tuple 
; this will become our generative model  
especially the parameter n  expected number of task groups . a particular episode in this environment can be described by the tuple  where n is a random variable drawn from an unknown distribution with location parameter  central tendency  of  note that we make almost no assumptions about this distribution; its characteristics will differ for different environments. for example  in the description of our dsn simulation early in section 1 we noted the physical process by which vehicle tracks were generated and that the length of the tracks was not normally distributed. 
   each task group  is associated with a track of length li and has the same basic objective structure  based on the dvmt: 
  li vehicle location methods  vlm's  that represent processing raw signal data at a single location to a single vehicle location hypothesis. 
  li - 1 vehicle tracking methods  vtm's  that represent short tracks connecting the results of the vlm at time t with the results of the v l m at time 
  1 vehicle track completion method  vcm  that repre-sents merging all the vtm's together into a complete vehicle track hypothesis. 
non-local precedence effects exist between each method at one level and the appropriate method at the next level as shown in figure 1-two vlms precede each v t m   and all vtm's precede the lone vcm. 

figure 1: objective task structure associated with a single vehicle track. 
   if we assume that each v l m has initial duration and each v t m has the initial duration do  vtm   then we can see from the task structure that for each task group the total execution time taken by a single processor agent will be: 
		 1  
　this task structure is a simplification of the real dvmt task structure. for example  there is no sensor noise  which will cause facilitation relationships between tasks  and there is no confusion caused by 'ghost tracks'. adding these features to the task structure will cause some interesting phenomena that we will discuss briefly in the conclusions  see also  decker and lesser  1b  for a representation of these extensions . 
1 	static vs. dynamic organizational structures 
now we have the necessary background to analyze static and dynamic organizational structures. the key to static structures is to divide up the overlap area a priori  rather than to penalize agents for doing redundant work in the overlap area  durfee et al.  1  . the key to dynamic organizational structures is to transfer tasks so that all the agents' resources are used efficiently. we will repeat the assumptions we discussed at the start of 
section 1 on page 1: the agents are homogeneous  cooperative  the data for each episode arrives in a single burst  and the only non-local effect is precedence. 
1 	analyzing static organizations 
in a static organization  agents divide the overlapping areas of their ranges as evenly as possible. the result is a new area of responsibility  for each agent with no overlap  see 
figure 1  1 given the task structure as described in section 1 and shown in figure 1  and any raw data or communicated task results provided by information gathering actions  the agent can at any time build a list of currently executable methods  under the set of precedence constraints . also  at any time an agent can build a list of methods that need to be executed  but cannot be executed because their precedence constraints have not yet been met. the communication action in this algorithm is a broadcast of the highest level results of all the task groups an 
     1 thc reason for overlap will be apparent in dynamic structures- multiple agents can work in an overlapping area without paying any cost for communicating raw data between them. overlap can also provide redundancy in case of agent failure. 
decker and lesser 

1 	distributed al 

both the basic method durations and the agents' organizational structure . this simple control algorithm can be analyzed easily  unlike many other systems where control costs are ignored. if we view the cost of control as the time spent by an agent when not performing an action  executing a method  information gathering  communication   then our algorithm runs in constant time between actions except for the two tests  get set of currently executable methods  and  get set of methods still waiting . each of these in the worst case requires a constant-time test of each element of the full task structure  which is of size . thus we see how the control costs  too  are related to organizational structure. 
1 	analyzing dynamic organizations 
in the dynamic organizational case  agents are not limited to the original organization and initial distribution of data. agents can reorganize by changing the initial static boundaries  changing responsibilities in the overlapping areas   or by shipping raw data to other agents for processing  load balancing . 
　in the case of reorganized overlapping areas  agents may shift the initial static boundaries by sending a  very short  message to overlapping agents  telling the other agents to do all the work in the overlapping areas. the effect at the local agent is to change its effective range parameter from its static value of 
to some value where changing the first two terms of eqn. 1  and adding a communication action to indicate the shift and an extra information gathering action to receive the results. another paper  decker and lesser  1a  discusses a particular implementation of this idea that chooses the partition of the overlapping area that best reduces expected differences between agent's loads and averages competing desired partitions from multiple agents. 
   in the second case  an agent communicates some proportion p of its initial data to a second agent  who does the associated work and communicates the results back. instead of altering the effective range and overlap  this method directly reduces the first two terms of eqn. 1 by the proportion p. the proportion p can be chosen dynamically in a way similar to that of choosing where to partition the overlap between agents  sec  decker and lesser  1a  . 
   whether or not a dynamic reorganization is useful is a function of both the agents local utility and also the load at the other agent. we will again be concentrating on the agent with the heaviest load. looking first at the local utility  to do local work under the initial static organization with n task groups  the heaviest loaded agent will take time: 
		 1  
when the static boundary is shifted before any processing is done  the agent will take time: 

to do the same work  where cshort is a very short communication action which is potentially much cheaper than the result communications mentioned previously  and 1  is calculated using 
 when balancing the load directly  local actions will take time: 

where 	is potentially much more expensive than the 
communication actions mentioned earlier  since it involves sending a large amount of raw data . if the other agent had no work to do  a simple comparison between these three equations would be a sufficient design rule for deciding between static and cither dynamic organization. 
1 	using meta-level communication 
for some environments  one of the three organizational choices may be clearly better in the long run  but for most environments the choice is not so clear given the variance in system performance. the choice that optimizes performance over the long run is often not optimal in any particular episode. taking the equations for local work in section 1 along with eqn. 1  we can compute confidence intervals on the predicted performance of an organization under each of the three coordination regimes by combining the local confidence interval on the expected load of the heaviest loaded agent  and the confidence interval on the average agent load. these results  for the 1% confidence interval  arc shown in figures 1 and 1. again we have assumed that all execution  communication  and information gathering action durations have the same value  making communication relatively expensive . the first figure  figure 1  highlights how the relationship between performance under a static organization and a dynamically load balanced organization changes as the number of agents increases. as expected  load balancing becomes more desirable as the number of agents increases  in relation to the average number of tracks : when there arc many agents  the average agent load becomes very low  which offsets the cost of transferring tasks. in this figure the performance difference between static and overlap reorganization remains nearly constant relative to the number of agents. 

figure 1: predicted 1% confidence intervals on the expected termination of a system under three coordination regimes  different numbers of agents  and three values of n  number of tracks . this figure is based on eqns. 1  1  and 1. 
　the second  figure 1  points out how dynamically reorganizing the overlap area increases the performance over static organization as the amount of overlap increases. for this graph we assumed that the agents would shrink their entire area of responsibility  as opposed to minimizing the difference in maximum versus average work as described in  decker and lesser  1a  . this graph shows the need for dynamically calculating the shrinkage parameter  p  especially at high levels of overlap  note how the dynamically reorganized organization is predicted to do worse at high levels of overlap in the n = 1 portion . the expected performance difference between the static organization and load balancing remains relatively constant across changing values of o. in both figures we have let 
changing these values will 
move the corresponding curves directly up or down. 
decker and lesser 


figure 1: predicted 1% confidence intervals on the expected termination of a system under three control regimes  different overlaps  and three values of n  number of tracks . 
   these figures bring us to the final point of this paper: often system performance can be improved significantly by dynamic reorganization  but it will rarely always be improved. therefore  meta-level communication between agents about their local loads can  with a small communication cost  pinpoint the true costs and benefits of the various organizational structures  allowing an informed organizational decision to be made. instead of an agent making a decision about restructuring or load balancing by assuming the average load  the agent will have the actual load for the neighboring agents. as we said in the introduction  the proper organization is often one that exploits information that resolves uncertainties about the current environment as it becomes available to the agents  allowing the agents to then create the most efficient organization for the situation. 
1 	conclusions 
the results of this paper can be looked at from three points of view. from the practitioners viewpoint  the analysis presented here resulted in a set of design equations that can be used directly to optimize the performance of a simple dsn  or explore the design space given some model of how expensive agents are and what bounds  mean  median  1% quantile  on their performance are required. several of the simplifying assumptions we used  such as constant communication and information gathering costs  can be easily replaced with submodels chosen by the designer. from the viewpoint of the distributed al community  we have returned to look at the some of the problems first studied by durfee  lesser  and corkill  durfee et ai  1 . they concluded that  our intent is to show that overly specialized organizational structures allow effective network performance in particular problem-solving situations  but that no such organization is appropriate in all situations.  in this paper we reach the same abstract conclusion  but also show precisely what the effect is of a particular organizational structure  characterized by both its structural components and its coordination algorithm  in an environment  characterized by the structure and frequency of its tasks  in a clear way that not only allows us to predict performance but to explain it. the technique of using binomial approximations should also prove useful in different domains. from the viewpoint of the general research community this paper presents a methodology for answering questions about the design of a system by analysis and simulation. in such a methodology  the observation of particular phenomena in a complex system  the dvmt  leads to the building and verification of general models that predict and explain such phenomena. 
1 	distributed al 
   in the short term  this work leads to the explanation of other interesting distributed problem solving phenomena displayed in  durfee et alt 1 . the addition of noise at dsn sensors leads to the necessity of more complex coordination with the introduction of more complex task interrelationships  such as 
facilitation  decker and lesser  1b  . the addition of correlated noise in the environment can then cause these new  more complex coordination mechanisms to break down  producing the phenomenon recognized as distraction. in the long term  we are working towards a complete characterization of generalized partial global planning  decker and lesser  1  as a first step towards a theory of coordination in distributed problem solving. 
　a longer technical report version of this paper is available from the authors. 

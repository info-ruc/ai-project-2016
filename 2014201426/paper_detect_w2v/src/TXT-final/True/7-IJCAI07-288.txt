
we aim to improve the performance of a syntactic parser that uses a part-of-speech  pos  tagger as a preprocessor. pipelined parsers consisting of pos taggers and syntactic parsers have several advantages  such as the capability of domain adaptation. however the performanceof such systems on raw texts tends to be disappointing as they are affected by the errors of automatic pos tagging. we attempt to compensate for the decrease in accuracy caused by automatic taggers by allowing the taggers to output multiple answers when the tags cannot be determined reliably enough. we empirically verify the effectiveness of the method using an hpsg parser trained on the penn treebank. our results show that ambiguous pos tagging improves parsing if outputs of taggers are weighted by probability values  and the results support previous studies with similar intentions. we also examine the effectivenessof our method for adapting the parser to the genia corpus and show that the use of ambiguous pos taggers can help development of portable parsers while keeping accuracy high.
1 introduction
some parsers use pos taggers as their preprocessors  and some use integrated models that achieve tagging and parsing simultaneously. because the latter approach is more general  it is successfully used by some of the state-of-the-art parsers  such as charniak's  charniak and johnson  1   as a natural consequence of the pursuit of accuracy. however  integrated models of tagging and parsing tend to be complex and computationally expensive  both in terms of training and run-time costs.
모on the other hand  pipelined systems of pos taggers and parsers can be built with independentlydevelopedtaggers and parsers. in such models  we can easily make use of taggers that use state-of-the-art sequence labeling techniques  most of which are difficult to be incorporated into syntactic disambiguation models. advantages of pipelined parsers also include their ability to adapt to domains. pos taggers for a new domain are much easier to develop than full parsers  because training corpora for pos taggers are easier to construct compared to those for full parsers  which require the annotation of nested phrase structures.
모however  independence assumption of taggers and parsers may degrade the overall accuracy of the parsers. watson  reported that using an automatic pos tagger caused the f1 score of grammatical relations output by a parser to drop by 1 points. she attempted to weaken the independence assumption by letting the taggers output multiple tags for each word  weighted by probability values. her approach improved the f1 score by 1 points.
모in this paper  we verify watson's results on ambiguous pos tagging using an hpsg  pollard and sag  1  parser developed and trained on the penn treebank  marcus et al.  1 . at the same time  we investigate the effectiveness of ambiguous pos tagging for domain adaptation of parsers using the genia corpus  ohta et al.  1  as the test set. experimental results show that the multiple output without probability values cannot improve the parser much and suggest the importance of probability distribution of multiple tags obtained by pos taggers. additionally  we show that the positive effect of ambiguous pos tagging is maintained for domains unfamiliar to the parser.
1 background
in this section  we describe the pos tagger and syntactic parser used in our experiments. these taggers and parsers were combined to make a pipelined syntactic parser for raw texts using the strategy described in the next section.
모as both of our tagging and parsing models are based on log-linear classifiers  we first briefly introduce log-linear models and then describe our tagger and parser.
1 log-linear models
log-linear models are among the most widely used machine learning techniques in nlp literature  and we use the models both for pos taggers and syntactic parsers. a conditionalloglinear model calculates the probability of an evente given the input: sentence s output: tag sequence t1 ...tn algorithm:
1. foreach ti do ti := null 1. foreach ti = null
compute probability distribution
p ti|ti 1 ti 1 ti+1 ti+1 s   1  by log-linear models
1. let i be easiest place to tag in ti :=  most probable tag for ti 
1. repeat 1 and 1 until null for each i
figure 1: algorithm for pos tagging
condition c as follows:
 
where the real-valued functions fi are used to indicate useful features for predicting e  parameters 뷂i are optimized to fit the model to the training data  and zc is a normalization constant. several criteria for estimating the parameters of log-linear models exist  and we used map estimation with gaussian prior distribution  chen and rosenfeld  1   which is most commonly and successfully applied in various nlp tasks.
1 pos tagger
we employ the bidirectional inference model proposed by tsuruoka et al.  for our pos taggers. the model consists of 1 log-linear models  each of which provides the
probability
모모모모모p ti|ti 1 ti 1 ti+1 ti+1 s  	 1  where s is a given sentence  and ti is the pos tag for the ith word. an algorithm used by the pos taggers is shown in figure 1. the key idea of the algorithm is that it does not work in the usual left-to-right manner  instead it iteratively tries to tag words that can be tagged most easily.  easiness  of tagging is measured by the highest probability value among the probability distribution of the tags. when we calculated eq.
1 in step 1 of the algorithm  each from ti 1 ti 1 ti+1 ti+1 could be null  so we prepared 1 = 1 classifiers to cover every pattern of the appearances of null. each token in a training corpus was used as training data for all 1 classifiers. the features used by the classifiers were the surface strings of words  base forms of words obtained by a dictionary  prefixes and suffixes  and poss of already tagged words.
모though the algorithm described above is totally deterministic  a slight modification with beam search strategy could make it output an approximation of k-best tag sequences with probability values.
1 grammar and parser
the parser we used is based on head-driven phrase structure grammar  hpsg   which was developed using the penn treebank  miyao et al.  1 . the disambiguationmodel for the hpsg grammar is a combination of two log-linear models.
모the first log-linear model is for selecting lexical entries for words of a pos-tagged sentence  which estimates the proba-
bility
	p li|wi ti  	 1 
where wi  ti  and li represent an ith word  pos tag  and lexical entry in a sentence  respectively. the information of wi and ti are used in combination as features of the log-linear model.
모the second model is for selecting the most probable parse from an hpsg parse forest f which is constructed from lexical entries that are weighted by the first model:
p t|l1 ... n w1 ... n t1 ... n  
where t 뫍 f. the overall disambiguation model is
argmaxp t|w1 ... n t1 ... n  =
모모모모모모모모모t뫍f argmax.
t뫍f
모the parsing algorithm for the disambiguation model is a cyk-like chart parsing with iterative beam search  ninomiya et al.  1 .
1 combining pos taggers and parsers
in pipelined parsers  pos taggers and syntactic parsers are developed separately  and we can freely change taggers for parsers  without any special care for the algorithms. to make pipelined systems of ambiguous pos taggers and parsers work the same way  we restrict the interface of ambiguous taggers and formalize the condition of the syntactic disambiguation models that can be applied to the output of ambiguous taggers without modification.
모we concentrate on the following situation: for each word in a sentence  pos taggers output a set of candidate pos tags  and the obtained tags are used to restrict parses in the parsing model.
모in our experiments  we compared the following three types of taggers.
single the single tagger outputs the most probable single tag for each word.
multi the multi tagger outputs a set of candidate pos tags for each word.
prob the prob taggeris similar to multi  but each pos tag is weighted by its probability. that is  it providesthe probability distribution p tij|s   where s is an input sentence and tij represents the jth candidate pos tag of the ith word.
모we assume that the parsing model consists of two independent models: terminal and non-terminal. a parse t of a given sentence s consists of the terminal structure tt and nonterminal structure tnt  and terminal and non-terminalmodels are used to estimate the probability distributions p tt|s  and p tnt|tt s . the best parse is given by argmaxp tnt tt|s  =
모모모모tnt tt argmaxp tnt|tt s p tt|s .
tnt tt
then  we assume that the terminal structure tt can be further decomposed into a sequence of terminal labels li ... ln  where the label li corresponds to the ith word of the sentence  and terminal labels are independent of one another in the terminal model:
.
the overall disambiguation model becomes
	argmax.	 1 
tnt tt
we assume that a tractable estimation method and disambiguation algorithm applicable to eq. 1 exist.
모let us then rewrite the distribution p li|s  to make it dependenton outputsof pos taggers  so that we can incorporate the information of pos tags into the parsing model.
	 	 1 
where tij is the jth element of a set of pos tags assigned to the ith word of the sentence  and p tij s  is the probability of that tag calculated by the prob tagger  multi and single taggers can be integrated into the model similarly by assuming the tags assigned to the same word by the taggers are equally probable . by replacing p li|s  that appears in eq. 1 with eq. 1  we can apply the same disambiguation algorithm as eq. 1 to the combined system of an ambiguous pos tagger and the parsing model.
모this strategy is applicable to a wide rangeof grammarsand disambiguation models including pcfg  where the terminal model is used to assign pos tags to words and lexicalized grammars such as hpsg  where the terminal model assigns lexical entries to words. the hpsg parser described in section 1 is straightforwardly adapted to this model  by taking eq. 1 as a terminal model.
모one problem with this strategy is the increased ambiguity introduced by multiple tags. as reported by watson   the increase in computational costs can be suppressed by applying appropriate parsing algorithms. the parsing algorithm we used  ninomiya et al.  1  is suitable for such purposes  and we will show experimentally that the disambiguation of the above model can be performed with efficiency similar to models with single taggers.
1 implementation of prob tagger
there can be various methods for implementing the prob tagger described above. our implementation outputs approximation of tag probabilities by marginalizing the probability of k-best tag sequences obtained by the algorithm described in section 1.
lp/lrf1.1.1.1table 1: accuracy on section 1 with correct pos tags
모to control the ambiguity of the tagger  we introduce a parameter 붿 which is used to threshold the candidate tags. if the marginalized probability of a candidate tag is smaller than the probability of the best tag of the same word multiplied by 붿  the candidate is discarded.
모figure 1 illustrates example outputs of each tagger from the 1 best analysis of the sentence   mr. meador had been executive vice president of balcor   without thresholding.
모marginalization of probability distribution output by pos taggers loses information about the sequential dependency of tags  which can harm the performance of the parser. for example  let us consider the sentence   time flies like an arrow.  when there are two candidate pos tag sequences  nn vbz in dt nn  and  vb nns in dt nn   the output of multi tagger will be  {nn  vb} {vbz  nns} in dt nn   which can induce a tag sequence  vb vbz in dt nn  that is not included in the original candidates.
1 experiments
the first experiment verified the effect of ambiguous pos tagging using the penn treebank for both training and testing. the second experiment examined the parser's capability of domain adaptation  using the penn treebank for training the parser  biomedical texts for training the tagger  and the genia corpus for testing.
모both experiments used the same hpsg grammar and parser. the grammar was developed using the penn treebank sections 1  and the disambiguation model was trained on the same data. the accuracy of the parser evaluated on the penn treebank section 1 using the correct pos tags is shown in table 1. labeled precision  lp  and labeled recall  lr  are the precision and recall of dependencies with predicate-argument labels  and f1 is the harmonic mean of lp and lr. each dependency between a pair of words is counted as one event. these measures were also used in the following experiments. the figures in table 1 can be considered the practical upper bounds  because they are not affected by incorrect predictions of pos taggers.  we will refer to the results using the correct pos tags as gold.  in the following  comparisons of the systems were performed using the f1 scores.
1 parsing penn treebank
inputmrmeadorhadbeenexecutivevicepresidentofbalcor.1 best sequencesnnpnnpvbdvbnjjnnnninnnp. 1  probability nnnnvbdvbnjjnnnninnnp. 1 nnpnnpvbdvbnnnnnnninnnp. 1 singlennpnnpvbdvbnjjnnnninnnp.multi{nnp  nn} {nnp  nn}vbdvbn{jj  nn}nnnninnnp.probnnp 1 	nnp 1 vbdvbnjj 1 nnnninnnp. probability nn 1 	nn 1 nn 1 figure 1: example of tagging results

lp/lrf1
# of training datatagging strategylp/lrf1
multi 붿 = 11/11multi 붿 = 11/11multi 붿 = 11/11multi 붿 = 11/11prob 붿 = 11/11prob 붿 = 11/11prob 붿 = 11/11prob 붿 = 11/11the pos taggers described in this section were trained on the penn treebank sections 1  and the performance of the tagger on the development set was 1%. as described in section 1  our taggers multi and prob have a hyperparameter 붿 for controlling the number of alternative answers table 1: accuracy with different 붿
included in the output  where a smaller 붿 means a larger number of alternative answers. before comparing ambiguous taggers  i.e.  multi and prob  with single  we first determined which of multi and prob and which value of 붿 perform best.
모the performance of the parser for various 붿 is shown in table 1. the parsers with the multi tagger was outperformed by prob in all cases1  so we only used the prob tagger in the following experiments. the performance of the parser with the prob tagger has a peak around 붿 = 1. the accuracy slowly decreases for smaller 붿s  the reason for which might be the problem noted in the last paragraph of section 1. we used the best performing 붿  = 1  in the following experiments.
모it was interesting to see whether the contribution of ambiguous tagging changed according to the performance of the syntactic disambiguation model  because if ambiguous pos tagging did not work well with a poorer disambiguation model  ambiguous tagging could be considered not to help the performance in domains unfamiliar for the parser  where the performance of the disambiguation model was likely to be lower. we observed a change in performance of the parser when the number of sentences used for developing the grammar and for training the syntactic disambiguation model was changed. table 1 shows the performance of the parser trained with various numbers of sentences selected from the penn treebank sections 1. figure 1 shows f1 scores of the systems trained on 1  1  and 1 sentences.
모ambiguous pos tagging with the prob tagger could be contended to contribute to the performance of the parser  because the performance of the parser with the prob tagger was consistently better than that of the single tagger in all of the
gold1/111single1/11prob1/11gold1/111single1/11prob1/11gold1/111single1/11prob1/11gold1/111single1/11prob1/11gold1/111single1/11 all prob1/11table 1: accuracy with different sizes of training data

# of sentences
figure 1: f1 of different sizes of training data
lp/lrf1parsingmean
time
gold1/111 msecsingle1/111 msecprob1/111 msectable 1: accuracy on test set
pos taggerlp/lrf1parsingmean
time
gold1/111 msecsingle-penn1/111 msecprob-penn1/111 msecsingle-bio1/111 msecprob-bio1/111 msectable 1: accuracy on genia
above experiments if evaluated in the f1 measure. with the entire training data used for the development of the parser  the contribution of ambiguous pos tagging was about 1. table 1 summarizes the performance of some of our systems evaluated using section 1 of the penn treebank. the overall tendency observed on the development set remained  but the contribution of ambiguous tagging was considerably bigger than in the development set.1 as can be seen from the table  prob was the slowest of all  but the difference is not so big. this may be because ninomiya's method of hpsg parsing  which outputs the first answer found  worked tolerantly to increase of ambiguity.
1 parsing genia corpus
one of the most crucial advantagesof separating pos tagging from syntactic parsing is that the domain adaptation of such systems can be partly achieved by just changing pos taggers. in this section  we verify that the effect of ambiguous pos tagging is also remains for domains with which parsing models are not familiar.
모the test data we used was the genia treebank  tateisi et al.  1   which annotates penn treebank-style tree structures to sentences of the genia corpus. the genia corpus consists of the abstracts of biomedical papers adopted from medline  campbell et al.  1 . we trained our pos tagger with the mixture of the wsj part of the penn treebank  the penn bioie corpus  kulick et al.  1   and the genia corpus  which consist of 1  1  and 1 sentences  respectively. following hara et. al.   we adopted 1 abstracts  1 sentences  for the evaluation. performance of the single tagger on these sentences was 1%.
모the result is shown in table 1. single-penn and prob-penn are single and prob taggers trained on the penn treebank  and single-bio and prob-bio are those trained on the biomedical domain  i.e.  the penn bioie corpus and the genia corpus . compared to the results with gold pos tags  the use of automatic taggers trained on a different domain degraded the performance by about 1 to 1 points in the f1 measure. this drop was recovered using well-tuned taggers  and remarkably  the results of prob-bio were only 1 points lower than the upper bound.1 the difference in processing time was  again  not

1
   though this figure alone seems not to be significant  we will show that the results of the same experiment using the test set have significant improvements. 1
   the improvement of prob over single is significant with p   1 according to stratified shuffling tests  cohen  1 . 1
the improvement  in terms of recall  of prob over single is sig-
so significant.
모in summary  we showed that the adaptation of pos taggers can significantly improve the performance of parsers in new domains  and the use of ambiguous pos tagging can extend the improvement further.
1 related work
charniak et al. investigated the use of pos taggers that output multiple tags for parsing and concluded that single taggers are preferable  because the accuracy of the tag sequences selected by parsers did not improvesignificantly  while the increase in computational cost is considerable. watson  revisited the same task and observed that in terms of the accuracy of parsing  multiple taggers improve the performance significantly. our results show that the taggers should pass to the parser not only multiple answers  but also probability values for each candidate. watson's results also imply that appropriate parsing strategies can make the increase of computational cost not as problematic as charniak et al. suggested. our results again agree with watson's at this point.
모clark et al.  introduced supertaggers that output multiple supertag candidates  and the taggers were used as a front end of their ccg parser. because the training of supertaggers require corpora more deeply annotated than pos tagged ones  their method should have difficulties if we exploit taggers for domain adaptation.
모adaptation of general parsers to a biomedical domain has already attracted several researchers. because the biggest difference between general english and biomedical literature is their vocabularies  use of lexical resources and tools is a natural approach. lease et al.  modified charniak's parser  to make it conform to genia's tagging convention and made use of biomedical dictionaries to restrict the parser output. they obtained an impressive error reduction of 1% and expected that further improvement is possible using named-entity recognizers.
모we can see that the performance shown in section 1 is significantly lower than those in 1. this suggests that changing pos taggers can only partially achieve domain adaptation  so we should consider training syntactic disambiguation models on the target domain if we desire further improvement. this is what hara et al.  explored  and their results suggested that a small number of in-domain data could bring considerable improvements of the performance if out-of-domain data was as large as the penn treebank. because their evaluation was done with pos tagged sentences  whether this is still the case for the task of parsing raw texts is an open question
1 conclusion
in this paper  we demonstrated that the accuracy of parsers could be improved by allowing pos taggers to output multiple answers for some words. when the performance of the parser was evaluated in terms of precision/recall of predicate argument relations  the performance of the parser with the

nificant with p   1 according to stratified shuffling tests. the improvement of precision is not significant.
ambiguous pos tagger consistently outperformed that with the conventional unambiguous tagger throughout the experiments  and this was also the case for a domain that was not used to train the parser. if the goal is to optimize the accuracy of predicate-argument structures  we can say ambiguous tagging is profitable  and introducingambiguoustagging without harming the capability of domain adaptation is possible.
모one apparent deficiency of our system is that it cannot take into account the dependencies among outputs of the pos taggers. perhaps we can achieve further improvement by running separate parsing processes for each candidate pos sequence that is output by the pos tagger  but this approach might not be acceptable considering computational cost.

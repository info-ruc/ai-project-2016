 
in this paper a framework is developed for measuring the complexities of deductions in an abstract and computationally perspicuous manner. as a notion of central importance appears the so-called polynomial transparency of a calculus. if a logic calculus possesses this property  then the complexity of any deduction can be correctly measured in terms of its inference steps. the resolution calculus lacks this property. it is proven that the number of inference steps of a resolution proof does not give a representative measure of the actual complexity of the proof  even if only shortest proofs are considered. we use a class of formulae which have proofs with a polynomial number of inference steps  but for which the size of any proof is exponential. the polynomial intransparency of resolution is due to the renaming of derived clauses  which is a fundamental deduction mechanism. this result motivates the development of new data structures for the representation of logical formulae. 
1 introduction 
the competitiveness of logic calculi is essentially determined by two complementary factors; on the one hand  by the ability to provide compact proofs  and on the other  by the effort needed for finding such proofs  that is  by the search spaces induced by the indeterminism inherent in the calculi. in this paper  we shall systematically address the problem how to measure the first of these two capabilities of a calculus-its in deterministic power-in an abstract and nevertheless computationally reliable manner. 
¡¡the paper consists of two parts  a conceptual part and an application part. in the conceptual part  we present a general framework for measuring the computational complexities of arbitrary transition relations and deductions  which are treated as particular transition relations. 
in order to be able to compare complexities on a level 
   *this work was financially supported by the esprit basic research actions 1 medlar i and 1 medlar ii. 
which is as abstract as possible  we subscribe to abstractions modulo polynomials  as usual in complexity theory. the central notions emerging this way are the properties of polynomial transparency and weak polynomial transparency. the polynomial transparency of a transition relation guarantees that the number of rewrite steps in any transition sequence represents an adequate measure for the actual computational complexity of the sequence. weak polynomial transparency is the adequate concept for evaluating the tndetermintstic powers of special transition relations  called proof relations  by restricting attention to shortest proofs only. 
¡¡the benefit of the framework is twofold  not only does it facilitate the classification of deduction systems  it also may give advice how to improve the systems. this is illustrated in the application part of this paper where the developed notions are used on the resolution calculus. it is proven that resolution lacks polynomial transparency  both in the strong and in the weak sense. as a consequence  the number of inference steps of a shortest resolution proof does not give a representative measure of the actual complexity of the proof. the use of number terms in the object language can remedy this weakness 
for a certain class of formulae. whether a general remedy exists remains an open problem. 
1 complexity measures for deductions 
the indeterministic power of a calculus is determined by the complexities of shortest proofs. this raises the fundamental question how the complexities of proofs and deductions in general should be measured. 
1 	deduction processes as transition relations 
for investigations into the computational complexity of logic calculi  it is important to realize that deductions can be given a declarative and a process interpretation. according to the declarative reading  deductions are typically defined as sequences of formulae 
where each  is derivable by applying an inference rule to formulae in d with an index stricly less than t. another popular interpretation is to define deductions as trees of formulae where each parent node can be derived from its immediate successors. there is no limitation to further ways of defining deductions. de-
	letz 	1 
ductions as static objects of the type mentioned above tend to be non-operational  in the sense that they do not prescribe the precise methodology according to which they have to be constructed. a deduction process can be viewed as one particular way of building up a deduction object. from a complexity point of view  the deduction process is the more fundamental notion and the deduction object is just a-even though extremely useful-by-product of the deduction process.1 

   1this evaluation can be justified by recalling under which conditions a given object is accepted as a deduction of a type 1  namely  if there exists a procedure which decides whether the object has type s. and the true complexity of a deduction object is the complexity of this verification procedure  for further motivation  consult  letz  1  . 
   1as a matter of fact  r- does not denote the standard logical consequence relation. 
   1a realistic machine model can be defined to be any machine model in which the elementary operations are polynomially related to the configurations of turing machines into si+i. conceptually  the chosen basic machine model can be viewed as another  more elementary  transition relation  written - . then  the elementary computing cost of the derivation d - so       sn can be defined as 

¡¡taking the elementary computing cost of a derivation as the measure of its complexity has certain disadvantages. first  for the standard realistic machine models  the measure is too detailed to be interesting as a quantity of comparison on a higher level of abstraction. second  its value may vary strongly  depending on the chosen realistic machine model-even though only up to polynomials. lastly  it may be very difficult to actually obtain the realistic computing cost  because the mapping down of high-level transition steps into basic machine operations is normally not carried out explicitly  instead one is satisfied with knowing about the possibility of such a transformation and its computational invariances. 
¡¡an advance is offered by disregarding the elementary computing cost and restricting oneself to a higher level of representation  by only considering the size of a derivation d = so ...  sn  which is simply the sum of the  string  sizes of the states in d: 

¡¡the highest abstraction level even ignores the size of a derivation d - so    -.  sn and considers only the number of rewrite steps in the top-level transition relation h  in 
terms of logic calculi  the number of inference steps: 
steps d  = n. 
¡¡eventually  it is this measure that is being striven for. it has been used successfully for analyzing the indeterministic powers of many propositional calculi  for example  in  reckhow  1    haken  1   and various other papers. the abstraction performed by these authors is an abstraction modulo polynomials; they make plausible that the elementary computing cost is polynomially bounded by the number of inferences. such an abstraction is very natural in that it takes into account the problem area of np vs conp  on the one hand  and additionally leaves aside uninteresting subpolynomial differences which result from the choice of the realistic machine model  on the other. 
1 	polynomial size- and step-transparency 
the following two notions are fundamental for a general theory of the abstraction modulo polynomials. first  we consider the abstraction step from the elementary computing cost to the size of a derivation  and state under which condition such an abstraction is permissible. 
definition 1  polynomial size-transparency  a transition relation l- is called polynomially size-transparent if 
 cf. the further remarks in  van emde boas  1  and  letz  1  . 

there is a polynomial p such that for every derivation 
d = 
   if a transition relation h is polynomially sizetransparent  then the size of any derivation gives a representative complexity measure of its elementary computing cost  as long as we are interested in complexities modulo polynomials. polynomial size-transparency generalizes a basic concept introduced by cook and reckhow in  cook and reckhow  1 . they define a  complete  proof system as a  surjective  in polynomial time computable function from the set of strings to the set of valid formulae. apparently  any proof system is polynomially size-transparent. 
   in order to define a general criterion which guarantees that we can even abstract from the size of a derivation  it is necessary to use polynomials in two arguments. 
d e f i n i t i o n 1  polynomial  step- transparency  a transition relation l- is called polynomially step-transparent or just polynomially transparent if there is a polynomial p in two arguments such that for every derivation d = 
   if a transition relation is polynomially transparent  then the input size and the number of rewrite steps of any derivation give a representative measure of the complexity of the derivation. 
n o t e it is apparent that indeed a polynomial in two arguments is needed  demanding that cost d    p n  does not result in a useful notion. as an example  consider a calculus which solely can check whether a logical formula has the structure  according to the intended reading of inference steps  we wish to say  that the calculus can verify its input in a single inference step. however  there is no complexity function  and hence no polynomial  which bounds the elementary computing cost for verifying formulae of arbitrary size that have the shape 
   clearly  if a transition relation l- is polynomially transparent  then l- is polynomially size-transparent. 
1 a sufficient c o n d i t i o n f o r p o l y n o m i a l t r a n s p a r e n c y 
it is apparent that polynomial transparency is a highly desirable property.1 the question is now how to determine whether a transition relation is polynomially transparent. polynomial transparency is a property defined on derivations of arbitrary lengths. it would be very comfortable if the polynomial transparency of a transition relation could be derived from more elementary 
   1 also  the concept of polynomial transparency leads to a natural generalization of the notion of a realistic machine model. by a generalized realistic machine model we can understand any computation model which  as a transition relation  is polynomially transparent and has the expressive power of turing machines. 
properties of the transition relation. a very useful sufficient condition for polynomial transparency  which only takes into account the step behaviour of a transition relation  can be defined as follows. 
d e f i n i t i o n 1  polynomial time step-reliability  a transition relation  is called polynomial time step-reliable if there is a polynomial p such that for any one-step derivation d = s s' in 
n o t e the development of data structures and algorithms for polynomial unification can be viewed as the attempt to achieve the polynomial time step-reliability of deduction systems using unification. 
   unfortunately  polynomial time step-reliability is not sufficient for guaranteeing polynomial transparency. additionally  a size increase condition is needed. the following very general one will do. 
d e f i n i t i o n 1  logarithmic polynomial size step-reliability  a transition relation l- is called logarithmic polynomial size step-reliable  or just logp size step-reliable  if there is an integer 1   1 and a polynomial p such that for every pair {s s'  €l-: 

the following proposition  a proof can be found in 
 letz  1   is fundamental for the theory of abstraction modulo polynomials. 
p r o p o s i t i o n 1 if a transition relation l- is polynomial time step-reliable and logp size step-reliable  then l- is polynomially transparent. 
1 	w e a k p o l y n o m i a l transparency 
there are transition relations for which polynomial transparency cannot be guaranteed for arbitrary derivations  so that not in any case the input size and the steps of a derivation give a representative measure of its complexity. but  one may argue  when the indeterministic power of the transition relation defined by a logic 
calculus is concerned  then it is legitimate to consider solely those derivations which are shortest proofs of the inputs. the question is how to define 'short'  in terms of elementary computing cost  in terms of derivation size  or number of steps. also  the shortest proof  in anyone of these models  may violate the condition of polynomial transparency  but the second shortest may fit. in order to facilitate the formulation of reasonably tolerant generalizations of polynomial transparency  we define minimal proofs with respect to polynomials. 
d e f i n i t i o n 1  p- step- minimal proof  given a proof relation and a polynomial p. a proof d of an input state s in is said to be p-minimal in  if for any proof d' of 1 in l-: 

and d is called p-step-minimal in l- if for any proof d' of s in 

	letz 	1 

¡¡now  polynomial difference in complexity poses no problems  not the absolutely shortest proof must be taken  any proof will do which p-simulates the shortest one. using p-step-minimal proofs the notion of polynomial transparency can be weakened as follows. 
definition 1  weak polynomial  step- transparency  a proof relation l- is called weakly polynomially steptransparent or just weakly polynomially transparent if there are polynomials p and p' such that for every input state s there exists a p-step-minimal proof d of s in l- with cost d    p' size 1  steps d  . 
note one could even be more liberal and only demand the existence of p-minimal proofs in the definition above. we think that the resulting notion would become too weak  for the following reason. with the notion of weak polynomial transparency we intend to express that the abstraction level of inference steps indeed provides a representative complexity measure for the indeterministic power of a proof relation  even though not for the absolutely shortest proofs  so at least for one of the short proofs. but the class of short proofs should be defined in terms of inference steps  this way demonstrating the usefulness of the abstraction level. 
1 transparency properties of resolution 
as a typical representative of a logic calculus relying on the use of lemmata  we shall study the transparency properties of the resolution calculus 1 the resolution calculus  robinson  1  can be formulated as a system of a single but complex inference rule of the shape 
are 
clauses; implicitly assumed is the renaming of the variables in one of the input clauses of the rule. 
¡¡let us illustrate at this example the distinction between the declarative and the process interpretation of a deduction. while a deduction of the former type is simply a sequence d of clauses where each element of d is either from the input set or derived from earlier elements of d  the deduction process consists of a sequence of increasing clause sets. if the deduction process is based on unrestricted resolution-which is free of reduction rules like subsumption deletion-  then any state of the deduction process is just a deduction of the declarative type. this property holds for all calculi which are accumula-
tive1 
¡¡¡¡1 the transparency properties of other calculi are studied in  letz  1 . 1 in general  however  the states of a deduction process need not represent declarative deduction objects  even if no reduction rules  like subsumption deletion  are applied. this example also exhibits a certain disadvantage of measuring the size of a deduction as the sum of the sizes of the states 
1 	resolution and polynomial transparency 
while polynomial size-transparency can be guaranteed for resolution-provided polynomial unification algorithms are used-  it is evident that resolution is not polynomially transparent. 
proposition 1 resolution for first-order logic is not polynomially transparent. 
proof consider the following formula f consisting of three clauses1 of the shape 
example 1 	
where 1 denotes a constant. by performing selfresolution on the second clause co of f and then repeatedly applying self-resolution to the deduced resolvents  in k steps one can generate a clause ck of size   from ck the empty clause can be deduced in two further resolution steps. clearly for any polynomial p there of this type such that 
size that is  the size of d cannot be bounded by any polynomial on the size of the input formula and the number of resolution steps. d 
¡¡consequently  in contrast to propositional logic  for first-order logic the number of resolution steps is not an adequate measure for the complexities of resolution derivations and proofs. the apparent reason is the following. due to the renaming of derived clauses  resolution violates the logp size step-reliability.1 
¡¡but one may object that a resolution proof of the specified type is not an optimal one  and that there exists a shorter resolution proof for f which immediately derives the empty clause  by simply resolving the two facts and for this short proof the relation be-
tween the proof size and the proof steps is polynomial modulo the input size. 
1 	resolution and weak polynomial transparency 
the question is now whether for shortest resolution proofs the sizes and the inference steps are always polynomially related  or in our terminology  whether weak polynomial transparency can be guaranteed for resolution. unfortunately  the answer to this question is no  too. there is an infinite formula class for which every resolution proof is exponential in size with respect to the input formula  whereas there are proofs that get by on polynomially many resolution steps. 
¡¡the next example specifies a formula class with this property. assume in the following that  for any 1   *   
in the deduction process  since untouched parts of the states are counted multiply. a finer model would count only the touched parts of the non-initial states. 
   1  for reasons of readability  we prefer to write clauses as disjunctions of literals; furthermore  we use the term 'formula' for sets of clauses. 
   1  it should be emphasized that the reason is indeed the renaming of derived clauses and not their multiple use as parent clauses. 

is the value of the i-th prime number  and that 
abbreviates a term of the structure 
example 1 for any positive integer n  let fn denote a horn formula consisting of the following structure: 

¡¡if in this class of horn formulae the function symbol 1 is interpreted as the successor function  and if the denotation of a predicate p  is the set of natural numbers divisible by the i-th prime number  then such a formula can be used to compute common multiples of primes. apparently  from these considerations we can derive the following lemma. 
lemma 1 given a formula fn of the type specified in 
example 1  let be any ground instance of the first clause c fn such that is unsatisfiable. 
then the largest occurring term in c1 must denote a common multiple of the first n prime numbers. 
¡¡since the least common multiple of a sequence  of primes equals   the following obvious result gains importance. 
lemma 1 there is no polynomial p such that for every positive integer n: 

   an immediate consequence of this result is that  cannot be polynomially bounded by the size .of the input formula fn. 
lemma 1 there is no polynomial p such that for every positive integer n: p size  where fn is a formula of the type specified in example 1. 
¡¡the formula class described in example 1 is intractable for resolution. 
proposition 1 there is no polynomial p such that for every positive integer n: p size fn   1 greater than the size of any resolution refutation for fn. 
¡¡in the proof of this proposition we shall exploit the fact that the formula class in question consists of horn clause formulae  for which the following lemma holds. 
lemma 1 // / is a resolution refutation dag1 for a horn clause formula  then t contains one branch b - called the negative branch-on which exactly the nega-
tive clauses of the refutation lie  i.e.  those clauses which are void of positive literals. 
   1a resolution dag  directed acyclic graph  is a rooted dag whose nodes are labelled with clauses such that every nonleaf node n has two outgoing edges to nodes n   n1  and the clause at n is a resolvent of the clauses at n1 and n1 a resolution refutation dag is a resolution dag whose root is labelled with the empty clause. 
proof of lemma 1 it suffices to notice that  on the one hand  in such a dag no non-negative clause can dominate a negative clause  and  on the other hand  every negative clause must be derived from a negative and a non-negative clause. 
proof of proposition 1 let t be an arbitrary resolution refutation dag for a formula fn  and let b be the negative branch of t  which exists by lemma 1. clearly  each occurrence of a negative clause on 1 is used only once as a parent clause in t. consequently  replacing all clauses on the branch 1 by appropriate ground instances does not alter the length of the branch  while the resulting dag remains a refutation-of resolution with free  i.e.  not necessarily most general  unification rule. if this partial instantiation is performed on t  the negative branch b' of the resulting refutation dag t' must contain ground instances 

	letz 	1 
the first approach is to weaken the transition relation and to define a transition relation l-'  for example  by taking out each pair  s  s'  which violates the logp size step-reliability  since this may be the problematic property  like in the case of resolution. the most radical method to perform this modification on the resolution calculus is to forbid the renaming or even the multiple use of lemmata. the latter results in the calculus of tree resolution. tree resolution is polynomially transparent  even in the strict sense  a proof can be found  e.g.  in  eder  1  or in  letz  1  . but unfortunately  this has the unacceptable consequence that many proofs are thrown out which are short in steps and small in size. 
 also  eliminating problematic pairs from a transition relation does not work for arbitrary transition relations. this leads to the second alternative. in order to preserve the problem solving functionality of the relation  that is  to guarantee that the transitive closures-or at least the provable states-of both transition relations remain identical  in the general case  each problematic step must be replaced by a series of computationally innocuous steps. for logic calculi  this amounts to a redefinition of the notion of an inference step. 
 both methods are relatively unappealing for the practical working with logic calculi  since in no case the wdetermintstic power of a calculus is increased  either it is weakened or it remains unchanged  and only the presentation structure of the calculus is modified. 
the real importance of the notion of polynomial transparency for the advance of science is that it can motivate research following the third approach. the third approach is to let the general structure of a transition relation as it is  and to try to remedy the polynomial intransparency of the transition relation. since the typical stumble-block for attaining polynomial transparency is the violation of the logp size step-reliability  a promising research direction consists of improving the data structures of the elements in the transition relation in such a way that they can be represented with less space than in the original relation  with the hope to gain polynomial transparency this way. the advantage of such an attempt  if it succeeds  is that the distances between the the first inequality holds because of properties of the arithmetical mean  while the others are trivial. ¡õ 
   the propositions 1 and 1 have as an immediate consequence that  even if only step-minimal proofs are considered  the number of steps of a resolution proof may not be a representative measure for the complexity of the proof. 
t h e o r e m 1 resolution for first-order logic is not weakly polynomially transparent. 
¡¡the violation of the logp size step-reliability turns out to be fatal  even if only short proofs are counted. 
1 m e t h o d s for o b t a i n i n g p o l y n o m i a l t r a n s p a r e n c y 
the situation is quite instructive  because we can illustrate at the example of resolution the three principal solution methodologies when facing the polynomial intransparency of a transition relation k 
elements in the transition relation can be preserved while the real computing cost and sizes properly decrease. 
   the difference between the solution methodologies is that the second approach always succeeds  whereas the third one may fail in principle.1 
1 i m p r o v e m e n t s of t h e r e p r e s e n t a t i o n of f o r m u l a e 
similar to the case of the unification operation  which  in order to attain the polynomial time step-reliability of an inference system  has enforced the necessity to represent logical terms as dags  one should think about the development of more sophisticated mechanisms which would admit a notation for resolvents polynomially bounded in 
1  such an impossibility result for resolution is proven in 
 letz  1 . there it is shown that there can be no data structure for achieving the strong polynomial transparency of resolution  if not the factoring rule is modified. this result indeed enforces a redefinition of the resolution inference step. 

size by the number of their derivation steps  with respect to the input formula. 
   an obvious improvement is to integrate into the object language the same vocabulary of upper indices we already used in our meta-language for the purpose of polynomially specifying terms of exponential depth. it is apparent that with the use of such number terms the transparency problems of the examples 1 and 1 can be solved  even polynomial transparency in the strong sense can be achieved for these examples. one can predict that number terms will play an important role in future automated deduction systems.1 
   we shall not pursue further the attempt of extending the representation of logical formulae  instead we want to present a critical example class which may turn out to be a hard problem for the efforts to achieve polynomial transparency- these new formulae are obtained from the previous class of example 1 by augmenting the arity of the function symbol s by 1. this means that the previous formula class is just an abstraction of the new class. 
e x a m p l e 1 for any positive integer n  let fn denote a horn formula of the following structure: 

   in the new class the second argument of the function symbol s does not play any role at all  the variables at these positions are just dummy variables. consequently  the results concerning proof steps and proof lengths carry over from example 1 to this example. but there is a crucial difference between both examples  which becomes apparent when self-resolution is applied to a clause of the mixed type in example 1. let us demonstrate this with the input clause corresponding to the prime number 1: 

in its self-resolvent 

the number of distinct dummy variables has doubled. in general  in any such self-resolution step the resolvent contains 1n - 1 more distinct variables than the original clause. accordingly  for this class of formulae  in 
1
¡¡¡¡ much more than polynomial unification algorithms  which have turned out to be relatively unimportant for the practice of deduction systems. this can be verified by observing that the examples  particularly example 1  for demonstrating the necessity of number terms are much simpler and occur more frequently in practice than the ones which demand polynomial unification techniques. 
any polynomial-step proof of an instance f n   clauses are needed in which not only the term depth is exponential  which could be remedied by using number terms in the object language  but also the number of distinct variables. and to this problem no obvious solution is in sight.1 
conclusion and further research 
this paper has illustrated that a formalization of intuitively existing abstraction concepts for logic calculi can be very fruitful. the developed notion of polynomial transparency promises to serve as a useful and researchstimulating property of deduction systems  and of transition relations in general. the main technical result of this paper is the demonstration that the number of inference steps of resolution proofs do not give a representative measure of the actual proof complexities  even if only shortest proofs are considered. 
   as further obvious research perspectives concerning the transparency problem of resolution and other calculi using the renaming of lemmata  we wish to mention the development of more sophisticated data structures than number terms; the clarification of the relation between strong and weak polynomial transparency; and finally  the study of the difficulties of rendering particular calculi polynomially transparent and the connection of these difficulties with certain problem classes in the polynomial hierarchy. 

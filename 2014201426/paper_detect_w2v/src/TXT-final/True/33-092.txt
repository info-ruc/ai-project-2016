: 	the 	current 	state 	of a 	theorem proving system 	 the 	markgraf karl 	refutation 	procedure  	at the 	university 	of karlsruhe 	is 	presented. 	the 	goal of this project 	can 	be 	summarized by 	the 	following three 	claims: 	it 	is possible 	to program a theorem 
prover  tp  and augment it by appropriate heuristics and domain-specific knowledge such that 
	 i  	it will display 	an 	'active' 	and directed be-
haviour in its striving for a proof  rather than the 'passive' combinatorial search through very large search spaces  which was the cha-
racteristic 	behaviour 	of 	the 	tps 	of 	the 	past. 
consequently  ii  it will not generate a search space of many thousands of irrelevant clauses  but will find 
a proof with comparatively few redundant derivation steps.  hi  such a tp will establish an unprecedented leap in performance over previous tps expressed in terms of the difficulty of the theorems it can prove. the results 	obtained 	thus 	far 	corroborate 	the 	first two claims. o. introduction 
the working hypothesis of this tp project  ds1   
 ds1   f i r s t formulated in an early proposal in 1  reflects the then dominating themes of a r t i f i cial intelligence research  namely that tps have attained a certain level of performance  which w i l l not be significantly improved by: 
 i  developing more and more intricate  refinement strategies  like unit preference  linear resolution  toss  mtoss     whose sole purpose 
is to reduce the search space  nor by 
  i i   using different logics  like natural deduction logics  sequence logics  matrix reduction 
methods etc  
although this was the main focus of theorem proving research in the past. 
the relative weakness of current tp-systems as compared to human performance is due to a large extent to their lack of the rich mathematical and extramatematical knowledge that human mathematicians have: in particular  knowledge about the subject and knowledge of hpw to find proofs in that subject. 
hence the object of this project is to make this knowledge explicit for the case of automata theory  to find appropriate representations for this knowledge and to find ways of using i t . as a testease and for the final evaluation of the projects success or failure  the theorems of a standard mathematical textbook  de1  shall be proved mechanically. 
in the f i r s t section of this paper we give a general overview of the system as it is designed  albeit not completed. the second section concentrates on those parts of the system  whose implementation is f i nished and evaluated. in the third section experimental results are given and the final two sections present an evaluation based on the present findings. 
1. overview of the system 
	a 	bird's-eye 	view 
proving a theorem has two distinct aspects: the creative aspect of how to find a proof  usually re-
garded as a problem of psychology  and secondly the logical aspect as to what constitutes a proof and how to write it down on a sheet of paper  usually referred to as proof theory. 
these two aspects are in practice not as totally separated as this statement suggest  see e.g.  sz1    however we found it sufficiently important to let it dominate the overall design of the system: 

the supervisor consists of several independent modules and has the complex task of generating an overall proposal  or several such  as to how the given theorem may best be proved  invoking the necessary knowledge that may be helpful in the course of the search for a proof and finally transforming both proposal and knowledge into technical information sufficient to guide the logic engine through the search space. 
the logic engine is at heart a traditional theorem prover based on kowalski's connection graph proof procedure  k1   augmented by several components that account for i t s strength. 
the data bank consists of the factual knowledge of the particular mathematical field under investigation  i.e. the definitions  axioms  previously proved theorems and lemmata  augmented as far as possible by local knowledge about their potential use. 
	a 	view from a leaser altitude 
the diagram of figure 1 sufficiently refines figure 1 to gain a feeling for the overall working of the system: 

nical assistant  ta   whose task is to transform this information  which up to this point is i n t e l l i g i b l e for a human user  into technical advice and code  which w i l l then govern the top level behaviour of the logic engine and is for that reason passed on to the monitor. 
the monitor governs and controls the global behaviour of the logic engine: immediately after a c t i vation it checks for an easy proof using the terminator heuristic  see section 1  and only upon 
failure activates the f u l l machinery of the logic engine. typical control tasks are detecting constant replications of the same lemma  detecting a circular development in the search space and keeping track 
of the 'self resolving' clauses. a good example how the monitor governs the top level behaviour is in i t s prevention of the unsteady behaviour which the system showed during earlier experimentation: the selection heuristics constantly suggest 'interesting' steps to take and forced the system to vacillate 
between different parts of the search speace -very unlike the behaviour of people  who  if put into the same situation  would tackle an interesting 
path until they either succeed or become somehow convinced that it was a blind alley. 
up to this point the decisions and activities of the pg and the ta are to a large extent based on the semantics of the theory under investigation and knowledge about proofs in this theory and their topgoal may be formulated as: to be helpful  in finding a proof . once they have done so  that topgoal becomes  to derive a contradiction  the empty clause   and although this goal is of course identical to the previous one  it implies that d i f f e rent kinds of information may be useful: the o r i ginal information provided by the pg based on the semantics  which is by now coded into various parameters  p r i o r i t y values and activation modules  as well as information based on the syntax  of the connection graph or the potential resolvent . 
it may be objected that this is the main goal of a traditional tp also. while this of course true  there is the important difference that a traditional  resolution based  tp is not dirextly guided towards this goal in a step by step fashion  as no refinement  l1  specifies which l i t e r a l to resolve upon next. for example linear resolution reduces the search space as compared to binary resolution  but within the remaining space the search is as blind as ever. 
the pg and the ta are currently under development and not implemented at the time of writing. 
1. the logic engine 
the logic engine is based on kowalski's connection graph proof procedure  k1   which has several advantages over previous resolution based proof procedures: there is no unseccessfull search for potentially unifiable l i t e r a l s   every resolution step is done once at most and the deletion of links and subsequently of clauses leads to a remarkable im-
1 provement in performance  which is heavily exploited in the deletion-module. most crucial to our approach however is the observation that since every link represents a potential resolvent  the selection of a proper sequence of links leads to the alleged active  goaldirected behaviour of the sy-
1. l 	input and output 
the interactive facilities are too numereous to account for here and instead a protocol of a typical session is presented at the conference. an interesting point to note is that the interaction at this level was only designed for the intermediate stages of development. it is now to an increasing degree taken over by the supervisor as it develops  with the intention to move the interface with the user althogether to the outside and to make the supervisor take most of the low level decisions. two sets of instructions however are to stay  the in-module is used to set up  and to read  the data bank in a 
way easily i n t e l l i g i b l e for the user. it also performs a syntactical and semantical analysis of the data bank  which is of considerable practical importance in view of the fact that it eventually contains a whole standard mathematical textbook. 
the protocol-module provides several f a c i l i t i e s for tracing the behaviour of the system at different degrees of abstraction in order to cope with i t s complexity. 
1 the monitor 
the deduction steps within the connection graph are governed and controlled by several modules  which are conceptually collected in the monitor. 
we shall give a brief summary of the task of each of these modules  although each module represents a software development of about the size of a traditional theorem proving system . only the heuristic selection functions are presented in more detail below. 

the splitting and reduction module is activated f i r s t and converts the i n i t i a l formulas into cnform subject to possible splitting and reduction 
operations  bl1 . the resulting set s  of en-formulas are then transformed into the i n i t i a l connection graph s   which again are substantically reduced by subsumption and purity checks  ei1    wa1 . 
the unification module contains special purpose unification algorithms for frequently occurring axioms like associativity  commutativity  idempotence and their combinations  and hence these axioms are re-
moved from the data base prior to activation. 
the refinement module simulates standard derivation strategies and most of the time only a small fraction of a l l links in the graph is declared active. for example if only the links emanating from a clause in the i n i t i a l set of support are declared active and subsequently only the links of each resolvent in turn are declared active and the pre-
vious one passive  by appropriate   on-off-switches'   the resulting derivation is linear. the refinementmodule allows to chose among some of the standard strategies and setting refinements cl1 . this has turned out to be advantageous  since it substantially reduces the number of active links and hence the expense for the computation of the heuristic selection functions and the most successful runs 
were obtained with this 'mixed approach'. the decision  which refinement to choose  is taken by the monitor based on some genereal heuristics. 
the planning module is currently under development and contains additional  heuristically motivated  splitting and simplification routines for the connection graph as well as planning capabilities for 
proof plans. 
the tracking module controls the logic engine and detects circular developments in the search space  constant reapplication of the same lemma etc. 
the focussing of attention module prevents the unsteady behaviour mentioned in section one and ensures that theorems and lemmas selected by the supervisor are used in preference to other clauses. both activities are achieved by special weights attached to the links in question. 
the definition expansion module exists in a rudimentary form only: as more complicated examples are tried  more refined heuristics are necessary to control the expansion process  i.e. the replacement of the defined l i t e r a l by its defining clauses. 
the rule base contains lemmas in the form of a production system and each time the if-part is satisfied the then-part is added to the current connection graph. 
the rewrite rule module contains simplification and reduction rules in the form of rewrites  which are applied to the terms of the i n i t i a l graph  as well as to every generated resolvent. 
the deletion-module heavily exploits the crucial property of this proof procedure that distinguishes it from other proof procedures based on graphs  sh1    si1 : the fact that the deletion of links and clauses can lead to a snowball effect of further deletions. because of this effect it is worth every effort to find and compute as many criteria for potential deletions as possible. at present a clause is marked for deletion i f : 
 i  it is pure  wa1  
 ii  it is a tautology  nasi  
   i i i   it is subsumed by some other clause  ei1  and this information has absolute priority over the relative priorities to be discussed below. 
the factoring module controls the factoring of clauses  which is based on special types of links in the connection graph. 
   in contrast to the global search strategies and global heuristics  the heuristic selection functions of the heuristic-module 
are based on local eyntaotical information about the graph or the resolvent  pararoodulant  respectively u s e i l these heuristics wars obtained with two types of experiments: in the f i r s t experinent a human testperson is asked to prove a given set of formulas by resolution without any information on the intended meaning of the predicate or function symbols  then the same set is proved by the system and in case i t s performance is inferior  the analysis of the deviation  and introspection of the test-
person on why a particular step was taken  can give valueable hints for further heuristics. 
in the second type of experiment the system is set to prove a theorem. in the case of success  an analysis of the protocol  where in the l i s t i n g of a l l steps the steps necessary for the proof are marked  provides a remarkably good source of ideas for improvement  particularly if the reason why a certain step was chosen  is also printed in the protocol l i sting. during the last two years several hundreds of such listings were analyzed. 
i n i t i a l l y we experimented with about 1 different heuristic feature*  where each feature attaches a certain value to every link k in g.. 1. is the present graph  g. is the resulting graph after resolution upon linx k and res is the resolvent resulting from this step: 

the problem is that although each heuristic feature has a certain worth  the cost of i t s computation can by far outweigh i t s potential contribution. also it may not be independent of the other heuristic features; for example features  xi  and  xii  both measure the  degree of groundness of res   but in a different way. similarly the values for res and for g i + 1 are not independent for certain features  e.g. x i i i and v l i   . also there are the two problems of finding an appropriate mtrio for each feature and to decide upon their relative worth in case of conflict with other features. 
the information contained in the heuristic features is entered in different ways: certain facts  e.g. decreasing sise of the graph  have absolute priority and override a l l other information  see also the merge feature of tt in  da1  . most of the information of the other features is expressed as a real number in  1   where we experimented with several  linear  nonlinear  metrics. this information is then entered in a weighted polynomial and the resulting real number  the p r i o r i t y value  expresses the relative worth of the particular link and is attached to each link. in case of no overriding i n formation the control-module selects the link with the highest p r i o r i t y value. s t i l l other information is entered using the  window-technique : among the links whose p r i o r i t y value is within a certain i n terval  the 'window'   the control-module choses the one which minimizes some other feature. 
the system has been designed such that heuristic features can easily be added and deleted  however after two years of experimentation the system has stabilized with the following solution  stabilized in the sense that neither the addition of heuristics from the above l i s t nor the use of different metrics 
w i l l significantly change the performance of the system on an appropriately large set of tests : 

these features influence the actual derivation in the following way: a l l steps that lead to a reduction in the size of the graph have absolute priority and are immediately executed. that i s   every link which leads to a graph with fewer clauses or fewer links or both is put into a special class  which is executed before any further evaluation takes place. the decision whether or not a link leads to a reduction is based on information from the deletion-module and is optionally taken for every link or for the active links only. note that the re-
duction in the size of the graph may lead to further deletions  hence a potential snowball effect of deletions is carried out immediately  which accounts for the f i r s t main source of the strength of the 
system. 
all other features have a relative priority and are classified as situation dependent and situation i n dependent respectively  since the cost of their i n i t i a l computation and later updating differs fundamentally  ss1 . 
a successful usage of the relative priorities depends on an appropriate metric for each feature  which expresses its estimated worth. a discussion of why the following metrics where chosen is outside of the scope of this paper and may be found in  ss1 ; but the important point to notice i s   that each metric displays a particular characterietio  which expresses the heuristic worth relative to i t s argument. 

1 



tation of clauses 	 the connection graph  into a 
proof procedure  baaed on connection graphs  as it defines a particular selection function  which maps graphs to links. this mapping is complex and based on information provided by several modules  but for clarity it is entirely contained in the control-nodule. 
it should not be necessary to say that the complex interplay of the various modules  which 'suggest' which step to take next  prevents of course the overall deduction from being 'standard* and the respective completeness results do not necessarily hold. however  by an appropriate setting of the weight for face  it is impossible for a link to be ignored indefinitely for selection and for that reason we believe the system is complete. 
the potential explosion of links is the bottleneck of the connection graph: the following 'challenge' proposed by p. andrews  carnegie mellon at the 1 deduction workshop  provides a point of demonstration: 	¡ö 
the i n i t i a l graph of this formula consists of a l most 1 links and several hundred new links are added to the grpah for each resolution step. if a l l these links were declared 'active'  the computation of the selection functions would become intolerably expensive. 
in our system the example is s p l i t   reduced and subsequently deleted to a graph never exceeding 1 links and easily proved within a few steps. even for 
more 'natural' examples  the number of deletion steps is about one third and sometimes over one half of the total number of steps. 
scorn 	technical data about 	the project 
name of project: incorporation of mathematical knowledge into an atp-system  i n vestigated for the case of automata theory. 
funding agency: german research organisation  dfg  bonn  de 1  de 1. 
tim period: 1 to 1  six years  machine: siemens 1 
minimally required storage space: 	1 k 	 virtual memory  
languages: 	siemens-interlisp cep1  
present size of system: 	* 1 k of source code 
effort: 	* 1 manyears for i t s implementation 
with more than 1 k of actual code at present and approximatly 1 k under design for the next two years  the system is the largest software development undertaken in the history of automated theorem proving and it may be indicative for the changing pattern of research in this f i e l d . 
1. performance statistics 
to gain a feeling for the improvement achieved by the system  figure 1 gives a sample of some test runs. in order to avoid one of the p i t f a l l s of stat i s t i c a l data  which is to show the improvement achieved on certain examples and not showing the 
deterioration on others  the system is to be tested on a l l of the main examples quoted in the atp l i terature:  wm1    m1    kryku1j. of a l l exanples tested thus far  the examples of figure 1 are representative  and wore tease  i.e. a l l other examples 
were even more favourable for our system . the examples of figure 1 are taken from the extensive  comparative study undertaken at university of maryland  wm1   where eight different proof procedures 
were tested and statistically evaluated on a total of 1 examples. 
       the table is to be understood as follows: the f i r s t column gives the name of the set of axioms in  wm1   e.g. ls-1 in line 1. the next three columns quote the findings of  wm1   where the figure in brackets gives the value for the worst proof procedure among the eight tested procedures and the other figure gives the value for the proof procedure that performed best. the final three columns give the corresponding values for the markgraf karl procedure. for example  in order to prove the axiom set ls-1  line 1  the best proof procedure of  wm1  had to generate 1 clauses in order to find the proof  which consisted of 1 clauses  and the worst proof procedure had to generate 1 clauses in order to find that proof. in contrast our system 
generated only 1 clauses and as these figures are typical and hold uniformly for all cases  they are the statistical expression and justification for the first two claims put forward in the abstract. 
1. kinship to other deduction systems 
the advent of planner  he1  marked an important point in the history of automatic theorem proving research  ah1   and although none of the techniques proposed there are actually present in our system it is none the less the product of the shift of the research paradigm  of which planner was an early hallmark. 
the work most influential  which more permeates our system than is possible to credit in detail  is that of w. bledsoe  university of texas  bt1    bb1    bb1    bl1    bl1   in contrast to  bt1   we tried to separate as much as possible the logic within which the proofs are carried out from the heuristics which are helpful in finding 
the proof. 
the strongest resolution based system at present is  m1   and we have tested their examples in our system. comparison with their reported results  shows that if our system finds a proof it is superior to the same degree as reported in figure 1. 
however  there are s t i l l several more difficult examples reported in  mow1  which we can not prove at present. the strength of the system  m1  derives mainly from a successful technique to handle equality axioms and almost all the examples quoted in  m1  rely on this technique. for that reason  as long as our paramodulation module is not fully equipped with proper heuristics there is no fair comparison  the test cases were obtained with the f u l l set of equality axioms and no special treat-
ment for the equality predicate . 
finally among the very large systems which presently dominate theorem proving research is the system developed by r. boyer and j.s. moore at sri  bm1 . their system relies on powerful induction techniques and although some of the easier examples quoted in  bm1  could be proved by our system at present  a justifiable comparison is only possible once our induction modules are completed. 

1 

a theorem prover based on heuristic evaluation was also reported by slagle and farrell  sf1  however it appears that such heuristics are not too successful for an ordinary resolution based prover. 
1. conclusion 
at present the system performs substantially better than most other automatic theorem proving systems  however on certain classes of examples  induction  equality  the comparison is unfavourable for our system  section 1 . but there is l i t t l e doubt that these shortcomings reflect the present state of development; once the other modules  t-unification  paramodulated connection graphs  a far more refined monitoring  induction  improved heuristics etc  are operational  traditional theorem provers w i l l no longer be competitive. 
this statement is less comforting than it appears: the comparison is based on measures of the search space and it totally neglecte the  enormous  resources needed in order to achieve the behaviour described. within this frame of reference it would be easy to design the  perfect  proof procedure: the supervisor and the look-ahead heuristics would find the proof and then guide the system without any unnecessary steps through the search space. 
doubtlessy  the tp systems of the future w i l l have to be evaluated in totally different terms  which take into account the total  time and space  resources needed in order to find the proof of a given theorem. 
in summary  although there are good fundamental arguments supporting the hypothesis that the future of tp research is with the finely knowledge engineered systems as proposed here  there is at present no evidence that a traditional tp with i t s capacity to quickly generate many ten thousands of clauses is not just as capable. the situation is reminiscent of todays chess playing programs  where the programs based on intellectually more interesting principles are outperformed by the brute force systems relying on advances in hardware technology. 
references 
 ah1  b. anderson  p. hayes: an arraignment of 
theorem proving or the logicians f o l l y   
coop. logic memo 1  univ. of edinburgh 
 bb1  n. ballayntyne  w. bledsoe: autom. proofs and theorems in analysis using nonstandard techniques  atp-1  1  univ. of texas  bbh1  w. bledsoe  b. boyer  hemmeman: computer proofs o f l i m i t theorems  j . a r t . i n t e l l i g . v o l 1  1 
 bl1  w. bledsoet s p l i t t i n g and reduction heuris t i c s i n atp  j . a r t . i n t .   v o l 1   1 
bl1 w. bledsoe: a maximal method f o r s e t v a r i a b l e s in atp  atp-1  univ. of texas  1 
 bn1  r.s. boyer  j . s . moore: a computational log i c   sri i n t e r n .   comp. s c i . lab.  1 
bt1 w. bledsoe  m. tyson: the ut i n t e r a c t i v e prover  univ. of texas  atp-1  1 
 da1  j . l . d a r l i n g t o n : connection graphs and fact 
nets  i n t e r n . rep.  gmd bonn  i . s . t .   1 
 da1  j . l . d a r l i n g t o n : connected fact nets and 
automatic programming  gmd bonn  i.s.t. 1 
cda1  j . l . d a r l i n g t o n : a net based theorem proving procedure f o r program v e r i f i c a t i o n and synt h e s i s   1th workshop on a r t . i n t .   bad honnef  1 
 de1  p. deussen: halbgruppen und automaten  
	springer 	1 
 ds1  p. deussen  j. siekmann: neuantrag sum forschungsvorhaben 'untersuchung zur einbesiehung mathematischen wlssens beim automatischen bewelsen am b e i s p i e l der automatent h e o r i e *   dfg-forschungsprojekt  as. de 1 
1 
 ds1  p. deussen  j. siekmann: zusatsantrag sum forschungsvorhaben *untersuchung sur einbeziehung mathematischen wlssens beim autom. 
bewelsen am b e i s p i e l der automatentheorie *  
	dfg-projekt de 1 1 / 1   	1 
 ei1  n. e i s i n g e r : subsumption and connection graphs  u n i v e r s i t l t karlsruhe  1 
 ep1  b. epp: interlisp programmierhandbuch  i n s t i t u t f a r deutsche sprache  mannheim 
 he1  c. h e w i t t : d e s c r i p t i o n and t h e o r e t i c a l anal y s i s of planner  ai-tr-1  mit 
1 

 hu1  g. huett confluent reductions: a b s t r a c t properties and a p p l i c a t i o n s to tern rewriting systems  	1th ieee symp. on pound  of coop. 
	s c i e .   	1 
 k1 r. kowalski: a proof procedure based on 
connection graphs  jacm  v o l 1  no 1  1 
 ia1  d.s. lankford  a.n. b a l l a n t y n e : complete sets of p e m u t a t i v e reductions  atp-1  
atp-1  atp-1  univ. of texas at a u s t i n   
1 
 l1  d. loveland: automated theorem p r o v i n g   north holland  	1 
 n1  j. nccharen  r. overbeck  l. nos: problems and experiments f o r and w i t h automated theorem proving programs  ieee transae  on computers  vol-c-1  no 1  1  rrykv1  reboh  raphael  yates  k l i n g   velarde: 
study of automatic theorem proving programs  
1  stanford research i n s t i t u t e   sri-tn-1 stanford 
 sf1  j.r. s l a g l e   c d . f a r r e l l : experiments i n automatic learning f o r a multipurpose heur i s t i c program  cacm v o l 1  1 
 si1  j. siekmann: mathematical reasoning as done by man and machine  report  forthcoming   u n i v e r s i t a t karlsruhe  1 
 sh1  r.p. shostak: r e f u t a t i o n graphs  j. of a r t . 
	i n t e l l i g e n c e   v o l 1  no 1  	1 
  s i 1   s. s i c k e l : i n t e r c o n n e c t i v i t y graphs  ieee 
	trans  on computers  v o l c-1  no 1  	1 
 sb1  j. siekmann  k. bl&sius: forschungsvorhaben zur behandlung des gleichheitspradikates beim automatischen beweisen  u n i v e r s i t a t karlsruhe  1 
 ss1 j. siekmann  g. smolka: selection h e u r i s t i c s   d e l e t i o n s t r a t e g i e s and n-level-terminator 
	s i t u a t i o n s i n connection graphs  	u n i v e r s i t & t 
	karlsruhe  seki-report  	1 
 sw1  j. siekmann  g. n r i g h t s o n : paramodulated 
	connection graphs  acta i n f o r m a t i c a   	1  
1 
 sz1  p. szabo: the c o l l e c t e d papers of g. gentsen  north h o l l a n d   1 
 wa1  c. n e i t h e r : forschungsvorhaben zur automat i s i e r u n g von induktionsbeweisen  u n i v e r s i ty t karlsruhe  	1 
 wm1  g. wilson  j. minker: r e s o l u t i o n   refinements and search s t r a t e g i e s ; a comparative study  ieee transac. on comp.  v o l c-1  no 1  	1 
 ma1  c. n e i t h e r : e l i m i n a t i o n of redundant links in extended connection graphs  	springer 
	fachberichte  v o l 1  	1 
references 

 heuristic methods from the program descriptions  which are often quite technical and detailed. 
　　　one example of this w i l l suffice. the sin program contains an important heuristic  which moses describes as follows:  the edge heuristic is based on the liouville theory of integration. in this theory it is shown that if a function is integrable in closed form  then the form of the integral can be deduced up to certain coefficients. a program which employs the edge heuristic  called edge  uses a simple analysis to guess at the form of the integral and then it attempts to obtain coefficients.   page 1 . the edge heuristic is further described on seventeen pages in chapter 1-
　　　unfortunately  the author fails to formulate this important heuristic method in abstract terms. such an abstract formulation could e.g. run as follows: the purpose of the integration program is to start from a given  i n i t i a l object  and to apply the right operators  from a given set of operators  in the right order  u n t i l the given object has been transformed into a given target set   i . e . the set of a l l expressions where the integral sign s  have been eliminated . the edge 
heuristic relies on information which is local to this particular problem environment  and which makes it possible to say  during the search of the solution tree  where in the target set we w i l l eventually land. the edge program utilizes this information to get a better estimate of the remaining  distance  to the target set from each node. - with such a description  it becomes clear that the same heuristic may well be applicable to other problem environments  in other expertiseoriented programs. 
-1-　　　abstract method descriptions  as outlined here  can of course not serve as substitutes for conventional ones. a concrete description  like the one moses has given for sin  w i l l always be needed by the user of the program  or the researche who attempts to improve on previous 
work. by contrast  the abstract description is useful for the man who wants to carry over methods to other problem environments  and  of course  for the theoretician who  some time in the future  w i l l attempt to build a mathematical theory of heuristics. 
　　　the morale i s   therefore  that we need an abstract frame of reference  a set of concepts for describing and analysing heuristic methods. such concepts would help in the dissemination of know-how; they would also make it possible to compare the efficiency of various methods and 
programs  expertise-oriented as well as generalityoriented. 
　　　in this report  we shall attempt to set up such a  frame of reference . in section 1  we formulate a general  transformation problem   and discuss some of i t s cases. in sections 1  various commonly used heuristic techniques are formulated and discussed. since we argued  in section 1  that one-input and multiple-input operators must be carefully distinguished  we use section 1 to extend the conventional search tree into a search l a t t i c e . our stock of concepts is tested in sections 1  where abstract descriptions of some well-known programs and heuristic methods are given. 
1. heuristic search: rules of the game 
　　　the problem environments for heuristic search methods always include a set p of objects and a set q of operators on these objects. the following problem has often been studied   see e.g. {newell 1c} and {doran 1a}   and has sometimes been referred to as the problem-solving problem: 
basic transformation problem. 
　　given an i n i t i a l set determine r in r and q    q 1   . . . q in q such that 

exists and is a member of the target set m. we call this a transformation problem from r to m. 
　　　a method for solving basic transformation problems is called a heuristic search method if it searches the tree s  of a l l possible operator applications  and the order in which the nodes of this tree are inspected  is governed in some ways by properties of the nodes which have already been created. heuristic methods require  therefor  that the objects in p are known as symbolic expressions or otherwise have a non-trivial information content. they cannot simply be non-informative tokens of the form   p .   . the following variations to the basic transformation problem occur frequently: 
operators with several outputs. 
　　　the problem specification is changed as follows. application of an operator can return a set of objects  rather than a single object. in the transformation process  each output of the operator must then be transformed into the target set. 
example: in analytic integration  the target set m consists of the set of a l l formulae where the integration sign does not occur. the rule 

can be used as an operator 	q 	defined by 

in other words  q t e l l s us to integrate a + b by integrating a and b separately.  the f i n a l task of joining together the solutions to those two integration problems with a + sign is a t r i v i a l matter . 
operators with several input. 
　　　the problem specification is changed as follows. i n i t i a l l y   each member of 	r 	is considered 	/ available. at each cycle of.the solution process  one selects one operator  which requires 	i 
arguments  and 	i 	available objects 

is defined  it is included among the available objects. problem: find some available object which is also a member of m . 
exemple: this variation frequently occurs in  forward  logical inference  e.g. in the resulution logic environment. it has been common practice 
in heuristic research to consider the cases of several inputs or several outputs as t r i v i a l extensions of the one-input/one-output case. for example  the general problem solver is formulated in terms of one input operators  and then immediately applied to a problem environment where a two-input operator  modus ponens in forward proof  is essential. similarly  slagle r s group have attempted to use their multiple program  which is designed for one-input  multiple-output operators  to the resolution logic environment  where the most important operator has two inputs and one output. 
　　　the fact that an operator requires several inputs can be  hidden  in various ways. in the case of modus ponens  which takes a and  as 
inputs  one can say that the operator  essentially  
takes 	as input  so that the merit of an formula determines whether the operator -
shall be applied or not. if the system decides to apply modus ponens to a formula  it checks whether the formula a is available. if it is not  the output is   f a i l u r e     - another  and more general way of hiding multiple inputs is to consider the set of a l l available objects as a  higher level  object. similarly  the operators are redefined to accept one higher level object as input  and to emit an incremented object as output. the disadvantage of a l l such tricks is that important information gets lost to the system. for example  with the 

1-

introduction of  higher level  objects and operators  one w i l l have 

  except when 	is essential for the 
application of q  or q p  - p is essential for the application of q'  . it is hard to make traditional tree-search routines  aware  of such commutativity. in our opinion  one should instead face the fact that some operators take multiple inputs  and study then separately. 
　　　thus the failure to recognize multiple-input operators has led to inefficient programs. it has also led to a regrettable lack of communication: techniques which have been designed for handling multiple-input operators  e.g. the various  strategies  for the resolution method  have not been recognized as heuristic methods. people seem to think that they are technical details for handling resolution  whereas in fact they are examples of quite general heuristic principles. one can make a parallell with the  edge  heuristic discussed in section 1: general principles have gone unnoticed for lack of abstract concepts to phrase them i n . 
　　　as a f i r s t step to remedy this situation  let us introduce separate names for the various kinds of operators. the following terms are believed to be i l l u s t r a t i v e : 
number of inputs 
one one 
multiple multiple number of outputs 
one 
multiple one multiple name 
perporator diporator 
conporator fociporator our second step is to introduce a formalism and a vocabulary which enables us to deal with these different kinds of operators. the formalism is based on lattice theory  and requires a section  section 1  of i t s own. 
　　　our third step w i l l be to illustrate these general concepts and principles by re-interpreting some current heuristic methods  including the unit preference strategy in resolution . this is done in sections 1 and 1. 
　　　some other complications which may occur in the basic transformation problem are: 
operators with or-connected outputs. 
　　　one often encounters operators which  like diporators  yield a set of objects of outputs  but which merely require that one of the outputs is to be transformed to the target set. such orconnections may occur 
 a  i n t r i n s i c a l l y     i n order to prove prove a  or prove 
 b  because the operator is ambigous  e.g. in resolution logic  where the resolution operator takes two clauses as input and gives one clause as output. each of the two clauses is a set of 
l i t e r a l s   and the operator  annihilates   in a certain sense  two l i t e r a l s   one from each input. the operator has one output for each combination of l i t e r a l s in the two inputs  and is therefore ambiguous. 
 c  because the operator requires a parameter  which may or may not be in the set of objects. for example  in order to prove b in conventional predicate calculus  it is sufficient to prove a and    where a is arbitrary. 
we shall refer to a l l operators which yield oroonnected outputs  as ambiguous. thus  a  exemplifies an ambigous perporator   b  an ambiguous conporator  and  c  an ambiguous diporator. 
s t i l l another complication is 
operators with restricted domain  i.e. a domain which is a proper subset of the set p. some possible ways of dealing with this complication are discussed in section 1. 
example: in integration  the partial integration operator is not always applicable. 
a f i n a l complication is 
no back-up. 
　　　in typical problem-solving  application of an operator is never irrevocable: we are always permitted to back up in the solution tree and try some other operator on a previously used object. in some situations  e.g. the edinburgh studies of heuristic automata   one encounters similar problems where back-up is not permitted. the transformation problem the* boils down to the problem of selecting the best operator in each step. 
　　　sometimes  e.g. in planning  a back-up problem can be transformed to a no-back-up problem  or vice versa. we therefore consider both kinds as variants of the same basic problem. 
　　　summing up  transformation problems can be characterized by a couple of features  i.e. 
 1  what kinds of operators   per-  con-  d i -   foci-porators  
 1  are operators ambiguous  
 1  are there restrictions to the domain of operators  
 1  is back-up permitted  
1. approaches to heuristic search 
　　　in this section  we shall attempt to classify and name some methods of heuristic search. our classification w i l l be put to use in the next few sections  where some previously published methods for heuristic search are reviewed. 
　　　in example  b   we assume forward proof  and in  a  and  c  backward proof. 

-1-

　　　in each cycle of the heuristic search process  the program should select one operator to use  and one object  viz. set of objects  to use it on. object selection seems to be performed in most cases by either of the following two methods: 
 al  labyrinthic methods proceed doan the search tree  and have an explicit mechanism for deciding direction in the tree.* this mechanism t e l l s the program  this is a good branch  go on the same direction   or  this is a bad branch  back up - steps and select another branch . 
 a1  best bud methods use an evaluation function which assigns a p r i o r i t y or merit to each growth direction  bud  in the tree. at each cycle  the program takes a global look at a l l the buds  selects the best one  sprouts i t   and iterates the cycle. in the new cycle  the best bud from last cycle is no longer a candidate  but it has yielded several new buds. a l l other buds from last cycle are candidates anew. back-up occurs automatically if the new buds are unable to compete with the stand-by buds from last cycle. 
　　　methods  al  and  a1  have been formulated for perporators. it is easy to extend them to diporators. for conporators  it is sometimes a good idea to select one input to the operator according to a labyrinthic or best-bud method  and then to select  best companions  to the selected f i r s t input. we consider this the generalization of  al  and  a1  to multiple-input 
operators. a third method cathegory for them would be 
 a1  best bud bundle methods  which use an evaluation function which assigns a p r i o r i t y to each combination   bundle   of  buds   and selects the best one in each step. 
gps and sin use labyrinthic methods  whereas 
saint  the graph traverser  multiple  and pps use best-bud methods. the unit preference heuristics  strategy  in resolution is an example of a best bud bundle method. 
　　　another  and at least in principle  independent  basis of classification is how the program selects the operator in; each cycle. the following methods have often been used in practice: 
 bl  object s  f i r s t   one operator afterwards method; first select the most promising object s  to work upon  according to a labyrinthic or best-bud method. after that  find a good operator to apply to it  them . 
 b1  exhaustive method: select object s  like in  bl  and apply a l l operators to i t . 
 b1  object s  f i r s t   a few operators afterwards method: a compromise between  bl  and  b1 : 
　　　as we shall see later  we sometimes have a 
　　　l a t t i c e rather than a simple tree. 
a few  but not a l l   operators are selected and applied to the object s . 
 bk  object and operator together method: consider a l l possible object-operator combinations and select one of them  using a p r i o r i t y function.  this is in other words a best-bud method  where each object-operator combination is considered as a  bud .  
the multiple program is an example of  b1   
gps and saint are examples of  b1   whereas unit preference and pps are examples of  b1 . the version of the graph traverser described in { doran 1a} is an example of  b1   whereas the later version described in {michie 1a} is of type  bl . 
　　　in methods  b1  and  b1   object selection in one cycle is effectively a choice of operator in the previous cycle. therefore  they can be considered as special cases of  bl   with a very careful and timeconsuming method for operator selection. 
　　　the four cases above are clearly not exhaustive  as it is in principle quite possible to run an operator f i r s t   object afterward method. also  labyrinthic instead of best-bud selection of operators is possible  one would keep using the same operator u n t i l a  back-up  or  change operator  criterion is satisfied . however  these possibilities are probably useless for practical problems. 
　　　if the number of operators is very large  or if some operators are ambiguous with a large number of alternatives  then it is not possible to search through a l l possible cases. this excludes  b1  and  b1  methods. one must f i r s t select the proper object s   and then use a function which selects one or a few operators  and ways of applying them  if ambiguous . usually  this function recognizes features in the given object  features which determine what operators may be suitable. 
　　　in many practical problem environments  one encounters operators which are only defined on a subset of the set p of objects. this restriction has been dealt with in at least two ways  which provides us with a classification in s t i l l another dimension: 
 cl  consider as f a i l u r e . if we have heuristically selected an object and an operator  and it turns out that the object is not in the domain of the operator  then give up this branch and try something else. 
 c1  solve sub-problem. let mr be the domain of the operator. solve the transformation problem from the given object to m1  and apply the given operator to the result. formally  we extend the definition of our operators  so that q p  ＊ q. pi    vhere p1 is the  possibly ambiguous i  solution to the transformation problem from p to the domain of 
1.   

-1-

　　　saint uses a type  cl  method  whereas gps and pps use type  c1  methods. 
　　　in conclusion  we have pointed out three features in heuristic methods. these features can be used to classify and characterize the methods. they are: 
 a  mode of object selection 
 b  mode of operator selection 
 c  way of handling restricted domains for operators. 
k. some frequent techniques in heuristics. 
in this section  we shall discuss the use of 
 merit orderings   plans  and feature vectors   images   in heuristic methods. 
use of merit orderings. 
　　　definitionwise  best-bud methods require that there exists a way of selecting the  best  one from a set of buds. in a l l best-bud-type methods known to the author  this selection is based on an  explicit or implicit  partial ordering   on the set p of objects. some maximal bud according to     i . e . some bud b such that no other bud satisfies  is then selected as  best bud   and is sprouted. 
　　　in some  but not in a l l cases  the merit ordering   is implemented as an explicit merit assignment function e   i.e. a mapping from p to the set of real numbers.   is then defined in an obvious manner through 

　　　the problem of finding a suitable merit ordering for a given problem environment is of course crucial. often  it is thought about as an 
estimate of distance. one attempts to define a 
function 	d   where 	is a rough estimate 
of the work  the number of operator applications  
required t o transform 	i n t o . 	similarly  
one attempts to compute 

for reasonable sets b . the merit function e is then defined e.g. as 
　　　the use of merit orderings is not restricted to best-bud methods. in labyrinthic methods  the criterion for abandoning a path and trying another may be that 	by some merit ordering. 
the gps u t i l i z e s exactly this heuristics. 
　　　the name  general problem solver  has sometimes been criticized as being too uninformative. it is natural to call a heuristic method goaldirected if i t s merit function is defined through d. the variant of gps described in {newell 1la} can then be characterized as a goal-directed perporator search method. 
　　　at f i r s t sight  the idea of using a merit ordering has much appeal. on closer scrutiny  it turns out to be less than obvious. it a l l depends on what kind of economy we desire. 
　　　suppose we are solving a transformation problem for perporators  and that we have already searched part of the tree. then which of the following quantities do we want to minimize in our next step: 
 dl  the number of steps   i . e . operator applications  in the  solution path  from the i n i t i a l set r to the target set m   
 d1  the remaining number of steps in the  solution path  from the selected bud to a member of the target set m   
 d1  the  remaining  number of steps  including steps that are performed in blind alleys   i . e . the t o t a l number of arcs in the solution tree the way it looks when we have reached m   
 dm the quantity mentioned in  d1   except that if a path is trodden  abandoned through back-
up  and then resumed  the steps which are trodden several times shall be counted ab multiple steps  
　　　if the path to the solution of the transformation problem is to be used as a plan for a more expensive activity in another environment  then  dl  is of course the correct criterion. on the other hand  if we are interested in a member of m  rather than in the path to this member  e.g. if we are searching for a solution to an integration problem   then  d1  or  d1  would be the correct quantity to minimize.  d1  should be used if the entire search tree is stored in memory  and  d1  should be used if the search tree is stored implicitly on the push-down-list  so that abandoned paths are garbage-collected and a l l work there has to be re-performed.  d1  is sound in no-back-up situations  like doran's heuristic automaton. 
　　　if criterion  dl    d1   or  d1  is to be used  then the  merit  of a bud is not simply a function of that bud and the target set  but instead a function of the srhole  stump  of the solution tree that has been searched up to now. for example  if the criterion  d1  is used  then the remaining work from a bud is affected if there exists some other bud which has almost as much merit  and which in the future may attract the problem-solver's attention for blind-alley work. it follows that the idea of a merit ordering is sound only if we want to use criterion  d1 . 
　　　although theoretically shaky  the use of merit orderings seems to be the only available technique today. if c r i t e r i a  d1  or {d1  are relevant  which is usually the case   then the use of a distance estimate as a merit function is even more questionable. we shall treat this question in a later paper. but again  the distance estimate seems to be the only technique we have. 

-1-

use of plans. 
　　　let p  1 q  r  and m define a transformation problem for which a solution is known  and let p'  q' = q  r'   and m' define a transformation problem which is to be solved. assume also that there exists some mapping h which maps p1 onto p  r' onto r  etc. in such a way that if p and q p  are steps in the known solution  and if p = h   p '     then q p  = h q p'  . in other words  the function h maps solutions in p' onto solutions in p. then we can clearly find a solution in p' by just retracing the solution in p *. the solution in p w i l l be referred to as a plan for the solution in 
p'. 
　　　this ideal situation probably never exists  except when h is the identity function. however  it may be the case that the requirement q p'  = h q p   often  though not always  holds. then it can s t i l l be a good strategy to t r y to follow the plan. if it does not work  we have to take resort in another plan  or in the object-operator selection methods mentioned above   in other words  use of plans may be considered as yet another method   b1   of operator selection . 
　　　plans can be generated in several ways  e.g. by memorization of previous  successful solutions  doran's heuristic automaton   by human advice  or by  look-ahead : solution of an analogous problem in an auxiliary problem space  e.g. in the planner system and the pps . 
　　　when the problem environment is predicate calculus  the  abstraction function  h can e.g. be selected so as to throw away everything except the variables in the formulas  planning gps  or to throw away everyting except the boolean connectives  planner . 
a third technique is 
use of images. 
　　　by an image  we mean an item which expresses some  but not a l l the information of an object in the set p. the image may be for example  a vector of features in the object  or  in the case of a lisp-type formula   the top-levei structure of the object  with lowerlevel sub-expressions being replaced by asterisks. although they rarely talk about it in abstract terms  many creators of heuristic programs do in fact use such images. images are used for several purposes  including: 
  l   as a basis for merit functions  a numerical value is assigned to each feature  and merit is computed as a weighted average of the feature values  or distance functions computed as a wighted average of distance  
　　　to insure that we have a solution  we must assume that only members of m' are mapped into m  
i.e. 
n p f     m o p ' ♀ m' 
moreover  it is essential that r1 is mapped onto 
 rather than into  r  and that m' is mapped onto 
m. 
between features ; 
 1  as objects in an auxiliary problem space used for planning; 
 1  in methods of type  b1   for the selection of operators that should be applied to a given object. 
examples:  l  game-playing programs and  with certain modifications  doran's heuristic automaton;  1  planning gps  planner  pps;  1  gps. 
　　　in this section  we have described and classified general heuristic techniques  and given references from each technique to actual programs which utilizes i t . in sections 1  we shall build an inverse system of references. each section w i l l review one heuristic program in terms of the classification and concepts above. 
1. lattice instead of trees. 
　　　heuristic search is often referred to as tree search. however  the tree model is only applicable to cases where a l l operators are perporators or  with some extra conventions  diporators. with conporators  the need for a more general structure arises. in this section  we shall suggest one possible way of performing the generalization. 
　　　instead of a solution tree  we shall introduce a solution l a t t i c e . for perporators  but not for diporators  the solution l a t t i c e degenerates into a tree as usually drawn. - for a good introduction 
to lattice theory  see {rutherford 1a}. 
　　　first some general notation. let 	q 	be an unambiguous operator which is defined with one set 	p1 c p 	as inputs  and which yields 	p c p as outputs. we then write 	p  c q p'  . for the 
moment  we forget about ambiguous operators. 
　　　the ordered k-tuple whose elements are a   a 1   . . . a  w i l l be written  a 1   a 1   . . . a. . a and   a  are considered as distinct items*. if b is a k-tuple  the last element of b is written a  b  . i f b is a set of tuples  the set of last elements of members of b is written ft b  . 
　　　we now define the set s  the solution lattice  as follows: 
 1  if 	p 	is an object  then  p  is a member of s; 
 1  if s and t are members of s   then sv t and s a t are also members of s; 
 1  see below. 
　　　following rutherford  we define x c y to mean x ＊ x a y . also  we assume commutative  associative  and absorptive laws for vj and o . distributive and idempotent   x x ＊ x etc.  laws for   and r  follow easily. also  we find that the c relation is transitive  and that x c y a y c x x = y 
　　　instead  we shall frequently write a when we mean {a}   

-1-


-1-

inferred from the others  and is crucial. 
　　let us f i n a l l y turn to the case of ambiguous operators. suppose  in example 1  figure 1  that q is an ambiguous perporator  and that it is sufficient to transform either set m. we then simply redefine with unchanged notation otherwise. see figure 1   and compare figure 1. 
　　　if desired  the notation can of course be further extended to a r b i t r a r i l y complex and/or structures: 
example 1. after applying operator q to object p   we find that it is sufficient to transform 

to the target set m. with s. as before  we then simply define 

　　　using the obvious distributive etc. laws  this expression can be reduced to the canonical form of an ambiguous diporator. 
　　　in summary of this section  we have suggested a formal and pictorial representation of the search 
 trees  for arbitrary operators. our search lattice s is the set of a l l possible nodes in search space. in the search for a solution  we gradually extend the searched poset  which is a subset of s  u n t i l it has been proved that 

1. heuristics in the saint program 
　　　in sections 1  some aspects of heuristic programs have been discussed. as an exercise in the use of these concepts  we shall now give a description of slagle's program saint. we wish to demonstrate that  with the concepts that have been introduced  the description can be more abstract and involve less programming details than before. 
problem environment. 
　　　the set p of objects consists of a l l formulas b u i l t from real numbers  variables  various arithmetic functions   and one functional: the integration operator. the target set m consists of a l l objects which do not use the integration operator. the i n i t i a l set r consists of one single object  which is given to the program on each occasion of use. 
　　　the set q consists of 1 operators. a l l are perporators  except for one diporator  the formula 
　　　addition  subtraction  multiplication  power function  logarithmic  trigonometric  and inverse trigonometric functions. 
for the integral of a sum. some of the perporators  e.g. the substitution operator  are ambiguous and governed by a parameter. most operators have a restricted domain. 
discussion of heuristic method. 
　　　it is natural to sort up the operators in q into the following disjoint cathegories: 
a. standard forms  1 operators . these are 
perporators whose output is always in the target set m   i f the input contains only one occurrence of the integral operator . an example of such a perporator is 

remark: the possibility to single out those operators which land in the target set is particular for this problem environment  and does not occur in e.g. logical inference. 
b. algorithm-like transformations  1 operators . these are operators which  if applicable  are usually appropriate. the diporator is one of them. 
c. heuristic transformations  1 operators . these are operators which may or may not be appropriate. substitution is one of them. 
let us call these sets a n d r e s p e c t i v e l y   and define: 
pi the set of a l l objects in p which are in the domain of some operator in ql; 
p1 the set of a l l objects in p-pl which are in the domain of some operator in 

　　　objects in pi have a solution just around the corner  and should of course be given top p r i o r i t y . for objects in p1  we know which operator should be applied   i t turns out that there is never more than one   so such objects are given higher p r i o r i t y than objects in p1. for objects in p1  several operators may be applicable  so a heuristic search has to be performed. 
　　　each object p stands for an expression b u i l t with functions. the  maximum depth  of this 
expression is significant for the following reasons:  l  the members of pi  usually  have small maximum depth;  1  operators often perform only a small change  one or a few units  in the maximum depth of their input. under such conditions  it is reasonable to use the depth of an expression as a gross measure of its  distance  to the target set  and  therefore 1  to use it as a merit function. 
　　　with this background  the heuristic method used by saint can be outlined. 

-1-

images. 
　　　the saint program uses images = feature vectors with eleven components. maximum depth of expression is one of them. images are used for three purposes: 
 a  selection of best bud  only maximum depth component used ; 
 b  selection of appropriate operators for a given object in p1; 
 c  selection of parameters for ambiguous operators. 
handling of restricted domain. 
　　　if a selected operator is not applicable to a selected object  saint just gives up. it does not try to solve a sub-problem. 
object and operator selection. 
　　　abstractly speaking  the saint program uses an  object f i r s t   a few operators afterwards  selection system  where objects are selected with a best bud method based on a merit ordering. however  there are certain complications to this simple scheme. 
       the following merit ordering is used:  i f f 	p is a member of pi and  is not  
or p is a member o f a n d is a member of p1  
or 	both p and p' are members of p1  but p has less maximum depth than p' has. 
　　　in each step  saint selects some maximal bud in the search tree according to this partial order  and applies suitable operators to i t . the operators are selected according to the following table: 

　　　in p1  only one operator is usually applicable; in p1  the object's image determines which operators shall be selected. notice in particular that if object is in p1  then an operator from q1 is never selected  even if the object is in its domain. the reason is that an object in p1 can be transformed one or more steps by operators in q1  and then the desired operator in q1 can be applied to the result. this is sufficient  and is in fact a good pruning technique   since operators in q1 only effect t r i v i a l modifications on the objects. 
programming 
　　　since only one operator is applied to objects in pi and p1  these objects and operators can be given a separate and  algorithmic  treatment. the heuristic search need only span objects in p1 and operators in q1. 
　　　like most heuristic programs  saint maintains a bud l i s t   i.e. a l i s t of objects to which no operator has yet been applied. this l i s t contains members of p1 ordered according to  the merit order    . 
　　　somewhat idealized  the cycle in the saint program runs as follows: 
 1  take the f i r s t object on the bud l i s t .  this is a maximum bud in p1 . 
 1  select suitable operators for this object. 
apply them. the set or results is called p . 
 1  for each member of p   check if some member of ql or q1 is applicable. if so  apply i t . if it was a member of ql  terminate. otherwise  include the result in p  and reperform  1  on i t . 
 k  	let p+ be the modified p  after a l l ql or q1 operators have been applied. by hypothesis  p+ is a subset of p1. merge p+ into the bud l i s t according to   . 
　　　the cycling starts in step 1 with the bud l i s t empty  and with p  = the given  i n i t i a l object   the given integration problem  . 
　　　the occurrence of a diporator in the problem environment is a complication. to handle t h i s   the program maintains a  goal tree   which is equivalent to the search poset of last section  but utilizes a slightly different notation. on discovery of a member of ql  step  1  in the routine  saint does not actually terminate  but utilizes instead the  goal tree  to remove from the bud l i s t those buds that need no longer be transformed to the target set. in lattice terms  if saint has proved for a node t is the search poset that f | m   t   then it removes from the bud 

l i s t a l l nodes t1 such that t! b . also  and for the same reason  such members of p   p   are thrown away. saint then continues the above cycle  starting in step   l     as long as there is anything l e f t on the bud l i s t . 
remarks 
　　　this terminates our description of the saint program. it is based on a rather short summary of the work on saint  { slagle 1a}  rather than the f u l l thesis. there may therefore be mistakes in details of our description. however  let us repeat that the intention with this section was to demonstrate how exactly the same material may be described in completely different terms when it is to be used for another purpose. 
　　　to f a c i l i t a t e comparison  let us finally give a short dictionary that translates between slagle's terminology and ours: 

-1-


t  the unit preference heuristics in resolution 
　　　the purpose of this section is the same as that of section 1  i . e . to demonstrate the usefulness of abstract heuristic concepts. in 
addition  we shall t r y to show that the so-called strategies used in resolution are in fact heuristic methods  and amenable to the same treatment as other such methods . therefore  we have selected to make a description of the unit preference strategy for resolution. 
problem environment 
　　　each object in the set p is a set of l i t e r a l s   a l i t e r a l being a symbolic expression 
 not  ri    	or 	 % 	  . the 
target set m has one member: the null set   i . e . the set of no l i t e r a l s   . the i n i t i a l set r consists of a relatively small number of objects and is given to the program on each occasion of i t s use. 
　　　notice that in this case  r is given as input to the program  and m is fixed. in the case of saint  ve had the opposite situation. 
the set q consists of a two-input conporator 
images  it is reasonable to take the image of an object as a crude estimate of i t s merit in the search towards the target  with small images having a higher merit. therefore  operations which decrease the image can be expected to bring us closer to a solution. this gives us a preference for factoring  and for resolution when one input has image 1. 
　　　a t r i v i a l strategy would be to reduce the image to zero through successive factorings. however  we run into problems with the restricted domains of the operators: factoring when the image of the input is 1   i . e . the last step  is never possible  and in a l l reasonable problems we would 
f a i l far before that. 
　　　resolution when the partner's image is 1   unit resolution   seems to be a better strategy  adn is what our heuristics prefers as f i r s t choice. when it cannot be had  we perform other resolutions or factoring a couple of steps  in the hope of achieving unit resolution later. 
handling of restricted domain. 
　　　if a desired operator is not applicable  the unit preference method just gives up. 
object and operator selection. 
　　　unit preference utilizes a best bud bundle method  where a suitable operator and i t s input s  are selected together. the system makes implicit use of a merit ordering   defined as follows on i   1 : 
numerical relationship 	merit ordering 
    	means  less than   	    	means  better than   

  resolution   and a perporator   factoring  . both have a restricted domain  and both are ambiguous. the ambiguities are moderate: the 
number of alternatives is f i n i t e and so small that a l l can be t r i e d . 
images 
　　unit preference uses images for objectoperator selection. the image of an object is an integer  v i z . the number of l i t e r a l s in the object. operators can be extended to images in the following manner: if the inputs to the resolution operator have images and k.   then the output   i f it exists  has image . similarly  if the input to the factoring operator has image then the output  if it exists  has j - 1 as image**. 
discussion of heuristic method. 
　　　since the target object has image zero  and the operators effect a relatively small change on 
feigenbaum  in his ifip 1 paper { feigenbaum 
1a}  argues a similar standpoint. 
** 
　　　it may accidentally happen that the image of the relation   is extended to p w p in the the output is less than  but never greater than  obvious way. j+k-1 v i z .  . such accidents are rare and do not affect the heuristics. 
-1-

　　　in each cycle  unit preference uses   to select one maximal object or object-pair and applies the correct operator  factoring in the case of an object  resolution in the case of an object-pair  to i t . in case of ambiguity  a l l alternatives are treated with the same p r i o r i t y . if operator application in some alternative is successful  and the output has higher priority than the input  and therefore  higher priority than the other alternatives processed together with this one   then the higher priority is honored immediately. 
programming. 
　　　although our reference says l i t t l e about the actual program that performs the unit preference heuristics  the following are some suggestions for such a program. 
the program utilizes l i s t s l   lq  . . . l.  
. . .   where l. contains a l l generated objects with image j  together with the following information for each object: 
 1  has factoring been attempted on this object  
 1  if factoring is ambiguous  for which cases has it been attempted  
 1  with what other objects has resolution been attempted  
 u  	if resolution is ambiguous  for which cases has it been attempted  
　　　the answers to these questions can be represented as follows: 
 1  for each l i s t l- where j   1  a pointer indicate how far down the l i s t factoring has proceeded; 
 1  for the pointed-at element of each l i s t l-  the attempted alternatives are listed.  for a l l other alternatives of l j   either none or a l l alternatives have been attempted ; and similarly  for each object p. on each l i s t 
 1  for each l i s t l where k    j   a pointer indicates how far down lk resolution with p. has been attempted; 
{h  for the pointed-at element of each l i s t l k   the attempted alternatives are l i s t e d . 
with these conventions  programming is straightforward. 
remark. 
　　　the images used by the unit preference method have a noteworthy property: the image of the output of an operator is a function of the image s  of the input s   if the operator is applicable; but the image does not contain enough information to determine applicability. this  semi-deterministic  property has otherwise been characteristic of planning methods  notably planning gps  and planner. as a result of some present work  we believe that semi-deterministic images have interesting theoretic properties. 
pruning c r i t e r i a . 
　　　the unit preference heuristics should only be used in combination with various pruning c r i t e r i a   such as: 
 1  restriction on .-search pth' tne depth of an object is the number of resolutions that was required to construct i t . objects of depth    k   where kq is a fixed parameter  are rejected; 
 1  set  of sjijyoort strategy.. a subset t of r is singled out as  essential i n i t i a l objects   and nodes p in the search poset which satisfy 
	  i	   
	p  = u	~
are given zero merit; 
 1  rejection:1 by pattern.. objects p which conform to certain patterns  e.g. contain two l i t e r a l s of the form a viz.  not a    are rejected. 
　　　we have then made a distinction between heuristics  i.e. rules which govern the order in which the solution lattice is searched  and pruning c r i t e r i a  which are extreme cases of heuristic rules since they cut off some  branches  altogether . in the resolution literature  both heuristics and pruning c r i t e r i a are called strategies. 
　　　pruning criteria can formally be treated as 1 further restriction on the domains of operators. the f i r s t two pruning c r i t e r i a above can  alternatively  be implemented by using images  .j d s    defined as follows: 
　　　if p is a member of the i n i t i a l set r   p's image is  j d s    where j is the number of l i t e r a l s in p ; d is zero; s is the truth-value of p ♀ t 
　　　if p was derived through resolution  and the images of the inputs were   ji d1 and 
 
j1 	d1 	  then the' image of 	p 	is 	 j d s    
where j = j + j - 1  the number of literals in p  d = max d. dp  + 1 
　　　finally  if p was derived through factoring  and the image of the input was  j d s    then the 

-1-

image of the output 	is 	
　　　when the p a r t i a l order   is extended to t r i p l e s  and p a i r s of such t r i p l e s   the f o l l o w i n g items are considered as zeroes   i . e .   a l l other items  and t h e r e f o r e r e j e c t e d : 

with these exceptions  the order 	  	t r e a t s 

　　　notice t h a t if we ignore the accidents mentioned in the f o o t n o t e on page 1  both operators are s e m i - d e t e r m i n i s t i c on these extended images. 
m o d i f i c a t i o n : the fewest-component preference h e u r i s t i c s . 
       slagle has proposed to streamline the u n i t preference h e u r i s t i c s i n t o a fewest-component preference method. the idea is to change the d e f i n i t i o n of the m e r i t order so t h a t the s p e c i a l preference f o r p a i r s 	  l 1 j   	i s dropped. the d e t a i l s a r e : 	in the above d e f i n i t i o n of   	  drop r u l e s   l   through   1     and use r u l e s 	 1  through  1  even if some of 	i   j   k 	or 	m 	equals one. for the redefined 	    we have e . g . 


	1. 	conclusion 
　　　we have defined a number of concepts which are u s e f u l f o r the compact and abstract d e f i n i t i o n or h e u r i s t i c methods. for i l l u s t r a t i o n   these concepts have been applied to two well-known 
methods. examples of t h e i r compactness can be found on pages 1   s l a g l e ' s and/or t r e e p r u n i n g     1  set of support s t r a t e g y   and 1  fewestcomponent preference h e u r i s t i c s   . we have argued t h a t a b s t r a c t 	d e s c r i p t i o n s o f s i m i l a r k i n d w i l l be u s e f u l as complements to conventional d e s c r i p t i o n s of h e u r i s t i c programs 	and methods. 
	index of h e u r i s t i c methods 	and programs. 
arrow method 
{ h a r t 1a}  	{nilsson 1a} 
deducom 
{slagle 	1a} 
fewest-component 	preference 	h e u r i s t i c 
{slagle 	1b} 
gps  general problem solver  
{newell 1c}  	{newell 1la} 
graph t r a v e r s e r 
{doran 1a}  	{doran 1a}  {michie 1a} 
h e u r i s t i c 	automaton 
{doran 1a} 
logic 	theory machine 
{ s t e f f e r u d 1a}  	{ m i l l s t e i n  a} 
multiple 
{slagle 	1a} 
planner 
{hewitt 	1a} 
planning gps 
{newell 1c}  	{newell 1a} 
pps  planning problem solver  
{sandewall 1b} 
saint 
{slagle 	1a} 
sin 
{moses 1a  
unit 	preference 	h e u r i s t i c s 
{wos 1a} 

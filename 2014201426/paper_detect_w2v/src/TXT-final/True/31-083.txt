 
in order to deal with over-constrained constraint 
satisfaction problems  various extensions of the csp framework have been considered by taking into account costs  uncertainties  preferences  priorities...each extension uses a specific mathematical operator  +  max...  to aggregate constraint violations. 
in this paper  we consider a simple algebraic framework  related to partial constraint satisfaction  which subsumes most of these proposals and use it to characterize existing proposals in terms of rationality and computational complexity. we exhibit simple relationships between these proposals  try to extend some traditional csp algorithms and prove that some of these extensions may be computationally expensive. 
1 	introduction and related works 
the csp framework provides a very convenient framework for representing and solving various problems related to ai and or  scheduling  assignment  design... . when a real problem is casted in the csp framework  different types of knowledge have to be dealt with: 
  hard constraints: physical properties  eg. spatial or temporal constraints   which have to be necessarily satisfied  are naturally represented as constraints; 
  preferences: properties which should be satisfied  when possible   due dates  user preferences  cost...  are either represented as constraints or simply ignored; 
  uncertainties: properties that are relevant in some sit-uations which cannot be predicted with certainty; such properties are then ignored  or represented as constraints. 
thus  such soft constraints can be either ignored  which naturally leads to a poor mean quality of the solutions or represented as hard constraints which may yield an inconsistent csp. a better solution is to take the violation of these constraints into account in a specific criterion that should be minimized. 
¡¡various proposals have been made in this direction  extending classical csp in order to express  soft  constraints with 
'this work has been partially funded by the french centre na-
a dedicated semantics in terms of priorities  schiex  1; borning et al  1   preference degrees  rosenfeld et a/.  1; martin-clouaire  1; dubois et al.  1; ruttkay  
1   costs  shapiro and haralick  1; dechter etal.  1; 
freuder and wallace  1  or probabilities  rosenfeld et al.  1; fargier and lang  1 . the specific nature of the criterion optimized allows dedicated branch and bound algorithms to be defined. 
¡¡in these approaches  hard constraints and preferably satisfied/uncertain constraints are expressed as constraints but a valuation  usually a number  is associated to each constraint c  or each tuple t of a constraint. this valuation expresses the impact of violating the constraint c or using the tuple t on the quality of the solution. these valuations are combined using an operator that gives them a specific semantics. for example  in  schiex  1   the valuations of violated constraints are combined using a max operator  which gives the valuations an interpretation in terms of priorities  while in  shapiro and haralick  1   the valuations are numbers combined using addition  with an obvious interpretation as costs. 
¡¡in this paper  rather than choosing a specific set for expressing valuations and a specific operator  we observe that an ordered commutative monoid  an ordered set with an operator satisfying some properties   is enough to encompass most existing csp extensions. the valuations are taken from the set of the monoid  combined using its operator and compared using the order. for the sake of simplicity  we consider that valuations are only associated to constraints. 
¡¡our aim is then to use this abstract framework to provide general algorithms and properties  to bring to light relations between previous proposals and to identify where the difficult problems are  and what property makes them difficult1. 
¡¡the next section defines the valued csp  vcsp  framework  rapidly justifies the algebraic structure used and gives some simple properties. section 1 describes previous proposals as vcsp and shows how they relate to each other in terms of rationality and complexity. section 1 considers the generic extension of different backtrack based algorithms and ends with preliminary experiments on the related observed complexities of some types of vcsp. 
¡¡this work is therefore related to  shafer  1  which considers an axiomatic framework where hyper-tree structured problems are solved efficiently and to  minoux  1; bistarelli etal  1  where a semi-ring is used to study the possible generalization of shortest 

tional d'etudes spatiales and by the european euclid project calma. path and k-consistency enforcing algorithms respectively. 
	schiex  fargier  and verfaillie 	1 

1 	constraint satisfaction 

schiex  fargier  and verfaillie 	1 bilistic vcsp  obtained in polynomial time and the problem of finding one optimal assignment for the max-vcsp may be reduced to the problem of finding one optimal assignment of the corresponding lex-vcsp. 
¡¡the partition between idempotent and strictly monotonic vcsp classes is also made clear at the level of polynomial classes: the existence of an assignment with a valuation lower than v in a strictly monotonic binary vcsp with domains of cardinality two is obviously np-hard by restriction to max1sat  garey et al  1 . one of the few polynomial classes which seems to extend to all classes of vcsp is the class of csp structured in hyper-tree  see  dechter et al  1; shafer  1  . 
	1 	extending traditional algorithms 
1 local consistency 
in classical binary csp  all constraints are supposed to involve two variables only   satisfiability defines an np-complete 
problem  k-consistency properties and algorithms  freuder  1  offer a range of polynomial time weaker properties: enforcing strong k-consistency in a consistent csp will never lead to an empty csp. 
¡¡from the vcsp point of view  strong k-consistency enforcing defines a kind of lower bound of the csp valuation: if strong k-consistency enforcing yields an empty csp  then we 
know that the csp valuation is greater than t and therefore equal to t  else it is simply greater than x  which is always true. 
¡¡arc-consistency  strong 1-consistency  is certainly the most prominent level of local consistency and has been extended to max-vcsp years ago  rosenfeld et al  1 . in max-vcsp  are-consistency can be defined as follows: 
definition 1 a vcsp v is said to be arc-consistent iff  1  there exists  for each variable  a value that defines an assign-
ment with a valuation strictly lower than t and  1  any assignment a of one variable can be extended to an assignment a' on two variables with the same valuation  vp a  = v-p  a'  . 
polynomial worst-case time algorithms that enforce this property on max-csp are defined in  rosenfeld et al  1; snow and freuder  1; schiex  1 . these algorithms yield an are-consistent max-vcsp with the same valuation distribution on complete assignments  and a lower bound on the vcsp valuation can easily be derived from it. 
¡¡obviously  this definition could also be used in non idempotent vcsp. but it is useless if we can not define the corresponding arc-consistency enforcing algorithms that should compute  in polynomial time  a vcsp v which is both arc-consistent and in some sense  equivalent to the original vcsp v. the strongest level of equivalence one could achieve  stronger than our strong equivalence notion  def. 1  is the equality of 
the valuations in both vcsp for all complete assignments. 
¡¡but the generalization of ac enforcing algorithms that consists in using min and  r  respectively for projection and combination of constraints fails for non idempotent monotonic vcsp as it has been shown in a similar framework  see  bistarelli et al.  1   in these proceedings . the distribution of valuations may be modified and the algorithm may fail to terminate. however  it is still an open question whether more drastic modifications of the algorithms/properties  or a 
1 	constraint satisfaction 

weakening of the  equivalence  notion  as def. 1  would allow 	  a stronger local consistency property will define a better us to recover something related to arc-consistency. 	lower bound  leading to a tree search with less nodes but possibly more computation at each node. 
1 tree search 
following the works from  shapiro and haralick  1; 	1 extending backtrack 
schiex  1; freuder and wallace  1; dubois era/.  1   backtrack uses the local inconsistency of the current partial we try to extend some traditional csp algorithms to the binary assignment as the condition for backtracking. therefore  the 

vcsp framework to solve the problem of finding a provenly optimal assignment. the class of algorithms which we are interested in are hybrid algorithms that combine backtrack tree-search with some level of local consistency enforcing at each node. these algorithms have been called look-ahead  prospective or prophylactic algorithms. some possible instances have been considered in  nadel  1 : backtrack  forward-checking   really full look ahead. we consider here that such algorithms are described by the type of local consistency enforcing maintained at each node: checkbackward  check forward  arc-consistency or more... 
¡¡in prospective algorithms  an assignment is extended until either a complete assignment  a solution  is found  or the given local consistency property is not verified on the current assignment: backtrack occurs. the extension of such algolower bound derived is the valuation of an optimal relaxation in which the current assignment is consistent. this is simply the relaxation which precisely rejects the constraints violated by the current assignment  these constraints have to be rejected or else local inconsistency will occur; rejecting these constraint suffices to restore the consistency of the current assignment in the relaxation . the lower bound is therefore simply defined by: 

and is obviously computable in polynomial time. 
rithms to the vcsp framework  where the problem is now an valuations of all the constraints violated by xi using  r .. 
optimization problem  relies on a transformation of the back- the generic vcsp algorithm defined encompass all the track tree search schema to a depth first branch and bound  branch and bound  algorithms defined for max-vcsp or ealgorithm. dfbb is a simple depth first tree search algorithm  vcsp in  schiex  1; freuder and wallace  1; fargier  which  like backtrack  extend an assignment until either  1  1; ruttkay  1 . note that for max-vcsp  thanks to a complete assignment is reached: a new  better  solution idempotency  it is useless to test whether constraints whose is found or  1  a given lower bound on the valuation of the valuation is lower than the lower bound associated to the best assignment that can be found by extending the current father node have to be rejected since their rejection cannot 
assignment exceeds the valuation of the current best solution 	influence the bound. 
found: backtrack occurs. the lower bound used defines the 1 extending forward checking algorithm. our aim is to derive a lower bound from any given 
local consistency property. 	forward-checking uses an extremely limited form of arc-
¡¡in classical csp  seen as a-vcsp  the actual local consis- consistency: backtracking occurs as soon as all the possible tency property used gives the  lower bound : for example  in extensions of the current assignment a on any uninstantiated really full look ahead  the inexistence of an arc-consistent variable are locally inconsistent: the assignment is said non closure of the csp guarantees that the valuation of any ex- forward-checkable. therefore  the lower bound used is the minimum valuation among the valuations of all the relaxations tension of the current assignment will be greater than t and that makes the current assignment forward-checkable. therefore equal to t. however  as we pointed out earlier  no 
                                                 a relaxation in which a is forward-checkable  1  should arc-consistency enforcing algorithm is available for strictly necessarily reject all the constraints violated by a itself and monotonic vcsp. we will therefore use classical local consistency notions plus the notion of relaxation of a vcsp  which  1  for each uninstantiated variable xi it should reject one of defines classical csp  to define our class of bounds: the sets c xi  v  of constraints that are violated if xi is instantiated with value v of its domain. since  r  is monotonic  the 
property 1 given a classical local consistency property l  a minimum valuation is reached by taking into account for each lower bound on the valuation of a given vcsp v is defined by variable  the valuation of the set c xi  v  of minimum valuathe valuation of an optimal relaxation of p among those that tion. the bound is again computable in polynomial time since 
satisfy the  local consistency  property l used  consistency it is the aggregation of  1  the valuations all the constraints of the current assignment  absence of domain wipe-out after violated by a itself  i.e.  the bound used in the extension of ¡¡the lower bound can easily be computed incrementally when a new variable xi is assigned: the lower bound associated to the father of the current node is aggregated with the 

check-forward or arc-consistency enforcing... . 
this valuation is a lower bound of the valuation of an optimal assignment since the valuation of an optimal assignment is also the valuation of an optimal consistent relaxation and all the relaxations where the  local consistency  property l is not verified are non consistent. 
these lower bounds verify two interesting properties: 
  they guarantee that the extended algorithm will behave as the original  classical  algorithm when applied to a classical csp seen as a a-vcsp  a classical csp seen as a a-vcsp has only one relaxation with a valuation lower than t: itself ; 
the backtrack algorithm  see 1  and  1  the valuations of the constraint in all the c xi  v . this computation needs less than  e.n.d  constraint checks and  r  operations  e is the number of constraints ; all the minimum valuation can be computed with less than  d.n  comparisons and aggregated with less than n  r  operations. note that the lower bound derived includes the bound used in the backtrack extension plus an extra component and will always be better than the  backtrack  bound. 
¡¡the lower bound may be incrementally computed by maintaining during tree search  and for each value v of every unassigned variable xi the aggregated valuation b v  xi  of all the 
	schiex  fargier  and verfaillie 	1 

constraints that will be violated if v is assigned to xi given the current assignment. initially  all b y  xi  are equal to 1. 
when the assignment a is extended to a' - a u {xj = u}  the b may be updated as follows: 
  
that takes into account all the constraints between xi and xj that are necessarily violated if  is assigned to xj. upon backtrack  the b have to be restored to their previous values  as domains in classical forward-checking. note that the b offer a default value heuristic: choose the value with a minimum b. 
¡¡the lower bound is simply obtained by aggregating  using  r   the valuations of all the constraints violated by the assignment and all the minimum b v  xi  for each unassigned variable. the aggregated valuation v a'   a! - a u {xj = u}   of all the constraints violated by the assignment a! is easily computed by taking the valuation v a  computed on the father node  r 'ed with b u  xj . 
¡¡additional sophistications include deleting values v of the domains of non instantiated variables if the aggregated valuation of v a'  and b v xi  exceeds the upper bound  see  freuder and wallace  1  . the generic vcsp algorithm defined encompass the forward-checking based algorithm for max-vcsp described in  schiex  1  or the 
partial forward-checking algorithm defined for   vcsp in  freuder and wallace  1 . note that for max-vcsp  and thanks to idempotency  the updating of b can ignore con-
straints whose valuation is less than the b updated or than the 	for example  figure 1 illustrates the micro-structure of the csp 
current lower-bound. 	built from the set  the trans-
¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡formation is clearly polynomial. furthermore  one may prove that 1 trying to extend really full look ahead the existence of a truth assignment that satisfies at least k clauses 
really full look ahead maintains arc consistency during tree of $ is equivalent to the existence of a relaxation with a non-
search and backtracks as soon as the current assignment in-
duces a domain wipe-out: the csp has no arc-consistent closure. for a vcsp  the bound which can be derived from are-consistency will be the minimum valuation among the valuations of all the relaxations such that the current assignment does not induces a domain wipe-out. 
¡¡let us consider any class  r -vcsp of the vcsp framework such that  r  is strictly monotonic and for any a  1 € e a b -  be any valuation different from t and 
empty arc-consistent closure and a valuation lower than 
with 	occurrences of l this shows that 
max1sat oc max-ac-csp. 	
¡¡therefore  extending really full look ahead seems difficult since computing the lower bound itself is np-complete. for idempotent vcsp  the bound may be computed using polynomial time algorithms for enforcing are-consistency  rosenfeld et al  1; snow and freuder  1 .    the decision problem corresponding to the computation 	1 experimentations of the lower bound in this class can be formulated as: 
¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡¡the forward-checking algorithm has been coded and applied problem 1  max-ac-csp  given such a &-vcsp and a val- to random vcsp generated as follows: a classical random uation v  is there a set such that the relaxation csp with 1 variables  domains of size 1 is generated as in  has a non empty arc-consistent closure and a val- hubbe and freuder  1 . a first possibilistic vcsp is uation lower than v  obtained by randomly assigning a valuation j  i  ¡ì or 1 to 
we have supposed that  r  and are polynomial in the size of their arguments. 
¡¡we give the polynomial transformation from max1sat  garey et al.t 1  to max-ac-csp. an instance of max1sat is defined by a set of e 1-clauses and a positive integer k  the problem being the existence of a consistent subset of of cardinality larger ¡¡because of limited space  we only report mean number of constraint checks performed to find an optimal assignment and prove optimality for a slice of the random csp space  see figure 1 : constraint satisfiability is fixed to 1% and the constraint graph goes from tree structured csp to a theorem 1 max-ac-csp is strongly np-complete. each constraint. a lexicographic vcsp is then built simply by using the transformation from possibilistic to lexicographic sketch of proof: the problem belongs to np since computing the csp described in section 1. this vcsp is a strong refinement arc-consistent closure of a csp can be done in polynomial time and of the original possibilistic csp. than k. let be the set of n prepositional variables occurring complete graph. at each point 1 classical  possibilistic and in   we consider the binary csp  x  d  c  which is composed corresponding lexicographic csp are solved with the follow-
1 	constraint satisfaction 

i.e.  uselessly trying to anticipate a possible inconsistency  is relatively inexpensive  even for lex-vcsp. on inconsistent csp  possibilistic csp are not much harder than classical csp  but the transition phase is apparently extended to the left. last  but not least  lexicographic csp are incredibly more difficult which again shows the computational complexity of strictly monotonic  r : rationality seems expensive. stronger argument could probably be obtained using recent developments in complexity theory  the transformations of section 1 defining metric reductions between optimization problems  krentel  1 . 
1 	conclusion 
the vcsp framework enables the expression of a large number of real constraint satisfaction/optimization problems. if idempotent vcsp have already received a lot of attention and most classical csp algorithms/properties have been extended to this setting  fargier  1   the case of non idempotent operators  a desirable property as it has been shown  seems much harder to tackle and few csp algorithms have been extended to this case  freuder and wallace  1 . 
¡¡since local consistency enforcing algorithms are unavailable in this case  we have considered a general class of bounds  that could be used in a depth first branch and bound algorithm and which have been derived from classical local consistency properties. it appears that at the level of arc-consistency  the problem of computing the bound is as difficult as solving a vcsp itself and other types of bounds have to be considered. 


rating how well a routine activity is performed can be valuable in a variety of domains. making the rating inexpensive and credible is a key aspect of the problem. we formalize the problem as map estimation in hmms where the incoming trace needs repair. we present polynomial time algorithms for computing minimal repairs with maximal likelihood for hmms  hidden semi-markov models  hsmms  and a form of hmms constrained with a fragment of the temporal logic ltl. we present some results to show the promise of our approach.
1 introduction
rating how well a person performs a routine activity is a broadly useful capability with many applications: professors train medical students by rating their execution of established procedures  caregivers assess the well-being of their wards by rating how well they are able to perform activities of daily living  and managers and workflow experts identify poorly performed procedures that cause bottlenecks in a system. although rating routine activity is certainly useful  as conventionally done it is also very expensive - each activity performance requires a dedicated human observer  often an expert . many situations where gauging the performance of routine activities could be helpful are therefore either not rated at all  or rated in a cursory manner. clearly  an opportunity exists for automated techniques to reduce the cost of rating. in this paper  we explore methods for automatically rating performances of routine activities.
﹛the basic classification task of rating  going from observations to scores  is amenable to a variety of standard approaches. rating becomes challenging  however  if we wish to make it both incrementally inexpensive and credible. we define an incrementally inexpensive rater to be a rater in which the extra cost of rating a new activity is relatively low. the main determinant of cost is whether rating a new activity requires a custom classifier to be developed from scratch  or whether a generic classifier of some kind can be easily customized to the task. a credible rater is one that is both relevant and transparent. by relevant  we mean that the classification model for a particular rating task should reflect constraints on activity performance that are important to those using the rating. for example  a professor grading anesthesiology students performing an intubation may want to indicate what her notion of good performance is. by transparency  we mean that the system should be able to justify why it has assigned a particular rating. ideally  the justification should be constructive  in that it should suggest how a low-rated performance may be altered to obtain a high-rated one.
﹛our techniques for rating activity routines are designed to satisfy the above requirements. to lower incremental cost  we choose a representation that is easily learned: all activities to be rated in our system are modeled by variants of hidden markov models  hmms . we intend that these models  especially given simple prior information  can be learned easily from training examples. more crucially  we formulate the justification for a rating relative to this model generically as the set of edits required on the trace generated by the rated activities; we therefore do not require special identification and modeling of errors and their causes. a fundamental weakness of these models is that they are first order  preventing them from capturing certain important correlations. we augment the markov models with an intuitive constraint formalism  a small fragment of the temporal logic ltl   that allows raters to explicitly state relevant constraints. given these relevant and easy-to-construct models  we formulate rating as the likelihood of  possibly edited  observation sequences.
﹛the core of this paper consists of efficient algorithms to compute maximum likelihood paths of minimally edited versions of incoming observations with respect to various representations for activities  including hmms  hsmms and temporally constrained hmms. the algorithms use the dynamic programming technique used to great effect by the wellknown viterbi algorithm. a preliminary evaluation shows the promise of our techniques.
1 overview
in this section  we describe how we expect our system to be used  and we sketch how our system supports this usage model. in this paper  our goal is to develop a system that rates how well an elder performs day-to-day activities. such a system is of great interest to the eldercare industry. in theory  caregivers will assess the elders' well-being by consulting ratings summaries and credible explanations of performance deficits. for example  the system may recognize that an elder is no longer able to prepare their daily bowl of soup  and report why  e.g.  can't reach cabinet or difficulty holding spoon .
﹛to end-users  our system represents activities as a set of steps. each step has a duration and a set of observed actions performed  and is succeeded by other steps. for instance  the activity  making soup  for a particular elder may have the following steps:  preheat water    open can    mix and boil ingredients    serve   and  clean up.  the step  open can   may have an average duration of 1 seconds and contain the following actions:  use utensil drawer    use can opener  
 use can   and  use pantry door. 
﹛for concreteness  we will assume in what follows that we are using rfid-based  sensors that will directly sense the action of using particular objects. therefore  all of our actions are of the form  use x  where x is some object. inherently  our system requires that actions are observable by sensors. given an activity trace  i.e.  a trace of actions that constitutes a particular execution of an activity   our system provides a rating  e.g.  pass or fail . if the grade is a fail  the system provides an alternate sequence of actions as close to the original as possible that would have elicited a pass grade  essentially a constructive justification of the grade . in more detail  use of the system proceeds as follows:
learning the model a human demonstrator performs the routine in an exemplary fashion. the system collects traces y1 ... yn of the routine. each trace yi is a
sequence of time-stamped observations yi1 ... yimi of the demonstrator's actions. the traces are used to learn a dynamic stochastic model  either an hmm or an hsmm  with parameters 竹. the hidden states s1 ... sn of the model correspond to the  activity steps  above  and are labelled l1 ... ln with the names of the step.
adding global constraints typically  the first-order model learned in the previous step cannot capture important higher-order correlations. for instance  in a successful soup-making routine  the stove  if it is used  should eventually be turned off after it is turned on. the turning on would happen in the  preheat water  step  but the turning off may not happen until the end of the  serve  step. the human rater explicitly adds a set c of constraints on the sequence of hidden states or observations that specify these required higher-order correlations. in this case  a possible constraint would be of the form use  stove control knob   e use  stove control knob    read as  a use of a stove control knob should eventually succeeded by a use of a stove control knob .
learning rating thresholds a human rater rates each trace yi with a rating ri ﹋ {pass fail}. let the constrained map likelihood of trace y given 竹 and c 
 ly = cmap m y c   be the likelihood of the path s y with maximum a posteriori  map  likelihood given 竹 and y that satisfies c. we perform a simple thresholding computation to calculate the likelihood threshold l such that  given the classification function r l  = if l   l then fail else pass  r  lyi  = ri for as many of the yi as possible. intuitively  l separates the passes from the fails.
generating a rating and justification given the constrained model  竹 c  and threshold l  the automated rater is ready for use. the person to be rated generates a trace y = y1 ... ym to be rated automatically. the rater finds the constrained map likelihood  ly and path s y =  s 1 y1  ...  s m ym  for y   and assigns it the rating r = r  ly  . if r = fail  the rater attempts to produce a repaired trace  such that the edit distance between y and y 1 is as small as possible  and  ly 1   l. in other words  y 1 is the closest trace to t that passes. the rater offers r as the rating for the activity and  if appropriate  汛s y  s y1  the set of edits needed to transform s y into s y 1  as the justification for the rating.
﹛as described above  our rating system employs two key non-standard pieces of machinery.
1. a method to compute the repaired observation trace t1  that is a minimum edit distance from a given trace t whose likelihood is above a pre-specified threshold l.
1. a method to compute the constrained map likelihoodfunction cmap m t c .
1 trace repair for hidden markov models
a hidden markov model  hmm  竹 =  a b 羽  is a commonly used stochastic model for dynamic systems . we formally pose the trace repair problem as a variation of estimating the most likely state sequence given a sequence of observations  classically solved via the viterbi algorithm . an hmm is defined as follows. let qa = {q1 ... qn} be the states of the process being modeled  and ob = {o1 ... om} the observation signals possibly generated by the process. we use meta-variables st and yt to denote the states and observations respectively at time t. aij is the probability p st+1 = qj|st = qi  of transitioning from state qi at time t to qj at time t + 1 for any t; bij is the probability p yt = oj|st = qi  of generating observation oj when in state qi  we write biyt for bij such that yt = oj . the initial state distribution 羽i = p s1 = qi .
1 the repaired map path estimation problem
we now formulate the problem of map path estimation given an observation sequence if we are allowed to first make a limited number of edits or  repairs  to the sequence. we begin by formalizing the notion of an edit. we then state the repaired map path estimation problem and present a variation of the viterbi algorithm to solve it.
﹛let y n be the set of length-n strings of observations over some finite alphabet y . then ek n =
  b1 s1  ... bn sn   is a length-n k-edit vector on y n  with bi boolean  si strings over y   and k = p1≒i≒n bi +
|si| .	for instance  y 1 =  cat  is a string in 
  false  bb    false      true  r    is an edit vector on y 1. applying an edit vector e to string y n = y1 ...yn  written e y   results in a new string y 1 obtained as follows. for 1 ≒ i ≒ n  let if e.bi is true  then replace yi with y i1  else replace yi with yie.si  e.si appended to yi . for example 

figure 1: trellis for k-edit viterbi on hmms
  cbbar . a string y 1 is a k-edit of another y  if there exists edit vector ek n such that y 1 = ek n y  .
﹛we are now ready to specify the problem of map estimation with repairs:
definition 1.  repaired map path estimation problem  rmap   given observation sequence y t  hmm 竹 =
 a b 羽  and edit distance k find observation sequence  that is a k-edit of y t and path s t1 = s灸1 ... s灸t1 maximizing p s t1 y t1  over all t1  s t1 and y t1.
﹛before discussing our solution  we define string y 1 as the  k a -edit of string y n if y 1 = ek n y   for some ek n  |ek n.sn| ≒ a  and additionally  ek n.bn if a = 1 and |ek n.sn|   1 if a   1. the  k a -edit of a string requires its last character to be either preserved or replaced by at least one character  with at most a characters added. edits compose as follows  d糸n = n   糸 ; a1 = 1 if a 1= 1  1 otherwise;  糸 汐  k n a  if 糸   n and 汐 ≒ k  or if 糸 = n and 汐   a :
lemma 1.  edit composition  let  be the set of all
 k a -edits of the n-prefix of string y  over y . then
{ 1 |	y  1	y	d	1	k}.
﹛table 1 specifies an algorithm  the k-edit viterbi  kev  algorithm  to solve rmap. kev iterates over the t original observations in the incoming observation string. for each original observation  it iterates over possibilities for the k added observations at that position  for a total of tk + t iterations. at each iteration t corresponding to original obervation  t  = t div  k + 1  + 1 and added observation #t = t mod  k+1   kev computes the likelihood 汛tik of the most likely path ending in state i given an observation string that is a  k #t -edit of y1 ...y t  over all such edit vectors; kev also records as 肉tik the penultimate state and edit in this path. following the chain of 肉tik's back to the start state iteration gives the map repaired path.
﹛the trellis of figure 1 illustrates kev. columns of the trellis represent edits considered for inclusion into the final string. large circles represent original observations and small ones represent adds. for technical reasons  to allow skipping the first original observation   we add a distinguished start state q1 with new start probabilities and
ai1 = 1 and add a column  t = 1  processed in the initialization step. to allow skipping the last original observation with initialization: t = 1 k = 1...k 1 ≒ i ≒ n
	汛t1k = 1	汛tik = 1	肉tik =  1
iteration: 1 ≒ t ≒ tk+t k = at at+1 ... k
	 肉tik 汛tik =	 arg max	汛而j百biyitaji
而 j 百 s.t. 百+at+d而t=k
termination: t = tm = tk + t + 1
 肉tik 汛tik =  arg max 汛而i百 ;im = argmax 汛tik 而 j 百 s.t. 百+at+d而t=k 1≒i≒n
backtracking:  t i k  = 肉tmimk; while t   1 
	1  s灸t y灸t  =  qi yit 	1  t i k  ↘ 肉tik
table 1: the k-edit viterbi algorithm for hmms
no adds  we add a column  t = tm = tk + t + 1 . rows represent possible hidden states.
﹛the end result of the algorithm is a forward path  shown in light grey in figure 1  through the trellis that  unlike in the conventional viterbi algorithm  may jump between nodes in non-adjacent time slices. if the path jumps over the slice for an original observation yi  where i is the position of the observation in the input string y    we conclude that yi was deleted from y   otherwise not. further  if the path passes through a sequence of added nodes with no intervening original node such that yi is the first original observation to the left of the sequence  and the observations at these nodes are yi1 ... yin  we conclude that the string yi1 ...yin was added at the i'th spot in the incoming string. the forward path is the required solution s t1  and the string of observations along the path is the edited string y t1.
﹛the algorithm uses three intermediate variables  at  dt而 and yit. variable at = 1 if #t 1= 1 and 1 otherwise; d而t =  t     而   represents the number of deletes skipping original observations between 而 and t; yit is the observation considered when processing state i at slice t. note that we only process original observations at time slices 1 k + 1k + 1 .... in all other  added  slices  we need to propose the observed value to be added. a simple but inefficient approach would be to consider for each state  k-value and iteration t  every possible observable o ﹋ ob as a candidate. in fact  we can consider a single observation instead of all |ob|. the key insight is that  when processing state i in an added slice  it is sufficient to consider adding as observable the most likely observable in that state. let sn and yn be the sets of all length-n sequences of states and observables. let y灸i = argmax bij. let sq  be the result of appending state q to
﹛﹛﹛1≒j≒m sequence s   and similarly for yy  . then  for all qi ﹋ qa:
lemma 1.
s 
	this follows from the fact that max p sq  i yy  i 	=
yi
 	=
. given this identity
for the optimal observable to be added in state qi  we set yit to y灸i if t is an  added  timeslice  and to y t  otherwise.
﹛we are now ready to establish the soundness of the kev algorithm. let sni be the set of length-n sequence of states ending in state qi. let be the set of length-n strings of observables that are  k #t -edits of y1 ...y t .
lemma 1.  肉tik 汛tik =	 arg max	p s   y  
n s ﹋sni  y ﹋yntik
proof sketch. proof is by induction on t. we focus on the inductive case for 汛. for 肉  replace  max  with  argmax . 汛tik = max ajibiyit汛而j百 j 而 百 s.t.  百 + at + d而t  = k
而 j 百
	=	 by the inductive hypothesis 

given sn  sn+1 is independent of s n 1 y n:
aji	=	p sn+1 = qi|s s 	n = qj y    n s ﹋sn 1 y ﹋yn而j百
       = p sn+1 = qi|s   y    n s ﹋snj y ﹋yn而j百 similarly  for yn+1 given sn+1:
biyit	=	p yn+1 = yit|s s 	n+1 = qi y    n s ﹋snj y ﹋yn而j百
substituting for aji and biyit above  and using p a b  = p a|b p b  twice  we have  with  百 + at + d而t  = k:

lemma 1 ensures that maximizing over yy  it maximizes over all strings yy  . by lemma 1 maximizing over all yy  with y  ﹋ yn而j百 maximizes over. finally 
 1≒i≒n s ﹋sni+1s . modifying the previous equation to reflect these insights:
	汛tik =	max	p s   y   =	max	p s   y  
	n s ﹋sni+1 y ﹋yntik+1	n s ﹋sni  y ﹋yntik

﹛the soundness of kev follows in a straightforward way from the above lemma. further  given that the trellis has o tkn  nodes  that at each node we compute o k  汛 and 肉 values  and we consult o nk  preceding data values to do so  the complexity of kev as a whole is o tn1 .
1 trace repair for hsmms
a	hidden	semi-markov	model	 hsmm 	 竹	=
 a b d 羽  is identical to an hmm except for the duration distribution d. where an hmm generates a single observation according to b on each visit to a state s  the hsmm generates l independent observations from b on each visit  where l is drawn according to dsl = p l|s . the added flexibility is useful when modeling human activities  since the duration of stay in a state is restricted to be geometric  and therefore biased to small values  in hmms. in what follows  we assume that d is over a finite set  of size |d|  of durations  where the longest duration is l steps.
﹛the rmap problem is: given hsmm  a b d 羽   observations y t and limit k  find argmax p s   y  .
t s ﹋qta y ﹋obt  y  k-edit of y t
init.  term.  bactracking: see table 1.
iteration: 1 ≒ t ≒ tk+t  k = at at+1 ... t
	 肉tik 汛tik =	 arg max	汛而j百p y百k而ti ajidi|y百k而ti|
1≒而≒t j 百 y百k而ti
table 1: the k-edit viterbi algorithm for hsmms
﹛table 1 specifies a variant of kev to solve the problem  and figure 1 shows a trellis for this algorithm. the trellis is identical to that used by kev  we represent k added nodes with a single small circle   only its use is different. we focus on how 汛tik is calculated. at each timestep t  state i and edit distance k  as with kev  we iterate over previous timesteps  states and edit distances 而  j and 百. however  this time instead of discarding the observations in the intervening timesteps  we seek their sub-sequence y百k而ti. we assume that step t only ends a stay in state qi that begins immediately after the stay in qj that ended in step 而. if e而t is the number of edits in y百k而ti  added nodes included + original nodes ignored   we require 百 + at + e而t = k. the problem of maximizing the likelihood of the path ending at  i t  then reduces to the problem of finding y百k而ti maximizing p y百k而ti di|y百k而ti|.
we find this maximum by iterating through durations l in
di; for each l  we iterate through predecessors  而 j 百  of
 t i   finding a sequence y百k而ti of length l with the highest probability; we keep a running tally of the maximum p y百k而ti dil. finding y百k而ti reduces to identifying na added nodes  to include in y百k而ti  and no original nodes  to ignore   such that na + no = k   百   at  to satisfy the k-edit criterion   and na +    t     而     no  = l  to satisfy the duration constraint . the two equations fix na and no. since all the added nodes have the same probability y灸i = p o i|qi   it doesn't matter which particular na we pick. on the other hand  we pick the no original nodes with lowest probability of observation for exclusion; this can be done by sorting the original nodes in o tlog t  time offline  with o l  access during execution. once the sequence of nodes is picked to get y百k而ti  we simply multiply their observation and transition probabilties together to get p y百k而ti   a process that takes l operations  since |y百k而ti| = l = o l .
﹛given o tnk  trellis nodes  computing o k  汛 and 肉 values at each node  consulting o |d|nk  preceding values for each value  and spending o l  for each preceding value considered  the entire algorithm takes o tn1|d|lk1  steps. note that in the  fairly  common case that d and l are unbounded  this running time becomes o t1k1 .

figure 1: trellis for kev on hsmms
1 trace repair for constrained hmms
we define a temporally constrained hmm  tchmm  as 竹 =  a b c 羽   where c is a temporal constraint of the form 耳1e耳1e ...e耳|c|. the 耳i are propositional boolean formulas over state labels l and observations y: 耳 ::= state l |obs y |耳 ＿ 耳| 耳. path suffix si ...st and observations yi ...yt satisfy the constraint suffix cj = 耳j ...耳w if for any k ≡ j  耳j sk yk  implies that  sk+1 ...st yk+1 ...yt  satisfy cj+1  written  sk+1 ...st yk+1 ...yt  ` cj. intuitively if one formula in the constraint sequence is true w.r.t. the head of the state/observation sequences  then the formulas that follow must also eventually be true in their specified order later in the sequences. the constraint  state cook  ＿ obs oil  e state wash ＿obs soap   could  for instance capture the constraint that if oil is used in the cooking step of making dinner  soap should be used in the eventual required washing step.
﹛the rmap problem may now be reformulated as given tchmm with constraints c  observations y t and limit k  find sy = argmax 耳 s   y   such that sy ` c.
t s ﹋qta y ﹋obt  y  k-edit of y t
﹛our solution for rmap estimation is restricted to formulas of the form 耳 ::= state l |耳＿耳| 耳  we disallow dependences on observables . a small modification to the kev algorithm enables polynomial time solution of this problem. we use the same trellis as in kev. for each timestep t  state i and edit distance k  we also now maintain an additional |c|-vector. an element 汛tikm with 1 ≒ m   |c| represents the likelihood of the map path ending at state i in time slice t with  k #t  edits that still requires constraint suffix cm+1 to be satisfied  except 汛tik1  which has no outstanding constraints to be satisfied . this likelihood can be computed compositionally from 汛而j百米  with 而   t and  百 米  pointwise ≒  k m  in o tn1|c|1p  steps  where formulas 耳i can be evaluated in o p  steps  where p is the size of the formulas .
﹛even map estimation  without trace perturbation  for tchmm's has apparently neither been formulated nor solved previously  although it is potentially quite powerful. for instance  the constrained inference work of culotta et. al.  is a special case of tchmm k-edit map estimation  with k = 1  and c = state q1 estate qi  . map estimation is a special case of rmap estimation with k = 1. our variant of kev above therefore performs map estimation. interestingly with k = 1  we can allow the more general version of formulas 耳 and still retain the fast running time. it is open how general c can be while remaining tractable. for instance  our constraints can be viewed as a fragment of linear temporal logic  ltl  . it is interesting to consider larger fragments as candidates.
1 evaluation
how does model choice affect advice  the k-edit viterbi algorithm dispenses advice based on the parameters of its activity models. the credibility of this advice will suffer from any differences between these models and the reality they represent. in order to illustrate this point  we conducted two experiments over three different activity models. the two experiments compare a regular hmm and a time-sensitive hsmm  and a regular hsmm with an hsmm that has temporal logic constraints  respectively.
﹛first  we compare the output of hmms versus hsmms on three activity traces from different activity models  see the top row of figure 1 . each activity trace was intentionally made incorrect: for making tea  the preparation step was hurried; for making a sandwich  not enough ingredients were collected; and for grooming  brushing teeth and combing hair were performed too rapidly. in the top row of figure 1  we plotted the maximum likelihood values at each step of the activity traces  where a  step  is considered to be a state transition . hmms fail to detect any problem  exhibiting high likelihood. however  hsmm likelihoods plummet  due to sensitivity to the amount of time spent in each state. the kedit trace correctly adds the proper number of observations to each state  resulting in a high likelihood.
﹛second  we compare the output of hsmms with and without temporal logic constraints  tlcs   see the bottom row of figure 1 . again  we intentionally chose incorrect sequences for the three activities: for making tea  the stove is turned on but never turned off; for preparing a sandwich  the refrigerator door is opened and never closed; and for grooming  the sink water is turned on and never turned back off. in the top row of figure 1  we plotted the maximum likelhood values at each step of the activity traces. regular hsmms fail to detect any problem  reporting high likelihood. hsmms with tlcs report low likelihood  because they are only allowed to consider state-transitions which satisfy all constraints. in these traces  constraints are broken and alternate  low-likelihood  paths must be considered. the kedit trace correctly adds the necessary steps  i.e.  turn off stove  shut refrigerator  and turn off sink   resulting in high likelihood.
﹛how does the rating change as k increases  the k-edits viterbi algorithm provides advice for up to k edits. ideally  we desire a trace that is above the likelihood threshold with the minimum number of edits. one method is to incrementally increase k until the threshold is exceeded. for this reason  we are interested in how the likelihood changes as k increases.
﹛in this experiment we ran k-edits viterbi for hsmms on an empty trace of the  making tea  activity. in figure 1 we plotted the overall likelihood of each trace as the number of possible edits was increased. the dashed line is a threshold showing the likelihood of an acceptable  good  trace. obviously  the original empty sequence had low likelihood. as k was increased from one to three  the algorithm was forced to assemble partially complete activity traces which had even lower overall likelihood. when k = 1 the algorithm formed a complete trace and met the threshold. as k increased further  the algorithm tweaked the sequence for a slightly higher likelihood. the most likely possible path was reached at k = 1. afterwards  we see an  odd-even  effect as the algorithm is forced to add new  less likely  observations  and then opportunistically delete other observations. for k ≡ 1  the likelihood drops as the algorithm performs too many modifications to the trace and is unable to reach the optimal solution.

figure 1: one activity per column; top row compares hmms to hsmms  bottom to tchmms﹛how intuitive is the advice  we now examine the advice dispensed by k-edits viterbi in several scenarios. we ran the algorithm on activity traces that had the following problems: restarted the activity  got two steps out of order  performed a step too quickly  and missed or sped through several nonconsecutive steps. all traces are from the  making tea  activity and likelihoods are reported using the optimal number of edits  i.e.  k value .
﹛the beginning steps of the next trace were performed twice  i.e.  a  start  and a  restart  . the algorithm finds the maximum likelihood solution by deleting extra observations. however  the algorithm did not delete the entire start or restart  but decided to  pick and choose  among the two  keeping the best observations of both. in contrast  our intuition would be to advise the user to keep either the start or the restart. similarly  in a trace in which two steps were performed out of order  the algorithm deletes one of the misordered steps and inserts new steps in the correct position. we found this to be less intuitive than simply telling the user to switch the two steps to the correct order.
﹛in the next trace  one step was performed too quickly: the  preparation step  only generated one observation  when it should have generated at least two. the algorithm suggested new observations that corrected the amount of time is spent in the state. however  the algorithm will always suggest the most likely observation from the state  because this maximizes the overall likelihood. at first glance  we found this suggestion strategy to be non-intuitive  although mathematically optimal   however  it became a non-issue for models in which observations were spread across multiple states.
﹛in the last trace several non-contiguous steps were missed entirely or performed too quickly. as k increased  the algorithm first chose to insert states that had been missed entirely  and then to add more observations to states that had been vis-

figure 1: the likelihood of kedit traces as k increases.
ited too briefly. in other words  the algorithm advises the user to at least visit each step of the activity before it advises how to perfect each step. this  top-down  approach fits with our intuition of how advice should be given.
1 conclusions
in this paper  we describe the credible activity rating problem. we introduced the k-edits viterbi algorithm and showed that given model parameters and an activity trace it can provide optimally repaired traces with from zero to k edits. we improved the algorithm by incorporating high-level temporal logic constraints. finally  we evaluated the strengths and limitations of the algorithm on data from three activity models.

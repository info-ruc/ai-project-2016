 

several methods for analyzing three dimensional scenes are discussed with respect to their advantages and difficulties in getting real three dimensional coordinates. stereo picture processing and light intersecting methods are described along with the result of a new hardware system. on the example of a software system some special problems with the abstraction of scenes with primitive objects are mentioned. a short look ahead to the future closes this paper. 
1 - introduction 

when designing a robot system  we have to deal with the problem of how the robot can get information about its environment. to get full information it seems to be necessary to design a visual input facility. therefore there is the problem of how the automaton can get a three dimensional image of the world from visual information. this paper describes some systems  designed in the past  and tries to point out their problems and difficulties. starting from these considerations  a new system is presented with which some of the well known difficulties may be overcome. 
1. stereo pictures 

for interpretation of stereo pictures the system needs two pictures of the same scene  taken from different viewing angles  fig. 1 . provided that 

the two camera positions p1 and p1 and the angles a and b are known  the three dimensional coordi-
nates of the point b of the scene can be calculated. the main problem in stereo picture processing is to define two conjugate points in the stereo 
pair. after the definition of one point in the first picture  the corresponding point in the second picture must be located. this can only be done if the picture point contains significant information  e.g. a corner point. this means that we have to deal with two different problems: first  we have to define a significant point in a first picture  and second  we have to recognize the corresponding point in the second picture. in order to solve the first problem we have to apply timeconsuming preprocessing methods like edge enhancement  etc. the second problem can be solved by two dimensional local correlation methods 	f /. because 
of these difficulties  stereo methods are not used 
in fully automatic systems since now. 
1. light intersecting methods 

in all methods described below  illumination of the scene is regarded as a part of the recognizing system. then all visible points of a scene f i t with a straight line of light or with an illuminating plane of light. with this information the three dimensional coordinates of all visible points can be calculated from their two dimensional coordinates in the picture. using this principal several systems were designed. 
1 laser range finder 

the laser range finding system uses a plane of light with known orientation in space for illumination of the scene. the plane of light is generated with a laser and a cylindrical lens. in such an illuminated scene the camera is able to see only the intersecting line of the light plane and the surface of the scene. the camera takes a complete picture of this image and transmits it to the computer for further processing and extraction of three dimensional coordinates of the intersecting line. by moving the light source step by step across th whole scene  the process of transmitting pictures and calculating spatial coordinates is repeated. it is evident that there is a large amount of data being transmitted and processed  one picture per line  containing very little information. 
therefore the system is intolerably timeconsuming  agin and binford /1/ need about 1 to 1 minutes per scene. 
1 parallel grid illumination 

in order to get quick results from the system  one must try to take the complete information of the scene with only one picture  i.e. the scene has to be illuminated with all planes of light at the same time. the simplest way to do this is to use an optical grid  being projected cnto the scene. processing of the picture could be done by tracing the images of the intersecting lines in the picture. computation of three dimensional coordinates can be done correctly only  if it is possible to identify the images of the lines of light in the picture by their mathematical equations. this problem causes some restrictions to this method: 
a  the camera has to be adjusted in such a way that the pictures contain parts of the ground surface. 
b  shadows  interrupting the image of a line  cause the system to stop tracing the line. 
c  the camera position must be chosen in such a way that lines  running on the top surface of an object can be distinguished from those running on the ground surface behind the obj 

1 

d  scenes with more than one object must not have hidden planes of objects. 
 in order to be able to identify the light lines by their mathematical equations it is necessary that beam in space are well known. projection of the 
scene is made by a cylindrical lens onto a one dimensional camera  designed as a line of photo diodes of ocd-technology. thus each sensor of the camera represents a plane in space as shown in fig.1 the lines start from the ground surface with known 
position. 
other difficulties arise in the evaluation of inner and outer parameters of the camera  position elevation  rotation and focus   especially when more than one parameter is variable. i.e. sobel suggested a method to solve this problem by imaging a 
scene with an object of known size and orientation /1/. if the identity of one line is determined  all points on this line can be aomputed with their three dimensional coordinates. but errors may occur i f a line is interrupted by shadows or other objects 

or if there exists a transition from one line to another  generated by the projection of the camera  fig. 1 . 
if a l l these restrictions are considered and found tolerable to the concrete application  this method 
seems to be a guick possibility to analyze three 
 dimensional scenes. for processing a picture with 1 x 1 sanples  containing 1 lines of light  our computer cdc 1 requires about 1 seconds to 
compute the complete three dimensional 	coordinates 
of 	the lines. 
1 grid and point illumination 
 if the restrictions remarked in 1 are intolerable better results can be achieved by combining two different pictures of one scene  taken by the same ca-
mera in the same position: one picture contains the image of the grid illuminated scene and the other contains the same scene  illuminated by a point light source. in many cases edges  missing in a grid illuminated scene  are precisly imaged in a corresponding point illuminated scene and vice versa as shown in fig.1 . the combination process could be done by three consecutive steps: first we process the grid illuminated scene as far as possible and compute the three dimensional scene coordinates. then we do some contour finding process in the point illuminated image and get a list of contours. then in a third step we generate a two dimensional image out of the computed three dimensional coordinates  containing those contours found in the first step. then we are able to combine both two dimensional contour pictures getting a picture containing a l l contours from both images. 
1 hardware extraction of three dimensional 

in all light intersecting methods for analyzing three dimensional scenes described above  one of the three coordinates is computed from the data of illumination and two coordinates from the data of the picture. this can be changed so that two coor-
dinates are derived from the illumination and only one coordinate from the camera. then we get subsystems which can be built easily in hardware  being not too expensive. 
the scene is illuminated by a single beam of light  generated by a locally fixed laser and deflected under computer control by an electrooptical deflection system. the scene is scanned systematically 
and in each position of the laser beam  the two equations describing the straight line of the light only the intersecting point of this plane and the straight line  formed by the deflected laser beam  is visible to the system  so three dimensional co-
ordinates can be computed directly without any picture processing. as this system measures three di-
mensional coordinates of cnly one point of the scene at one time  there are no restrictions to the scene 
as mentioned in 1  which derived from the parallel grid illumination. 
the time required for processing a whole scene depends on the distance between object and camera because of the quadratic dependance of the sensitivity of the camera. scanning a scene with a resolution of 1 points is expected to require 1 to 1 seconds /1/. fig. 1 shows the complete system. 

1. experimental system 

in order to study the above mentioned problems an experimental system was built  containing a i l parts from scanning the scene until classification of objects  fig.1 . as an input device a tv camera with a zoom lens is used  fig.1 . maption of data rates is made by an analog scan conversion memory. the camera writes with european iv rate  1 mbit per second  into the memory and the computer reads out with its own rate  about 1 mbit/sec  . all other parts of the experimental system are built in software running on a cdc 1 with 1k core. 
1 picture processing 

the scene is illuminated with parallel grid light  generated by a slide projector. iherefore picture preprocessing such as contrast enhancement is not necessary. with a tracing algorithm  following the local maximum of grey level  the computer generates 

1 

chain encoded data strings  which represent the illuminated lines in the picture. fig. 1 shows the 
grid illuminated  a  and the traced  b  scene. 
1 abstraction of scene 
the process of abstraction  described below  works with a l l surfaces  which could be described analyt i c a l   but the current software system is r e s t r i c ted to simple objects with plane surfaces like cubes  wedges  pyramides etc. in order to define the contours of these objects it is necessary to extract those points of the data strings  were a significant change of direction occurs  fig.1  in the chain encoded data. after that  three dimensional coordinates of a l l points on edges are computed  but that can only be done correctly if i d e n t i f i c a tion of lines is correct. this sometimes f a i l s   as shown in f i g . 1. the failure is caused by the narrow lines on the l e f t vertical plane of the cube so that on top the last line is connected with a wrong horizontal line on the ground. because of systematic errors  the extraction of three dimensional coordinates is always within some failure range. beyond t h i s   by using grid illuminat i o n   in some cases corners of objects may only be extracted by interpolation between points of d i f f e rent edges. both problems can be solved by using the fact that a scene is restricted to simple objects with plane surfaces. that means that some of the extracted points always form a straight line in space and that some straight lines must form a 
plane. the next step is to check which points form a straight line and which edges form a plane of the object. in both cases  the same decision rule in used. in the following  the algorithm is explained for the extraction of plane surfaces. the straight lines are defined by their starting and ending points p . fixed by a minimum data set  1 points for a plane  the equation for the f i r s t plane f- is computed  fig.1 . then the distance dr between this f i r s t plane and a next point  iv  is computed and checked against a threshold ¡ê . i f the distance d1 is less than ¡ê   then the point p  belongs to the same plane  fig.1 b  and the equation of the plane is recomputed by regression analysis using the points p-  p-  p. and p.. this a l -
gorithm is repeated for a l l neighboring points. 
fig.1 c-e shows the completion of a cube. 

the intersection of the two planes f- and f  forms the f i n a l vertical edge of the cube   f i g . 1 . after that  a l l coordinates are changed so that they f i t with the equations of the planes. 

1 data structure 
with the computed points and planes a three dimensional  hierarchical  ring oriented data structure is generated. the complexity of objects is restricted to a maximum of 1 points  1 edges and 1 planes  where up to 1 edges are allowed to touch the same point.these restrictions are given by the limited working storage capacity of the computer. in addition  the experimental system contains parts for mainpulating data structures  rotation  translation  scaling  and presenting them on a display. 
1 classification of three dimensional objects 
tne last block in the experimental system is formed by a classificator which compares data structures of known objects against the description of 
an unknown input object. the features for classification are: 

in order to be able to classify three dimensional objects it is ultimately necessary to be independant of the given orientation of the object in the scene. therefore classification must be done i n variant to rotation and translation of objects. by control of parameters the user is able to specify size invariant or size sensitive classification. furthermore he can get results dealing with scaling and distortion of objects. fig. 1 shows an example of data structures presented on a display together with the result of a classification: 
dreibein was identified to be the same object as dreib1 and dreib1. 
the classification process itself is done by rotating  translating and scaling the unknown object until it f i t s with one or more of the known objects. the classification is very quick: to ident i f y the object dreibein in f i g . 1  the cdc 1 requires about 1 seconds. 

1 

lyze scenes consisting of one object with plane surfaces. investigations on more complex scenes present a lot of difficulties as shown in 1. therefore the system mentioned in 1 is proposed to avoid these difficulties. 
furthermore there are. no criteria for seperation of complex objects. several criteria axe being considered  such as  as large as possible    number of planes as few as possible    as compact as posiible  etc. 
first efforts with hidden lines have been published for the two dimensional case /1/. this method with a successive eliminations of objects and hypothetic completions of hidden lines seems to be well suited also for the three dimensional case. research in the past has shown that the light intersecting methods are practical for analyzing three dimensional scenes  especially in cases with 
a fixed working space. one can think of applications like  nuclear research centers in so called hot cells  for mounting on assembly belts and also for intelligent robots in space flight missions or remote sensed identification of vehicles and aircraft. 
examination of objects with curved surfaces and their description in a computer is a hard problem 
with no practical solution at hand. curved surfaces can be described by approximation with many small planes /1/. approximation by generalized cylinders reduces the amount for description  but there are no satisfactory results /1/. it seems that scanning and picture processing in robotics is a solvable problem  but description of objects requires more research in that field. 
1. literature 
/!/ k. wolferts  special problems in interactive image processing for traffic analysis  proc. 
1.nd international joint conference  ijcpr1  on pattern recognition  pp 1  august 1 hyngby  denmark 
1 



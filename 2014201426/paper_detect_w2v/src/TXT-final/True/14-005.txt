 	1. prediction 
         
         a c r o n y m is a comprehensive domain independent modelbased system for vision and manipulation related tasks. many of its sub-modules and representations have been described elsewhere. here the derivation and use of invariants for image feature prediction is described. we describe how predictions of image features and their relations are made and how instructions are generated which tell the interpretation algorithms how to make use of image feature measurments to derive three dimensional sizes and structural and spatial constraints on the original three-dimensional models. some preliminary examples of a c r o n y m ' s interpretations of aerial images are shown. 
1- introduction 
         at the previous 1jca1 we reported |1  on the design and development of a model-based vision system called a c r o n y m   which could indentify instances of modeled objects in images since then the scope of a c r o n y m has been increased to include extraction of three dimensional information from images  including monocular images    reasoning about bow to grasp objects  binford  1    and real time simulation of multiple manipulator work stations for purposes of off-line programming and the design and analysis of new manipulators  soroka 
         to support these devlopments we have added a class and subclass relation representation scheme to the geometric modeling system   1    1  this is based on the use of symbolic algebraic constraints. in support of this a constraint manipulation systems which includes a partial decision procedure on consistency of sets of non- linear inequalities was formulated and implemented  1  a geometric reasoning system which can deal with underconstrained spatial relations was developped  1  a new matcher which could manipulate the constraint systems was built for interpretation  1  all of these systems were implemented in a mixture of m a c l i s p and a new rule system built for the purpose. 
         we have thus moved from a purely geometric representation and qualitative geometric reasoning system to a system with a combined algebraic and geometric representation and a geometric reasoning system which can make precise deductions about partially specified situations the geometric and algebraic aspects of the representation complement each other during interpretation. 
         in this paper we deal with the techniques developed for image feature and feature-relation prediction  and then give some first examples  february 1  of the performance of the new incarnation of a c r o n y m on some images the low level processes we currently use provide either little or noisy data. nevertheless a c r o n y m makes strong and accurate deductions about the objects appearing in the images we expect even better performance when more accurate low level descriptive* processes become available 
this work was supported by the defense advanced research projects 
agency under contract mda1 c 1  by the national science 
foundation under contract dar1 and by a grant from the alcoa corporation. 
         in the a c r o n y m system generic object classes and specific objects are represented by volumetric models based on generalised cones along with a partial order on sets of non-linear algebraic inequalities relating model parameters image features and relations between them which are invariant over variations in the models and camera parameters are identified by a geometric reasoning system. such predictions are combined first to give guidance to low level image description processes  then to provide coarse filters on image features which are to be matched to local predictions predictions also contain instructions on how to use noisy measurements from identified image features to construct algebraic constraints on the original three dimensional models. local matches are combined subject both to consistently meeting predicted linage feature relations  and the formation of consistent sets of algebraic constraints derived from the image. the result is a three dimensional interpretation of the image. 
         this section describes some of the invariants that are identified by the reasoning system  and gives examples of how the back constraints are set up giving three dimensional information about the instances of the models which appear in images. 
1 constraints 
         to illuminate the discussion in succeeding sub-sections we briefly describe the uses and capabilities of a c r o n y m ' s constraint mechanism and the allowed structure of constraints themselves. 
         acronym's three-dimensional models are represented by units and slots  e.g. bobrow and winograd  1  . any slot which admits numeric fillers also admits quantifiers  predeclared variable names  and expressions over quantifers using the operators +  -  x   / and j. 
         constraints can be put on quantifiers. they take the form of inequalities between expressions as defined above  along with the possibility of including max and mm  on the left and right of    respectively . equality can be encoded as two inequalities. for instance suppose a cylinder is represented as a generalized cone whose straight spine has its length defined by the quantifier cyl length and whose cross section is a circle with radius cyl radius. then the class of all cylinders of volume 1  in some units  can be represented by the two constraints. 

	the 	a c r o n y m 	constraint 	manipulation 	system 	 cms   
described in detail in |1   operates on sets of constraints. a set of constraints  implicitly conjunctive  defines a subset of n dimensional space for which all constraints are true  where n is the number of quantifiers mentioned in the constraint set  this is called the satisfying set  and is empty if the constraints are inconsistent. the cms is used for three tasks related to this constraint set. 
1. given a set of constraints partially decide whether their satisfying set is empty the outcomes are  empty  or  i don't know*. 
1 
1. find numeric  or + oo  upper and lower bounds on an expression in quantifers over the satisfying set of a constraint set. this uses procedures called sup and inf. 
1.  a generalisation of 1.  for and expression e and a set of quantifiers v find expressions l and h in v such that l   b   h identically over the satisfying set of the constraint set. 
         in 1 and 1 the expressions being bounded can include trigonometric functions such as sin  cos and arcsin. the cms we have implemented in a c r o n y m is a non-linear generalisation of the linear sup-inf method described by bledsoe  1   and shostak  1 . it behaves identically to that described by the latter for purely linear sets of constraints and linear expressions. in addition it can often produce good bounds  numeric and expressions  on highly non-linear expressions in the presence of many non-linear constraints. 
1 shape prediction 
         we predict shapes as ribbom  the two dimensional analogue of three dimensional generalised cones  and ellipses. these are also the features which are found by the low level descriptive process we are temporarily using in a c r o n y m . 
         ribbons are a good way of describing the images generated by generalised cones. consider a ribbon which corresponds to the image of the swept surface of a generalised cone for straight spines  the projection of the cone spine into the image would closely correspond to the spine of the ribbon. thus a good approximation to the observed angle between the spines of two generalised cones is the angle between the spines of the two ribbons in the image corresponding to their swept surfaces. we do not have a quantitative theory of these correspondences. ellipses are a good way of describing the shapes generated by the ends of generalised cones. the perspective projections of ends of cones with circular cross-sections are exactly ellipses. 
         shape prediction involves deciding what shapes will be visible  predicting ranges for shape parameters  to be used as a coarse filter during interpretation and also to guide the low level descriptive processes  and deriving instructions about how to locally invert the perspective transform and hence use image measurements to generate constraints on the original three dimensional models. 
         to predict the shapes generated by a single generalised cone  we do not explicitly predict all possible qualitatively different view points. rather we predict what shapes may appear in the image  and associate with them methods to compute constraints on the model that are implied by their individual appearance in an the image. for example  identification of the image of the swept surface of a right circular cone constrains the relative orientation of the cylinder to the camera  we call these back constraints  identification of an end face of the cylinder provides a different set of constraints. if both the swept surface and an end face are identified then both sets of constraints apply we also predict specific relations between shapes that will be true if they are both observed correctly. for more complex cones  the payoff is even greater for predicting individual shapes rather than exhaustive analysis of which shapes can appear together. 
         at other times during prediction invariant cases of obscuration are noticed. for instance it may be noticed that one cone abuts another so that its end face will never be visible. the consequences of such realisations are propagated through the predictions. 
         prediction of shapes proceeds in five phases. first  all the contours on a generalised cone which could give rise to image shapes are indentified by a set of special purpose rules these include occluding contours and contours due purely to internal cone faces. thus for instance a right square cylinder will generate contours for the end faces  the swept faces  and contours generated by the swept edges at diagonally vertices of the square cross section. the contours are generated independently of camera orientation  and in terms of object dimensions rather than image quantities. 
         second  the orientation of the generalised cone relative to the camera  this is done by the geometric reasoning system  see  1    €   is then examined to decide which contours will be visible and how their image shapes will be distorted over the range of variations in the model parameters which appear in the orientation expressions. 
         the third phase predicts relations between contours of a single generalised cone  see section 1 . 
         fourth  the actual shapes are then predicted the expected values for shape parameters in the image are estimated as closed intervals  see below  
         finally the back constraints which will be instantiated during interpretation are constructed. 
1.1 back constraints 
¡¡¡¡¡¡¡¡suppose that we wish to predict the length of an observable feature which is generated by something of length / lying in a plane parallel to the camera image plane  at distance d from the camera. furthermore suppose the camera has a focal ratio of /. 	then the measured length of the observed feature is given by 
any or all of /  / and d may be expressions in quantifiers  rather than numbers. using the cms we can obtain bounds on the above expression for image feature length  giving that it will he in some range p =  p i p h   where p  and ph are either numbers or  for more complex geometries the expression for p will be more complex  but the method in the same  trigonometric functions are usually involved  
         now  given an image feature  which is hypothesised to correspond to the prediction we have to decide whether it acceptable on the basis of its parameters. the low level descriptive processes are noisy and provide an error interval  rather than an exact measurement for image parameters. suppose the interval is  for a feature parameter predicted with expression p. then the parameter is acceptable if  is non-empty this is the coarse filtering used during initial hypothesis of image feature to feature prediction matches. 
¡¡¡¡¡¡¡¡but note also that it must be true that the true value of p for the particular instance of the model which is being imaged must he in the range m 	thus we can add the constraints: 

to the instance of the model being hypothesised  where i  f and d are numbers or expressions in quantifiers. 
1.1 trigonometric back constraints 
         when the expression p involves trigonometric functions the above method of generating back constraints will not work. it would generate constraints involving trogonmetnc functions  which our cms can not handle. 
         one approach to this problem is to bound expression p above and below by expressions involving no quantifiers contained in arguments to trigonometric functions  and then use these expressions in setting up the back constraints. this has the unfortunate side effect of losing all information implied by the image feature about the quantifiers eliminated from the bounds. 
         a second approach is sometimes applicable. if a trigonometric function has as its argument e  an expression  and if the cms determines that e is bounded to he within a region of the function's domain where it is strictly monotonic and hence invertible  then specific back constraints on r can be computed at interpretation time  as distinct from during prediction  we illustrate with an example a cylinder with length cyl length is sitting upright on a table a camera with unknown but constrained pan and tilt  the latter is constrained to he in the interval  is looking across from the side of the table  and it is elevated above table top height the geometric details and numeric 
1 
constants are not important here. suffice it to say that the geometric reasoning system deduces that the pan of the camera is irrelevant to the prediction of the length of the ribbon corresponding to the swept surface of the cylinder. it predicts that the length of the ribbon in the image will in fact be: 

where 1 is the focal ratio of the camera and cylinder. camz is an internal quantifier generated by the prediction module. 
         both of the above approaches are used to generate back constraints to ensure coverage of all the relevant quantifiers. they are: 

the first two are non-trigonometric back constraints and at interpellation time a simple susbsitution of the measured numeric quantities for m1 and mh  is done. the latter two require further comuptation at interpretation time. after the substitution  expressions must be bounded over the satisfying set of all the known constraints  and the function arccos applied to give numeric upper and lower bounds on the quantifier tilt. 
         the techniques described here work for a more general class of functions than trigonometric functions  in the current implementation of a c r o n y m we use it for functions sin  cos and arcsin . the requirement is that the domain of the function  e.g. the interval  -¦Ð  ¦°  for 
sin and cos   can be subdivided into a finite number of intervals over which the function is strictly monotonic  and hence locally invertible. 
1 feature relation prediction 
         image feature  shape  predictions are organised as the nodes of the prediction graph. the arcs of the graph predict image-domain relations between the features. during interpretation pairs are constructed which match in mage features and prediction nodes they are coarsely checked for consistency by attempting to instantiate the predicton arcs. some arcs also include back constraints which the instantiation of the arc implies about the model these are treated in exactly the same manner as those associated with image feature predictions. 
         prediction arcs are generated to relate multiple shapes predicted for a single cone. for instance a right circular cylinder prediction includes shapes for the swept surface and perhaps each of the end faces  depending on whether the camera geometry is known well enough to determine a priori exactly which faces will be visible . it can be predicted that a viable end face will be co- incident at at least one point in the image with a visible swept surface.  in fact a stronger prediction can be made: the straight spine of the swept surface image ribbon can be extended through the center of mass of the elliptical image of the end face.  
         prediction arcs are also generated between shapes associated with predictions for different generalised cones. these are actually of more importance in arriving at a consistent global interpretation of collections of image features as complex objects. 
the semantics of the arc types we currently use are as follows. 1.1 exclusive 
         if a generalised cone has a straight spine  and during sweeping  the cross section is kept at a constant angle to the spine  then at most one of the cone's end faces can be visible in a single image. exclusive arcs relate image features which are mutually exclusive for this or other reasons.  note that in this case  instantiations of the two end facet would probably result in inconsistent back constraints being applied to the spatial orientation of the original model  so that eventually the cms would detect an inconsistency. however checking for the existence of a simple arc at an early stage is computationally much cheaper than waiting to invoke the decision procedure.  
1.1 colinear 
         if two straight line segments in three-space are coliner then any two-space image of them will either be a single degenerate point or two cohnear line segments as was pointed out earlier  the spine of the image shape corresponding to the swept surface of a cone is usually a good approximation to the projection of the spine of the cone into the image. thus if two cones are known to have cohnear spines in three dimensions  a cohnear spine arc between the predictions of their swept surfaces can be included. 
1.1 coincident 
         if two cones are physically coincident at some point s  in threespace  then for any camera geometry  if they are both visible then thenprojections will be coincident at some point s   except for some cases of obscuration . failure to match predicted coincident arcs turns out to be the strongest pruning process during image interpretation. 
1.1 angle 
         if the angle between the spines of two generalised cones as viewed from the modeled camera is invariant over all the rotational variations in the model  or if an expression for the observed angle can be symbolically computed and is sufficiently simple  then a prediction of the observed angle can be made. for example wing-wing and wingfuselage angles are invariant when an aircraft is viewed from above this is because the only rotational freedom of an aircraft on the ground is about an axis parallel to the direction of view of an overhead camera. again the fact that the projections of model spines correspond to image spines is used here. this arc type includes  trigonometric  back constraints which make use of the observed angle. some such constraints constrain relative spatial orientations of generalised cones. others provide constraints on the orientation of the plane of rotation  which generated the angle  relative to the camera  and hence constraints on an object's orientation relative to the camera. 
1.1 approach-ratio 
         suppose a cone b is affixed at one end of its spine to another cone a  with a straight spine  somewhere along its length. the spines need not be coincident  but the cones must be. suppose the spine of cone a has endpoints o  and a1  and let o1 be the point on the spine of a closest to the end of the spine of b then the approachratio is the ratio of the length of the spine segment from o  to o1 and the length of the complete spine from o  to a1 if the spines of a and b are both observable  then the approach-ratio is invariant under a normal projection for all camera geometries. thus it is a quasiinvariant for a perspective projection for a camera sufficiently far from the object. for example  the ratio of the distance from the rear of the fuselage to the point of wing attachment  to the length of the fuselage  is almost invariant over all viewing angles for objects sufficiently far from the camera. again this relies on the corresspondences between the projection of a cone spine and the spine of the ribbon generated by the image of its swept surface. approach-ratio arcs are only generated for pairs of unage features which have a coincident arc. they provide back constraints on the model via the symbolic expression which describes the modeled spine approach ratio. 
1.1 distance 
         sometimes symbolic expressions for the image distance between two image features can computed. distance arcs are only generated for pairs of image features which also have an angle arc  but no coincident arc. distance arcs generate back constraints on the original model. 
1 1 
         
1. some image interpretations 
         the image interpretations reported here are of a rather preliminary nature. they were carried out when the various sub-systems had only been running together for about two weeks. further experimentation has been hampered b address space limitations - the current system occupies two 1k address spaces on a dec-1- an effort is underway to transport the system to a vax. 
         in the examples to be described here a c r o n y m was given a generic model of wide-bodied passenger jet aircraft  along with class specialisations to l-1s and boeing-1t. the boeing 1 class bad further subclass specialisations to boeing-1b and boeing-1sp. the subclasses are do not completely partition their parent classes. the classes are described by sets of constraints on some 1 quantifiers. figure 1 shows instances of the two major modeled classes of jet aircraft these diagrams were draw by a c r o n y m from the models given it to carry out the image interpretations. the constraints for the generic class of wide bodied jets are given in figure 1. units are meters. 
         the camera was modeled as being between 1 and 1 meters above the ground. thus there is little a priori knowledge of the scale of the images. a specific focal ratio was given: 1.  similar interpretations have been carried out with a variable focal ratio  but then the final constraints on camera height and focal ratio are coupled  and not as clear for illustrative purposes - no accuracy is lost due to the non-linearities that are introduced into the constraints  although both computation time and garbage collection time are increased.  
         the aircraft models  the camera model and the number of pixels in each dimension of the image  1 x 1 in these examples  were the only pieces of world knowledge input to a c r o n y m . it has no special knowledge of aerial scenes: all its rules are about geometry and algebraic manipulation. these were applied to the particular generic models it was given  to make predictions and then to carry out interpretations. 
         figures 1 through 1 show three examples of interpretations carried out by a c r o n y m . in each case part a is a half-tone of the original grey level image the 1 version is the result of applying the line finder of nevatia and babu  1  that line finder was designed to find linear features such as roads and rivers in aerial photos. close examination of results on these images indicate many errors  and undue enlargement in width of narrow linear features. it also produces many noise edges in in smooth brightness gradients  not visible at the resolution of the reproductions of these figures . these edges are the lowest level input to a c r o n y m . 
         an edge linker  is directed by the predictions to look for ribbons and ellipses. in this case there is very little a priori information about the scale of the images. the c versions of each figure show the ribbons fitted to the linked edges when it is searching for candidate matches for the fuselage and wings of aircraft there is even further depredation of image information at this stage this is the only data which the a c r o n y m reasoning system is given to interpret. notice that in the. figure 1 almost all the shapes corresponding to aircraft are lost. quite a few aircraft in 1 are lost also. besides losing many shapes  the combination of the edge finder and edge linker conspire to give very inaccurate image measurements. we assume all image measurements have a + 1% error  except that for very small measurements  we assume that pixel noise swamps even those error estimates. then the error is estimated to be inversely proportional to the measurement with a 1 pixel measurement admitting a 1% error thus the data which a c r o n y m really gets to work with is considerably more fussy than indicated by the the c series of figures. 
         we intend to make use of new and better low level descriptive processes being developped in our laboratory by other researchers as soon as they become robust enough for every day use  e.g. baker  i  whose descriptions from stereo will also include surface and depth information . 
         despite this very noisy descriptive data a c r o n y m makes good interpretations of the images. the d series of figures show its interpretations with the ribbons labeled by what part of the model they were matched to  the numbers which may be unreadable in 1d show the groupings into individual aircraft.  
         a c r o n y m first uses the most general set of constraints  those associated with the generic class of wide bodied jets  when carrying out intitial prediction and interpretation. interpretation addn additional constraints for each hypothesised aircraft instance for example in finding the correspondences in figure 1d constraints were added which eventually constrained the wing width  the width of the wings where they attach to fuselage  to he m the range  1.1  compared to the modeled bounds of  1 . the height of the camera  modeled to he in the range |1  is constrained by the interpretation to the range  1 . 
         once a consistent match or partial match to a geometric model has been found in the context of some set of constraints  model class   it easy to check whether it might also be an instance of a subclass. we need only add the extra constraints associated with the subclass and check for consistency with those already implied by the interpretation using the cms as described in section 1. the aircraft located in 1d is consistent with the constraints for an l-1  but not for a boeing-1. examination of the images by the author had previously indicated that the aircraft was an l 1 the additional symbolic constraints implied by accepting that the aircraft is in fact an l-1 propagate through the entire constraint set although the constraints decribing an l-1 do not include constraints on camera height  the back constraints deduced during interpretation relate quantifers representing such quantities as length of the wings to the height  and focal ratio in the more general case . thus the height of the camera is further constrained in 1 ad to he in the range  1  recall that all image measurements were subject to +1% errors  and that this estimate has taken all such errors into account 
         figure 1d indicates matches were found for three airplanes. examination of the data in 1c indicates that this is the best that could be expected. note however that only partial matches were found in all three cases. for such small ribbons errors were apparently larger than the generous estimate used the fuselage ribbon in the leftmost aircraft  number 1  for instance fails to pass the coarse filtering stage. despite the partial match  this particular aircraft is found to be consistent with the constraints for an l 1  but not consistent with those of a boeing 1. again this is correct. 
the other two aircraft identified are even more interesting. 
the author had thought from casual inspection of the grey level image 
1 
         
that they were instances of boeing-1a they both gave matches consistent with the class of wide-bodied jets as expected neither was consistent with the extra costraints of an l 1. however  although each individual parameter range from the interpretation constraint sets was consistent with the individual parameter value or range for the class of boeing-1s  neither set of constraints was consistent with that subclass  the constraints contain much finer information than just the parameter ranges - in the same manner as in the example above where constraints on wing length propagate to constrain the camera height . on close examination of the grey-level image it was determined that the aircraft were not in fact boeing-1's the author used the fact that they were much smaller than the l-1 to make that deduction  but acronymmade the deduction at the local level before considering comparisons between aircraft. 
         the aircraft  probably boeing-1's  are in fact too small to be wide-bodied jets of any type since the scale of the image is unknown a prion this can not be deduced locally. however it is reflected in the height estimates derived at the local level  1  interpreting the l-1 just as a generic wide-body    1  as an l-1   and  1  1  for the rightmost aircraft thus a c r o n y m deduces that either the left aircraft is a wide- body and the others are not  or the nght two are wide bodies and the left one is not  it is too big . 
         finally note that geometrically there were other candidates for aircraft in the ribbons of figure 1c for instance the wing of the aircraft just to the right of those indentified and a ribbon found for its passenger ramp could be the two wings of an aircaft with a fuselage missing between them. in fact these two ribbons were instantiated as an aircraft on the basis of the coarse filters on the nodes and arcs. however the set of back constraints they generated were mutually inconsistent. 
         thus we can see from the examples that even with very poor and noisy data the combined use of geometry and symbolic algebraic constraints can lead to accurate image interpretations. the system should be tested on more accurate low level data to fully evaluate the 
power of this approach 

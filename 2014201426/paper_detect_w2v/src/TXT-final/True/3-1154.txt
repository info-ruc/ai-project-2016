
many real-world decision making tasks require us to choose among several expensive observations. in a sensor network  for example  it is important to select the subset of sensors that is expected to provide the strongest reduction in uncertainty. it has been general practice to use heuristic-guided procedures for selecting observations. in this paper  we present the first efficient optimal algorithms for selecting observations for a class of graphical models containing hidden markov models  hmms . we provide results for both selecting the optimal subset of observations  and for obtaining an optimal conditional observation plan. for both problems  we present algorithms for the filtering case  where only observations made in the past are taken into account  and the smoothing case  where all observations are utilized. furthermore we prove a surprising result: in most graphical models tasks  if one designs an efficient algorithm for chain graphs  such as hmms  this procedure can be generalized to polytrees. we prove that the value of information problem is nppp-hard even for discrete polytrees. it also follows from our results that even computing conditional entropies  which are widely used to measure value of information  is a #p-complete problem on polytrees. finally  we demonstrate the effectiveness of our approach on several real-world datasets.
1 introduction
in probabilistic reasoning  where one can choose among several possible but expensive observations  it is often a central issue to decide which variables to observe in order to most effectively increase the expected utility. in a medical expert system   for example  multiple tests are available  and each test has a different cost. in such systems  it is thus important to decide which tests to perform in order to become most certain about the patient's condition  at a minimum cost. occasionally  the cost of testing can even exceed the value of information for any possible outcome.
모the following running example motivates our research and is empirically evaluated in section 1. consider a temperature monitoring task  where wireless temperature sensors are distributed across a building. the task is to become most certain about the temperature distribution  whilst minimizing energy expenditure  a critically constrained resource .
모many researchers have suggested the use of myopic  greedy  approaches to select observations  1; 1; 1; 1 . unfortunately  this heuristic does not provide any performance guarantees. in this paper  we present efficient algorithms  which guarantee optimal nonmyopic value of information in chain graphical models such as hidden markov models  hmms . we address two settings: subset selection  where the optimal subset of observations is obtained in an open-loop fashion  and conditional plans  a closed-loop plan where the observation strategy depends on the actual value of the observed variables  c.f. fig. 1 a  . to our knowledge  these are the first optimal and efficient algorithms for these tasks for this class of graphical models. for both settings  we address the filtering and the smoothing versions: filtering is important in online decision making  where our decisions can only utilize observations made in the past. smoothing arises for example in structured classification tasks  where there is no temporal dimension in the data  and hence all observations can be taken into account. we evaluate our algorithms empirically on three real-world datasets  and also show that they are well-suited for interactive classification of sequential data.
모most problems in graphical models  such as probabilistic inference and the most probable explanation  that can be solved efficiently for chain-structured graphs  can also be solved efficiently for polytrees. we prove that the problem of maximizing value of information is nppp-hard even for discrete polytree graphical models  giving a complexity theoretic classification of a core artificial intelligence problem. nppp-hard problems are believed to be significantly harder than np-complete or even #p-complete problems commonly arising in the context of graphical models. as a special case  we also prove that computing conditional entropies is #p-complete even in the case of discrete polytrees. this is a surprising result about a measure of uncertainty that is frequently used in practice.
1 optimization criteria
in order to maximize value of information  our objective functions should depend on probability distributions over variables. let s = {x1 ... xn} be a set of discrete random variables. we consider a class of local reward functions r  which are defined on the marginal probability distributions of the variables. this class has the computational advantage that local rewards can be evaluated using probabilistic inference techniques. the total reward will then be the sum of all local rewards.
모let o be a subset of s. then p xj | o = o  denotes the marginal distribution of variable xj conditioned on observations o. for classification purposes  it can be more appropriate to consider the max-marginals pmax xj = xj | o = o  = maxx p x = x xj = xj | o = o   that is  for xj set to value xj  the probability of the most probable assignment to all other random variables conditioned on the observations o. the local reward rj is a functional on the probability distribution p or pmax over xj. we write

as an abbreviation to indicate expected local rewards  where the expectation is taken over all assignments o to the observations o. important measures for value of information include:
  entropy. if we set rj p xj | o   =  h xj | o  =
pxj o p xj o logp xj | o   the objective in the optimization problem becomes to minimize the sum of residual entropies. we choose this reward function in our running example to measure the uncertainty about the temperature distribution.
  maximum expected utility. the concept of local reward functions also includes the concept of utility nodes in influence diagrams. if uj : aj 뫄 domxj 뫸 r is a utility function mapping an action a 뫍 aj and an outcome x 뫍 domxj to a reward  then the maximum expected utility principle states that actions should be selected as to maximize euj a | o  = px p x | o uj a x . the more certain we are about xj  the more economically we can choose our action. hence we can define our local reward function r p xj | o   = po p o maxa euj a | o .
  margin. we can also consider the margin of confidence: rj pmax xj | o   = po p o  pmax x j | o  pmax 몬xj | o    where x  = argmaxxj pmax xj | o  and x몬 = argmaxxj1=x  pmax xj | o   which describes the margin between the most likely outcome and the closest runner up. this reward function is very useful for structured classification purposes  as shown in sec. 1.
these examples demonstrate the generality of our notion of local reward. one can generalize the algorithms even more  e.g.  to measure the total entropy or the margin between the most probable explanation and its runner up. details are omitted here due to space limitations.
모we also want to capture the constraint that observations are expensive. this can mean that each observation xj has an associated positive penalty cj that effectively decreases the reward. in our example  we might be interested in trading off accuracy with sensing energy expenditure. alternatively  it is also possible to define a budget b for selecting observations  where each one is associated with an integer cost 붹j. here  we want to select observations whose sum cost is within the budget  but these costs do not decrease the reward. in our running example  the sensors could be powered by solar power  and regain a certain amount of energy per day  which allows a certain amount of sensing. our formulation of the optimization problems allows both for penalties and budgets. to simplify notation we also write c o  = pxj뫍o cj and 붹 o  = pxj뫍o 붹j to extend c and 붹 to sets.
1 decomposing rewards
in the following sections 1 and 1  we present efficient algorithms for two problems of optimizing value of information in the class of chain graphical models.

 a  example conditional plan.	 b  decomposition of the reward. figure 1: example  and decomposing reward idea
모the set of random variables s = {x1 ... xn} forms a chain graphical model  a chain   if xi is conditionally independent of xk given xj whenever i   j   k. we can assume that the joint distribution is specified by the prior p x1  and conditional probability distributions p xi+1 | xi . the time series model for the temperature measured by one sensor in our example can be formulated as a chain graphical model.
모chain graphical models originating from time series have additional  specific properties: in a system for online decision making  only observations from the past and present time steps can be taken into account  not observations which will be made in the future. this is in general referred to as the filtering problem. in this setting  the notation p xi | o  will refer to the distribution of xi conditional on observations in o prior to and including time i. for structured classification problems as discussed in section 1  in general observations made anywhere in the chain must be taken into account. this situation is usually referred to as the smoothing problem. we will provide algorithms both for filtering and smoothing.
모we will now describe the key insight  which allows for efficient optimization in chains. consider a set of observations o   s. if the j variable is observed  i.e.  xj 뫍 o  then the local reward is simply r xj | o  = r xj | xj . now consider xj 뫍/ o  and let oj be the subset of o containing the closest ancestor  and for the smoothing problem also the closest descendant  of xj in o. the conditional independence property of the graphical model implies that  given
oj  xj is independent of the rest of the observed variables 
.	thus  it follows that
모these observations imply that the expected reward of some set of observations decomposes along the chain. for simplicity of notation  we add two independent dummy variables x1 and
xn+1  where r1 = c1 = 붹1 = rn+1 = cn+1 = 붹n+1 = 1. let o = {xi1 ... xim+1} where il   il+1  i1 = 1 and im+1 = n + 1. using this notation  the total reward r o  = pj rj xj | o  for the smoothing case is given by:
.
v=1
in filtering settings  we simply replace rj xj | xiv xiv+1  by rj xj | xiv . figure 1 b  illustrates this decomposition.
모consider now a hidden markov model unrolled for n time steps  i.e.  s can be partitioned into the hidden variables {x1 ... xn} and the emission variables {y1 ... yn}. in hmms  the yi are observed and the variables xi form a chain. in many applications  some of which are discussed in section 1  we can observe some of the hidden variables  e.g.  by asking an expert  in addition to observing the emission variables. in these cases  the problem of selecting expert labels also belongs to the class of chain graphical models addressed by this paper.
1 subset selection
in the subset selection problem  we want to find a most informative subset of the variables to observe in advance  i.e.  before any observations are made. in our running example  we would  before deploying the sensors  identify k time points that are expected to provide the most informative sensor readings according to our model.
first  define the objective function l on subsets of s by
	.	 1 
the subset selection problem is to find the optimal subset
	o  =	argmax	l o 
o s 붹 o 뫞b
maximizing the sum of expected local rewards minus the penalties  subject to the constraint that the total cost must not exceed the budget b.
모we solve this optimization problem using a dynamic programming algorithm  where the chain is broken into sub-chains using the insight from sec. 1. consider a sub-chain from variable xa to xb. we define la:b k  to represent the expected total reward for the sub-chain xa ... xb  where xa  and xb in the smoothing case  is observed  and with a budget level of k. more formally:
                       b 1 o {xa+1...xb 1} x
la:b k  =	max	rj xj | o 뫋 {xa}    c o  
j=a+1
붹 o 뫞k
for the filtering version  and
                       b 1 o {xa+1...xb 1} x
la:b k  =	max	rj xj | o뫋{xa xb}  c o  
j=a+1
붹 o 뫞k
for the smoothing version. note that l1:n+1 b  = maxo:붹 o 뫞b l o   as in eq.  1   i.e.  by computing the values for la:b k   we compute the maximum expected total reward for the entire chain.
모we can compute la:b k  using dynamic programming. the base case is simply:
b 1
la:b 1  = x rj xj | xa  
j=a+1
for filtering  and
b 1
la:b 1  = x rj xj | xa xb  
j=a+1
for smoothing. the recursion for la:b k  has two cases: we can choose not to spend any more of the budget  reaching the base case  or we can break the chain into two sub-chains  selecting the optimal observation xj  where a   j   b: la:b k  =max{la:b 1  	max	{ cj+
j:a j b 붹j뫞k
+ rj xj | xj  + la:j 1  + lj:b k   붹j }}.
at first  it may seem that this recursion should consider the optimal split of the budget between the two sub-chains. however 
input: budget b  rewards rj  costs 붹j and penalties cj output: optimal selection o of observation times begin
for 1 뫞 a   b 뫞 n + 1 do compute la:b 1 ; for k = 1 to b do for 1 뫞 a   b 뫞 n + 1 do sel  1  := la:b 1 ;
for j = a + 1 to b   1 do sel j  :=
 cj + rj xj | xj  + la:j 1  + lj:b k   붹j ;
la:b k  = maxa j b sel j ;
   붦a:b k  = argmaxa j b sel j ; end
end
a := 1; b := n + 1; k := b; o :=  ; repeat j := 붦a:b k ;
if j 뫟 1 then o := o 뫋 {xj}; k := k   붹j;
   until j =  1; endalgorithm 1: optimal subset selection.
since the subset problem is open-loop and the order of the observations is irrelevant  we only need to consider split points where the first sub-chain receives zero budget.
모a pseudo code implementation is given in alg. 1. if we do not consider different costs 붹  we would simply choose 붹j = 1 for all variables and compute la:b n . alg. 1 uses the quantities 붦a:b to recover the optimal subset by tracing the maximal values occurring in the dynamic programming equations. using an induction proof  we obtain:
theorem 1. the dynamic programming algorithm described above computes the optimal subset with budget o n1  b evaluations of expected local rewards. 
모if the variables xi are continuous  our algorithm is still applicable when the integrations and inferences necessary for computing the expected rewards can be performed efficiently.
1 conditional plan
in the conditional plan problem  we want to compute an optimal querying policy: we sequentially observe a variable  pay the penalty  and depending on the observed values  select the next query as long as our budget suffices. the objective is to find the plan with the highest expected reward  where  for each possible sequence of observations  the budget b is not exceeded. for filtering  we can only select observations in the future  whereas in the smoothing case  the next observation can be anywhere in the chain. in our running example  the filtering algorithm would be most appropriate: the sensors would sequentially follow the conditional plan  deciding on the most informative times to sense based on the previous observations. fig. 1 a  shows an example of such a conditional plan.
모the formal definition of the objective function j is given recursively. the base case considers the exhausted budget:
j o = o;1  = x rj xj | o = o    c o .
xj뫍s
the recursion  j o = o;k   represents the maximum expected reward of the conditional plan for the chain where o = o has been observed and the budget is limited to k:
j o = o;k  = max{j o = o;1   max{
xj뫍/o
x
p xj = y | o = o  몫 j o = o xj = y;k   붹j }}.
y
the optimal plan has reward j  ;b .
모we propose a dynamic programming algorithm for obtaining the optimal conditional plan that is similar to the subset algorithm presented in sec. 1. again  we utilize the decomposition of rewards described in section 1. the difference here is that the observation selection and budget allocation now depend on the actual values of the observations.
모we again consider sub-chains xa ... xb. the base case deals with the zero budget setting:
b 1
ja:b xa;1  = x rj xj | xa = xa  
j=a+1
for filtering  and
b 1
ja:b xa xb;1  = x rj xj | xa = xa xb = xb  
j=a+1
for smoothing. the recursion defines ja:b xa;k   ja:b xa xb;k  for smoothing   the expected reward for the problem restricted to the sub-chain xa ... xb conditioned on the values of xa  and xb for smoothing   and with budget limited by k. to compute this quantity  we again iterate through possible split points j  such that a   j   b. here we observe a notable difference between the filtering and the smoothing case. for smoothing  we now must consider all possible splits of the budget between the two resulting sub-chains  since an observation at time j might require us to make an additional  earlier observation:
ja:b xa xb;k  = max{ja:b xa xb;1   max { cj+
a j b
x
p xj = xj | xa = xa xb = xb {rj xj | xj +
xj max	 ja:j xa xj;l  + jj:b xj xb;k   l   붹j  }}}.
1뫞l뫞k 붹j
looking back in time is not possible in the filtering case  hence the recursion simplifies to

xp xj = xj | xa = xa {rj xj | xj +
xj
ja:j xa;1  + jj:b xj;k   붹j }}}.
the optimal reward is obtained by j1:n+1  ;b  = j  ;b . alg. 1 presents a pseudo code implementation for the smoothing version - the filtering case is a straight-forward modification. the plan itself is compactly encoded in the quantities 뷇a:b which determines the next variable to query and 효:b  which determines the allocation of the budget. considering the exponential number of possible sequences of observations  it is remarkable that the optimal plan can even be represented using only polynomial space. alg. 1 indicates how the computed plan can be executed. the procedure is recursive  requiring the parameters a := 1  xa := 1  b := n + 1  xb := 1 and k := b for the initial call. again  by induction  we obtain:
theorem 1. the algorithm for smoothing presented above computes an optimal conditional plan in evaluations of local rewards  where d is the maximum domain size of the random variables x1 ... xn. in the filtering case  or if no budget is used  the optimal plan can be computed using evaluations respectively.	
모the faster computation for the no budget case is obtained by observing that we do not require the third maximum computation  which distributes the budget into the sub-chains.
input: budget b  rewards rj  costs 붹j and penalties cj output: optimal conditional plan  뷇a:b  효:b  begin
for 1 뫞a   b뫞 n + 1 xa 뫍 domxa xb 뫍 domxb do compute ja:b xa xb;1 ;
for k = 1 to b do for 1뫞a b뫞n+1 xa뫍domxa xb뫍domxb do sel  1  := ja:b 1 ; for a   j   b do sel j  :=  cj + rj xj | xj ; for a   j   b xj 뫍 domxj do for 1 뫞 l 뫞 k   붹j do ;
bd l  :=
모ja:j xa xj;l  + jj:b xj xb;k   l   붹j ; sel j  := sel j  + p xj | xa xb  몫 maxl bd j ;
 j xj  = argmaxl bd j ;
end
ja:b k  = maxa j b sel j ; 뷇a:b xa xb;k  = argmaxa j b sel j ; for xj 뫍 domx뷇a:b k  do 효:b xa xb xj;k  =  뷇a:b k  xj ;
end
   end endalgorithm 1: computation of optimal conditional plan.
input: budget k  observations xa = xa  xb = xb    뷇 begin j := 뷇a:b xa xb;k ; if j 뫟 1 then observe xj = xj;
l := 효:b xa xb xj;k ;
recurse with k := l  a := a  b := j;
모모모recurse with k := k   l   붹j  a := j  b := b; end endalgorithm 1: observation selection using conditional plan.
1 theoretical limits
many problems that can be solved efficiently for discrete chain graphical models can also be efficiently solved for discrete polytrees. examples include probabilistic inference and the most probable explanation  mpe . surprisingly  we prove that for the optimization problems discussed in this paper  this generalization is not possible  unless p = np. all proofs in this section are stated in the appendix.
모in order to solve the optimization problems  we will most likely have to evaluate the objective function  i.e.  the expected local rewards. our first result states that this problem is intractable even for discrete polytrees.

	1	1	1	1	1	1	1	1	1	1
	number of observations	number of observations	number of observations
 a  temperature data: improvement over  b  cpg island data set: effect of increas-  c  part-of-speech tagging data set: efthe uniform spacing heuristic.	ing the number of observations on margin fect of increasing the number of observaand classification accuracy.	tions on margin and f1 score. figure 1: experimental results.theorem 1. the computation of expected local rewards for discrete polytrees is #p-complete.1 
모this negative result can be specialized to the conditional entropy  one of the most frequently used reward function to characterize the residual uncertainty in value of information problems.
corollary 1. the computation of conditional entropy for discrete polytrees is #p-complete. 
모since evaluating local rewards is #p-complete  it can be suspected that the subset selection problem is at least #phard. we show that it is even nppp-complete1  a complexity class containing problems that are believed to be significantly harder than np or #p complete problems. this result provides a complexity theoretic classification of value of information  a core ai problem.
theorem 1. subset selection is nppp-complete even for discrete polytrees.	
모for our running example  this implies that the generalized problem of optimally selecting k sensors from a network of correlated sensors is most likely computationally intractable without resorting to heuristics. a corollary extends the hardness of subset selection to the hardness of conditional plans.
corollary 1. computing conditional plans is nppp-hard even for discrete polytrees.	
1 experiments
in this section  we evaluate the proposed methods for several real world data sets. a special focus is on the comparison of the optimal methods with the greedy heuristic and other heuristic methods for selecting observations  and on how the algorithms can be used for interactive structured classification.
1 temperature time series
the first data set consists of temperature time series collected from a sensor network deployed at intel research berkeley  as described in our running example. data was continuously collected for 1 days  linear interpolation was used in case of missing samples. the temperature was measured once every 1 minutes  and it was discretized into 1 bins of 1 degrees kelvin. to avoid overfitting  we used pseudo counts 붸 = 1 when learning the model. using parameter sharing  we learned four sets of transition probabilities: from 1 am - 1am  1 am 1 pm  1 pm - 1 pm and 1 pm - 1 am. combining the data from three adjacent sensors  we got 1 sample time series.
모the goal of this task was to select k out of 1 time points during the day  during which sensor readings are most informative. the experiment was designed to compare the performance of the optimal algorithms  the greedy heuristic  and a uniform spacing heuristic  which distributed the k observations uniformly over the day. fig. 1 a  shows the relative improvement of the optimal algorithms and the greedy heuristic over the uniform spacing heuristic. the performance is measured in decrease of expected entropy  with zero observations as the baseline. it can be seen that if k is less than about the half of all possible observations  the optimal algorithms decreased the expected uncertainty by several percent over both heuristics. the improvement gained by the optimal plan over the subset selection algorithms appears to become more drastic if a large number of observations  over half of all possible observations  is allowed. furthermore  for a large number of observations  the optimal subset and the subset selected by the greedy heuristic were almost identical.
1 cpg-island detection
we then studied the bioinformatics problem of finding cpg islands in dna sequences. cpg islands are regions in the genome with a high concentration of the cytosine-guanine sequence. these areas are believed to be mainly located around the promoters of genes  which are frequently expressed in the cell. in our experiment  we considered the gene loci hs1  af1 and al1  for which the genbank annotation listed three  two and one cpg islands each. we ran our algorithm on a 1 base window at the beginning and end of each island  using the transition and emission probabilities from  for our hidden markov model  and we used the sum of margins as reward function.
모the goal of this experiment was to locate the beginning and ending of the cpg islands more precisely by asking experts  whether or not certain bases belong to the cpg region or not. fig. 1 b  shows the mean classification accuracy and mean margin scores for an increasing number of observations. the results indicate that  although the expected margin scores are similar for the optimal algorithm and the greedy heuristic  the mean classification performance of the optimal algorithm was still better than the performance of the greedy heuristic.
1 part-of-speech tagging
in our third experiment  we investigated the structured classification task of part-of-speech  pos  tagging . problem instances are sequences of words  sentences   where each word is part of an entity  e.g.   united states of america    and each entity belongs to one of five categories: location  miscellaneous  organization  person or other. imagine an application  where automatic information extraction is guided by an expert: our algorithms compute an optimal conditional plan for asking the expert  trying to optimize classification performance while requiring as little expert interaction as possible.
모we used a conditional random field for the structured classification task  where each node corresponds to a word  and the joint distribution is described by node potentials and edge potentials. the sum of margins was used as reward function. measure of classification performance was the f1 score  the geometric mean of precision and recall. the goal of this experiment was to analyze how the addition of expert labels increases the classification performance  and how the indirect  decomposing reward function used in our algorithms corresponds to real world classification performance.
모figure 1 c  shows the increase of the mean expected margin and f1 score for an increasing number of observations  summarized over ten 1 word sequences. it can be seen that the classification performance can be effectively enhanced by optimally incorporating expert labels. requesting only three out of 1 labels increased the mean f1 score from by more than five percent. the following example illustrates this effect: in one scenario both words of an entity  the sportsman 'p. simmons'  were classified incorrectly - 'p.' as other and 'simmons' as miscellaneous. the first request of the optimal conditional plan was to label 'simmons'. upon labeling this word correctly  the word 'p.' was automatically labeled correctly also  resulting in an f1 score of 1 percent.
1 related work
decision trees  popularized the value of information as a criterion for creating conditional plans. unfortunately  there are no guarantees on the performance of this greedy method. bayer-zubek  proposed a heuristic method based on the
markov decision process framework. several researchers  1; 1  suggested myopic  i.e.  greedy approaches for selectively gathering evidence in graphical models. heckerman et al.  propose a method to compute the maximum expected utility for specific sets of observations. while their work considers more general graphical models than this paper  they provide only large sample guarantees for the evaluation of a given sequence of observations  and use a heuristic without guarantees to select such sequences the subset selection problem as an instance of feature selection is a central issue in machine learning  with a vast amount of literature  see  for a survey . the problem of choosing observations also has a strong connection to the field of active learning  in which the learning system designs experiments based on its observations.
1 conclusions
we have described novel efficient algorithms for optimal subset selection and conditional plan computation in chain graphical models  including hmms. empirical evaluation indicates that these algorithms can improve upon commonly used heuristics for decreasing expected uncertainty. our algorithms can also effectively enhance performance in interactive structured classification tasks.
모unfortunately  the optimization problems become intractable for even a slight generalization of chains. we presented surprising theoretical limits  which indicate that commonly used local reward functions  such as conditional entropies  cannot be efficiently computed even in discrete polytree graphical models. we also identified optimization of value of information as a new class of problems that are intractable  nppp-complete  for polytrees.
모our hardness results  along with other recent results for polytree graphical models  the np-completeness of maximum a posteriori assignment  and np-hardness of inference in conditional linear gaussian models   suggest the possibility of developing a generalized complexity characterization of problems that are hard in polytree graphical models.
모in light of these theoretical limits for computing optimal solutions  it is a natural question to ask whether approximation algorithms with non-trivial performance guarantees can be found. we are currently focusing our research in this direction.
모acknowledgements. we would like to thank ben taskar for providing the part-of-speech tagging model  and reuters for making their news archive available. we would also like to thank brigham anderson and andrew moore for helpful comments and discussions.
appendix
proof of theorem 1. membership in #p is straightforward. to show hardness  we use a construction similar to the one presented in  for the maximum a posteriori problem. let 뷋 be an instance of #1sat  where we have to count the number of assignments to x1 ... xn satisfying 뷋. let c = {c1 ... cm} be the set of clauses. now create a bayesian network with nodes ui for each xi  each with uniform bernoulli prior. add variables y1  which uniformly varies over {1 ... m} and y1 ... yn with cpts defined the following way:
 1 	if j = 1  or ui = ui yi |  yi 1 = j ui = ui  몲satisfies clause cj; j 	otherwise.
 in this model  yn = 1 iff u1 ... un encode a satisfying assignment of 뷋. let all nodes have zero reward  except for yn  which is assigned the following reward:
모모모모모모모모모1n  if p yn = 1 | o = o  = 1; r yn | o = o  =
	1 	otherwise.
 since the prior probability of any assignment is 1 n  the expected reward r yn | u1 ... un  is exactly the number of satisfying assignments to 뷋.	
proof of corollary 1. we start from the same construction as in the proof of theorem 1  and add an additional random variable z after yn on the chain. z | yn is 1 if yn = 1  and takes uniformly random values in {1} if yn 1= 1. then h z | u = u  is 1 if u is a satisfying assignment  and 1 otherwise. hence h z | o  = 1   k1 n  where k is the number of satisfying assignments to 뷋. 
proof of theorem 1. membership follows from theorem 1.
let 뷋 be an instance of emajsat  where we have to find an instantiation of x1 ... xn such that 뷋 x1 ... x1n  is true for the majority of assignments to xn+1 ... x1n. let c = {c1 ... cm} be the set of 1cnf clauses. create the bayesian network shown in fig. 1  with nodes ui  each having a uniform bernoulli prior. add bivariate variables yi =  seli pari   1 뫞 i 뫞 1n  where seli takes values in {1 ... m} and pari is a parity bit. the cpts for yi are defined as: sel1 uniformly varies over {1 ... m}  par1 = 1  and for y1 ... y1n:
seli |  seli 1 = j ui = ui  몲	1 	if j = 1  or ui satisfies cj; j 	otherwise;
pari |  pari 1 = bi 1 ui  몲 bi 1  ui 
where  denotes the parity  xor  operator.
we now add variables zit and zif for 1 뫞 i 뫞 n and let
           t |  ui = ui  몲  i1  {1}   otherwise;if ui = 1; zi where i denotes the uniform distribution. similarly  let
	f |  ui = ui  몲  i1  {1}  	otherwise.if ui = 1;
zi
intuitively  zit = 1 guarantees us that ui = 1  whereas zit =
1 leaves us uncertain about ui. the case of zif is symmetric.
모we use the subset selection algorithm to choose the zis that encode the solution to emajsat. if zit is chosen  it will indicate that xi should set to true  similarly zif indicates a false assignment to xi. the parity function is going to be used to ensure that exactly one of is observed for each i.
모we first assign penalties  to all nodes except for 1 뫞 i 뫞 n  and uj for n + 1 뫞 j 뫞 1n  which are assigned zero penalty. let all nodes have zero reward  except for y1n  which is assigned the following reward:
	  1n 	if p sel1n = 1 | o = o  = 1 and
모모모모모모모모모모  	 p par1n = 1 | o = o  = 1 or r y1n | o = o  =	p par1n = 1 | o = o  = 1 ;
	   1 	otherwise.
note that sel1n = 1 with probability 1 iff u1 ... u1n encode a satisfying assignment of 뷋  as in the proof of theorem 1. furthermore  we get positive reward only if we are both certain that sel1n = 1  i.e.  the chosen observation set must contain a proof that 뷋 is satisfied  and we are certain about par1n. the parity certainty will only occur if we are certain about the assignment u1 ... u1n. it is only possible to infer the value of each ui with certainty by observing one of ui zit or zif. since  for i = 1 ... n  the cost of observing ui is   to receive any reward we must observe at least one of zit or zif.
assume that we compute the optimal subset o  for budget 1n  then we can only receive positive reward by observing exactly one of.
모we interpret the selection of zit and zif as an assignment to the first n variables of emajsat. let r  = r y1n | o  .
we claim that 뷋 뫍 emajsat if and only if r    1. first let 뷋 뫍 emajsat  with assignment x1 ... xn to the first n variables. now add un+1 ... u1n to o and add zit to o iff xi = 1 and zif to o iff xi = 1. this selection guarantees
r   	1.
	now assume r 	 	1.	we call an assignment to
u1 ... u1n consistent if for any 1 뫞 i 뫞 n  if zit 뫍 o  

figure 1: graphical model used in proof of theorem 1.
then ui = 1 and if zif 뫍 o  then ui = 1. for any consistent assignment  the chance that the observations zi prove the consistency is 1 n. hence r    1 implies that the majority of all provably consistent assignments satisfy 뷋 and hence 뷋 뫍 emajsat. this proves that subset selection is nppp complete.	
proof of corollary 1. the construction in the proof of theorem 1 also proves that computing conditional plans is nppphard  since  in this instance  any plan with positive reward must observe all un+1 ... u1n and one each of the z1 ... zn  to satisfy the parity condition. in this case  the order of selection is irrelevant  and  hence  the conditional plan effectively performs subset selection.	


singleton arc consistency  sac  enhances the pruning capability of arc consistency by ensuring that the network cannot become arc inconsistent after the assignment of a value to a variable. algorithms have already been proposed to enforce sac  but they are far from optimal time complexity. we give a lower bound to the time complexity of enforcing sac  and we propose an algorithm that achieves this complexity  thus being optimal. however  it can be costly in space on large problems. we then propose another sac algorithm that trades time optimality for a better space complexity. nevertheless  this last algorithm has a better worst-case time complexity than previously published sac algorithms. an experimental study shows the good performance of the new algorithms.
1	introduction
ensuring that a given local consistency does not lead to a failure when we enforce it after having assigned a variable to a value is a common idea in constraint reasoning. it has been applied  sometimes under the name 'shaving'  in constraint problems with numerical domains by limiting the assignments to bounds in the domains and ensuring that bounds consistency does not fail  lhomme  1 . in sat  it has been used as a way to compute more accurate heuristics for dpll  freeman  1; li and ambulagan  1 . finally  in constraint satisfaction problems  csps   it has been introduced under the name singleton arc consistency  sac  in  debruyne and bessie`re  1b  and further studied  both theoretically and experimentally in  prosser et al.  1; debruyne and bessie`re  1 .
¡¡some nice properties give to sac a real advantage over the other local consistencies enhancing the ubiquitous arc consistency. its definition is much simpler than restricted path consistency  berlandier  1   max-restricted-path consistency  debruyne and bessie`re  1a   or other exotic local consistencies. its operational semantics can be understood by a non-expert of the field. enforcing it only removes values in domains  and thus does not change the structure of the problem  as opposed to path consistency  montanari  1   kconsistency  freuder  1   etc. finally  implementingit can be done simply on top of any ac algorithm.
¡¡algorithms enforcing sac were already proposed in the past  sac1  debruyne and bessie`re  1b   and sac1  barta¡äk and erben  1   but they are far from optimal time complexity. moreover  singleton arc consistency lacks an analysis of its complexity. in this paper  we study the complexity of enforcing sac  in section 1  and propose an algorithm  sac-opt  enforcing sac with optimal worst-case time complexity  section 1 . however  optimal time complexity is reached at the cost of a high space complexity that prevents the use of this algorithm on large problems. in section 1  we propose sac-sds  a sac algorithm with better worst-case space complexity but no longer optimal in time. nevertheless  its time complexity remains better than the sac algorithms proposed in the past. the experiments presented in section 1 show the good performance of both sac-opt and sac-sds compared to previous sac algorithms.
1	preliminaries
a constraint network p consists of a finite set of n variables x = {i j ...}  a set of domains d = {d i  d j  ...}  where the domain d i  is the finite set of at most d values that variable i can take  and a set of e constraints c = {c1 ... ce}. each constraint ck is defined by the ordered set var ck  of the variables it involves  and the set sol ck  of combinations of values satisfying it. a solution to a constraint network is an assignment of a value from its domain to each variable such that every constraint in the network is satisfied. when var c  =  i j   we use cij to denote sol c  and we say that c is binary.
¡¡a value a in the domain of a variable i  denoted by  i a   is consistent with a constraint ck iff there exists a support for  i a  on ck  i.e.  an instantiation of the other variables in var ck  to values in their domain such that together with  i a  they satisfy ck. otherwise   i a  is said arc inconsistent. a constraint network p =  x d c  is arc consistent iff d does not contain any arc inconsistent value. ac p  denotes the network where all arc inconsistent values have been removed from p. if ac p  has empty domain  we say that p is arc inconsistent
definition 1  singleton arc consistency  a constraint network p =  x d c  is singleton arc consistent iff  i ¡Ê x  a ¡Ê d i   the network p|i=a =  x d|i=a c  obtained by replacing d i  by the singleton {a} is not arc inconsistent. if p|i=a is arc inconsistent  we say that  i a  is sac inconsistent.
1	complexity of sac
both sac1  debruyne and bessie`re  1b  and sac1  barta¡äk and erben  1  have an o en1  time complexity on binary constraints. but it is not optimal.
theorem 1 the best time complexity we can expect from an algorithm enforcingsac on binary constraints is in o end1 .
proof. according to  mcgregor  1   we know that checking whether a value  i a  is such that ac does not fail in p|i=a is equivalent to verifying if in each domain d j  there is at least one value b such that   i a   j b   is  path consistent on  i a  .  a pair of values   i a  j b   is path consistent on  i a  iff it is not deleted when enforcing path consistency only on pairs involving  i a .  for each variable j  we have to find a value b ¡Ê d j  such that   i a   j b   is path consistent on  i a . in the worst case  all the values b in d j  have to be considered. so  the path consistency of each pair   i a   j b   may need to be checked against every third variable k by looking for a value  k c  compatible with both  i a  and  j b . however  it is useless to consider variables k not linked to j since in this partial form of path consistency only pairs involving  i a  can be removed. by using an optimal time path consistency technique  storing supports   we are guaranteed to consider at most once each value  k c  when seeking compatible value on k for a pair   i a   j b  . the worst-case complexity of proving that path consistency on  i a  does not fail is thus ¦²b¡Êd j ¦²ckj¡Êc¦²c¡Êd k  = ed1. furthermore  enforcing path consistency on  i a  is completely independent from enforcing path consistency on another value  j b . indeed  a pair   i a   j b   can be path consistent on  i a  while becomingpath inconsistent after the deletion of a pair   k c   j b   thus being path inconsistent on  j b . therefore  the worst case time complexity of any sac algorithm is at least in o ¦² i a ¡Êded1  = o end1 . 1
1	optimal time algorithm for sac
sac1 has no data structure storing which values may become sac inconsistent when a given value is removed. hence  it must check again the sac consistency of all remaining values. sac1 has data structures that use the fact that if ac does not lead to a wipe out in p|i=a then the sac consistency of  i a  holds as long as all the values in ac p|i=a  are in the domain. after the removal of a value  j b   sac1 checks again the sac consistency of all the values  i a  such that  j b  was in ac p|i=a . this leads to a better average time complexity than sac1 but the data structures of sac1 are not sufficient to reach optimality since sac1 may waste time re-enforcing ac in p|i=a several times from scratch.
¡¡algorithm 1  called sac-opt  is an algorithm that enforces sac in o end1   the lowest time complexity which can be expected  see theorem 1 .
¡¡the idea behind such an optimal algorithm is that we don't want to do and redo  potentially nd times  arc consistency algorithm 1: the optimal sac algorithm

function sac-opt inout p: problem : boolean;
/* init phase */;
1 if ac p  then pendinglist ¡û   else return false; foreach  i a  ¡Ê d do
pia ¡û p /* copy only domains and data structures */; dia i  ¡û {a}; if  propagac pia d i    {a}  then d ¡û d   { i a };
if propagac p { i a }  then foreach pjb such that  i a  ¡Ê djb do
qjb ¡û qjb ¡È { i a };
pendinglist ¡û pendinglist ¡È { j b };
1 else return false;
/* propag phase */;
1 while pendinglist 1=   do
1 pop  i a  from pendinglist;
1 if propagac pia qia  then qia ¡û  ;
1 else
1	d ¡û d   { i a };
1 if d i  =   then return false;
1 foreach  j b  ¡Ê d such that  i a  ¡Ê djb do
1	djb i  ¡û djb i    {a}; qjb ¡û qjb ¡È { i a };
1 pendinglist ¡û pendinglist ¡È { j b };
1 return true;

from scratch in each subproblem p|j=b each time a value  i a  is found sac inconsistent.  which represents n1 potential arc consistency calls.  to avoid such costly repetitions of arc consistency calls  we duplicate the problem nd times  one for each value  i a   so that we can benefit from the incrementality of arc consistency on each of them. all generic ac algorithms are incremental  i.e.  their complexity on a problem p is the same for a single call or for up to nd calls  where two consecutive calls differ only by the deletion of some values from p.
¡¡in the following  pia is the subproblem in which sacopt stores the current domain  noted dia  and the data structure corresponding to the ac enforcement in p|i=a. propagac p q  denotes the function that incrementally propagates the removal of set q of values in problem p when an initial ac call has already been executed  initialising the data structure required by the ac algorithm in use. it returns false iff p is arc inconsistent.
¡¡sac-opt is composed of two main steps. after making the problem arc consistent  line 1   the loop in line 1 takes each value a in each domain d i  and creates the problem pia as a copy of the current p. then  in line 1 the removal of all the values different from a for i is propagated. if a subproblem pia is arc inconsistent   i a  is pruned from the 'master' problem p and its removal is propagated in p  line 1 . the advantage of propagating immediately in the master problem the sac inconsistent values found in line 1 is twofold. first  the subproblem pkc of a value  k c  removed in line 1 before its selection in line 1 will never be created. second  the subproblems pjb created after the removal of  k c  will benefit from this propagation since they are created by duplication of p  line 1 . for each already created subproblem pjb with a ¡Ê djb i    i a  is put in qjb and pjb is put in pendinglist for future propagation  lines 1 .
¡¡once the initialisation phase has finished  we know that pendinglist contains all values  i a  for which some sac inconsistent value removals  contained in qia  have not yet been propagated in pia. the loop in line 1 propagates these removals  line 1 . when propagation fails  this means that  i a  itself is sac inconsistent. it is removed from the domain d of the master problem in line 1 and each subproblem pjb containing  i a  is updated together with its propagation list qjb for future propagation  lines 1 .
¡¡when pendinglist is empty  all removals have been propagated in the subproblems. so  all the values in d are sac.
theorem 1 sac-opt is a correct sac algorithm with o end1  optimal time complexity and o end1  space complexity on binary constraints.
proof. soundness. a value a is removed from d i  either in line 1 or in line 1 because pia was found arc inconsistent. if pia was found arc inconsistent in the initialisation phase  line 1   sac inconsistency of  i a  follows immediately. let us proceed by induction for the remaining case. suppose all values already removed in line 1 were sac inconsistent. if pia is found arc inconsistent in line 1  this means that pia cannot be made arc consistent without containing some sac inconsistent values. so   i a  is sac inconsistent and sacopt is sound.
¡¡completeness. thanks to the way pendinglist and qia are updated in lines 1 and 1  we know that at the end of the algorithm  all pia are arc consistent. thus  for any value  i a  remaining in p at the end of sac-opt  p|i=a is not arc inconsistent and  i a  is therefore sac consistent.
¡¡complexity. the complexity analysis is given for networks of binary constraints since the optimality proof was given for networks of binary constraints only.  but sac-opt works on constraints of any arity.  since any ac algorithm can be used to implement our sac algorithm  the space and time complexities will obviously depend on this choice. let us first discuss the case where an optimal time algorithm such as ac-1  bessie`re  1  or ac1  bessie`re and re¡ägin  1; zhang and yap  1  is used. line 1 tells us that the space complexity will be nd times the complexity of the ac algorithm  namely o end1 . regarding time complexity  the first loop copies the data structures and propagatesarc consistency on each subproblem  line 1   two tasks which are respectively in nd¡¤ed and nd¡¤ed1. in the while loop  line 1   each subproblem can be called nd times for arc consistency  and there are nd subproblems. now  ac-1 and ac1 are both incremental  which means that the complexity of nd restrictions on the same problem is ed1 and not nd ¡¤ ed1. thus the total cost of arc consistency propagation on the nd subproblems is nd¡¤ed1. we have to add the cost of updating the lists in lines 1 and 1. in the worst case  each value is removed one by one  and thus  nd values are put in nd q lists  leading to n1 updates of pendinglist. if n   e  the total time complexity is
o end1   which is optimal.	1
remarks. we chose to present the qia lists as lists of values to be propagated because the ac algorithm used is not specified here  and value removal is the most accurate information we can have. when using a fine-grained ac algorithm  such as ac-1 the lists will be used as they are. if we use a coarse-grained algorithm such as ac-1  mackworth  1  or ac1  only the variables from which the domain has changed are needed. the modification is direct. we should bear in mind that if ac-1 is used  we decrease space complexity to o n1   but time complexity increases to o end1  since ac-1 is non optimal.
1	losing time optimality to save space
sac-opt cannot be used on large constraint networks because of its o end1  space complexity. moreover  it seems difficult to reach optimal time complexity with smaller space requirements. a sac algorithm has to maintain ac on nd subproblems p|i=a  and to guarantee o ed1  total time on these subproblems we need to use an optimal time ac algorithm. since there does not exist any optimal ac algorithm requiring less than o ed  space  we obtain nd ¡¤ ed space for the whole sac process.
¡¡we propose to relax time optimality to reach a satisfactory trade-off between space and time. to avoid discussing in too general terms  we instantiate this idea on a ac1-based sac algorithm for binary constraints  but the same idea could be implemented with other optimal ac algorithms such as ac-1  and with constraints of any arity. the algorithm sacsds  sharing data structures  tries to use as much as possible the incrementality of ac to avoid redundant work  without duplicating on each subproblem p|i=a the data structures required by optimal ac algorithms. this algorithm requires less space than sac-opt but is not optimal in time.
¡¡as in sac-opt  for each value  i a  sac-sdsstores the local domain dia of the subproblem p|i=a and its propagation list qia. note that in our ac1-like presentation  qia is a list of variables j for which the domain dia j  has changed  in sac-opt it is a list of values  j b  removed from dia . as in sac-opt  thanks to these local domains dia  we know which values  i a  may no longer be sac after the removal of a value  j b : those for which  j b  was in dia. these local domains are also used to avoid starting each new ac propagation phase from scratch  since dia is exactly the domain from which we should start when enforcing again ac on p|i=a after a value removal. by comparison  sac1 and sac1 restart from scratch for each new propagation. but the main idea in sac-sds is that as opposed to sacopt  it does not duplicate to all subproblems pia the data structures of the optimal ac algorithm used. the data structure is maintained only in the master problem p. in the case of ac1  the last structure which maintains in last i a j  the smallest value in d j  compatible with  i a  on cij is built and updated only in p. nevertheless  it is used by all subproblems pia to avoid repeating constraint checks already done in p.
¡¡sac-sds  algorithm 1  works as follows: after some initialisations  lines 1   sac-sds repeatedly pops a value from pendinglist and propagates ac in pia  lines 1 . note that 'dia=nil' means that this is the first enforcement of ac in pia  so dia must be initialised  line 1 .1 if pia is arc inalgorithm 1: the sac-sds algorithm

function sac-sds-1 inout p: problem : boolean;
1 if ac1 p  then pendinglist ¡û   else return false;
1 foreach  i a  ¡Ê d do
1	dia ¡û nil ; qia ¡û {i};
1 pendinglist ¡û pendinglist ¡È { i a };
1 while pendinglist 1=   do
1 pop  i a  from pendinglist ;
1 if a ¡Ê d i  then
1	if dia = nil then dia ¡û  d   d i   ¡È { i a };
1 if propagsubac dia qia  then qia ¡û  ;
1 else
1	d i  ¡û d i    {a} ; deleted ¡û { i a } ;
1 if propagmainac d {i} deleted  then
1 updatesubproblems deleted 
1 else return false;
1 return true;
main/subfunction propagac inout d: domain; in q: set ;
inout deleted: set  : boolean;
1 while q 1=   do
1 pop j from q ;
1 foreach i ¡Ê x such that  cij ¡Ê c do
1	foreach a ¡Ê d i  such that last i a j  1¡Ê d j  do 1	if  b ¡Ê d j  b   last i a j  ¡Ä cij a b  then
1 last i a j  ¡û b
1 else
1	d i  ¡û d i    {a} ; q ¡û q ¡È {i} ;
deleted ¡û deleted ¡È { i a }1;
1 if d i  =   then return false;
1 return true;
/* ¡¤¡¤¡¤ : in propagmainac but not in propagsubac */;
procedure updatesubproblems in deleted: set ;
1 foreach  j b  ¡Ê d | djb ¡É deleted 1=   do
1 qjb ¡û qjb ¡È {i ¡Ê x / djb i  ¡É deleted 1=  } ;
1 djb ¡û djb   deleted;
1 pendinglist ¡û pendinglist ¡È { j b } ;

consistent   i a  is sac inconsistent. it is therefore removed from d  line 1  and this deletion is propagated in the master problem p using propagmainac  line 1 . any value  i a  removed from p is put in the set deleted  lines 1 and 1 . this set is used by updatesubproblems  line 1  to pass the values removed from p on to the subproblems  and to update the lists qjb and pendinglist for further propagation in modified subproblems.
¡¡at this point we have to explain the difference between propagmainac  which propagates deletions in the master problem p  and propagsubac  which propagates deletions in subproblems pia. the parts that are in boxes belong to propagmainac and not to propagsubac. function propagsubac  used to propagate arc consistency in the subproblems  follows the same principle as the ac algorithm. the only difference comes from the fact that the data structures of the ac algorithm are not modified. when using ac1  this means that last is not updated in line 1. indeed  this data structure is useful to achieve ac in the sub-

it in a former loop as in sac-opt.
problems faster  lines 1  since we know that there is no support for  i a  on cij lower than last i a j  in p  and so in any subproblem as well. but this data structure is shared by all subproblems. thus it must not be modified by propagsubac. otherwise  last i a j  would not be guaranteed to be the smallest supportin the other subproblemsand in p. when achieving ac in p  propagmainac does update the last data structure. the only difference with ac1 is line 1 where it needs to store in deleted the values removed from d during the propagation. those removals performed in p can directly be transferred in the subproblems without the effort of proving their inconsistency in each subproblem. this is done via function updatesubproblems  which removes values in deleted from all the subproblems. it also updates the local propagation lists qia and pendinglist for future propagation in the subproblems.
theorem 1 sac-sds is a correct sac algorithm with o end1  time complexity and o n1  space complexity on binary constraints.
proof. soundness. note first that the structure last is updated only when achieving ac in p so that any support of  i a  in d j  is greater than or equal to last i a j . the domains of the subproblems being subdomains of d  any support of a value  i a  on cij in a subproblem is also greater than or equal to last i a j . this explains that propagsubac can benefit from the structure last without losing any support  lines 1 . once this observation is made  soundness comes from the same reason as in sac-opt. completeness. completeness comes from the fact that any deletion is propagated. after initialisation  lines 1   pendinglist = d and so  the main loop of sac-sds processes any subproblem p|i=a at least once. each time a value  i a  is found sac inconsistent in p because p|i=a is arc inconsistent  line 1  or because the deletion of some sac-inconsistent value makes it arc inconsistent in p  line 1 of propagmainac called in line 1    i a  is removed from the subproblems  line 1   and pendinglist and the local propagation lists are updated for future propagation  lines 1 and 1 . at the end of the main loop  pendinglist is empty  so all the removals have been propagated and for any value  i a  ¡Ê d  dia is a non empty arc consistent subdomain of
p|i=a.
¡¡complexity. the data structure last requires a space in o ed . each of the nd domains dia can contain nd values and there is at most n variables in the nd local propagation lists qia. since e   n1  the space complexity of sac-sds1 is in o n1 . so  considering space requirements  sac-sds-1 is similar to sac1.
¡¡regarding time complexity  sac-sds-1first duplicates the domains and propagates arc consistency on each subproblem  lines 1 and 1   two tasks which are respectively in nd¡¤nd and nd ¡¤ ed1. each value removal is propagated to all p|i=a problems via an update of pendinglist  qia and dia  lines 1 . this requires nd ¡¤ nd operations. each subproblem can in the worst case be called nd times for arc consistency  and there are nd subproblems. the domains of each subproblem are stored so that the ac propagation is launched with the domains in the state in which they were at the end of the

figure 1: cpu time with n =1  d =1  and density= .1.
previous ac propagation in the subproblem. thus  in spite of the several ac propagations on a subproblem  a value will be removed at most once and  thanks to incrementality of arc consistency  the propagation of these nd value removals is in o ed1 .  note that we cannot reach the optimal ed1 complexity for arc consistency on these subproblems since we do not duplicate the data structures necessary for ac optimality.  therefore  the total cost of arc consistency propagations is nd ¡¤ ed1. the total time complexity is o end1 . 1
¡¡as with sac1  sac-sds performs a better propagation than sac1 since after the removal of a value  i a  from d  sac-sds checks the arc consistency of the subproblems p|j=b only if they have  i a  in their domains  and not all the subproblems as sac1 . but this is not sufficient to have a better worst-case time complexity than sac1. sac1 has indeed the same o en1  time complexity as sac1. sac-sds improvesthis complexitybecause it stores the current domain of each subproblem  and so  does not propagate in the subproblems each time from scratch.1 furthermore  we can expect a better average time complexity since the shared structure last reduces the number of constraint checks required  even if it does not permit to obtain optimal worst-case time complexity. this potential gain can only be assessed by an experimental comparison of the different sac versions. finally  in sac1 and sac1 each ac enforcement in a subproblem must be done on a new copy of d built at runtime  potentially nd¡¤nd times  while such duplication is performed only once for each value in sac-sds  by creating subdomains dia .
1	experimental results
we compared the performance of the sac algorithms on random uniform constraint networks of binary constraints generated by  frost et al.  1   which produces instances accord-

figure 1: cpu time with n =1  d =1  and density=1.
ing to model b  prosser  1 . all algorithms have been implemented in c++ and ran on a pentium iv-1 mhz with 1 mb of memory under windows xp. sac1 and sac1 have been tested using several ac algorithms. in the following  we note sac-1-x  sac-1-x and sac-opt-x the versions of sac1  sac1 and sac-opt based on ac-x. note that for sac1 the implementation of the propagation list has been done according to the recommendations made in  barta¡äk and erben  1 . for each combination of parameters tested  we generated 1 instances for which we report mean cpu times.
1	experiments on sparse constraint networks
fig. 1 presents performance on constraint networks having 1 variables  1 values in each domain  and a density of .1. these constraint networks are relatively sparse since the variables have five neighbours on average.
¡¡for a tightness lower than .1  all the values are sac. on these under-constrained networks  the sac algorithms check the arc consistency of each subproblem at most once. storing support lists  as in sac1  or local subdomains  as in sacopt and sac-sds  does not pay-off. a brute-force algorithm such as sac1 is sufficient. sac-1 shows the best performance.
¡¡on problems having tighter constraints  some sac inconsistent values are removed and at tightness .1 we can see a peak of complexity. however  as mentioned in  barta¡äk and erben  1   the improved propagation of sac1 is useless on sparse constraint networks and sac1-x  with x¡Ê {1 1}  is always more expensive than sac1-x on the generated problems. around the peak of complexity  sacsds-1is the clear winner. sac-opt-1and sac1 are around1 times slower  and all the others are between 1 and 1 times slower.
1	experiments on dense constraint networks
fig. 1 presents performance on constraint networks having 1 variables  1 values in each domain and a complete graph of binary constraints.
¡¡sac1 and sac1 show very close performance. when all values are sac consistent  tightness lower than .1  the additional data structure of sac1 is useless since there is no propagation. howeverthe cost of buildingthis data structure is not important compared to the overall time and the time required by sac1 is almost the same as sac1. around the peak of complexity  sac1-x  with x¡Ê {1 1}  requires a little less time than sac1-x. sac1 has to repeatedly recheck the arc consistency of less subproblems than sac1 but the cost of testing a subproblem remains the same. on very tight constraints  sac1 requires less time than sac1 since the inconsistency of the problem is found with almost no propagation and building the data structure of sac1 is useless.
¡¡conversely to what was expected in  barta¡äk and erben  1   using ac-1 in sac1  or in sac1  instead of ac-1 or ac1 is not worthwhile. the intuition was that since the data structure of ac-1 does not have to be updated  the cost of its creation would be low compared to the profit we can expect. however  sac1 and sac1 are far more costly than the versions based on ac-1 or ac1.
¡¡the best results are obtained with sac-opt-1 and sacsds-1 which are between 1 and 1 times faster than the others at the peak. these two algorithms have a better propagation between subproblems than sac1 but they also avoid some redundant work and so reduce the work performed on each subproblem.
1	summary and conclusion
we have presented sac-opt  the first optimal time sac algorithm. however  the high space complexity of this algorithm prevents its use on large constraint networks. hence  we have proposed sac-sds  a sac algorithm that is not optimal in time but that requires less space than sac-opt. experiments show the good performance of these new sac algorithms comparedto previous versions available in the literature. this opens again the issue of using sac as an alternative to ac for pruning values in a constraint network  or at least in 'promising' parts of the network. sac could also be used to compute variable selection heuristics  as this had been done with success in sat  li and ambulagan  1 .

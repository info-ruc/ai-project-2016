 
in expert-consultation dialogues  it is inevitable that an agent will at times have insufficient information to determine whether to accept or reject a proposal by the other agent this results in the need tor the agent to initiate an information-sharing subdialogue to form a set of shared beliefs within which the agents can effectively re-evaluate the proposal this paper presents a computational strategy for initiating such information-sharing subdialogues to resolve the system s uncertainty regarding the acceptance of a user proposal our model determines when information sharing should be pursued se lects a focus of information-sharing among multiple uncertain beliefs chooses the most effective information-sharing strategy and utilizes the newly obtained information to re-evaluate the user proposal furthermore our model is capable of handling embedded informauon sharing subdialogues 
1 	introduction 
we have been studying a particular kind of collaborative dialogue in which two participants  a consultant and an executing agent  collaborate on developing a plan to achieve the executing agent's domain goal in such an environment  the consultant and the executing agent have different knowledge about the domain and about the executing agent's particular circumstances and preferences that may affect the domain plan being constructed thus it is inevitable that an agenl will not always immediately accept the actions or beliefs proposed by the other agent however  an agenl should recognize the collaborative nature of the interaction and the fact that each agent has pnvate knowledge that is not shared by the other agent thus  rather than indiscriminately rejecting proposals that she does not have sufficient reasons to accept a collaborative agent should both share her private knowledge with the other agent and solicit relevant information from the other agenl in order for both agents to effectively re-evaluate the proposal and come to the most beneficial decision 
this material is based upon work supported by the national 
science foundauon under granl no iri 1 
   such collaborative in formation-sharing behaviour is lllus trated in the following dialogue segment based on transcripts of naturally occurng dialogues  sri transcripts  1  in this dialogue a travel agent  t  and a customer  c  are constructing a plan for two other agents to travel from san francisco to los angeles this segment follows a proposal that the travelers be booked on a particular usair flight 
 1  t 	can we put them on american  
 1  c 	why  
 1  t 	we re having a lot of problems on the usair seat maps so i don l know if i can get them together 
 1  but american 	whatever 	request pretty much we get 
 1  c 	i don t know if they care if they sit together 
 1  let s go ahead and stick with usair 
in this dialogue t proposes putting the travelers on american 
airlines instead of usair in utterance i  in  1  cquestions 
t s motivation for this proposed action - i e the support that t s pnvate knowledge provides for this proposal after t provides her motivation c informs t in  1  that she rejects the motivauon re-evaluates the proposal and in  1  rejects the actions proposed by t 
   this paper presents a computational model for collaborative information-sharing during proposal evaluation our model first uses the system s existing beliefs along with evidence pro vided by the user to evaluate user proposals and to determine whether they should be accepted or rejected if the system has insufficient information to make this decision it initiates an in formation-sharing subdialogue to form a set of shared beliefs within which the agents can effectively re-evaluate the proposal and come to agreement this may lead to evaluation of an agent s reasons for a proposal and further informationsharing about an agent s beliefs supporting these reasons thus leading to an embedded information-sharing subdialogue 
   our research contributes to response generation in collaborative interaction by i  providing an algorithm for identifying when an information sharing subdialogue should be initiated during proposal evaluation 1  providing a selection algo nthm for determining the beliefs that should be the focus of information-sharing 1  formulating information sharing 
	chu carroll and carberry 	1 
strategies and identifying the eritena a for invoking each stral egy and 1  capturing the process in a propose evaluatemodify cycle that enables embedded information-sharing subdialogues 
1 	modeling collaborative activities 
in modeling collaborative activities it is essential that the system captures the agents intentions conveyed by their utter ances our model utilizes an enhanced version of the dialogue model described in  lambert and carberry 1  to represent the current status of the interaction the enhanced dialogue model has four levels the domain level which consists of the domain plan being constructed for later execution the 
problem solving level which contains the actions being performed to construct the domain plan the belief level which consists of the mutual beliefs pursued to further the problemsolving intentions and the discourse level which contains the communicative actions initiated to achieve the mutual beliefs  chu-carroll and carberry 1  
   in our earlier work we developed a plan-based model that captures collaborative planning in a propose-evaluate modify cycle of actions  chu-carroll and carberry 1  this model treats a collaborative planning process as a sequence of the following actions agent a s proposal of a set of actions and beliefs to be added to the shared plan  grosz and sidner 1 allen 1  being developed  agent b s evaluation of the proposed actions and beliefs and b s proposed modifications to the original proposal in cases where the proposal is rejected notice that b's proposed modifications will again be evaluated by a and if conflicts arise a may propose modifications to b s proposed modifications resulting in a recursive process 
   however  our previous research assumed that an agent s evaluation of a proposal always results in the proposal being accepted or rejected and did not take into account cases in which the agent initially has insufficient information to determine whether or not to accept the proposal  as shown in the example in utterances  l - 1  this paper extends our earlier work by providing a computational strategy for collaborative information sharing during proposal evaluation we focus on situations in which the system s lack of knowledge occurs during the evaluation of proposals at the belief level of the dialogue model 1 
1 	information-sharing during collaboration 
since a collaborative agent initiates information-sharing subdialogues to help determine whether to accept or reject a proposed belief the information sharing process is captured as part of the evaluation process in the propose-evaluate modify cycle for collaborative activities thus the evaluation of a proposed belief involves the agent 1  determining the acceptance of the proposed belief based on the information 
     1  we are concerned with situations in which the system recognizes  he user s proposal but cannot decide whether to accept or reject it not those where the system initiates a clarification subdialogue to 
disambiguate the user s proposal  van beck el al 1 logan et a! 1 heeman and hirst 1 raskulu and zukerman 1  
natural language 
evaluate-belief  bel} 
1 evidence set - bei  appropriately endorsed as conveyed by the user  and the system s beliefs that support or attack  bel 
1 if  bel has no children return evaluate  bel evidence set  
1 evaluate each of  bel s children  beh 	 beln 
1 belief resuln-evaluate-beuer  bel   
	1 	rel resull 	evaluate-beuet supporls  bel   bel   
1 if belief-result = rejector rel rcsuli= reject ignore  bel  and supports -bel   bel  
1 else if belief .result = rel result = accept add{-bel  supports  bel   bel } to the evidence sei 
1 else if belief resuli = unsure or rel resuli = unsure add 
{ bel  supports  bei   bel } to the potenual evidence set 
1 evaluate  bel 
1 uppcrbound *- evaluate  bel evidence set + potential evidence sel  
1 lowerbound 1- evaluate  bel evidence set  
1 if upperbound = lowerbound = accept  accept  bel 
1 else if upperbound = lowerbound = reject rejeel  bel 
1 else unsure about -bel annotate  hel with upperbound lowerbound evidence sel and potential evidence set 
	figure 1 	algorithm for evaluating a belief 
currently available to her  and 1  in cases where she cannot decide whether to accept or reject the belief  initiating an information-sharing subdialogue so that the agents can ex-
change information and re-evaluate the proposed belief the following sections describe these two processes 
1 	evaluating proposed beliefs 
our system maintains a set of beliefs about the domain and about the users beliefs associated with each belief is a strength that represents the agent s confidence in holding the belief we model the strength of a belief using endorsements  cohen  1  followingigalliers 1 loganeral 1  based on the semantic form of the utterance used to convey a belief the level of expertise of the agent conveying the belief stereotypical beliefs  etc 
   the belief level of our dialogue model consists of one or more belief trees where the belief represented by a child node is intended to support that represented by its parent when an agent proposes a new belief and gives  optional  supporting evidence for it  this set of proposed beliefs is represented as a belief tree the system must then evaluate the proposed beliefs in order to determine whether to accept the proposal reject it  or pursue information-sharing to allow the agents to re-evaluate it the algorithm for evaluating proposed beliefs is shown in figure 1 and is applied to the root node of each proposed belief tree  the top-level proposed beliefs  since the acceptance of a child belief may affect the acceptance of its parent before determining the acceptance of a belief or evidential relationship its children in the proposed belief tree must be evaluated  step 1  thus for each child belief of  bel  the system evaluates both the belief  step 1  and the evidential relationship between the belief and  bel  step 1  a piece of evidence is marked as 1  accepted if both the child belief and the evidential relationship are accepted 1  rejected if either the child belief or the evidential relationship 

is rejected  and 1  uncertain otherwise 
   to determine the status  accepted  rejected  or uncertain  of a belief  bel the algorithm constructs an evidence set that contains the user s proposal of  bel  endorsed according to the user s level of expertise in that subarea as well as the user s strength in the belief as conveyed by the semantic form of the utterance  step 1   the system s own beliefs pertaining to  bel  step 1   and evidence proposed by the user that is accepted by the system  step 1  it also constructs a potential evidence set consisting of evidence proposed by the user whose acceptance is undetermined  step 1  the algorithm must then determine whether the potential evidence could have an impact on the system s decision-making it first evaluates  bel by invoking the evaluate function1 to compute an upperbound and a lowerbound for the system s acceptance of  bel the upperbound is computed by invoking the evaluate function with evidence from both the evidence set and the potential evidence set l e treating all uncertain evidence as accepted and the lowerbound is computed by invoking evaluate with only the evidence set i e   treating all uncertain evidence as re-
jected  steps 1 and 1  if  bel is either accepted or rejected in both cases  indicating that the uncertainty of the evidence if any  does not affect the acceptance of  bel the system accepts or rejects  bel  steps 1 and 1  otherwise the system has insufficient information to determine the acceptance of  bel and it is marked as uncertain  step 1  if the top-level pro posed belief is marked as uncertain  an information-sharing subdialogue will be initiated as described in the next section 
1 	initiating information-sharing subdialogues 
a collaborative agent when facing a situation in which she is uncertain about whether to accept a proposal should attempt to share information with the other agent so that each agent can knowledgably re-evaluate the proposal and the agents can come to agreement - to do otherwise is to fail in her responsi bill ties as a collaborative agent furthermore a collaborative agent should engage in effective and efficient dialogues thus she should pursue the information sharing subdialogue that she believes will most likely result in the agents coming to an intelligent decision about the proposal the process for initiating information-sharing subdialogues involves two steps selecting a focus of information-sharing from the proposed beliefs marked as uncertain during the initial evaluation process  and selecting an effective information-sharing strategy 
selecting the focus of information sharing 
the possible combinations of the upperbound and lowerbound values produced by the evaluate-belief algorithm  figure 1  are shown in figure 1 cases 1 and 1 correspond to steps 
　1 evaluate utilizes a simplified version of galliers belief revision mechanism  galliers 1 loganeral 1  which given a set of evidence compares the endorsements of the beliefs that support and attack bel and determines whether or not bel should be accepted 
1
　　our model assumes that a child belief is always intended to provide support for its parent belief  a piece of counter evidence is represented as a child belief supporting the negation of the parent be lief thus only six out of the rune theoretically possible combinations may occur 

figure 1 combinations of upperbounds and lowerbounds 
　1 and 1 in figure i respectively in which the decision to accept or reject is the same whether or not beliefs in the potential evidence set are accepted in these cases the uncertainty in the child beliefs need not be resolved since their acceptance will not impact acceptance of the parent belief that they are intended to support and thus will not affect acceptance of the top-level proposed belief that is important to the plan being constructed 1 in case 1 the system will remain unsure whether to accept or reject  bel regardless of whether the uncertain child beliefs if any are accepted or rejected i e resolving the uncertainty in the child beliefs will not help resolve the uncertainty in bel thus me system should focus on sharing information to resolve the uncertainty about  bel itself instead of its children in cases 1 and 1 acceptance of the child beliefs has the potential to influence acceptance of  bel and in cases 1 and 1 rejection of the child beliefs can lead to rejection of  bel thus in all three cases the system should initiate information-sharing that will allow the agents to come to agreement about the currently uncertain child beliefs 
   however there may be more than one uncertain child belief thus when the system initiates information-sharing it must first select a belief on which to focus during the information sharing process our algorithm for selecting the focus of information-sharing is shown in figure 1 select focus-info-sharing is initially invoked with  bel instantiated as the top-level proposed belief step 1 of the algorithm corresponds to case 1 in figure 1 where the uncertainty in the child beliefs is irrelevant to me acceptance of  bel thus the focus of information-sharing is  bel itself steps 1 and 1 of the algorithm correspond to cases 1 and 1 in figure 1 where the system attempts to share information to resolve the uncertai nty in the child beliefs and perhaps thereby accept or reject -bel 
   step 1 of the algorthm is concerned with cases where the potential acceptance of uncertain child beliefs may lead to the acceptance of  bel  caies 1 and 1 in figure 1  in selecting the focus of lnlormation-shanng in such cases two factors should come into play 1  how strongly the acceptance of each piece of evidence affects the acceptance of  bel - the stronger the impact that the potential evidence can have on the acceptance of  bel  the more useful it is to expend effort on resolving the 
1
　　 young et al  young et al  argued that if a belief is accepted even though a child belief that is intended to support it is rejected the rejection of the child belief need not be addressed since it is no longer relevant our strategy extends this concept to uncertain information 
	chu carroll and carberry 	1 


uncertainty about the proposed evidence and 1  how close each piece of evidence was to being accepted during the initial evaluation process - the closer a piece of evidence is to being accepted  the easier n is for the system to gather sufficient information to accept the evidence our algorithm first constructs a singleton set for each piece of uncertain evidence for  bel where a piece of evidence includes a pair of beliefs a child belief  bel  and the evidential relationship between  bel  and  bel supports   bel bel  the sets are ordered according to how close the beliefs in a set were to being accepted in the initial evaluation process  step 1  the first set   seti  is then added to the evidence set and  bel is re-evaluated with respect to the augmented evidence set  step 1  thus considering the potential effect of the acceptance of beliefs in  set1 on the acceptance of  bel if the result of the evaluation is to accept  bel indicating mat resolving the uncertainty of the beliefs in  seti is sufficient to resolve the uncertainty of  bel then select-focus-info-sharing is recursively applied to each belief in  seti in order to determine the focus for resolving the uncertainty of beliefs in  set1  step 1  on the other hand if the evaluation indicates that accepting  set1 does not result in the acceptance of  bel the next set   set1  is tried this continues until either the uncertain evidence in a set is predicted to resolve the uncertainty of  bel or all of the uncertain evidence is tried and none suffices for acceptance of  bel in the latter case  the set size is increased by one  sets of use requisite size are constructed by combining individual pieces of evidence the new sets are ordered and 
natural language 
the same process is repeated  step 1  thus our algorithm guarantees that the fewest possible beliefs are selected as the focus of information-sharing and that these beliefs require the least effort to achieve among those that are strong enough to affect the acceptance of  bel1 
step 1 of the algorithm corresponds to cases 1 and 1 in 
figure 1 the procedure for step 1 is similar to that for step 1 except that in predicting the effect of resolving a piece of uncertain evidence  bel is evaluated under the assumption that the set of uncertain evidence under consideration is rejected while the other uncertain beliefs are accepted  step 1  
selecting an information-sharing strategy 
we have identified four strategies which a collaborative agenl may adopt in initiating an information-shanng subdialogue to allow the agents to share information and re-evaluate a belief or evidential relationship  bel 
1 agent a may present a piece of evidence against .bel and  implicitly  invite agent b to attack it such a strategy focuses b s attention on the counterevidence and suggests that it is what keeps a from accepting  bel thus in collaborative activities this strategy should only be employed it as counterevidence is critical i e if proving that the counterevidence is invalid will cause a to accept  bel this strategy also allows the possibility of b accepting the counterevidence and perhaps both agents subsequently adopting  bel instead of  bel 
1 agent a may query b about his reasons for believing in 
 bel this strategy is appropriate when a does not know b s support for  bel and also does not have evidence against  bel herself it would result either in a gathenng evidence that contributes toward her adopting  bel or in a discovering b s invalid justification for holding  bel and attempting to convince b of -  bel 
1 agent a may query b for his evidence for  bel and also present her reasons for believing in -  bel this strategy is adopted when a does not know b s reasons for believing  bel but does have non-critical evidence against accepting  bel in this case b may provide his support for  bel  attack as evidence against  bel or accept as counterevidence and perhaps subsequently adopt - .bel 
1 agent a may indicate her uncertainty about  bel and present her reasons against  bel this strategy is adopted when a is least certain about how to go about sharing information to resolve the uncertainty - when a al ready knows b s reasons for believing  bel and only has non-cntical evidence against accepting  bel in a collaborative environment  a s indication of the uncertainty in her decision should lead b to provide information that he believes will help a re-evaluate the proposal 
   the process for initiating informal on-sharing subdialogues is performed by invoking the share-info reevaluate belief 
1 in cases where the focus set contains multiple beliefs additional processing is needed to determine the most coherent order in which to address the beliefs 

problem solving action on the focus identified by selectfocus-info-sharing  figure 1  it initiates an information sharing subdialogue using the most appropriate of the four information sharing strategies and re-evaluates the top-level belief taking into account the newly obtained information the recipe1 for share info reevaluate belief specifies that in order for the action to be invoked it must be the case that the system believes in neither a top-level proposed belief   bel  nor its negation - that is the system cannot determine whether to accept or reject  bel the body of share info reevaluate belief consists of alternative subactions which correspond to the aforementioned strategies that a collaborative agent can use to pursue information sharing the recipes for two of these subactions are shown in figure 1 
   the first specialization reevaluate after invite attack corresponds to the first information sharing strategy in which the system   sl  has a piece of critical evidence   bel1  against believing  bel 1 a belief proposed by the user   s1  and about which the system is uncertain this criterion is captured in the applicability conditions1 of the acuon the conditions that the system is uncertain about the acceptance of  bel 1 that the system believes in  bel1 which provides support for --bell and that the systems disbelief in  bel1 will result in its adoption of  bell the preconditions of reevaluate after invite-attack however show that the action cannot be performed until one of the following conditions is true 1  
   1a recipe  pollack 1  is a template for performing actions it contains the applicability conditions for performing an action the subactions comprising the body of an action etc 
   1 applicability conditions are conditions that must already be satisfied in order for an action to be reasonable to pursue whereas an agent can try to achieve unsatisfied preconditions 
the system and the user mutually believe  mb  in  bel1 and mutually believe that  bel1 supports - bell 1  the system and the user mutually believe in  bel1 or 1  the system and the user mutually believe that  bel1 does not support -bel in order to satisfy the preconditions the system will adopt the express doubt discourse action  lambert and carberry 1  in which the system expresses doubt at  bell by contending  bel and the evidential relationship between  bel1 and -- bell as an attempt to achieve mb s u  bel1  and mb s u supports j el1  bell   1 thus the system will initiate an information-sharing subdialogue by expressing its evidence against the proposed belief and inviting the user to comment on it if the outcome of the in form an on-sharing subdialogue satisfies one of the preconditions of reevaluate after invite attack the system can perform the body of the action and re-evaluate -top-belief  the root node of the proposed belief tree of which  bel i is a pan  taking into account the newly obtained information notice that the user s response to the express doubt discourse action is again considered a proposal of mutual beliefs and will be evaluated by the system the system may again have insufficient information to determine whether to accept or reject the new proposal which was intended to resolve the uncertainty of the previous proposal it will then initiate another information sharing subdialogue to resolve the new uncertainty resulting in embedded information sharing subdialogues 
   the second specialization of share info reevaluate belief is reevaluate after ask why which corresponds to the second information-sharing strategy in which the system attempts to find out the user s justification for believing -bell the action is applicable  figure 1  it the system   sl  does not know the users   s1 s  justification for holding -bell and also does not have any evidence against  bel 1 itself we argue that a collaborative agent should not accept a proposed belief merely because of the lack of evidence to the contrary instead  she should only accept a belief if the evidence supporting the belief is strong enough to warrant acceptance for instance suppose a student informs his advisor that the ai course scheduled for next semester has been canceled withouot giving any justification for it  such as attributing the source of the knowledge  although the advisor may not have evidence against believing in the cancellation she does not immediately accept the proposed belief because given the 
student s presumed low expertise in the domain the endorse ment attached to the proposed belief is not reliable enough to warrant acceptance the precondition of reevaluate after ask why indicates that the action can be performed only if the system knows the users evidence for holding -bell in order to satisfy this precondition the system will adopt discourse actions to query the user for such information thus 
   1these two mutual beliefs are selected as preconditions to be sat isfied because the system itself holds these beliefs the alternative preconditions are present in order to capture situations in which the user in response to the express doubt acuon convinces the system that  bel1 is false or that  bel1 does not serve as justification for - bel i the use of these alternative preconditions will be demon strated in section 1 
	chu carroll and carberry 	1 1 

initiating an information-sharing subdialogue 
1 	example 
suppose that the system an expert in the university course advisement domain has proposed the options of taking logic or algorithms to satisfy the user s core course requirement consider the following continuation which illustrates many of the features of our strategy for information-sharing during proposal evaluation 
 1  u 	logic is a better choice than algonthms 
 1  dr smith is teaching logic 
 1  s 	isn t dr smith going on sabbatical next year 1 
 1  u 	i thought he postponed his sabbatical until 1 
 1  s why do you think dr smith postponed his sabbatical until 1 
 1  isn t he spending next  ear at i b m ' 
in utterance  1   s initiates an in formation-sharing subdialogue to determine whether to accept or reject the belief that dr smith is teaching logic proposed by u in  1  by expressing a strong but not warranted belief1 thai dr smith is going on sabbatical next year in  1  u initiates an informationshanng subdialogue to determine whether to accept s s claim that dr smith is going on sabbatical next year by expressing his weak belief that dr smith has postponed his sabbatical finally in  1  and  1  s initiates an information-shanng subdialogue to determine whether to accept u s claim that dr smith has postponed his sabbatical by explicitly querying u s reasons for holding this belief and expressing her belief that dr smith is spending next year at i b m the following sections describe how our model will produce these information-sharing subdialogues 
1 	evaluating utterances  1  a n d  1  
utterances  1  and  1  propose two mutual beliefs better thanflogic algonthms  and teaches smirh logic  as well as an evidential relationship that the latter provides support for the former when presented these proposed beliefs  the system will first determine whedier to accept or reject the proposal by invoking evaluate-belief  figure i  on the top-level proposed belief better than logic algonthms  the system will evaluate the proposed evidence as part of evaluating the belief  step 1 in figure i  thus recursively invoking evaluatebelief on teachesfsmith logic   step 1  and the proposed evidential relationship  step 1  since teaches smith logic  has no children in the proposed belief tree u will be evaluated by a simplified version of galliers' belief revision mechanism  galliers  1   step 1  suppose that the system has the following evidence pertaining to teaches smith logic  1  a strong belief that dr smith usually teaches logic  1  a strong belief that dr smith is going on sabbatical next year and a warranted belief that going on sabbatical implies that a faculty member is not teaching courses and 1  the user's belief diat 
     1 the strength of a belief falls into one of three categories war ranted strong or weak hased on the endorsements of the belief 
natural language 
dr smith is teaching logic the strengms of evidence for and against teachesf smith  logic  will be combined and compared in this case  the strengths of the two sets of evidence are relatively comparable thus the system will not be able to decide whether to accept or reject teaches smith logic  based on the available information the system will then evaluate the proposed evidential relationship  step 1  since the system believes that 1  the user believes that dr smith is a good teacher and 1  students generally prefer courses taught by good teachers dr smith teaching logic provides support for die user preferring logic to algonthms thus the proposed evidential relationship will be accepted since the proposed evidential relationship is accepted while the child belief is uncertain this piece of evidence will be added to the potential evidence set  step 1  
   the system will men evaluate die top-level proposed belief taking into account the result of evaluating its only piece of evidence provided by the user the system's evidence set for better than logic algonthms  consists of a warranted belief mat algorithms is a pre-requisite for more cs courses than logic is which provides some support for algonthms being a better choice than logic as well as the user s statement that logic is a better choice dian algonthms the potential evidence set consists of a pair of beliefs the uncertain belief that dr smith is teaching logic and the accepted evidential relationship that dr smith leaching logic provides support for logic being a better choice than algonthms when both the evidence set and the potential evidence set are included in the evaluation the system will compute die upperbound of the acceptance of better-than logic algonthms  to be accept when considering only evidence from the evidence set  however  the system will be uncertain about the acceptance of the proposed belief the result of this evaluation corresponds to case 1 in figure 1 and results in the need for the system to initiate an information-shanng subdialogue to resolve the uncertainty 
   since die system cannot decide whedier to accept either of the proposed mutual beliefs  it will select a focus of information-sharing by invoking select-focus-info-sharing  figure 1  on better than logicalgonthms  since acceptance of die only piece of evidence provided by the user results in acceptance of the top-level proposed belief  step 1  the algonthm will be applied recursively to the child belief since it in turn has no children  teachesfsnuth logic  itself will be selected as the focus of information-sharing 
   the system will now invoke share info reevaluate belief on the identified focus since the system s belief that dr smith is going on sabbatical and its belief in the evidential relationship that being on sabbatical implies that dr smith is not teaching logic constitute the only obstacle against its accepting teaches smith logic  they are considered a piece of cntical evidence thus reevaluate after invite-attack will be selected as the specialization of share info reevaluate belief figure 1 shows the dialogue model that will be constructed for this process in order to satisfy the preconditions of reevaluate-after-invite-attack  figure 1  the 

 chu-carroll and carberry 1  in  1b  the user rejects mb s u on sabbatical  smith next year   while in  1c  the user rejects the evidential relationship mb s u supports on sabbatical smith  next year  -teaches smith logic    in the case where the user responds with  1b  if the system accepts the proposed belief that dr smith postponed his sabbatical until 1  the system and the user achieve the mutual belief mb s u -non-sabbattcal  smith next year   thus  the precondition of the reevaluate after invite attack action in figure 1 is satisfied and the system would re-evaluate better-than logic algorithms  taking into account the newly obtained information notice that in this case the mutual belief achieved to satisfy the preconditions of reevaluate afterinvite attack is different from the ones the system attempted to achieve - utterance  1  was generated as an attempt to achieve mb s  u on sabbaticah smith next  ear   but the result is that both the system and the user accept mb s u  on sabbattcal  smith next year   ithis case although the goal of the express doubt discourse action is not satisfied the agents mutual belief achieves the higher-level goal that the express doubt action is intended to achieve namely a pie condition of reevaluate after-invite attack thus the express doubt action is abandoned this example shows how the precondition of reevaluate after invite attack captures situations in which the user presents counterevidence to the system s critical evidence and changes the system s beliefs 
	1 	evaluating utterance  1d  
utterance  1d  will be interpreted as a case in which the user is uncertain about whether to accept or reject the system s proposal in  1  and attempts to share information with the system to re-evaluate the proposal it proposes a mutual belief postpone sabbatical  smith 1  which will be evaluated by evaluate-belief suppose the system believes that dr smith is spending next year at i b m which is evidence against dr smith postponing his sabbatical then the system cannot determine the acceptance of the proposed belief  resulting in the need to initiate an information-sharing subdialogue the focus of information-sharing is postpone sabbancal smith 1  since it is the only uncertain belief the system will then select an appropriate informationsharing strategy since the system does not know the user's reasons for believing postpone-sabbatical  smith 1  but does have a piece of non-critical evidence against the proposed belief the third information sharing strategy will be selected thus the system would query the user for support for the proposed belief and also provide its evidence against the belief  leading to the generation of the following utterances 
 1  s why do you think dr smith postponed his sab batical until 1  
 1  isn t he spending next year at ibm1 
	1 	related work 
grosz  sidner and lochbaum  grosz and sidner 1 lochbaum  1  developed a sharedplan approach to modelling collaborative discourse and sidner  sidner  1  
	chu carroll and carberry 	1 

formulated an artificial language for modeling such discourse sidner viewed a collaborative planning process as proposal/acceptance and proposal/rejection sequences her artificial language treats an utterance such as why do x  as a proposal for the hearer to provide support for his proposal to do x however  sidner s work is descriptive and does not provide a mechanism for determining when and how such a proposal should be made nor how responses should be formulated in information-sharing subdialogues 
   several researchers have studied the role of clarification dialogues in disambiguating user plans  van beek et al 1 raskutti and zukerman  1  and in understanding referring expressions  heeman and hirst 1  loganelal ilogan et al  1  developed an automated librarian that could revise its beliefs and intentions and could generate responses as an attempt to revise the user s beliefs and intentions although their system had rules for asking the user whether he holds a particular belief and for telling the system s attitude toward a belief the emphasis of their work was on conflict resolution and plan disambiguation thus they did not investigate a comprehensive strategy for information-sharing during proposal evaluation for example  they did not identify situations in which informarjon-shanng is necessary  did not address how to select a focus of information-sharing when there are multiple uncertain beliefs did not consider requesting the user s justifications for a belief etc in addition they do not provide an overall dialogue planner that takes into account discourse structure and appropriately captures embedded subdialogues 
1 	conclusion 
this paper has presented a computational strategy for collaborative information-shanng in situations where the system s current knowledge does not allow it to make a decision about whether to accept or reject a user proposal our model in eludes algorithms for determining when in formation-sharing subdialogues should be initiated and for selecting a focus of in formation-sharing the latter algorithm takes into account both the effect of the acceptance of a piece of evidence on the acceptance of the top-level belief and the difficulty in resolving the uncertainty about acceptance of a piece of evidence furthermore we have identified four alternative informationsharing strategies and the criteria under which each should be invoked thus allowing the agents to share the most pertinent information in order to re-evaluate a proposal in addition by capturing in formation-sharing as part of the evaluation process in a propose evaluate modify cycle of actions our model can handle embedded information sharing subdialogues 
acknowledgments 
the research has benefitted from discussions with stephanie 
elzer  kathy mccoy and candy sidner 

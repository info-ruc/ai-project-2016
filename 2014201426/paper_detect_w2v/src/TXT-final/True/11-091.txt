panel on natural language processing 
 roger schank  chairman ; eugene charniak; y o r i c k w i l k s ; terry winograd; w i l l i a m woods 
four questions were posed to the p a n e l i s t s . 
some p a n e l i s t s chose not to answer each question. the questions were: 
1  to what extent is n a t u r a l language processing a separate f i e l d   would it be wrong to say t h a t ai and nlp are i d e n t i c a l f i e l d s   can problem s o l v i n g be separated from nlp  for example  
1  has frame theory been a s i g n i f i c a n t c o n t r i b u t i o n to nlp  is the o r g a n i z a t i o n of world knowledge the fundamental problem in nlp  
1  is syntax a dead issue  what low l e v e l language problems remain to be solved  
1  why are new programming or r e p r e s e n t a t i o n l a n guages necessary f o r nlp  
ql: to what extent is n a t u r a l language processing a separate f i e l d   would it be wrong to say that ai and nlp are i d e n t i c a l f i e l d s   can problem s o l v i n g be separated from nlp  for example  
ec : n a t u r a l language processing has been a subbranch o f a r t i f i c i a l i n t e l l i g e n c e since the e a r l y days of the f i e l d . for most of t h i s time however  it has been s l i g h t l y on the p e r i p h e r y   p a r t i a l l y due t o i t s close r e l a t i o n to l i n g u i s t i c s   a r e l a t i o n not shared by other sub-branches  and p a r t i a l l y due to the f a c t that a r t i f i c i a l i n t e l l i g e n c e was seen as nearly synonymous w i t h problem s o l v i n g and h e u r i s t i c search. this has changed as of l a t e and it now seems c l e a r that language processing is a c e n t r a l topic w i t h i n a i . that is to say  many nlp researchers have been f i n d i n g 
that ai problems occur in nlp as w e l l . 
minsky  1  t a c i t l y assumes a close connect i o n between the problem of v i s u a l r e c o g n i t i o n 
  o f   say  a room  and language   r e c o g n i t i o n    as in recognizing that c e r t a i n story circumstances are instances of a b i r t h d a y p a r t y   . this assumption has been extended by bobrow and winograd  1  who see p r a c t i c a l l y a l l of ai in terms of the r e c o g n i t i o n problem. yet other researchers have commented on the r o l e of problem s o l v i n g  rieger 1   schank and abelson 1  or search  charniak 1  in nlp. there are s t i l l aspects of nlp which are unique to it w i t h i n ai  grammars  and problems in other domains which do not enter nlp   l i n e 
f i n d i n g     but it seems safe to say that nlp is 
w e l l s i t u a t e d i n the heart o f a i . 
whether nlp is deservingly s i t u a t e d in the h e a r t of ai is a more d i f f i c u l t q u e s t i o n   as 
it depends on whether one sees the extension 
of nlp i n t o questions of knowledge r e p r e s e n t a t i o n and problem s o l v i n g as w e l l motivated. that it is w e l l motivated can be supported by one or more of the f o l l o w i n g premises. 
a  these problems are important whether or not they are nlp in a s t r i c t sense. furthermore  since many of these issues are most e a s i l y approached from the viewpoint of nlp it makes sense to  extend  nlp to these issues. 
b  if one is concerned w i t h not merely  analys i n g   a sentence  but r e a l l y  understanding  i t   i do not see how these problems can be avoided. s t r i c t l y speaking t h i s would depend o n one's d e f i n i t i o n o f  understand   but i t i s surely not coincidence that a l l of the s t a n dard tests f o r n a t u r a l language comprehension assume that one has a large body of common sense knowledge  and that one can do problem s o l v i n g w i t h i t . 
c  some more obviously   l i n g u i s t i c   processes l i k e ambiguity and reference r e s o l u t i o n depend on these processes. 
these premises are not mutually e x c l u s i v e   and i would support a l l of them  but any one would do to support the c u r r e n t view of nlp held in a i . 
rs: natural language processing has been only a p e r i p h e r a l p a r t of ai u n t i l the l a s t few years. in the 1 ijcai only 1% of the papers were on nlp. in 1 that percentage was 1%. when i was l o o k i n g for a job in 1  i t a l k e d to the stanford ai lab about w r i t i n g a program that would t a l k to t h e i r hand-eye system in e n g l i s h . there was no i n t e r e s t in the p r o j e c t by the l a b . 
recently things have changed. part of the change was due to the success of winograd's program t h a t d i d what the stanford ai lab said was u n i n t e r e s t i n g . the change has come i t h i n k from something l a r g e r than any one program  however. l a t e l y   researchers in ai have s t a r t e d t a l k i n g about human process and programs t h a t simulate those processes  much more f r e q u e n t l y than they ever d i d . researchers are s t a r t i n g to understand that t o u r de-forces in programming are i n t e r e s t i n g b u t non-extendable. 
invited panel-1: schank 1 to go back to the example i c i t e d e a r l i e r   the ai lab at stanford was i n t e r e s t e d in winograd's t o u r - d e - f o r c e . on the o t h e r hand  it doesn't seem winograd was i n t e r e s t e d in it as much as stanford was. in any case he d i d n ' t pursue i t . he  as w e l l as the m a j o r i ty of members of t h i s panel  has become more i n t e r e s t e d in what the general issues a r e . how people do c o g n i t i v e processing is much more a p a r t of ai than it ever was b e f o r e . 
for that reason ai and nlp are more and more becoming nearly identical fields  as the ai people recognize that how people use and represent knowledge is the key issue in the field and as the nlp people realize that that same issue is at the root of the problems of language processing. 
researchers in nlp have become less and less concerned with language issues per se. we are more interested in inferencing and memory models for example. we seem lately to be coming against the same problems that everyone else in ai has; knowledge representation; processing of goals; planning and so on. i believe however that our solutions to these pro-
blems w i l l continue to be different than those already proposed in a i . whether ai shifts over to our solutions  or whether we continue to go on our merry way  it seems that a radical change from the i n i t i a l conception in ai of nlp as being some peripheral  albeit d i f f i c u l t   field has occurred. ai and nlp are becoming fields that aim to model human cognition. the 
more this becomes the case  the more the particular input and output devices being used to gather and transmit input to a system that understands w i l l become side issues. 
yw: the superficial answer is that nlp must remain a separate f i e l d   if only because requirements of text processing  like spelling correction  
w i l l have no analogue i n   say  visual processing. 
however  under the question are  i think  two deeper questions: 
a  will different ai activities  language  vision  physical manipulation  ultimately require access to the same knowledge base  
b  if knowledge bases for different activities are not independent  is one more fundamental than another  
on  a  i remain unconvinced by the  they must have the same base  arguments-it is not at a l l clear to me that my physical a b i l i t y to drive a car and my linguistic knowledge  or knowledge accessed in talk about cars  rather  are  or needs be  the same  viz: one's d i f f i culty in describing easy physical tasks . evolutionary arguments  gregory: language came later than vision-therefore visual structures 
were used for language  and those from dogs  say  that see but do not talk  seem to me very weak  and to lead to no clear  undisputable  consequences for constructing ai systmes. 
on  b  i believe that knowledge is dependent on language  rather than vice-versa  as seems the norm in ai beliefs  see mccarthy . this is hard to j u s t i f y without bringing in the 
whole of linguistic philosphy  but as a very high-level psychological assumption it does  i believe  have empitical consequences for how we should construct ai systems. 
tw: the fact that these questions are posed for a panel like this is a good indication of how immature our science s t i l l i s . imagine a time centuries ago when a similar panel gathered at the conference on celestial mechanics to discuss questions l i k e : to what extent is astronomy a separate field  would it be wrong to say that physics and astronomy are identical fields  can angular momentum be separated from astronomy  for example  
the answers to the questions  in both forms  are  to a large extent    yes   and   i t depends on what you mean by 'separate'.  ai is the general study of those aspects of cognition which are common to a l l physical symbol 
systems  including humans and computers. as such  it covers a wide range of cognitive processes  each of which embodies the general principles  and each of which has special features of its own. ai and nlp are not identical any more than ai and vision  or ai and game playing  or ai and medical diagnosis. human language poses a special set of problems  having to do with creating and interpreting structured symbolic objects which can be conveyed over a limited channel  sequence of speech sounds or marks   and which are i n tended to communicate from one thinking being to another. in this aspect  it is quite d i f ferent from any of the other ai topics listed above. the structure of language is a result of i t s function  and by reducing it to what it has in common with other ai areas  we lose sight of i t s unique features. 
the fact that the questions are posed as they are reflects a historical situation in the development of a i . in fact  most of the diff i c u l t issues with which researchers in nlp 
must grapple are not language issues at a l l   but more fundamental issues of representation and cognitive processing. these include issues such as: the role of primitives in representation; the use of frame-like constructs in reasoning; the nature of plans and their relation to actions; the structuring of knowledge for problem solving and deduction; the amount of inferencing done with new knowledge; etc. etc. a quick scan through the l i t e r a ture in ai natural language work w i l l show a 
high proportion of the verbiage devoted to these rather than the issues of language. 
invited panel-1: schank 1 this is a necessary step. it would be as impossible to develop a satisfactory theory of language without having an understanding of general cognitive processing as it would be to have a satisfactory theory of celestial 
motions without basing it on theories of mechanics . we who do natural language research are in a good position to examine these questions. by having a specific set of problems to deal with  we are put into contact with the 
broader issues in a way which would be impossible through sheer top-down musing. it w i l l almost certainly remain true for many years to come that research in natural language w i l l be intertwined with research in broader issues of cognition and representation. but in doing this kind of mixed research  we should not lose sight of the fact that we are really 
wearing two hats  and that language is only a partial reflection of the range of issues in 
ai. 
q1: has frame theory been a significant contribution to nlp  	is the organization of world knowledge the fundamental problem in nlp  
rs: frame theory may not be the particular solution to the problems of nlp  but its s i g n i f i cance seems clear. natural language processing w i l l be successful precisely when an adequate theory of the organization and representation of knowledge has been fully worked out. frames are one suggestion for how to organize world knowledge. they w i l l probably  
when f u l l y worked out  only help to solve one aspect of the organization of knowledge problem  but that is a significant aspect indeed. 
scripts  our particular instantiation of frame theory  w i l l in no sense solve a l l of the pro-
blems in nlp. but it seems clear that a good deal of human functioning is script-based  and we have gone f a i r l y far using scripts to understand newspaper stories. 
yw: i don't think it has yet  but it well may do so. there has been a rush of ingenious suggestions about  and implementations of  frame systems; but not yet enough thought about what claims are being made  and whether or not they are true. my instinct is to answer  no  to the second question  simply because i can imagine someone having organized world knowledge perfectly  but having got no farther 
with nlp. conversely  we are a l l pretty good at nlp  but have pretty bad organization of world knowledge in many respects. i cannot see that  organization of world knowledge  is a concept that makes much sense  as such  and 
wholly independent of particular tasks and purposes. 
however  it remains true that world knowledge organization is a growth point in nlp at the moment  and w i l l probably remain so for some time. my own hunch is that the use of world 
knowledge in nlp  at high levels  that is  is going to pay off in connexion with robust systems that run on texts where they don't already know a l l the word senses etc. and the question here that i am most unsure of the answer to i s   what is the role of highlevel knowledge structures  like frames  in actually parsing input text  
tw: the second half of this question is another form of the questions above. it is both true and patently false  depending on how  problem in nlp  is interpreted. if we are interested in building systems or models which reflect the processes of language production or comprehension  then the answer is  yes.  when a person uses language  he or she is not simply using a  language faculty   but is making use of a f u l l range of mental operations  of which only some are directly linguistic. if we wish to model this behavior  we must model a l l of these operations  and in doing so the organization of world knowledge provides the largest stumbling block. 
on the other hand  if we view  nlp  as describing a scientific enterprise  then the organization of world knowledge is not a problem within its domain at a l l . it is a problem in the more general domain of ai  and one whose solutions w i l l form a basis for attacking problems in nlp  which deal with the structure of language and communication. 
the f i r s t half of the question raises two i s sues. the phrase  contribution to nlp  is subject to a l l of the problems discussion above  and i won't go into them again. the phrase  frame theory  raises the question  what is a frame theory   as far as i can see  none of the work which goes by this name is really a  theory  at a l l . there are two levels at which it has been couched: a general i n t u i t i o n   and a set of specific mechanisms. at the intuitive level  it has bee 
invited panel-1: schank 1 been of great importance. the attention of researchers has been focussed on a different set of issues from those which were predominant in the older  more atomistic ways of thinking about knowledge and meaning. issues of memory structure  chunking  accessibility  and pattern-related control structure are beginning to make inroads into a literature which previously focussed on predicates  p r i mitives  parsers  and uniformly applicable algorithms. at the detailed level  i think we are far from having satisfactory notions of how to apply the intuitions. there are a number of simple ideas  such as the use of explicit cross linkages to switch between frames  minsky   the notion of scripts as linear sequences of stereotypical events  schank   the association of specific procedures with parts of a declarative frame structure  winograd   and the need to view a single object as an instantiation of multiple frames  bobrow and winograd   but a l l of these are over-simplified and lack the kind of depth which w i l l make them the center of a  theory . they are a l l useful  but do not constitute a theory any more than a set of specific tech-
niques for differentiation is a theory of calculus. 
 is syntax a dead issue  	what low level language problems remain to be solved  
syntax is by no means a dead issue  but it is by no means clear what the issue i s . nobody claims that one can do without syntax  it is too easy to give sentences where it comes in 
handy  and nobody claims that one can rely ent i r e l y on syntax to solve one's parsing pro-
blems  that we easily understand ungrammatical  or a-grammatical  sentences shows the contrary.   parsing  here is simply the process of going from surface structure to  semantic representation . i am not restricting the term to grammatical parsing.  the real substantive issues as i see it are two:  how much  syntax is needed  both for analysis and generation   and how should this information be interfaced 
with the rest of the system. further discussion w i l l show  i think  that we have no good answers to either of these questions  and so 
we should add a t h i r d   more pragmatic question: what is the best way to proceed u n t i l answers are ¡Àn on the f i r s t two  
in asking  how much  syntax is needed one usually takes as a basis for comparison the yet hypothetical set of rules which would allow one to generate a l l and only the grammatical sentences of english. 	restricting ourselves to problems of analysis  since synthesis has played a comparatively unimportant role in ai   
we can then ask at least two new questions. are there any rules in the hypothetical basic set which are never needed to parse english  and secondly  are there rules which are so seldom needed that we should not apply them  unless we have evidence that they are needed   these last are scare quotes only . as for the f i r s t of these  since nobody has offered any candidates for such a rule  the current answer must be  don't know . my personal guess however is that there are few if any such rules. take  for example  the question of verb subject agreement. as everybody knows  and i have i n advertantly shown a l l too often  in french   one can be understood in spite of the fact that one's verbs have the wrong ending. perhaps then various of the verb ending rules are not needed. there are  however  occasional sentences where they are crucial  hunting dogs is/are forbidden   hence they do not qualify as being completely superfluous. nevertheless  perhaps  they qualify as rules which are so seldom needed that we should only use them if we know they are necessary. 
this is plausible  but there are technical reasons why this is impossible with current parsing systems. virtually a l l ai parsers are depth f i r s t in that they try to produce one complete parsing  hopefully the correct one  f i r s t   and only try another if the f i r s t is rejected. in the example given above  by the time the parser gets to the verb it w i l l have made a choice about the structure of the noun phrase. if the parser were to ignore subject - verb agreement  it would reach the end of the sentence with a successful  but possibly wrong  parse. that is to say  it would have no way to  know  that in this example the rule of subject agreement is needed. one could  naturally  have one's parser discover both readings of the noun phrase  and hence have some indication that subject agreement is necessary  but whether in fact this is worth doing is a complicated trade-off question more time handling noun phrases against less time for verb phrases. my intuition t e l l s me it is a bad trade-off  but only because subject verb agreement is such a simple question. in fact  nobody really knows the answers to questions like this. 
one example may be suggestive  but it is hardly an argument. and the situation with respect to the second question i asked at the outset   how should syntactic information be interfaced with the rest of the system  is just as bad. so let me move on to the pragmatic question of what we should do next. my personal belief is that one should simply take one of the existing parsers  off the shelf  and use it as a  front end . this view is rather old fashioned  but my reasons are quite simple. few  if any of us  are really worrying about ungrammatical texts  hence a grammat i c a l parse w i l l not be unduly destructive. furthermore it can be quite useful in establishing the functional structure of the sentence.  that i s   answering questions l i k e   which is the direct object of the verb.  this is not say of course  that syntax is necessarily the only way  but given a free syntactic parser  
why not use i t . except from arguments stemming from our a b i l i t y to understand ungrammatical sentences  the only arguments one sees against syntactic parsers are of the form   why do a syntactic parse if it is not necessary . they are  that i s   efficiency arguments. 
even if these statements are correct  and i for one have seen no hard figures  or arguments  to back them up  we know so l i t t l e about language comprehension at the present time that questions of efficiency  aside from problems of exponential growth  are completely beside the point. 
invited panel-1: schank 1 this is not to say that syntax is no longer a problem. if it is true that we can syntactically parse a much broader range of sentences than our programs can  understand  it is because of our ignorance of the latter process  and not because we understand the former. 
rs: although i doubt that many people agree with me  syntax has always been a dead issue. our operating view was always semantics f i r s t   syntax later. later it became knowledge representation f i r s t   syntax later. syntax is the last thing that children get right when they learn how to talk. if that strategy 
works for them it should work for us. note that i am not saying that syntax doesn't exist  only that more progress on understanding issues w i l l be made by ignoring it than by studying i t . a great deal of effort has already been put into syntax. most of these efforts do l i t t l e to solve the problem because they beg the issue of what w i l l be done 
with the syntactic trees they produce. by concentrating on understanding issues  syntax 
w i l l be reduced to the secondary role it so richly deserves. 
yw: no  i t ' s not a dead issue  but a number of people have agreed to put it on ice  and turn to something more interesting for a while. 
although there are now good off-the-peg syntax parsers like woods'  i do not think syntax parsing is settled. those atn's are clearly much better than the harvard analyzer  say  but s t i l l far too fragile with regard to semantic problems. 
conversely  i do not think those who have argued the superiority of semantics-driven parsers have proved their case  t include myself.  i think they w i l l only do so when they produce a semantics-driven parser as ro-
bust and portable as woods' syntax one  and in as perspicuous a formalism   i . e . atn's or production systems  or something like that . this w i l l require a great deal more detail than has been forthcoming so far about how the semantic structures and rules determine relations as low-level as concord  for example  and where exactly the conventional syntactic generalizations are expressed in the system   i f they are not  that too w i l l be highly interesting . i think the whole business is unproven at the moment  and settling it w i l l have interesting consequences for linguistics. 
tw: syntax is far from a dead issue unless we take a narrow  though popular  view that it covers the parsing of simple  grammatical  sentences into trees. live questions i n clude: 
what is the relationship between standard syntactic forms and the  phrasal lexicon   many idioms are syntactic structures  e.g.  the x'er the y'er   which cannot be treated either through normal grammars or as lexical items. 
how are syntactic cues used to communicate i n formation about the message structure - focus of attention: what is important  what the speaker considers new information  etc. there is a good deal of work in this area among l i n guistics  and we are far from having satisfactory answers from the point of view of building successful systems for communicating with human users. 
how can syntactic analysis be f i t into a multi-knowledge-source framework  to handle real language  with its stops and starts  ungram-
m a t l c a l i t i e s   etc. . this w i l l demand integrating ideas of syntax and grammar with those of frames and prototypes. 
ww: during the past decade or so  many advances have been made in natural language processing. among these have been the development of formal grammar models that provide efficient systematic frameworks for implementing grammars of a complexity and sophistication matching the most advanced work in linguistics  e.g. woods  1 . 
the most powerful of these grammars contain augments that allow one to associate conditions with the grammar that refer to general semantic information and world knowledge  thus providing a formal interface between the syntactic knowledge embedded in the grammar itself and world knowledge that may be stored elsewhere and in some other form. this has permitted the beginnings of a systematic i n vestigation of the relationship between syntactic knowledge and general semantic and 
world knowledge. 	however  our present state of progress in this area is quite immature - much of it is based on understanding single sentences in isolation  and the role of world knowledge is largely limited to rejecting i n terpretations that do not satisfy certain se-
mantic selectional restrictions. the ultimate challenge in this area is to be able to choose between alternative readings of a sentence based on sophisticated evaluation of the plausibility of the alternatives in context. 
from the other direction  many people have tried to attack the language understanding problem directly from the world knowledge  
with minor if any interest in syntax. these systems to date  while they frequently i l l u s trate suggestive approximations to various aspects of human performance  have not begun to develop a formal mechanism capable of 
invlted panel-1: schank 1 handling a general range of language understanding phenomena. in many cases  the devices underlying such approaches  when viewed as formal automata  lack the power necessary for a general treatment of the phenomena they purport to solve. in many other cases  the actual mechanisms underlying their performance are not even sufficiently clear to make such judgments. much more care in formally defining representational conventions and the a l gorithms that operate on them is required in the work in this area. woods  1  discusses a number of representational issues that are frequently l e f t vague in knowledge representation schemes  and the work of cercone and schubert 1  and brachman  1  are beginning to make some progress in this area. 
one of the major d i f f i c u l t i e s in investigating the less syntactic characteristics of natural language understanding is that the fundamental problems of factual inference and plausible reasoning become a c r i t i c a l factor at this level. since these are active research areas in their own right and are far from understood investigations into knowledge-based language understanding that are to make progress at this point must be making contributions to the study of factual inferencesand plausible reasoning as well. unfortunately  many people who adopt the so-called knowledge-based approach do so without consideration of much relevant work that has gone on in the area of formal inference  dismissing the relevance of such work on the grounds that human reasoning is not necessarily logical or complete. in doing so  they lose the benefit of a great deal of understanding of fundamental problems and frequently propose inadequate treatments of problems that are well-known and well understood in the formal reasoning camps. 
while many of the goals of researchers in formal reasoning differ from those of natural language understanding and a r t i f i c i a l i n t e l l i gence  the kinds of discipline involved in formally specifying the details of one's theory and rigorously assessing i t s capabilities that is characteristic of the formal inferencing work is one that we should emulate. successful demonstration of a few chosen examples is not a sufficient benchmark - especially the high-level description of the procedure that accomplishes the demonstration seems i n t u i t i v e l y satisfying  but the details of how it works are obscure. in this situation  one is too easily led to believe that something 
has been accomplished when in fact the underlying mechanism may be inadequate  sometimes either t r i v i a l or totally unsystematic and ad hoc . 
in summary  while there remain a number of outstanding and troublesome problems of syntax in natural language understanding  especia l l y in the areas of coordinate and subordinate conjunctions  mass terms  nominal compounds  comparatives and superlatives  and discourse structure  it is clear that many of the most intractable ones involve the interaction of syntactic and semantic information and require access to plausible inference capabilities for the evaluation of alternative hypotheses. thus  the problems of factual i n ference and plausible reasoning are becoming a central problem in natural language understanding  as they have in a variety of other a r t i f i c i a l intelligence areas. they are not the only problems  however  and their role in natural language understanding is intricately intertwined with the use of syntactic and semantic knowledge. 
q1: why are new programming or representation languages necessary for nlp  
rs: i have noticed that when students are stuck on a problem in ai that is too d i f f i c u l t for them they often suggest writing a new programming language. i have l i t t l e doubt that such programming languages would be of some value in f a c i l i t a t i n g program writing  so that is not 
why i don't let them do i t . 
i don't let them do it because it has always seemed to me that writing a new programming language is a way of avoiding tackling a pro-
blem you do not know how to program in the f i r s t place. if you do know what the solution to a problem is l i k e   then it should be possible to program it in any language  though of course some languages w i l l make doing it easier than others. but if you don't know how to solve the problem  new programming languages won't help. 
don't misunderstand. i think that there is a strong possibility we might use such a language if strong theoretical biases that we disagree with are not b u i l t into i t . nonetheless i cannot help but wonder if the real problems aren't somehow being avoided by working on new languages. 
: i think the best reason is standardization  and the advantage that would come from downgrading superficial differences between notations and idiosyncratic systems. this facil i t y seems to me the main advantage offered by krl  but it w i l l be psychologically very d i f f i c u l t to get many researchers to adopt any 
such standard language. one reason is the obvious one that such high-level languages are bound to commit users  both as regards control structures and metaphysical questions of representation  in ways they do not want to be committed. if such a language does not commit one  and krl makes l i t t l e or no commitment about inference and control structures  then  of course  it w i l l not be a programming language at a l l   and many of the problems w i l l not arise. i have a hunch  and this may be 

invited panel-1: schank 1 

over-cynical  that advance on this front may not  in the end  be made by those working at it from our end  as it were. it may come from those working on programming languages proper  and their work may later be seen to be relevant to ai  rather than from those tackling the problem of knowledge representation from ai directly . i feel that we should for now go on working on sloppy systems that actually work  and hope that the language constructors  as well as the  semantics of programs  people  w i l l come along later and make what we do seem perspicuous and sensible as well as effective. the converse view  that we need advance with the languages f i r s t   seems to me unappealing because i cannot  here and now  imagine what a new-wonder-programming-language that made nlp possible would be like.  but 
that may well be only my own lack of imagination.  
tw: new programming and representation languages w i l l always be needed for research not only in nlp  but in a l l of ai. 	research follows a cycle: 
a researcher has some new intuitions about the structure of a problem or a mechanism  and decides to embed them in a program. 
he or she writes that program in some existing language  which was designed to facilitate 
working within a previously understood set of intuitions. 
some of the new ideas prove to be of general u t i l i t y . 
someone  possibly the same researcher  writes a new language which facilitates building systems which make use of these new ideas. 
the whole thrust of higher-level languages is to look for things which are done commonly and in a standard way  and to make their det a i l invisible to the user  so that he or she can concentrate on the next higher level of structure. without this  research would rapidly bog down  since the complexity of any system is s t r i c t l y limited by the mental capacities of people who program i t . to write more complex systems  we need languages which hide those complexities we can afford not to think about. ai went through a clear case of this twenty years ago  when the complexities of l i s t processing and storage allocation 
were hidden in the primitives of lisp. 
i believe  as do many others today  that there is another level which is ripe for the same treatment. this level has new structure along both the declarative and procedural d i mensions. declaratively  it deals with the way in which descriptions  defined by semantic notions of  description    prototype    instance   etc.  are implemented in l i s t structures. 	the ai languages  e.g. microplanner  connlver  qa1  took a small step in this direction  but did not try to deal with the semantics of description in a systematic 
way. 	current representation language research  krl  mds  owl  partitioned semantic nets  is much more ambitious in its attempt to provide the user with a higher level of structure. procedurally  new languages must provide means to reduce the complexities of building systems 
which multi-processing  resource allocation  and integrated goal-driven and data-driven processing. we have many different starting points in the current ai systems   including production systems  standard hierarchical control  coroutines  etc.  but they have not been satisfactorily unified in a workable system. 
although no one can predict the details  it seems clear that some language or languages at this higher level w i l l eventually become a widely accepted standard for work in nlp  and ai in general   just as lisp has dominated the more traditional algol/fortran languages for current ai work. 

invited panel-1: schank 1 

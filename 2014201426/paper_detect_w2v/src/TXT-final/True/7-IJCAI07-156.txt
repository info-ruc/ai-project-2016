
we present a general machine learning framework for modelling the phenomenon of missing information in data. we propose a masking process model to capture the stochastic nature of information loss. learning in this context is employed as a means to recover as much of the missing information as is recoverable. we extend the probably approximately correct semantics to the case of learning from partial observations with arbitrarily hidden attributes. we establish that simply requiring learned hypotheses to be consistent with observed values suffices to guarantee that hidden values are recoverable to a certain accuracy; we also show that  in some sense  this is an optimal strategy for achieving accurate recovery. we then establish that a number of natural concept classes  including all the classes of monotone formulas that are pac learnable by monotone formulas  and the classes of conjunctions  disjunctions  k-cnf  k-dnf  and linear thresholds  are consistently learnable from partial observations. we finally show that the concept classes of parities and monotoneterm 1-decision lists are not properly consistently learnable from partial observations  if rp = np. this implies a separation of what is consistently learnable from partial observations versus what is learnable in the complete or noisy setting.
1 introduction
consider the task of predicting missing entries in a medical database  given the information that is already available. how does one go about making such predictions  and what kind of guarantees might one provide on the accuracy of these predictions  the problem with which one is faced here is that of missing information in data  an arguably universal and multidisciplinary problem. standard statistical techniques schafer and graham  1  fail to provide a formal treatment for the general case of this problem  where the fact that information is missing might be arbitrarily correlated with the actual value of the missing information  e.g.  patients exhibiting a certain symptom might be less inclined to disclose this fact .
모in this work we employ learning as a means of identifying structure in a domain of interest  given access to certain observations. we subsequently utilize such identified structure to recover missing information in new observations coming from the same domain. note that the manner in which acquired knowledge may be utilized to draw conclusions is not necessarily a single step process  see  e.g.   valiant  1  . nonetheless  we focus here on examining whether even individual learned rules can be meaningfully applied on partial observations  given that such rules are learned from observations that are partial themselves. studying how multiple learned rules can be chained and reasoned with to draw richer conclusionspresents furtherchallenges  and necessitates a solution to the more fundamental problem examined herein.
모we present a general machine learning framework within which the problem of dealing with missing information can be understood. we formulate the notion of masked attributes  whose values in learning examples  e.g.  patient records  are not made known to an agent. such masked attributes account for missing information both in the given target that the agent attempts to learn  e.g.  the presence of a particular disease   as well as in the learning features over which the agent's hypotheses are formed  e.g.  various pieces of information from a patient's medical history . masked attributes are determined by an arbitrary stochastic process that induces for each example a possibly different but fixed distribution over partial observationsto which the example is mapped  see also  schuurmans and greiner  1  ; this is intended to capture situations such as the probabilistic failure or inability of an agent's sensors to provide readings. we extend the probably approximately correct learning semantics  valiant  1  to apply to the described situation. a salient feature of the extension we propose is the lack of need for specially prepared learning materials; the agent simply utilizes whatever information is made available through the masking process. we call this type of learning autodidactic to emphasize that although the agent might still employ supervised learning techniques  this is done without the presence of a teacher explicitly providing the agent with  labelled instances  during the learning phase. we propose consistency as an intuitive measure of success of the learning process. an agent faced with partial observations needs to produce hypotheses that do not contradict what is actually observed; the values of masked attributes need not be predicted correctly. in addition  hypotheses that do not assume a definite value due to masked attributes need not make a prediction. we allow  thus  the possibility of  don't know  predictions  but restrict such predictions in a natural manner  providing a notion of completeness of the prediction process.
모following the presentation of our framework  we discuss accuracy as an alternative measure of success  whereby an agent is expected to correctly predict the values of masked attributes. we show that the success of an agent in this stricter setting might be completely impaired  dependingon howconcealing the masking process is  i.e.  how adversarially information is hidden from the agent . on the positive side  we show that to the degree allowed by the masking process  an agent can perform optimally in making accurate predictions  by simply making consistent predictions. this surprising relation between the two measures of success allows an agent to focus on the more natural task of learning consistently  while not losing anything with respect to predicting accurately.
모we then examine consistent learnability more closely. we define a notion of reduction between learning tasks  and establish that any concept class of monotone formulas that is pac learnable by some hypothesis class of monotone formulas is also consistently learnable from partial observations; the result is obtained by reducing the learning task to one over complete observations. through a second reduction we show that the concept classes of conjunctions  disjunctions  k-cnf  k-dnf  and linear thresholds over literals  are all properly consistently learnable from partial observations.
모on the negative side  we show that the set of consistently learnableconceptclasses is a subset of the pac learnableconcept classes. we continue to prove that the concept classes of parities and monotone term 1-decision lists are not properly consistently learnable from partial observations  given that the widely held complexity assumption rp = np is true. the intractability of properly learning monotone term 1-decision lists from partial observations provides a partial answer to a question posed by rivest . our intractability results establish separations between our model of consistent learnability from partial observations  and the existing models of pac learnability  valiant  1  and learnability in the presence of random classification noise  angluin and laird  1 .
모we assume the reader is familiar with basic pac learning terminology  see  e.g.   kearns and vazirani  1  . proofs are only briefly discussed in this paper due to lack of space.
1 the learning framework
in the pac learning model  valiant  1   a set of boolean variables {x1 x1 ... xn} represents the attributes of the environment. a concept c is a boolean formula over the boolean variables. an example for the concept c is a truth-assignment to the boolean variables  drawn from an underlying probability distribution d  paired with the induced truth-value of c.
모such a treatment distinguishes the target attribute from the attributes acting as learning features for that target. as a more natural and better suited approach for autodidactic learning  where target attributes are not externally  labelled   we consider examples that treat all attributes equally as properties of the environment. the attribute acting as a learning target need only be defined as part of the learning task one undertakes.
definition 1  examples and observations  consider any non-empty finite set a of attributes. an example over a is a vector exm 뫍 {1}|a|. an observation over a is a vector obs 뫍 {1  }|a|. an observation obs masks an example exm if obs i  뫍 {exm i   } for every attribute xi 뫍 a. an attribute xi 뫍 a is masked in an observation obs if obs i  =  . a masking process is a  stochastic  function mask : {1}|a| 뫸 {1  }|a| that maps each example exm to some observation obs that masks exm.
모examples define the  truth  about the environment. such examples are drawn from some underlying fixed probability distribution d that is unknown to the agent. unlike standard pac learning  the agent does not directly observe such examples  but only masked versions of the examples. we denote by mask d  the induced distribution over these observations.
모the stochastic masking process can be understood in two ways. if attributes correspond to an agent's sensors  masking corresponds to the stochastic failure of these sensors to provide readings. if attributes correspond to properties of the environment  masking corresponds to an agent's inability to simultaneously sense all properties. in either case  masking induces for each example exm a possibly differentbut fixed distribution mask exm  overobservations; the induced distributions remain unknown to the agent  and so does mask d .
모masked attributes have their values hidden  without any connotations. in particular  a masked attribute is not to be understood as  non-deducible  from the rest of the attributes. the goal of an agent is not to deduce that a masked attribute is assigned the value    but rather to deduce the truth-value of the masked attribute according to the underlying masked example. this is a rather non-trivial  and sometimes impossible  task  depending on the masking process being considered.
definition 1  formulas  a formula f xi1 ... xik  over a is a function f : {1}k 뫸 {1} whose arguments are associated with the attributes xi1 ... xik 뫍 a. the value of f xi1 ... xik  given an example exm is defined to be val f xi1 ... xik |exm  exm ik  .
the value of f xi1 ... xik  given an observation obs  denoted by val f xi1 ... xik |obs   is defined to be the common value of the formula given all examples masked by obs  in case such a common value exists  or   otherwise.
모an agent's task of identifying structure in its environment can be made precise as the problem of learning how a certain target attribute in a can be expressed as a formula over other attributes in a  as these are perceivedthrough the agent's sensors.1 to study learnability  one usually assumes that the target attribute is indeed expressible as such a formula  called the target concept  and that the target attribute always assumes a truth-value according to the target concept. the described setting is captured by the following definitions.
definition 1  formula equivalence  formulas  1 and  1 over a are equivalent w.r.t. a probability distribution d if
pr val  1 |exm  = val  1 |exm  | exm 뫹 d  = 1.
definition 1  supported concepts  a concept class over a is a set c of formulas over a. a probability distribution d supports c for an attribute xt if xt is equivalent to some formula c뫍c w.r.t. d; c is the target concept for xt under d.
모supported concept classes essentially encode a known or assumed bias on the probability distribution from which examples are drawn. this imposes constraints on the examples  in what is perhaps the simplest possible mannerthat still facilitates learnability. assuming such a bias  the goal of an agent is then to identify a formula from some hypothesis class  that is consistent with the target attribute with high probability.
definition 1  learning tasks  a learning task over a is a triple  where xt is an attribute in a  c is a concept class over a  and h a hypothesis class of formulas over a.
모we omit writing the set of attributes a over which a learning task is defined  when this does not introduce ambiguities.
definition 1   1 붼 -consistency  a hypothesis h conflicts with a target attribute xt 뫍 a w.r.t. an observation obs if
{val h|obs  val xt |obs } = {1}. a hypothesis h is  1   붼 -consistent with a target attribute xt 뫍 a under a probability distribution d and a masking process mask if
pr {val h|obs  val xt |obs } = {1} | exm 뫹 d;obs 뫹 mask exm   뫞 붼.
모recall that formulas might evaluate to   given an observation. we interpret this value as a  don'tknow  prediction  and such a prediction is always consistent with a target attribute. similarly  a value of   for an attribute is interpretedas a  don't know  sensor reading  and every prediction is consistent with such a sensor reading. that is to say  as long as the prediction coming through a hypothesis and the sensor reading do not directly conflict by producing different {1} values  there is no inconsistency at the observational level.
모it is important to note that the ability to make  don't know  predictions cannot be abused by an agent. every hypothesis is necessarily a formula  which assumes a definite {1} value whenever sufficiently many of its arguments are specified. it only evaluates to   given an observation  when its value on the actual underlying example that was masked to obtain the observation cannot be determined. thus  our framework accounts for an implicit notion of completeness  by imposing a natural restriction on the  don't know  predictions.
definition 1  consistent learnability  an algorithm l is a consistent learner for a learning task  over a if for every probability distribution d supporting c for xt  every masking process mask  every real number 붻 : 1   붻 뫞 1  and every real number 붼 : 1   붼 뫞 1  the algorithm runs in time polynomial in 1/붻  1/붼  |a|  and the size of the target concept for xt underd  and with probability1 붻 returns a hypothesis h 뫍 h that is  1 붼 -consistent with xt under mask d . the concept class c over a is consistently learnable on xt by h if there exists a consistent learner for
1 consistent learners vs. accurate predictors
we have taken the approach that learned hypotheses are expected to be consistent with observations  a natural generalization of the respective requirements of pac learning. such hypotheseswill correctly predict the values of non-maskedattributes that are artificially  for the purposes of analysis   obscured  in an observation  after the observation is drawn. in some sense this is the best one can hope for. if an agent never gets to observe parts of its environment  then it can only form hypotheses that in the best case are consistent with its observations  although they might not agree with the underlying masked examples. this is reminiscent of developing physical theories by finding laws that are consistent with what we observe  without this implying that our current  past  or future physical theories are actually the  correct  ones. hypotheses developed in this manner are  of course  used to make predictions on masked attributes of the world. humans go into great lengths to subsequently obtain the values of such masked attributes  so as to experimentally validate a physical theory.
모in the contextof this work we study whetherdevelopedtheories  or hypotheses  that are consistent with the partial observations of an agent  would actually make accurate predictions on a hypothetical validation experiment. that is  given an observation obs masking an example exm  and an attribute xt that is masked in obs  we wish to examine whether it is possible to predict exm t   and thus accurately  and not simply consistently   fill-in  the missing information in obs.
definition 1   1   붼 -accuracy  a hypothesis h is  1 붼 accurate w.r.t. a target attribute xt 뫍 a under a probability distribution d and a masking process mask if
pr {val h|obs  val xt |exm } = {1} | exm 뫹 d;obs 뫹 mask exm   뫞 붼.
모hypotheses might still evaluate to   given an observation. thus  the accuracy requirement amounts to asking that whenever a hypothesis predicts a {1} value  the value should be in accordance with the actual  rather than the observed  value of the target attribute. identifying the conditions under which one can form accurate hypotheses is essential  in that an agent's actions yield utility based not on what the agent observes  but based on what actually holds in the agent's environment. the more informed the agent is about the actual state of its environment  either through observations or accurate predictions   the better decisions the agent might reach.
모clearly  predictions that are accurate are necessarily consistent  since it holds that obs t  뫍 {exm t   } . the other direction  however  does not hold in general. indeed  predictions on masked target attributes are always consistent  while there is no evident reason why they should also be accurate.
theorem 1  indistinguishability in adversarial settings 
consider a target attribute xt  and a concept class c over
a   {xt}  and let  1  1 뫍 c be such that. there exist probability distributions d1 d1 such that:  i   1  1 are equivalent w.r.t. neither d1 nor d1   ii   1 xt are equivalent w.r.t. d1  and  iii   1 xt are equivalent w.r.t. d1. there also exists a masking process mask such that mask d1  = mask d1   and no attribute in a   {xt} is masked in any drawn observation.
모theorem 1 shows that examples might be masked in such a way so that two non-equivalent concepts are indistinguishable given a set of observations. in fact  it suffices to only mask the target attribute in a few  but adversarially selected  cases for the result to go through. the non-masked attributes are also adversarially selected so that observations will imply a {1} value for all formulas over a   {xt}  excluding the possibility of a  don't know prediction. clearly  an agent has no means of identifying which of the probability distributions d1 d1 examples are drawn from  or equivalently  which of the formulas  1  1 is the target conceptfor xt. thus  it is impossible for the agent to confidently return a hypothesis that is highly accurate w.r.t. xt under mask d1  = mask d1 ; either confidence or accuracy is necessarily compromised.
모we note that the indistinguishability result imposes very mild restrictions on the probability distributions d1 d1  and the concept class c  which implies that an adversarial choice of the masking process mask can  almost always  prove disastrous for an algorithm attempting to make accurate predictions  even if the algorithm is computationally unbounded  the known bias on the probability distribution is as strong as possible  i.e.  the concept class is of cardinality two   and the hypothesis class comprises of all formulas over a   {xt}.
모the established impossibility result suggests that having an infrequently masked target attribute does not suffice to learn accurately; it is important to have an infrequently masked target attribute in the right context. we formalize this next.
definition 1   1   붾 -concealment  a masking process mask is  1   붾 -concealing for a learning task if 붾 is the maximum value such that for every example exm  and every hypothesis h 뫍 h
pr val xt |obs obs 뫹 mask exm ; {val h|obs  val xt |exm } = {1}  뫟 붾.
모roughly speaking  definition 1 asks that whenever a hypothesis is inaccurate  the agent will observe evidence of this fact with some probability. this generalizes the case of pac learning  where an inaccurate hypothesis is always observed to conflict with the target attribute  which is never masked . we note that the masking process mask whose existence is guaranteed by theorem 1 is necessarily 1-concealing for every learning task with a non-trivialconcept class.
theorem 1  the relation of consistency and accuracy  consider a learning task  and a masking process mask that is  1   붾 -concealing for . then   i  for every probability distribution d and hypothesis h 뫍 h  h is  1   붼/붾 -accurate w.r.t. xt under mask d  if h is  1   붼 -consistent with xt under mask d   and  ii  there exists a probability distribution d1 and a hypothesis h1 뫍 h such that h1 is  1   붼/붾 -accurate w.r.t. xt under mask d1  only if h1 is  1   붼 -consistent with xt under mask d1 .
모assuming that our physical world does not adversarially hide information from us  one can interpret the above result as a partial explanation of how it is possible for humans to learn rules  and construct physical theories  that make accurate predictions in situations where nothing is known  despite the fact that learning takes place and is evaluated mostly on observations with inherently missing information.
모similarly to the case of constructing learners for noisy examples  kearns  1   we assume that an algorithm is given a bound on the concealment degree of the masking process and allowed time that depends on this bound during learning.
definition 1  accurate predictability  an algorithm l is an accurate predictor for a learning task over a if for every probability distribution d supporting c for xt  every real number 붾 : 1   붾 뫞 1  every masking process mask that is  1   붾 -concealing for  every real number 붻 : 1   붻 뫞 1  and every real number 붼 : 1   붼 뫞 1  the algorithm runs in time polynomial in 1/붾  1/붻  1/붼  |a|  and the size of the target concept for xt under d  and with probability 1 붻 returns a hypothesis h 뫍 h that is  1 붼 -accurate w.r.t. xt under mask d . the concept class c over a is accurately predictable on xt by h if there exists an accurate predictor for over a.
it is now straightforward to show the following.
theorem 1  consistent learners / accurate predictors  consider a learning task   and a masking process mask that is  1   붾 -concealing for. if algorithm l is a consistent learner for   then algorithm l given 붾 as extra input and allowed running time that grows polynomially in 1/붾  is an accurate predictor for.
모we have thus established not only that consistent learning implies accurate predicting  but that the same algorithm can be used  with the only provision that the algorithm will be allowed more running time to achieve the same precision as determined by 붼. the running time dependence on 붾 can be eliminated if the following are true:  i  the consistent learner is such that it only uses the observations that do not mask the target attribute  and  ii  the induced predictor has access to an oracle that returns observations from distribution mask d   conditioned  however  on the observations not masking the target attribute. the use of such an oracle exemplifies the fact that a predictor does not require more computation to produce an accurate hypothesis  but rather more observations in order to obtain enough  labelled instances  of the target concept.
모a rather intriguing implication of our results is that a consistent learner is  without any knowledge of the concealment degree of the masking process  also able to predict accurately  albeit with a  discounted  accuracy factor. in fact  as condition  ii  of theorem 1 suggests  a consistent learner is  in some sense  as accurate a predictor as possible. given this result  it suffices to restrict our attention to consistent learning for the rest of our study on learning from partial observations.
1 consistently learnable concept classes
the stronger learnability requirements we impose compared to pac learning do not render learnability impossible. it is an easy exercise to show that the typical algorithm for pac learning conjunctions  valiant  1  and its analysis can be applied essentially unmodified on partial observations.
theorem 1 the concept class c of conjunctions of literals over a   {xt} is properly consistently learnable on xt.
1 one-to-many reductions
reductions between learning tasks are often used to establish that certain concept classes are or are not learnable. standard reductions map examples from one learning task to examples of a different learning task. in our case such reductions map  in general  partial observations to partial observations.
definition 1  reductions  the learning task-cnf formulas are defined  since exactly one substitution isover a is reducible to the set over of learning tasks  where r 뫍 n is polynomially-bounded by |a|  if there exists an efficiently computable hypothesis mapping g : h1 뫄...뫄hr 1 뫸 h  and an efficiently computable instance mapping fj : {1  }|a| 뫸 {1  }|aj| for every j 뫍 {1 ... r   1}  such that the following conditions hold:

 i  for every tuple h 뫍 h1 뫄 ... 뫄 hr 1 and every obser-

vation obs 뫍 {1  }|a|  it holds that g h  conflicts with xt w.r.t. obs only if there exists j 뫍 {1 ... r   1}

such that hj = h j  conflicts with xjt w.r.t. fj obs ;
 ii  the probability distribution mask d  from which obs is drawn is such that d supports c for xt only if for every j 뫍 {1 ... r   1} there exists an induced probability distribution maskj dj  from which fj obs  is drawn such that dj supports cj for xjt  and the size of the target conceptfor xjt under dj is polynomially-boundedby and the size of the target concept for xt under d.
모roughly  the two conditions guarantee that  i  learned hypotheses can be meaningfully employed in the original task  and that  ii  observationsin the resulting tasks can be obtained by masking examples drawn from appropriate distributions.
theorem 1  learning through reductions  consider a learning task  that is reducible to the set of learning tasks  over. the concept class c is consistently learnable on xt by h if for every j 뫍 {1 ... r 1}  the concept class cj is consistently learnable on xjt by hj.
모the following special case is of particular interest  in that observations in the resulting learning tasks are complete.
definition 1  total reductions  a reduction is total if for every j 뫍 {1 ... r   1}  fj : {1  }|a| 뫸 {1}|aj|.
1 shallow-monotone formulas
we establish a reduction between certain classes of formulas.
definition 1  shallow-monotonicity  a formula   is shallow-monotone w.r.t. a set m of substitutions if the process of substituting an attribute for every sub-formula 뷍 of   such that  produces a monotone formula; denote by basis  |m  the resulting  monotone formula. a set f of formulas is shallow-monotone w.r.t. a set m of substitutions if every formula   뫍 f is shallow-monotone w.r.t.
m; we define basis {basis  |m  |   뫍 f}.
모we implicitly assume that the substitution process replaces distinct new attributes for distinct sub-formulas of    and that the resulting formula is entirely over these new attributes.
모clearly  every set f of formulas is shallow-monotonew.r.t. some set m of substitutions. the emphasis of definition 1 is on the choice of m  and the corresponding basis of f w.r.t. m. note  for instance  that the class of k-cnf formulas for some constant k 뫍 n has a basis that comprises of conjunctions  and this basis is w.r.t. a set of substitutions that is only polynomially large in the number of attributes over which the required for each of the polynomially many possible clauses .
theorem 1  reduction to monotone classes  the learning task  over a is reducible to the learning task  if there exists a set m of substitutions such that:  i  m is computable in time polynomial in |a|   ii  every sub-formula substituted under m can be evaluated given an observation in time polynomial in basisbasis c |m   andbasis h|m .
모an immediate corollary of theorems 1 and 1 is that the concept class of k-cnf formulas is properly consistently learnable for every constant k 뫍 n.
1 learning monotone formulas
we employ reductions to establish certain learnability results.
theorem 1  total self-reduction  the	learning	task  over a is total reducible to the learning task such that 
h = h  and g 몫  is the identity mapping  if c and h are classes of monotone formulas over a   {xt}  and proof idea: by monotonicity  any formula in {xt} 뫋 c 뫋 h that assumes a {1} value given obs retains its value when masked attributes are mapped to val xt |obs  뫍 {1}. 
모theorem 1 establishes a rather surprising fact for monotone formulas: consistently learning frompartial observations reduces to consistently learning the same concept class from complete observations. equally intriguing is the fact that hypotheses learned  from complete observations  for the resulting task  apply unmodified for making predictions  on partial observations  in the original task. the preceding facts nicely complement theorem 1  which establishes that consistently learned hypotheses are also as accurate as possible. together  theorems 1 and 1 imply that a concrete strategy to predict accurately on partial observations is to simply assign appropriate default truth-values to masked attributes  consistently learn from the resulting complete observations  and then employ the learned hypothesis unchanged to make predictions.
모a technical point worth discussing here is the encoding of the value of the target attribute in certain attributes of the resulting task. observe that an agent learning in the resulting task  although agnostic to this fact  uses the  label  of the example in a much more involved manner than its standard use as a means to test the predictionsof a hypothesis. what makes the result established by the reduction non-trivial  is the fact that the hypothesis does not depend on the target attribute in the context of the original task. in some sense  we allow an agent to use an example's  label  in an involved mannerwhen learning  but require that the hypothesis eventually employed for makingpredictionsdoes not depend on the targetattribute.
모the next corollary follows from theorems 1 and 1  and the pac learnability of certain monotone concept classes.
corollary 1 each concept class c 뫍 {conjunctions  disjunctions  k-cnf  k-dnf  linear thresholds} of literals over a   {xt} is properly consistently learnable on xt.

1
모모assumingis without loss of generality  since sampling can be used to determine w.h.p. whether the target concept is a tautology  and the reduction can be used only when this is not the case.
모the result holds  more generally  for any class of monotone formulas pac learnable by some class of monotone formulas.
1 negative results in consistent learning
consistent learnability is at least as strong as pac learnability  as it requires learning under arbitrary masking processes  including the trivial identity masking process. this observation provides a basic upper bound on consistent learnability.
theorem 1 a concept class c over a {xt} is consistently learnable on the target attribute xt by a hypothesis class h over a   {xt} only if c is pac learnable by h.
모theorem 1 implies that any concept class known not to be pac learnable  possibly under some assumptions   is also not consistently learnable  under the same assumptions .
모we continue to present negative results on the consistent learnability of certain specific concept classes. for the rest of this section we only require that partial observations have at most three masked attributes. this suggests that the property of masking that compromises consistent learnability is not the frequency of the masked attributes  but rather the context in which they appear. recall that theorem 1 establishes that a similar property also compromises accurate predictability.
1 intractability of learning parities
our results so far leave open the possibility that every concept class pac learnable by some hypothesis class is also consistently learnablefrom partial observationsby the same hypothesis class. we dismiss this possibility by showing the concept class of parities  known to be properly pac learnable  helmbold et al.  1   not to be properly consistently learnable from partial observations  unless rp = np.
theorem 1 the concept class c of parities over a   {xt} is not properly consistently learnable on xt  unless rp = np.
모the proof of theorem 1 follows similar proofs from the literature  see  e.g.   pitt and valiant  1  . the reduction is from 1-sat  and it relies on constructing observations that in order to be explained consistently  require the learned hypothesis to dependon any non-empty subset of the masked attributes  without  however  the observations specifying which such subset is to be chosen. it is the case that with complete observations one can still force the learned hypothesis to depend on certain attributes  but the possible dependencies are necessarily restricted in a subtle  yet critical  manner.
1 intractability of learning decision lists
rivest showed that the conceptclass of k-decision lists for a constant k 뫍 n is properly pac learnable  by showing how to identify a hypothesis that agrees with a given set of examples  and employing an occam's razor type argument  blumer et al.  1 . he asked whether the same can be done when instead of examples one considers partial observations. in our notation  he defined agreement1 of a formula   with an observation obs to mean val  |obs  = val xt |obs   where xt is the target attribute  which he assumed to be nonmasked. as posed  the question almost always admits a trivial negative answer: an observationobs generally masks a set of examples such that the value of   varies across examples  implying val  |obs =   and making   disagree with obs.
모we recast the notion of  agreement  to what  we believe  is a more appropriate  and possibly the intended  form: a formula   agrees with an observation obs if   does not conflict with the target attribute xt under obs. this weaker notion of  agreement  only requires that val  |obs  = val xt |obs  when val  |obs  val xt |obs 뫍{1}. we partially answer this new question in the negative  by showing the concept class of monotone term 1-decision lists not to be properly consistently learnable from partial observations  unless rp = np. the negativeanswer carries to rivest's original question  due to his stronger notion of  agreement .
theorem 1 the concept class c of monotone term 1decision lists over a {xt} is not properly consistently learnable on xt  unless rp = np.
모theorem 1 establishes a separation from the framework of learning in the presence of random classification noise  in which the concept class of k-decision lists is known to be properly learnable for every constant k 뫍 n  kearns  1 .
1 related work
valiant  recognizes early on the problem of missing information in observations  and proposes a model in which the target attribute is positive exactly when the target concept is positive in all examples masked by the observation. some subsequent work follows a similarly-flavored approach in making certain assumptions regarding the value of the target attribute. schuurmansand greineremploy a masking process closely related to ours  although they assume that the target attribute is never masked. their goal is also different  in that they focus on learning default concepts from partial observations  and not on the problem of recovering missing information. goldman et al.  consider a model in which the target attribute is positive/negative exactly when the target concept is correspondingly so in all the examples masked by the observation; the target attribute is masked only when the value of the target concept cannot be deduced from the non-masked attributes. thus  they effectively treat  don't know  as a third distinguished value  and the problemreduces to that of learning ternary functions in what is essentially a complete information setting. in contrast  we focus on learning boolean formulas from partial observations without making such assumptions: the target attribute is masked arbitrarily  and when non-masked it simply indicates the value of the target concept for some example masked by the observation.
모decatur and gennaro  assume that attributes are masked independently  a crucial prerequisite for their statistical learning approach to work. we  on the other hand  consider the general setting where attributes are masked arbitrarily  staying thus closer to the spirit of the pac semantics; arbitrary probability distributions model the unknown dependencies between properties of the environment  while arbitrary masking processes model the unknowndependencies on what is observable within the environment.
모multiple instance learning bears some resemblance to our work  see  e.g.   dietterich et al.  1  . in that setting  a partial observation is an arbitrary bag of examples  usually assumed to be drawn independently   and an observation is positive exactly when at least one example is positive. our partial observations can be seen as structured bags of  not independently drawn  examples. the structure restricts the possible combinations of examples  while the bag  labels  are much less informative  since they can assume either truthvalue when bags contain both positive and negativeexamples. our masking process resembles the models of random attribute  shackelford and volper  1 and classification  angluin and laird  1  noise  where the values of attributes are affected  although independently across different examples  before being observed by an agent. our model is perhaps closer to that of malicious noise  valiant  1   in that no assumption is made as to how attributes are affected across examples. malicious noise is known to render learnability almost impossible  kearns and li  1   while our more benign model  where affected attributes are explicitly made known to an agent  does not severely impair learnability.
1 conclusions and open problems
we have presented an autodidactic learning framework as a means to recover missing information in data. our framework builds on two natural generalizations of valiant's pac model  valiant  1 to address the problemof learning from partial observations: learning consistently and predicting accurately. producing accurate hypotheses was shown to be impossible under certain masking processes  even for computationally unbounded learners. on the positive side  producing consistent hypotheses was shown to be a concrete strategy for predicting as accurately as permitted by the masking process.
모within our framework we have presented a reduction technique  through which a number of natural boolean concept classes were shown to be consistently learnable. on the other hand  we have shown that properly consistently learning certain other concept classes is intractable  establishing  thus  a separation from the models of learning from complete or noisy observations. it remains open whether the intractability results are only representation-specific  and whether consistently learning from partial observations is  strictly  harder than learning under the random classification noise model.
모a more general question concerns the consistent learnability of concept classes that are not shallow-monotone w.r.t. some efficiently computable set of substitutions. it is unclear whether such learnability results can be obtained through total reductions  which work for monotone concept classes.
acknowledgments
the author is grateful to leslie valiant for his advice  and for valuable suggestions and remarks on this research.

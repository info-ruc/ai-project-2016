 
causality is typically treated an all-or-nothing concept; either a is a cause of b or it is not. we extend the definition of causality introduced by halpern and pearl 1a to take into account the degree of responsibility of a for b. for example  if someone wins an election 1  then each person who votes for him is less responsible for the victory than if he had won 1. we then define a notion of degree of blame  which takes into account an agent's cpistemic state. roughly speaking  the degree of blame of a for d is the expected degree of responsibility of a for b  taken over the epistemic state of an agent. 
1 introduction 
there have been many attempts to define causality going back to hume 1  and continuing to the present  see  for example   collins et al  1; pearl  1  for some recent work . while many definitions of causality have been proposed  all of them treat causality is treated as an all-or-nothing concept. that is  a is either a cause of b or it is not. as a consequence  thinking only in terms of causality docs not at times allow us to make distinctions that we may want to make. for example  suppose that mr. b wins an election against mr. g by a vote of 1. each of the people who voted for mr. b is a cause of him winning. however  it seems that their degree of responsibility should not be as great as in the case when mr. b wins 1. 
모in this paper  we present a definition of responsibility that takes this distinction into account. the definition is an extension of a definition of causality introduced by halpern and pearl 1a. like many other definitions of causality going back to hume 1  this definition is based on counterfactual dependence. roughly speaking  a is a cause of b if  had a not happened  this is the counterfactual condition  since a did in fact happen  then b would not have happened. as is well known  this naive definition does not capture all the subtleties involved with causality. in the case of the 1 vote  it 
   * supported in part by nsf under grant ctc-1 and by the dod multidisciplinary university research initiative  muri  program administered by onr under grant n1-1. 
joseph y. halpern* department of computer science 
cornell university ithaca  ny 1  u.s.a. 
email: halpern cs.cornell.edu 
is clear that  according to this definition  each of the voters for mr. b is a cause of him winning  since if they had voted against mr. b  he would have lost. on the other hand  in the case of the 1 vote  there are no causes according to the naive counterfactual definition. a change of one vote does not makes no difference. indeed  in this case  we do say in natural language that the cause is somewhat  diffuse . 
모while in this case the standard counterfactual definition may not seem quite so problematic  the following example  taken from  hall  1   shows that things can be even more subtle. suppose that suzy and billy both pick up rocks and throw them at a bottle. suzy's rock gets there first  shattering the bottle. since both throws are perfectly accurate  billy's would have shattered the bottle had suzy not thrown. thus  according to the naive counterfactual definition  suzy's throw is not a cause of the bottle shattering. this certainly seems counter to intuition. 
both problems are dealt with the same way in  halpern and 
pearl  1a . roughly speaking  the idea is that a is a cause of b if b counterfactually depends on c under some contingency. for example  voter 1 is a cause of mr. b winning even if the vote is 1 because  under the contingency that 1 of the other voters had voted for mr. g instead  voter 1 's vote would have become critical; if he had then changed his vote  mr. b would not have won. similarly  suzy's throw is the cause of the bottle shattering because the bottle shattering counterfactually depends on suzy's throw  under the contingency that billy doesn't throw.  there are further subtleties in the definition that guarantee that  if things are modeled appropriately  billy's throw is not a cause. these are discussed in section 1.  
모it is precisely this consideration of contingencies that lets us define degree of responsibility. we take the degree of responsibility of a for b to be 1/ n + 1   where n is the minimal number of changes that have to be made to obtain a contingency where b counterfactually depends on a.  if a is not a cause of b  then the degree of responsibility is 1.  in 
particular  this means that in the case of the 1 vote  the degree of responsibility of any voter for the victory is 1  since 1 changes have to be made before a vote is critical. if the vote were 1  the degree of responsibility of any voter would be 1. on the other hand  if the vote is 1  then the degree of responsibility of each voter for mr. b for mr. b's victory is 1; each voter is critical. as we would expect  those 
voters who voted for mr. g have degree of responsibility 1 for mr. b's victory  since they are not causes of the victory. finally  in the case of suzy and billy  even though suzy is the only cause of the bottle shattering  suzy's degree of responsibility is 1  while billy's is 1. thus  the degree of responsibility measures to some extent whether or not there are other potential causes. 
모when determining responsibility  it is assumed that everything relevant about the facts of the world and how the world works  which we characterize in terms of what are called structural equations  is known. for example  when saying that voter 1 has degree of responsibility 1 for mr. b's win when the vote is 1  we assume that the vote and the procedure for determining a winner  majority wins  is known. there is no uncertainty about this. just as with causality  there is no difficulty in talking about the probability that someone has a certain degree of responsibility by putting a probability distribution on the way the world could be and how it works. but this misses out on important component of determining what we call here blame: the epistemic state. consider a doctor who treats a patient with a particular drug resulting in the patient's death. the doctor's treatment is a cause of the patient's death; indeed  the doctor may well bear degree of remerman  1  . our definitions  by design  do not take into account intentions or possible alternative actions  both of which seem necessary in dealing with moral issues. for example  there is no question that truman was in part responsible and to blame for the deaths resulting from dropping the atom bombs on hiroshima and nagasaki. however  to decide whether this is a morally reprehensible act  it is also necessary to consider the alternative actions he could have performed  and their possible outcomes. while our definitions do not directly address these moral issues  we believe that they may be helpful in elucidating them. 
모the rest of this paper is organized as follows. in section 1 we review the basic definitions of causal models based on structural equations  which are the basis for our definitions of responsibility and blame. in section 1  we review the definition of causality from  halpern and pearl  1a   and show how it can be modified to give a definition of responsibility. in section 1  we give our definition of blame. in section 1  we discuss the complexity of computing responsibility and blame. proofs of the theorems can be found in the full paper  available at http://www.cs.cornell.edu/home/halpern/papers/blame.ps. 

sponsibility 1 for the death. however  if the doctor had no idea that the treatment had adverse side effects for people with high blood pressure  he should perhaps not be held to blame for the death. actually  in legal arguments  it may not be so relevant what the doctor actually did or did not know  but what he should have known. thus  rather than considering the doctor's actual epistemic state  it may be more important to consider what his epistemic state should have been. but  in any case  if we are trying to determine whether the doctor is to blame for the patient's death  we must take into account the doctor's epistemic state. 
모we present a definition of blame that considers whether agent a performing action b is to blame for an outcome the definition is relative to an epistemic state for a  which is taken  roughly speaking  to be a set of situations before action b is performed  together with a probability on them. the degree of blame is then essentially the expected degree of responsibility of action b for   except that we ignore situations where  was already true or b was already performed . to understand the difference between responsibility and blame  suppose that there is a firing squad consisting of ten excellent marksmen. only one of them has live bullets in his rifle; the rest have blanks. the marksmen do not know which of them has the live bullets. the marksmen shoot at the prisoner and he dies. the only marksman that is the cause of the prisoner's death is the one with the live bullets. that marksman has degree of responsibility 1 for the death; all the rest have degree of responsibility 1. however  each of the marksmen has degree of blame 1.1 
모while we believe that our definitions of responsibility and blame are reasonable  they certainly do not capture all the connotations of these words as used in the literature. in the philosophy literature  papers on responsibility typically are concerned with moral responsibility  see  for example   zim-
1  we thank tim williamson for this example. 





1 blame 
the definitions of both causality and responsibility assume that the context and the structural equations are given; there is no uncertainty. we are often interested in assigning a degree of blame to an action. this assignment depends on the epistemic state of the agent before the action was performed. intuitively  if the agent had no reason to believe that his action would result in a certain outcome  then he is not to blame for the outcome  even if in fact his action caused the outcome . 
모to deal with the fact that we are considering two points in time-before the action was performed and after-we add superscripts to variables. we use a superscript 1 to denote the value of the random variable before the action was performed and the superscript 1 to denote the value of the random variable after. thus  y1 = 1 denotes that the random variable y has value 1 before the action is performed  while y1 = 1 denotes that it had value 1 afterwards. if 뷍 is a boolean combination of  unsuperscripted  random variables  we use 뷍뫢 and 뷍1 to denote the value of 뷍 before and after the action is performed  respectively. 
모there arc two significant sources of uncertainty for an agent who is contemplating performing an action: 
  what the true situation is; for example  a doctor may be uncertain about whether a patient has high blood pressure. 
  how the world works; for example  a doctor may be un-certain about the side effects of a given medication. 
모in our framework  the  true situation  is determined by the context and  how the world works  is determined by the structural equations. thus  we model an agent's uncertainty by a pair  ac  pr   where ac is a set of pairs of the form  a/  a   where m is a causal model and u is a context  and pr is a probability distribution over ac. following  hlalpern and pearl  1b   who used such epistemic states in the definition of explanation  we call a pair  a/  u  a situation. 
모roughly speaking  the degree of blame that setting x to x has for 뷍 is the expected degree of responsibility of x = x for 뷍  taken over the situations   where 
 our actual definition of blame is just 
this definition  except that  when computing the expectation  we do not count situations in ac where 뷍 was already true or x was already x. to understand why  suppose that we are trying to compute the degree of blame of suzy's throwing the rock for the bottle shattering. assume that we are interested in a period in a bottle in the period between time 1 and time 1  and the bottle was actually shattered at time 1. we certainly don't want to say that suzy's throw was to blame if suzy didn't throw between time 1 and time 1 or if the bottle was already shattered at time 1. so suppose that suzy does in fact throw between time 1 and time 1  and at time 1  she considers the following four situations to be equally likely: 
   m1 u1   where the bottle was already shattered before suzy's throw; 
   m1 u1   where the bottle was whole before suzy's throw  and suzy and billy both hit the bottle simultaneously  as described in the model in figure 1 ; 
   m1 u1   where the bottle was whole before suzy's throw  and suzy's throw hit before billy's throw  as described in the model in figure 1 ; and 
   m1 u1   where the bottle was whole before suzy's throw  and billy did not throw. 
to compute the degree of blame assigned to suzy's throwing the rock for the bottle shattering  we ignore  a/  u1   because the bottle is already shattered in  m u1  before suzy's action. the degree of responsibility of suzy's throw for the bottle shattering is 1 in  m1 u1  and  m1 u1   and is 1 in  m1/1 . it is easy to see that the degree of blame is 

example 1 consider again the example of the firing squad with ten excellent marksmen. suppose that marksman 1 knows that exactly one marksman has a live bullet in his rifle. thus  he considers 1 situations possible  depending on who has the bullet. let pl be his prior probability that marksman i has the live bullet. then the degree of blame of his shot for the death is pi. the degree of responsibility is cither 1 or 1  depending on whether or not he actually had the live bullet. thus  it is possible for the degree of responsibility to be 1 and the degree of blame to be 1  if he ascribes probability 1 to his having the live bullet  when in fact he does   and it is possible for the degree of responsibility to be 1 and the degree of blame to be 1  if he mistakenly ascribes probability 1 to his having the bullet when he in fact does not . 
example 1 the previous example suggests that both degree of blame and degree of responsibility may be relevant in a legal setting. another issue that is relevant in legal settings is whether to consider actual epistemic state or to consider what the epistemic state should have been. the former is relevant when considering intent. to see the relevance of the latter  consider a patient who dies as a result of being treated by a doctor with a particular drug. assume that the patient died due to the drug's adverse side effects on people with high blood pressure and  for simplicity  that this was the only cause of death. suppose that the doctor was not aware of the drug's adverse side effects.  formally  this means that he docs not consider possible a situation with a causal model where taking the drug causes death.  then  relative to the doctor's actual epistemic state  the doctor's degree of blame will be 1. however  a lawyer might argue in court that the doctor should have known that treatment had adverse side effects for patients with high blood pressure  because this is well documented in the literature  and thus should have checked the patient's blood pressure. if the doctor had performed this test  he would of course have known that the patient had high blood pressure. with respect to the resulting epistemic state  the doctor's degree of blame for the death is quite high. of course  the lawyer's job is to convince the court that the latter epistemic state is the appropriate one to consider when assigning degree of blame. 

1 	the complexity of computing responsibility and blame 
in this section we present complexity results for computing the degree of responsibility and blame for general recursive models. 
1 	complexity of responsibility 
complexity results for computing causality were presented by eiter and lukasiewicz 1a; 1b. they showed that the problem of detecting whether x - x is an actual cause of 뷍 is -complete for general recursive models and npcomplete for binary models  liter and lukasiewicz  1b .  recall that  is the second level of the polynomial hierarchy and that binary models are ones where all random variables can take on exactly two values.  there is a similar gap between the complexity of computing the degree of responsibility and blame in general models and in binary models. 
모for a complexity class a   consists of all functions that can be computed by a polynomial-time turing machine with an oracle for a problem in a  which on input x asks a total of  queries  cf.  papadimitriou  1  . we show that computing the degree of responsibility of x = x for 뷍 in arbitrary models is -complete. in  chockler et al.  1   we show that computing the degree of responsibility in binary models is 
	since there are no known natural 	-complete 
problems  the first step in showing that computing the degree of responsibility is -complete is to define an 
-complete problem. we start by defining one that we call maxqsat1. 
모recall that a quantified boolean formula  stock meyer  1   qbf  has the form . .뷍.   where x1  x1 ... are propositional variables and 뷍 is a propositional formula. a qbf is closed if it has no free propositional variables. 
tqbf consists of the closed qbf formulas that are true. for example  
meyer 1  the following problem qsat is 
that is  qsat1 is the language of all true qbfs of the form where 뷍 is a boolean formula in 1-cnf. 
모a witness f for a true closed is an assignment / to x under which we define 
maxqsat1 as the problem of computing the maximal number of variables in x that can be assigned 1 in a witness 
formally  given  n e to be k if there exists a witness for that 
assigns exactly k of the variables in x the value 1  and every assigns at most k'   k variables in a' the 
value 1. 
theorem 1 
모the proof of theorem 1 shows explicitly how to reduce the computation of any  problem to maxqsat1. 
given a polynomial-time turing machine m with oracle in that on an input of size 1/. makes 1 log u  oracles queries  we construct a formula is a boolean formula in 1-cnf such that given we can compute the output of m in polynomial time. essentially  the formula 뷍 describes the output of m for all possible sequences of answers for oracle queries and gives the correct sequence of answers. since the total number of oracle queries is   the number of all possible sequences of answers is polynomial in the size of the input  and thus the size of  is also polynomial in the size of the input. the construction is somewhat complicated; see the full paper for details. 
   similarly 	to 	maxqsat1  	we 	define 	to be the minimum number of 
variables in x that can be assigned 1 in a witness for  if there is such a witness  and  otherwise. it is easy to see that minqsat1 has the same complexity as maxqsat1  since 

where  1  is obtained from 뷍 by replacing each propositional variable with its negation. 
모using a reduction from minqsat1  we can prove the desired complexity result. 
theorem 1 the degree of responsibility is complete for general recursive causal models. 
proof: due to lack of space  we present the proof here in a somewhat abridged form. membership in  can be proved using an argument similar to the one used in  chockler et al  1  to prove membership of the degree of responsibility for binary causal models in 
모the proof that computing the degree of responsibility is -hard essentially follows from an argument in  eiter and lukasiewicz  1a  showing that qsat1 can be reduced to the problem of detecting causality. in fact  their argument actually provides a reduction from minqsat1 to the degree of responsibility. given a qbf of the form  뷍 eiter and lukasiewicz construct a causal model m whose endogenous variables include x'  y  and a fresh variable x*. they consider a context u in which all variables in x' get the value 1. they show that  is true iff x'* = 1 is a cause of 뷍 in  m  u . if x* = 1 is indeed a cause  then the set w in ac1 must be a subset of x. that is  if there is a partition  w z  and a setting  x'.w'  satisfying ac1 showing that x* = 1 is a cause of 뷍  then w must be a subset of x. moreover  the variables in w that change value from 1 to 1 in w' are precisely those such that an as-


1 	complexity of blame 
given an epistemic state  k  pr   where k consists of n possible situations  each with at most n random variables  the straightforward way to compute is by 
computing 	for each 
such that   	.     	and then computing the 
expected degree of responsibility with respect to these situations  as in definition 1. recall that the degree of responsibility in each model is determined by using a binary search thus uses  queries in each model in k. since the number of models is n  we get a polynomial time algorithm with n log n oracle queries. the type of oracle depends on whether the models are binary or general. for binary models it is enough to have an np oracle  whereas for general models we need a  we do not have a matching lower bound but  as we show in the full paper  any binary-search style algorithm for computing the degree of blame requires  oracle queries  for n - o n . 
acknowledgment 	we thank michael ben-or and orna 
kupferman for helpful discussions. 

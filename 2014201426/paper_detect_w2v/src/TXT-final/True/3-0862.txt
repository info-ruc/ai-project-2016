
this paper explores the topic of sensitivity analysis in markov networks  by tackling questions similar to those arising in the context of bayesian networks: the tuning of parameters to satisfy query constraints  and the bounding of query changes when perturbing network parameters. even though the distribution induced by a markov network corresponds to ratios of multi-linear functions  whereas the distribution induced by a bayesian network corresponds to multi-linear functions  the results we obtain for markov networks are as effective computationally as those obtained for bayesian networks. this similarity is due to the fact that conditional probabilities have the same functional form in both bayesian and markov networks  which turns out to be the more influential factor. the major difference we found  however  is in how changes in parameter values should be quantified  as such parameters are interpreted differently in bayesian networks and markov networks.
1 introduction
in the domain of uncertainty reasoning  graphical models are used to embed and represent probabilistic dependencies between random variables. there are two major types of graphical models: bayesian networks  pearl  1; jensen  1  and markov networks  pearl  1 . in both models  there are two components  a qualitative part and a quantitative part. in the qualitative part  a graph is used to represent the interactions between variables  such that variables with direct interactions are connected by edges  and information of independence relationships between variables can be inferred from the network structure. in the quantitative part  a set of parameters are specified to quantify the strengths of influences between related variables. the joint probability distribution can then be induced from the two components.
¡¡bayesian networks and markov networks differ in both the qualitative and quantitative parts of the models. for the qualitative part  directed edges are used in a bayesian network to represent influences from one variable to another  and no cycles are allowed in the graph  while undirected edges are used in a markov network to represent symmetrical probabilistic dependencies between variables.
¡¡for the quantitative part  the parameters in a bayesian network are specified in conditional probability tables  cpts  of the variables  where each cpt consists of the conditional probability distributions of a variable given instantiations of its parents  which are the variables that directly influence this variable. because these parameters are conditional probabilities  they are more intuitive  but have to obey certain properties. for example  the probabilities in each conditional distribution must be normalized and sum to 1. on the other hand  the parameters in a markov network are given in potentials  defined over instantiations of cliques  which are maximal sets of variables such that every pair of variables in a clique are connected by an edge. these parameters do not need to be normalized and can be changed more freely.
¡¡the topic of sensitivity analysis is concerned with understanding and characterizing the relationship between the local parameters quantifying a network and the global queries computed based on the network. sensitivity analysis has been investigated quite comprehensively in bayesian networks  laskey  1; castillo et al.  1; jensen  1; kj rulff and van der gaag  1; chan and darwiche  1; 1; 1 . earlier work on the subject has observed that the distribution induced by a bayesian network corresponds to multi-linear functions  providing effective computational methods for computing  pr e / ¦Èx|u: the partial derivative of a joint probability with respect to a network parameter. these earlier results were recently pursued further  providing effective methods for solving the following problems:
  what is the necessary parameter change we need to apply such that a given query constraint is satisfied  for example  we may want some query value pr z | e  to be at least p by changing network parameters. efficient solutions were given to this problem for computing minimum changes for single parameters  chan and darwiche  1   and multiple parameters in a single cpt  chan and darwiche  1 .
  what is the bound on the change in some query value if we apply an arbitrary parameter change  here  we are interested in finding a general bound for any query and any parameter of any network. it has been shown that the log-odds change in any conditional query in a bayesian network is bounded by the log-odds change in any single parameter  chan and darwiche  1 .
  what is the bound on the difference between some query value induced by two networks that have the same structure but different parameter values  the solution to this problem is based on a newly proposed distance measure  chan and darwiche  1   which allows one to bound the difference between the query values under two distributions. based on this distance measure  and given two bayesian networks that differ by only a single cpt  the global distance measure between the distributions induced by the networks can be computed from the local distance measure between the cpts  thereby allowing one to provide a bound on the difference between the query values. moreover  if we are given multiple cpts that do not intersect with each other  the global distance measure can still be computed as the sum of the local distance measures between the individual cpts.
¡¡in this paper  we address these key questions of sensitivity analysis but with respect to markov networks. the main question of interest is the extent to which these promising results hold in markov networks as well. there is indeed a key difference between bayesian networks and markov networks which appears to suggest a lack of parallels in this case: whereas the joint distribution induced by a bayesian network corresponds to multi-linear functions  the joint distribution induced by a markov network corresponds to ratios of multi-linear functions. as it turns out  however  the conditional probability function has the same functional form in both bayesian and markov networks  as ratios of multi-linear functions. this similarity turns out to be the key factor here  allowing us to derive similarly effective results for markov networks. this is greatly beneficial because we can answer the previous three questions in the context of markov networks as well  with the same computational complexity. for example  we can go through each parameter in a markov network  compute the minimum single parameter changes necessary to enforce a query constraint  and find the one that perturbs the network the least. alternatively  we can change all parameters in a single clique table  and find the change that minimizes network perturbation. afterwards  we can compute a bound on any query change using the distance measure incurred by the parameter change.
¡¡our results  however  point to a main semantical difference between bayesian networks and markov networks  relating to how one should quantify and measure parameter changes. that is  how should one quantify a parameter change from .1 to .1  in a bayesian network  parameters are interpreted as conditional probabilities  and the measure which quantifies the change is the relative odds change in the parameter value. this means query values are much more sensitive to changes in extreme probability values  whether close to 1 or 1. on the other hand  in a markov network  parameters are interpreted as compatibility ratios  and the measure which quantifies the change is the relative change in the parameter value. this difference stems from how the parameters in the two models are interpreted and will be explained in more depth later.
this paper is structured as follows. section 1 is dedicated
	 	a1 

 
figure 1: a sample markov network structure in terms of an undirected graph g.
to the definition and parameterization of markov networks. section 1 presents a procedure which tunes parameters in a markov network in order to satisfy a query constraint. section 1 introduces a distance measure that can be used to bound query change between distributions induced by two markov networks. section 1 concludes the paper.
1 markov networks
a markov network m =  g ¦¨  consists of two parts: the network structure in terms of an undirected graph g  and the parameterization ¦¨. each node in the undirected graph g represents a random variable  and two variables are connected by an edge if there exists a direct interaction between them. the absence of an edge between two variables means any potential interaction between them is indirect and conditional upon other variables.
¡¡as an example  consider four individuals  a1 a1 b1 b1  and we wish to represent the possible transmission of a contagious disease among them. a network structure which consists of these variables is shown in figure 1. each pair of variables {ai bj} is connected by an edge  meaning these pairs of individuals are in direct contact of each other. however  a1 and a1 are not connected with an edge  meaning they do not interact directly with each other  although diseases can still be transmitted between them indirectly through b1 or b1.
¡¡to quantify the edges in a markov network  we first define cliques in the network structure. a clique c is a maximal set of variables where each pair of variables in the set c is connected by an edge. in the network structure in figure 1  there are four cliques: {a1 b1}  {a1 b1}  {a1 b1}  {a1 b1}.
¡¡for each clique c  we define a table ¦¨c that assigns a nonnegative number ¦Èc to each instantiation c of variables c  which measures the relative degree of compatibility associated with each instantiation c. the numbers given indicate the level of compatibility between the values of the variables in the clique  where direct interactions exist between every pair of variables. for example  in our example network  we define the same clique table ¦¨ai bj shown in table 1 for each clique {ai bj}. for example  it can be viewed that both ai and bj not having the disease is four times more compatible than both ai and bj having the disease  since ¦Èa¡¥i b¡¥j = 1¦Èai bj.1
ai bj¦¨ai bjai	bj1ai	b¡¥j1a¡¥i	bj1a¡¥i	b¡¥j1table 1: the clique table of {ai bj} of the markov network whose structure is shown in figure 1.
1 joint and conditional probabilities induced by markov networks
we now proceed to find the distribution induced by a markov network. if x is the set of all variables in the markov network m =  g ¦¨   the joint potential ¦× over x induced by m is
defined as:	def y
	¦× x  =	¦Èc.	 1 
c¡«x
that is  ¦× x  is the product of parameters ¦Èc in each clique c  such that instantiation c is consistent with x. the joint distribution prm induced by markov network m is then defined as its normalized joint potential:
 
p
where k = 1/ x ¦× x  is the normalizing constant. from this equation  we can easily verify that the specific parameter values in a clique are not important  but their ratios are. this is a major departure from bayesian networks  where specific parameter values in cpts are important.
¡¡given the network structure in figure 1 with the parameterization in table 1  we can compute the joint probability of any full instantiation of variables induced by our example network. for example  the joint probability of a1 a¡¥1 b1 b¡¥1 is equal to k¦Èa1 b1¦Èa1 b¡¥1¦Èa¡¥1 b1¦Èa¡¥1 b¡¥1 = k ¡¤1¡¤1¡¤1¡¤1  where k is the normalizing constant.
¡¡for an instantiation e of variables e   x  we can express the joint probability prm e  as:
	x	x
	prm e  =	prm x  =	k¦× x  = k¦Õ e  
	x¡«e	x¡«e
where the function ¦Õ e  is defined as the sum of the potentials of x which are consistent with e:
¡¡¡¡x	x y def
	¦Õ e  =	¦× x  =	¦Èc 	 1 
	x¡«e	x¡«ec¡«x
and any conditional probability prm z | e  as:
	e 	¦Õ e 
from equation 1  we can see that both ¦Õ z e  and ¦Õ e  are sums of products of the network parameters. therefore  the conditional probability prm z | e  induced by a markov network can be expressed as the ratio of two multi-linear func-
tions of the network parameters.
¡¡as a comparison  the parameterization ¦¨ of a directed acyclic graph n for a bayesian network consists of a set of cpts  one for each variable x  which are conditional probabilities in the form of ¦Èx|u = pr x | u   where u are the parents of x. the joint distribution prb induced by bayesian network b =  n ¦¨  is:
prb x  def=¦Èx|u.
x x
the joint probability prb e  can be expressed as:
x y
	prb e  =	¦Èx|u 
x¡«e x u¡«x
and any conditional probability prb z | e  as:
	p	q
	prb z | e  = prprbb z  ee   = pxx¡«¡«z eeqx x uu¡«¡«xx¦È¦Èxx|u|u.	 1 
we can easily see the similarities between the expressions of prm z | e  and prb z | e  in equations 1 and 1 lie in the fact that both can be expressed as ratios of two multilinear functions of the network parameters. this is different for joint probabilties  where in a bayesian network they are multi-linear functions of the network parameters  while in a markov network they are ratios of multi-linear functions of the network parameters  since the normalizing constant canp be expressed as k = 1/ x ¦× x  = 1/¦Õ true . this similarity in terms of conditional probabilities will be the basis of our results in the following section.
1 tuning of parameters in markov networks
we now answer the following question in the context of markov networks: what is the necessary change we can apply to certain parameter s  such that a query constraint is satisfied  for example  if pr is the probability distribution induced by a markov network  we may want to satisfy the query constraint pr z | e  ¡Ý k  for some k ¡Ê  1 .1
¡¡notice that given all the parameters ¦Èc in the clique c  ¦Õ e  can be expressed as a multi-linear function of these parameters  as shown in equation 1. since ¦Õ e  is linear in each parameter ¦Èc  and no two parameters in the same clique are multiplied together  if we apply a change of  ¦Èc to each parameter ¦Èc in the clique c  the change in ¦Õ e  is:
x  ¦Õ e 
 ¦Õ e  =	 ¦Èc. c	 ¦Èc
to ensure the query constraint pr z | e  ¡Ý k  from equation 1  this is equivalent to ensuring the inequality ¦Õ z e  ¡Ý k ¡¤ ¦Õ e . if the current ¦Õ values of z e and e are   z e  and   e  respectively  this inequality becomes:
¡¡¡¡¡¡¡¡  z e  +  ¦Õ z e  ¡Ý k   e  +  ¦Õ e    or:
 .
rearranging the terms  we get the following theorem and corollary.
theorem 1 to ensure the probability distribution pr induced by a markov network satisfies the query constraint pr z | e  ¡Ý k  we must change each parameter ¦Èc in the clique c by  ¦Èc such that:
x
	¦Á ¦Èc  ¦Èc ¡Ý     z e    k ¡¤   e   	 1 
c
where   z e  and   e  are the current ¦Õ values of z e and e respectively  and:
	 ¦Õ z e 	 ¦Õ e 
	¦Á ¦Èc  =	  k	.	 1 
	 ¦Èc	 ¦Èc
corollary 1 if instead of changing all parameters in the clique c  we are only allowed to change a single parameter ¦Èc by  ¦Èc  the solution of theorem 1 becomes:
¡¡¡¡¡¡¡¡¡¡¦Á ¦Èc  ¦Èc ¡Ý     z e    k ¡¤   e   	 1  which returns a solution interval of possible  ¦Èc.
¡¡therefore  to solve for  ¦Èc in inequality 1 for all parameters in the markov network  we need to compute the original values   z e  and   e   which should already be known when computing the original probability of z | e  and the partial derivatives  ¦Õ z e / ¦Èc and  ¦Õ e / ¦Èc  to find ¦Á ¦Èc  in equation 1 for all parameters ¦Èc. to do this  we can use a procedure in time complexity o nexp w   where n is the number of variables and w is the treewidth of the markov network  similar to the one proposed to compute partial derivatives in a bayesian network  darwiche  1 . this can greatly help users debug their network when they are faced with query results that do not match their expectations.
¡¡we now use our example network to illustrate this procedure. the probability distribution pr induced by the current parameterization gives us the conditional query value pr  ¡¥a1 | a1  = .1. assume that we would like to change a single parameter in the clique {a1 b1} to ensure the constraint pr  ¡¥a1 | a1  ¡Ý .1. we need to compute the ¦Á values for each parameter in the clique using equation 1  and then use inequality 1 to solve for the minimal  ¦Èc. the solutions
are: ¦Èa1 b1¡Ü 1; ¦Èa1 b¡¥1¡Ü 1; ¦Èa¡¥1 b1¡Ý1; ¦Èa¡¥1 b¡¥1¡Ý1.however  notice that since the parameter values have to be non-negative  the solution for  ¦Èa1 b1 is impossible to achieve. therefore  no possible single parameter change on ¦Èa1 b1 is possible to ensure our query constraint. however  we can decrease the parameter ¦Èa1 b¡¥1 from 1 to .1 to ensure our query constraint.
¡¡if we are interested in changing all the parameters in the clique {a1 b1} to satisfy our query constraint  we need to find a solution that satisfies inequality 1. as a consequence  we are now faced with multiple solutions of changing the parameters  and we want to commit to one which disturbs the network the least. we will discuss this in the next section using a distance measure which measures network perturbation.
1 bounding belief change between markov networks using a distance measure
we now answer the following question in the context of markov networks: what is the bound on the difference between some query value induced by two networks that have the same structure but different parameter values  we will answer it by using a previously proposed distance measure.
¡¡let pr and pr1 be two probability distributions over the same set of variables x. we use a distance measure d pr pr1  defined as follows  chan and darwiche  1 :
d pr pr1  def=	lnmax pr1 x    lnmin pr1 x   x pr x 	x pr x 
where we will define 1 def= 1 and ¡Þ/¡Þ def= 1
¡¡the significance of this distance measure is that if the distance measure is d pr pr1  = d  the change in the probability of any conditional query z | e is bounded by:
 
where o1 z | e  and o z | e  are the odds of z | e under distributions pr1 and pr respectively.1 given p = pr1 z | e   this result can also be expressed in terms of probabilities:

¡¡the advantage of this distance measure is that it can be computed using local information for bayesian networks. given distributions prb and prb1 induced by two bayesian networks b and b1 that differ by only the cpt of a single variable x  if pr u    1 for every u of parents u  the distance measure between prb and prb1 can be computed as:

	x u ¦Èx|u	x u ¦Èx|u
this is useful because we can compute the bound on any query change using inequality 1 by computing the local distance between the cpts ¦¨x|u and . for example  if x is binary  and we only change a single parameter ¦Èx|u while applying a complementary change on ¦Èx¡¥|u  the bound on the change in query z | e is given by:
	 	 1 
where are the odds of parametersu and ¦Èx|u respectively. intuitively this means the relative change in the query odds is bounded by the relative change in the parameter odds.
¡¡we can get a similar result for markov networks  where the distance measure between distributions induced by two markov networks that differ by only a single clique table can be computed by the distance measure between the tables.
theorem 1 given distributions prm and prm1 induced by two markov networks m and m1 which differ by only the parameters in a single clique c  such that the clique tables  respectively  the distance measure between prm and prm1 is given by:
	¦Èc	c
if  ¦× x / ¦Èc 1= 1 for all c ¡« x.1
proof given instantiation c such that c ¡« x  the joint potential ¦× of x is linear in the parameter ¦Èc  and the ratio of ¦×1 x  and ¦× x  induced by m1 and m respectively is:
	¦×1 x 	¦Èc1  
 =
	¦× x 	¦Èc
if  ¦× x / ¦Èc = 1	. we have:
	prmm1  xx  	kk¦×1¦×1  xx  	kk¦È1¦Ècc1 .
	=	=
pr
note that since the parameters have changed  the normalizing constants k and k1 for networks m and m1 respectively are different. therefore  the distance measure between prm and prm1 is given by:
	m prm1 	=	lnmaxx prprmm1  xx     lnminx prprmm1  xx  
d pr
k1¦Èc1   lnmin k1¦Èc1
	=	lnmax
	c k¦Èc	c k¦Èc
	=	lnmax   lnmin
	c ¦Èc	c ¦Èc
 
if  ¦× x / ¦Èc 1= 1 for all c ¡« x.
¡¡therefore  the global distance measure between the distributions induced is equal to the local distance measure between the individual clique tables. this is useful for computing the bound on query change after changing the parameters in a clique table. for example  what is the bound on the change in some query value if we apply an arbitrary change on the single parameter ¦Èc  the distance measure in this case is:
 

figure 1: the amount of parameter change ¦Ä that would guarantee the query pr z | e  = .1 to stay within the interval  .1 .1   as a function of the current bayesian network parameter value p.
and the change in query z | e is bounded by:
¦Èc1 oom1 z | e  ¦Èc1 .  1  ¦Èc ¡Ü m z | e  ¡Ü ¦Èc
this means for markov networks  the relative change in query odds is bounded by the relative change in the parameter itself  not the relative change in the parameter odds as for bayesian networks. this is an important distinction between markov networks and bayesian networks.
¡¡as an example  suppose we have a network and we want to ensure the robustness of the query pr z | e  after we apply a parameter change. assume that we define robustness as the relative change in any query odds to be less than 1. for example  if currently pr z | e  = .1  the new query value must stay in the interval  .1 .1  after the parameter change. we may ask  how much change can we apply to a parameter if we want to ensure robustness  the answers for bayesian networks and markov networks are different due to our previous results  as we will show next.
¡¡for a bayesian network  the amount of permissible change is determined by inequality 1  and is plotted in figure 1. we can see that the amount of permissible change is small when the parameters have extreme values close to 1 or 1  because the relative odds change is large when even a very small absolute change is applied.
¡¡on the other hand  for a markov network  the amount of permissible change is determined by inequality 1  and is plotted in figure 1. we can see that the amount of permissible change is proportional to the parameter values  because relative change is used instead of relative odds change.
¡¡therefore  for a bayesian network  the sensitivity of the network with respect to a parameter is largest for extreme values close to 1 or 1  and becomes smaller as the parameter approaches .1  while for a markov network  the sensitivity of the network with respect to a parameter is proportional to its value  and increases as it grows larger.
¡¡the distance measure is useful in many aspects of sensitivity analysis. for example  given the possible single parameter changes in our example in the previous section  we can choose the one which perturbs the network the least according to the distance measure. in this case  the most preferred

figure 1: the amount of parameter change ¦Ä that would guarantee the query pr z | e  = .1 to stay within the interval  .1 .1   as a function of the current markov network parameter value p. single parameter change is to decrease the parameter ¦Èa1 b¡¥1 from 1 to .1  incurring a distance measure of 1.
¡¡moreover  we can also use the distance measure to find the optimal solution for changing all parameters in a clique table  which is the solution that satisfies inequality 1 and minimizes the distance measure. as the distance measure d ¦¨c ¦¨1c  is computed using the maximum relative change in the parameters  the relative changes in all parameters must be the same for the optimal solution  because to obtain another solution that satisfies the constraint  we must increase the relative change in one parameter while decreasing the relative change in another  thereby incurring a larger distance measure.
¡¡for example  in our example from the previous section  to ensure our query constraint  we would like to decrease the parameters ¦Èa1 b1 and ¦Èa1 b¡¥1 and increase the parameters ¦Èa¡¥1 b1 and ¦Èa¡¥1 b¡¥1  such that the relative changes in all parameters are the same. however  since only the ratios between the parameters are important  we can keep the first two parameters constant and only increase the last two parameters. the optimal solution of inequality 1 is:
 ¦Èa1 b1=1; ¦Èa1 b¡¥1=1; ¦Èa¡¥1 b1=1; ¦Èa¡¥1 b¡¥1=1.this parameter change incurs a distance measure of .1. it involves all parameters in the clique table and incurs a smaller distance measure than any of the single parameter changes computed earlier.
¡¡finally  if we change the parameters in different clique tables which do not share any variables  the distance measure can be computed as the sum of the local distance measures between the clique tables. this result is also similar to the case of bayesian networks  chan and darwiche  1 .
1 conclusion
in this paper  we expanded some of the main results in the topic of sensitivity analysis from bayesian networks to markov networks. we were able to find many parallels between the results in both models even given the differences in how their parameters are interpreted. our results allow for the effective debugging of markov networks by changing parameters in a single potential for ensuring query constraints. we also showed how to compute a bound on any query change between two markov networks that have the same structure  but differ in the parameters of a single potential  and to choose parameter changes which minimize network disturbance. finally  we identified a key semantical difference between bayesian networks and markov networks  relating to how parameter changes should be quantified.


a planning system must reason about the uncertainty of continuous variables in order to accurately project the possible system state over time. a method is devised for directly reasoning about the uncertainty in continuous activity duration and resource usage for planning problems. by representing random variables as parametric distributions  computing projected system state can be simplified. common approximations and novel methods are compared for over-constrained and lightly constrained domains within an iterative repair planner. results show improvements in robustness over the conventional non-probabilistic representation by reducing the number of constraint violations during execution. the improvement is more significant for larger problems and those with higher resource subscription levels but diminishes as the system is allowed to accept higher risk levels.
1 introduction
planning systems that reason about real world events must eventually deal with the inherent uncertainty of any real world mechanism. for example  actions may take longer or consume more resources than predicted. even if it were possible to model every variable that affected a planned set of actions  doing so is impractical for realistically sized domains. further  practical modeling abstractions themselves also introduce uncertainty into reasoning about a system.
﹛the way a planning system deals with uncertainty in its actions and observations is critical to how well the system is able to perform in the real world. clearly  systems that effectively reason about uncertainty can better avoid generating plans that are likely to violate execution constraints. but effective use of uncertainty can also improve the longterm efficiency of a plan by balancing acceptable risk levels against the inefficiencies incurred to avoid those risks. finally  knowledge of uncertainty allows the system to better

 
﹛﹛this research was carried out at the jet propulsion laboratory  california institute of technology  under a contract with the national aeronautics and space administration.assess and report on the most risky plan segments.
﹛one historical approach to dealing with uncertainty is to assume no uncertainty at the level of planning abstraction. to be used in a real world system  such systems are often augmented with some replanning mechanism for when predictions do not match results  chien et al.  1; koenig  1 . one step further is to depend on an execution system to handle any variations in plan execution. effectively  the planner itself is abstracted from any knowledge that the real world does not behave as predicted.
﹛there are many planning systems that reason more directly about uncertainty. classifications and surveys of this work are given by bresina et al.  1   blythe  1   and boutilier et al.  1 . some techniques handle some level of temporal uncertainty  puterman  1; boyan & littman  1  or continuous resources  e.g.  bertsekas & tsitsiklis  1; smart & kaelbling  1   and one can represent both complex temporal constraints and continuous states/resources  dearden et al.  1 . this is important for domains where concurrent tasks interact in their effect on continuous resources. for example  a spacecraft can be slewing  operating instruments  and communicating at the same time. metric resources such as power  energy  memory  and temperature are continuously affected and often require complex temporal constraints to balance safe operation with efficiency.
﹛this paper outlines one possible approach for directly reasoning about the uncertainty in action timing and resource consumption. while dearden et al. use a monte carlo approach to estimating the value of a plan  1   we directly compute parametric probability distributions for time and resource variables based on a user-supplied model of activities and resources. the distributions are then combined during planning to determine the net probability distribution of a resource at any time point  which in turn may be integrated to yield the probability of violating any execution constraints on the resource. the key idea is to use this  probability of conflict  to score potential plans and to drive the planner's search toward low-risk actions. an output plan provides a balance between the user's risk aversion and other measures of plan optimality. this is a simple conformant planning approach- the planner does no contingency planning but also assumes no future state observability.
﹛the present work deals only with durations and resource usages that can be modeled as normally distributed random variables  though the techniques are more widely applicable. to gauge the effectiveness of our probabilistic system  batch-generated plans are executed in a stochastic simulator. a comparative evaluation of our technique versus some common probabilistic approximations is provided along with an analysis of its applicability to different kinds of planning problems.
1 approach
planning effort is directed to repairing areas of a plan that have unacceptable levels of risk  as determined by a userspecified risk tolerance on each resource as a function of time. risk for any one timeline segment is assessed by computing the probability that the sum of all activity reservations that potentially overlap the segment would exceed one of the modeled system resource limits. this probability of resource constraint conflict is readily derived if the resources' net probability density functions are available. our approach for maintaining each net resource distribution is to combine individual activity resource reservations parametrically.
﹛each activity in the plan is considered to make uncertain resource reservations that follow a known distribution. further  each activity can also have a duration that is similarly uncertain.  for simplicity  all activities are considered to have certain start times - an assumption that holds for directly commanded actions  but may not apply for exogenous events.  in this paper  we only consider reservations and durations that are normally distributed random variables  though in practice other parametric distributions can also be used. the parametric representation for a normal distribution is very compact  requiring only the distribution mean  米  and standard deviation  考 . in comparison  a particle filter  gordon  salmond  & smith  1  requires a value and weight for each sample taken from a distribution. conveniently  specified values can be also represented as normal random variables with a given 米 but 考 = 1.
﹛in the case of activities that make persistent reservations on a resource  that is  they consume or produce a resource   the net resource distribution for a timeline segment is the sum of all current and preceding normally distributed reservations. fortunately  the sum 曳 of i independent normal reservations n is itself a normal  with parameters 米曳 = pi 米ni
and 考曳 = ppi 考ni1. notice that the uncertainty of the sum is greater than any single component  indicating that resultant uncertainty grows with the number of interacting reservations.
﹛for actions that only have a transient reservation  lasting for their duration only   the same method can be applied to those reservations that are concurrent. in the simple case that each concurrent activity has a certain duration  the net resource distribution is computed by adding each local reservation. in the more complex case of concurrent activities with uncertain duration  the net resource distribution itself becomes a function of time.
﹛for an activity a with start time ts and duration d = d米 ㊣ d考  consider p a  t  to be the probability that action a is executing at time t  see figure 1 . as d is normally distributed  the end time te is also a normal  and we can express p a  t 

figure 1: probability of activity a with normally distributed duration d continuing after its start time ts.

figure 1: transient resource usage distribution for activity a of uncertain duration  showing peaks at r when the activity is likely and 1 when the activity is unlikely.

figure 1: computing the sum of two bimodal resource usage distributions results in a multi-modal distribution. each resultant peak weight is the product of the component weights.
as:
p 
where 朴米 考 x  is the cumulative distribution function for a normal with mean 米 and standard deviation 考. strictly  normal distributions may yield negative samples  so we must truncate only the duration distributions to  1 ﹢   or in practice  1 米 + 1考 .
﹛each of a's resource reservations must reflect the gradual diminishment of the activity's probability. if a makes a reservation r when active  its effective reservation becomes a function of time  r t   as in figure 1 . this distribution is bimodal: one peak at zero resource usage represents that the activity is not in effect  weighted w1 = 1   p a  t    and the r peak represents a's transient reservation  weighted wra = p a  t  . the peak at zero is a scaled dirac delta function: it integrates to w1  but has infinitesimal width.
﹛the time-sensitive reservations seen in figure 1 are no longer simple normals  so the net resource distribution must also be more complex. in fact  the sum of |ai| different bimodal reservations results in a multi-modal distribution with o 1|ai|  distinct peaks: one for each combination of activities that could be in effect  see figure 1 .
﹛with the net resource distribution pdfr x t  in hand  computing the probability of violating a system resource constraint during a timeline unit becomes a simple integral. for a timeline unit t with a random variable resource level r and constraints that r ﹋  lmin lmax   then the probability of violation is given by:
	p vt  t 	=	p r t    lmin  + p r t    lmax 
	=	1   p lmin ≒ r t  ≒ lmax 
	=	1    cdfr lmax t    cdfr lmin t  
 pdfr x t dx
fortunately  this integral for normal distributions is fast to compute and multi-normal distributions require simple linear combinations of this integral.
﹛in the end  p vt  t  may still be a function of time. in this event  we report p vt  as the maximum instantaneous probability of violation during the timeline unit.  such an assumption works for systems where each random value is chosen once and not resampled.  to avoid checking all t ﹋ t  we currently only check a constant number of critical times from t  including the endpoints.
﹛the probability of constraint violation for each timeline unit is compared to the user-specified acceptable risk level  and any violations that are more likely than the risk tolerance are flagged as plan conflicts. a planning algorithm can use the tolerance to help decide whether and where to add  order  move  or remove an activity.
﹛in our application  we use an iterative repair planner that chooses one over-risk-tolerance timeline unit at a time and attempts to reconcile the risk by moving  adding  or deleting resource contributors. for our purposes  the plan is scored according to how many remaining  too risky  timeline units remain  and the planner gradually hill-climbs toward plans with only tolerable risk levels.
1 comparison approximations
approximation methods were implemented for comparison against the fully probabilistic system described above. each fits within the same planning and heuristic framework  but maintains the net resource distributions differently.
﹛means only: one very natural approximation method is to disregard all uncertainty and consider only the one value of

figure 1: single peak approximation for resource usage distribution in place of multi-modal distribution  figure 1 .
maximum likelihood as representative of a distribution. for normal distributions  this is the mean. because durations are also estimated by the mean  there are no multi-modal distributions  and resource values are tracked as a single value on each unit. the means only approximation is equivalent to an assumption that everything behaves as expected.
﹛pessimistic: similar to the means only approximation  the pessimistic approximation only tracks one value from each distribution. instead of choosing the value of maximum likelihood  however  it chooses the  worst case  value. for a normal distribution  our pessimistic system tracks only the value 米 + 1考  or 米   1考   and considers that to be the actual resource reservation. the choice of which direction constitutes the worst case is inherently domain dependent and must be specified.
﹛single peak: a possible limiting factor of the fully probabilistic system are the o 1|a|  peaks required when combining reservations of uncertain-duration activities a. the single peak approximation uses a single normal distribution in place of this set  as in figure 1  compare with figure 1 . this forfeits accurate representation in favor of much improved time complexity. the single peak approximation is optimistic in that it underestimates reservations.
﹛chebyshev bound: the chebyshev bound approximation is similar to the single peak approximation in that both eliminate the multi-modal distributions that arise from uncertain duration. however  the chebyshev bound uses a more rigorous mathematical foundation for its approximation: for any random variable r  no matter the distribution  the probability of receiving a sample further than l from the distribution mean 米 is given by the single-tailed version of chebyshev's inequality:
                 1 p 
﹛because the chebyshev bound assumes so little about a distribution  it is necessarily pessimistic. like the single peak  chebyshev tracks only a single mean and standard deviation  and the sum of two approximated values is taken to have the worst case standard deviation of 考曳 = pi 考ni1. we apply the one-sided chebyshev inequality to the net mean and standard deviation  and report the resulting upper bound on violation probability as the violation probability.

figure 1: execution error means for the three abstract domain variations. the 1% confidence of the mean is shown as an error bar.
1 results
the full probabilistic system was evaluated against each of the comparison algorithms in two disparate planning domains. the first domain is an abstract testbed  and the second is a much more complex orbiting spacecraft domain.
﹛for each domain  a random problem generator provided the initial schedule for the planner to repair. an iterative optimization planner was then run for a fixed number of iterations on the seed plan. the planner was augmented to use each of the full probabilistic and approximation algorithms  and an output plan was saved for each. the saved plans were then executed on a stochastic simulator that reported the number of resource constraint violations that occurred. notably  no replanning was allowed as information became available during simulation. it would be possible to augment our experiments with more elaborate execution models  flexible time points  replanning  etc   but such was not investigated in the present work.
1 abstract domain
the abstract testbed domain has a single resource and a series of activities that may consume or replenish that resource. the model was run with both permanent and transient resource reservations  and with different levels of reservation uncertainty. a valid solution existed for every generated problem.
﹛a comparison of the simulation error means for each approximation method is show in figure 1. as expected  the means only approximation stacked activities until the resource value was very close to its limit. this resulted in simulation errors when the simulated values exceeded the mean. the pessimistic approximation only fared slightly better  likely due to its representation deficiency: a simulation error occurs when a resource exceeds its limit or falls below zero. after a sequence of several overestimated consumers  the pessimistic approximation replenished those reservations with twice as many underestimated replenishers. this causes the resource to fall well below zero  and an error is reported. in real systems  resources may have one-sided constraints.
﹛the full probabilistic system fared the best  consistently achieving nearly zero errors in each domain. it added an appropriate amount of both resource and schedule slack to accommodate the specified risk tolerance of 1%. the single bump approximation also performed well  only having difficulty when the resource uncertainty was doubled in  b . notably  the chebyshev approximation did not meet expectations: it turned out to be so very pessimistic in its distribution estimation that it failed to find good solutions  floundering with imagined conflicts.
﹛the price of using the fully probabilistic system is of course computation time. for problems in which duration was not uncertain  the fully probabilistic system was about 1 times slower  unoptimized  than non probabilistic approaches. when duration was made uncertain  however  a vast difference appeared. notably  the single peak approximation was almost 1 times faster than full probabilistic  on par with the non-probabilistic approaches. systems where computational time is at a premium would likely fare well to adopt a simple single peak approximation and instead leave the full probabilistic approach for systems where execution errors are extremely high cost.
1 orbiter domain
the second domain is a more realistic mock up of an orbiting spacecraft model. the model is based on a synthesis of ideas from actual models for the eo-1 spacecraft  chien et al.  1  and the proposed ase spacecraft  chien et al.  1 . in addition  we strove to model many of the issues presented in similar planning competition models  long & fox  1 . there are other planning systems that have treated similar spacecraft domains  e.g.  globus et al.  1; frank et al.  1 .
﹛the modeled hypothetical spacecraft is an earth-orbiting satellite equipped with a camera for imaging the planet. the craft must take actions only when sufficient power is available to its solar panels or by drawing on its battery. the craft must avoid overrunning its battery  memory  and disk space capacities. in addition  the processing power and antenna bandwidth are modeled as system resources. finally  the external environment is modeled as providing limited availability windows for downlinks  imaging  and solar power.
﹛the probe is tasked with acquiring images during target visibility windows  processing those images in ram  recording them to disk  and later downlinking them to a ground station. the probe has to reason about 1 resources and has 1 different activities to complete its goals. each activity makes reservations on multiple resource timelines. in this domain  the random problem generator does not guarantee that its problems will always have a completely valid solution  that is  the problems could be over-constrained since the planner is forbidden to shed goals .
﹛as before  the fully probabilistic system achieves statistically significantly fewer simulation errors than either of the non-probabilistic systems  and generates plans on par with the single peak approximation's. the box plot in figure 1 conveniently shows a comparison of the error counts for each system. on a per-problem basis  the full probabilistic system had a mean 1 fewer simulation errors  with a

figure 1: execution error distribution for each reasoning system. the box plot shows the median as a horizontal line  a 1% confidence of the median as a notch  and the interquartile range as a box. the whiskers extend to encompass 1 more interquartile ranges  and outliers are plotted beyond that.

	 1	 1	 1	1
simulation error count improvement of full probabilistic over means only
figure 1: execution error improvement distribution for problems of different goal densities.  the improvement is measured as the per-problem difference in errors. 
1% confidence interval of   1  1  . the pessimistic approximation still suffers from the double resource bound problem noted for the abstract model  but still achieves performance comparable to the means only approach. the overly pessimistic chebyshev system still fares worse than the fully probabilistic system  but is not statistically significantly worse than the either of the non-probabilistic systems. notably  the single peak approximation achieves an error rate that is comparable to - perhaps even better than  confidence of 1%  - the fully probabilistic system. this is likely an artifact of our domain  in which activities seldom have tails that stack up into large multi-modal distributions.
﹛various parameters of the system were changed to evaluate the relative sensitivity of each approach. one such parameter is the user-specified risk tolerance. as expected  the payoff  in terms of reduced simulation errors  for using the fully
probabilistic over a means only approach diminishes as the

figure 1: execution error distribution for problems of different sizes

	 1	 1	 1	 1	1	1
simulation error count improvement of full probabilistic over means only
figure 1: execution error improvement distribution for problems of different sizes
risk tolerance is increased. at a risk tolerance of 1%  they are distinct with 1% confidence  but even at 1% risk tolerance the statistical significance has dropped to 1%. at a risk tolerance of 1%  the full probabilistic system becomes mathematically equivalent to the means only system.
﹛the difficulty of the problem also plays an important role in determining the full probabilistic system's dominance. as problem difficulty  measured as number of goals required  decreases  the means only approach gains on and eventually overtakes the full probabilistic approach in terms of simulation errors. figure 1 shows the relevant confidence intervals.
﹛perhaps the most important change is that due to overall problem size. figure 1 shows that both the probabilistic and non-probabilistic systems suffer a roughly exponential growth in simulation errors as a function of problem size. however  the slope of the full probabilistic system's function is significantly lower than that for means only. this indicates that the difference in simulation error counts will probably grow roughly exponentially was well. figure 1 demonstrates this fact more clearly by showing the per-problem improvement distribution. at large problem sizes  the fully probabilistic system vastly dominates the means only approach  while at small problem sizes  there is hardly any difference.
1 conclusions
we have described an approach for directly dealing with plan uncertainty by collecting and merging the probability distributions from action duration and resource usage. the essential idea is that by maintaining such merged distributions  a planning system can ask specific questions about the risk of violating constraints at any time. being able to ask such questions allows the planner to better balance its risk posture against its desire to achieve goals.
﹛we have shown that augmenting a planner with such a probabilistic reasoning system allows for plans with execution-time quality superior to that which can be obtained without directly considering uncertainty. though the underlying structure of the planner's decisions are not changed  the more robust risk assessment afforded by a probabilistic system allow the planner to focus its decisions on the most probable errors. as problem size increases or as resources become more saturated with subscriptions  such focus becomes more important to finding plans that perform well on execution.
﹛the fully probabilistic system makes its gains using a o 1n  algorithm  but we have also shown that a simple approximation technique that still tracks distributions can achieve comparable  and sometimes superior  results with only a o n  algorithm.
﹛the techniques we have demonstrated are applicable to most planning problems that satisfy a few constraints. first the resource and duration distributions of actions must be known. second  the system must have a relatively high risk averseness for the probabilistic system to make a difference. in the current implementation  we have not handled many desirable planner capabilities such as direct temporal constraints or discrete state resources. we believe the techniques are still applicable for problems with such characteristics  albeit with some modification. probabilistic reasoning is especially suited to problems of large size and high cost of failure.

 
because of very high branching factors  a backgammon program must rely on knowledge rather than search for performance. we here discuss insights gained about the structure of evaluation functions for a large domain such as backgammon. evaluation began as a single linear polynomial of backgammon features. later  we introduced mate-classes  each with its own evaluation function. this improved the play  but caused problems with odge-effects between state-classes. our latest effort uses models of position potential to select across the set of best members of each represented state-class.  this has produced a significant jump in performance of bkg. 
because of the localization of knowledge  state-classes permit relatively easy modification of knowledge used in evaluation. they also permit the building of opponent models based upon what evidence shows the opponent knows in each state-class. 
our program plays a generally competent game at an intermediate level of skill. it correctly solves a high percentage of intermediate level problems in books. i. why yet another game  
backgammon is a game of skill and chance. it is an interesting object of study for ai because in any given position  of with there are 1   1  le1    there are 1 possible combinations that the throw of two dice can produce. each of these  can be played legally in the average board position about 1 different ways   about 1 in actual game positions . thus if one were to investigate a backgammon position by tree searching  it would be necessary to deal with a branching factor of more than 1  !!  at every node. clearly this is completely impractical. therefore backgammon must be approached with evaluation and knowledge in mind. position pi will have to preferred over position p1 because it has features that more endear it to the player who can produce it than the features that obtain in p1. 
in a game such as chess  it has been customary to search very large trees of 1 to 1 million terminal nodes. in such a paradigm  the execution of a terminal evaluation function requires a certain amount of time  which must then be multiplied by the expected number of terminal nodes in the search. thus designers of chess programs are very circumspect in creating 
	tins 	work was supported by the 	advanced research 
projects agency of the office of the secretary of defense 
 contract f1-c-1  and is monitored by the air force office of scientific research. 
p r o h l f n-sol v  nr 1 
evaluation functions which require lengthy execution times. for this reason certain features that are not trivial to compute are usually left out  so that the program may operate faster and search more. since there can be little or no searching in a practical backgammon program  these contingencies will not apply. on the contrary  it is desirable to apply all possible knowledge to successor positions of the root node  in an attempt to find the best next move. further  the fact that modern backgammon involves doubling places an even greater emphasis on the use of knowledge  since it requires an understanding of a position  not just the ability to discriminate the best move  to know when to double and when to accept or refuse. 
ii. the structure of bkg 
bkg is an interactive program. for a given roll of the dice  it generates a list of all possible legal plays. if it is the program's turn to play  it serves these potential plays up one at a time to the evaluation procedure. it then selects the best. if it is a human opponents's turn to play  it waits to receive a legal play from its environment. 
bkg now plays a completely legal game of backgammon. it is capable of doubling and accepting or refusing doubles at all times. it will also resign positions in which there is no possibilty of winning  and accept resignations when there is no possibility of it winning a gammon. 
iii. some evaluation terms 
in versions of bkg up to the end of 1  a linear polynomial of backgammon features was used to produce evaluations in positions where the two sides were still engaged. this polynomial derived most of its strength from excellent recognition of blot danger  the danger of a man being hit by the opponent on his next roll   and blockading factor  the ability to keep opponent's men bottled up . both these calculations went through a considerable history of experimentation which is described in  be1 . below  we briefly describe their current form. when the sides are disengaged  a running game calculation is performed since capturing and blocking are no longer possible. 
a. blot danger calculation 
our procedure considers all hitting relations between potential hitters and blots. it finds the optimal way to play every potential roll so as to hit the greatests number of blots or point on a blot. if only one blot can be hit  it calculates hitting the most advanced one. thus it can decide for any position what the probability is of having one or more men hit  and what the expected loss of pips in being hit is. this information is basic to understanding the risk of any potential play. 
b. blockading factor 
a blockade consists of a set of points  made  by one side  which prevent an opposing man from having access to those points. clearly  such points can have a great effect on the opponent's movements  and their location is of great importance. 
1 : 	be*r 1  ner 

we note that since there are only 1 men on a side  it is impossible to have more than 1 blockading points. for each combination of zero to seven blockading points at a distance of 1 to 1 spaces in front of a man  we computed the number of rolls that could legally be played by the blockade runner. this number was put into a table associated with the blockading pattern. this allows quick lookup of the degree to which each man is blockaded. 
c. the running game 
bkg has been doubling and accepting doubles in the running game almost since its inception. there has been much published on when to double and accept in the running game phase of backgammon  ke1  th1  1 . we have tried to follow this advice in structuring algorithms for deciding who is winning and by how much. this has resulted in quite good performance by the program  even in situations where the decision is close. 
to support decision making during the bearing off phase  bkg has extensive tables which give the probability for a given position of one side  of bearing off all men in 1 -- 1 rolls and the expected number of rolls  enr  to bear all men off. the tables cover all situations for up to and including 1 men in the home board  and up to and including 1 pips worth of men in the home board. 
the use of the tables in move selection is simple. bkg moves to the position with the lowest enr. there are two exceptions to this case; that is when it is far behind or far enough ahead to have a chance of winning a gammon. in the former case  it moves to the position which has the greatest probability of bearing all men off in the number of rolls that are expected for the opponent to get off. when it is far ahead  it moves to the position which gives it the greatest chance of bearing all men off in the number of rolls it expects to have before the opponent gets his first man off. 
for doubling and accepting doubles the situation is more intricate. whenever  bkg can legally double during this phase  or when it has been doubled  it executes a win probability calculation. if the positions of both sides can be looked up in the tables  then bkg can calculate the exact probability of the side on move winning by itteratively calculating the probability that the side on move will get all its men off on this roll  and then changing whose move it is  until the sum of the probabilities - 1. if both positions cannot be looked up  the win probability calculation is based on adjusted pipcount of both sides  but this is notably less accurate than the table lookup method  which performs superlatively. 
the power 	of the bear-off tables is 	very impressive. 
to illustrate the type of thing bkg does to amaze its author  we show an example. 

	1 1 1 	w h i t e 1 1 1 
figure 1 
in the bottom part of figure 1  white is to play a 1. the 1 must obviously be played from the 1 point. but what is the correct way to play the 1  almost every human player would say 1. however  this is not correct; 1 is better. the bear-off tables report the respective enr's to be 1 and 1. upon examination  it turns out that all sequences of future tolls produce the same results in the two positions except when one of the next two rolls is 1. if this occurred  it would leave men on the 1 and 1 points with the preferred play  which allows 1 additional combinations of getting them both off on the next roll over the other way of playing it. 
the second example in the top part of figure 1 has similar features. here black is to play a 1. the 1 must be played from the 1 point; the question is how to play the 1. again human players would automatically play 1 - 1   but this is incorrect. 1 is correct because of future double 1ns. for these two examples it would seem that the rule:  when there are a small odd number of men on the board  play to maximize use of doubles  would seem to be the correct way for humans to capture the knowledge that is contained in the tables. this illustrates that at times precise calculation will outdo good intuition. 
iv. the evaluation process 
in the first several years of development of bkg  we used a linear polynomial to order states in the statespace. this was fine while new and better terms were being developed for the polynomial. however  once a firm basis for detecting advantages and disadvantages was established  it became apparent  as indeed the research of samuel  sa1  sa1  would indicate  that such a polynomial would not serve. it was possible to tell 

prom*n-so1 v nr;-l: berliner u 1 

bkg about the general utility of any feature  but not enough about the utility of the feature in specific circumstances. 
therefore  we began partitioning the state-space into state-classes. the issues associated with state-classes are these: we assume that it is possible to partition alt states in the state-space into mutually exclusive stateclasses. this is not difficult and can be accomplished by merely having recognizers for a set of state-classes  invoking these recognizers in a canonical order  and putting all not-recognized states into a grab-bag class. we further assume that within a stateclass  a linear polynomial function exists which can order the members of this class according to goodness. it is apparent that this is true in the limit  when there is a 
state-class for each state; however  the degree to which this is possible when there are a large number of members in a given class is not clear. in practice it is possible to get very good  if not perfect  orderings  and to split a state-class when the ordering procedure becomes too complex. 
this approach produced a significant improvement  but also brought some additional problems to the forefront. whenever it was normal to progress from one state-class to another  but such a transition required the program to submit to temporary danger  it would not do so unless there was no safe alternative. with this organization as with earlier ones  bkg was unwilling to take any unforced risk  since it had no understanding of the advantages that could be accrued if the risk succeeded  but did understand the dangers of the risk. another cause of vacillation comes up when a reshaping of the advantage is required in the transition. this can occur when the new state-class does not value highly what is valued highly in the old state-class. an example of this would be reluctance to give up containment of enemy men in order to make a transition to a superior running game position. this type of problem occurs in chess too. 
to correct the above problems within the framework of the linear polynomial  it would be necessary to pinpoint where postponing the taking of the risk could no longer be justified  or when a certain advantage had outlived its usefullness. 
we tried to overcome these problems by having some functions which were invoked only when a change of state-class occured. this type of recognition produces in effect a different state-class for two identical positions  given that one is reached from a member of the same state-class and the other not. we found this to be a very difficult method of doing business that did not look anything like a long term solution to the problem. 
the purpose of having state-classes was to get away from the purely linear relations among terms in the evaluation function. this way we could emphasize certain features that would have a strong impact on future situations derivable from the current state-class. such features include the stability  likelihood of being hit in the case of backgammon  of the state  and measures of the degree of difficulty in making further progress. usually  the side that is closest to winning will want more stable positions  and the side that is closest to losing more unstable ones. however  this is not always the case. the side that has a slightly better position may want to introduce some instability in the hope it will result in an even more favorable position  or even won   while risking losing the advantage or possibly getting slightly the worse of it. this kind of decision is very difficult to program  unless the terms in the evaluation function interact with one another. however  the edge-effect situation between stateclasses became extremely difficult to overcome. 
actually  notions such as progress and risk are crutches that are not needed when a universal measure of goodness such as expectation exists  as it does in backgammon. thus we should always move to the state with the greatest expectation  and state-classes are not needed at all. however  this is only in a system with perfect knowledge. when there is imperfect knowledge  such crutches appear necessary. 
therefore  our present system attempts to overcome edge-effects in the following way: for each applicable state-class  the best member is chosen by the linear polynomial for that state-class. then we compute the expectation associated with each selected state-class representative  and choose the one with the highest expectation as the actual move. this has the advantage of applying the linear polynomial of a state-class to select the play with best local features  and then letting procedures with more global knowledge select the best across state-classes. the difficult part of this is to be able to compute the expectation in complicated positions. in figure 1 below  we show how this can be done for a moderately difficult example. 


problem-sol vinr -l 	rerl iner 1 

characterized by the winning side being ahead in the pipcount  having to cross exactly two more enemy points with his most-back man  and having no hitable blots. we can now imagine an evaluation function for this class which would consider the position of the doubling cube  the exact difference in the pipcount  the ease with which the most-back man can be safely moved up  the containment power of the losing side should he succeed in hitting a blot  the time lost in entering such a hit blot  and the number of pips that arc available to be played as slack before any of these values are materially changed. this function would compute the expectation of white. such a function could be derived either by analytie means or by actual simulation of positions in the class to find out how each of the above variables affected the expectation of white. further  such a function could be tuned as experience is accumulated. let us assume that such a function exists and predicted that in the situation of figure 1 white should win 1 of the time  win a gammon 1 of the time  lose 1 / of the time and lose a gammon 1 of the time  for a net expectation for white of +.1. 
now from this position it is possible to move to four state classes: the present one  class i   an unstable state-class where white has two points to cross  but has a blot in danger of being hit  class ii   an unstable class where white has only one more point left to cross  class iv   and a stable class where white has only one point left to cross  class iii . further  if a blot is hit in state-classes ii or iv  we have another stateclass  v  in which white has a man on the bar which must enter in front of black's blocking position. for each of these state-classes an evaluation function will be able to calculate the expectation. 
white's win probability  w  in a state where he is to move is the sum i**l to n  t w -  where t; is the probability of transiting to state i on the play by playing it optimally  and wy is the probability of winning once state i is reached. if it is black to play  white's win probability can be computed in a like manner. this method can be used to decide between plays that result in differing state classes even though one class may be unstable and the other not. we illustrate by an example. 
let ph denote the probability of a blot being hit on the next roll. let w'j be the probability of winning in stateclass i if the losing side is on move. further  assume w1 ¡ö .1  w- v1 - .1  1  and w1 -.1. then:   '   
wn  -  ph * w1 +  1-ph  * w 1   and w'/  - ph * w1 +  1-ph  * w1. 
to get w1 we must compute the probability of white escaping over the blockade on his next roll  as otherwise he will be doubled and will have to resign. if he does escape  he has about an even chance in the resulting position. these constants should make clear the computation below. it should be noted that when w for a side that is on roll and can double is ¡ê .1  i.e. his expectation   .1  he can double and force his opponent's resignation. thus such terms should be ignored as their value drops to 1. this is true for instance of the term dealing with the situation where white is hit and contained. 
problem-solving 
wo now use this method to decide how to play a difficult roll  1 - 1   in figure 1. there are basically two plays: run one man from the 1 point resulting in a 
position of class ii  or play both men from the 1 point remaining in class i. for the first play: 
w-  1 -ph *w 1 + ph*w1 
- 1 * .1 + 1 * 1 *.1 - .1 
for the second play  there are 1 rolls which result in transition to state-class iii  1  1  1  1  1   1 rolls that result in a class ii position  1   1 rolls that result in class iv positions  1  1  1  1   and 1 rolls that result in remaining in state-class i. the appropriate computation is:  note that wj has dropped to .1 since white reduced his chances of bringing up his most-back man safely  
u~  1 * .1 	 i  
	+ 1*  1 * 	1 *.1 + 1 v  .1  	 ii  
	 f 1 * .1 	  i i i   
	+ 1vc  1 * 1 *.1 + 1 *.1   	 iv  
/1 - 1 / 1 * .1 
therefore  it can be seen that it is better to make play two. it should be noted that as the probability of containing a hit man varies with black's defensive formation  this calculation will also vary accordingly. the wj-  s we have given above are very crude and probably off by a considerable amount. however  the main purpose of this exercise was expository. as of this writing  we have implemented somewhat as sketched the state-class computations required for the above example. bkg now plays all rolls involving 1's correctly. 
the method we have described above can be used for deciding the very important problem of when to move to a state that is in a state-class different from the one we are currently in. however  the whole method assumes that an evaluation function exists for each stateclass which properly orders its members  and that reasonable expectations can be produced across stateclasses. at the moment we have confidence in the first part of this procedure  and the second part has been coming along extremely well. 
we would still like to comment on how such a system can be improved in the face of error. for each state-class there are new state-classes that can be reached in one optimal play for each side without a capture being made. we call these classes forward with respect to the original class. likewise  there are new classes that can be reached from the current class in one optimal play by each side  when there has been at least one capture of a man. we call these classes hack-ward with respect to the original class. 
it is possible to start with a class for which we have excellent expectation data  i.e. the class of bearing off positions that can be looked up in our tables  class b . next  we consider all classes for which class b is forward  and improve the evaluation function for those classes  tuning the coefficents of existing terms and adding new ones as required. this will improve these evaluation functions. we also note all classes that are 
 1 : 	r e r l i n p r 

1 

backward to this class  and put them on a list together with the name of the current class. we can continue this process indefinitely  but painfully until every class has been encountered. whenever the evaluation function of a class that is on the backward list is improved  we go back and modify all the evaluation functions of the affected classes. we can thoh continue our process or go back to one of the classes whose function has just been modified and start anew from there. it is clear that this is a converging procedure. it would probably be necessary to eventually automate this proceedure  if for no other reason than that eventually the evaluation functions would become so good that they would do a better job of ordering members of a class than the experimenter would. such automation except for the introduction of new terms has been previously done by samuel  sa1  for checkers. it would appear likely that for a game such as backgammon  it would be possible to get a selection of terms such that no new ones will ever be required. then it will be merely a matter of tuning old evalution functions  and occasionally trying a new  but known  term to see if it can improve prediction. 
bkg has a simulation facility which can be useful in acquiring the above data. we can ask bkg to play both sides repeatedly any number of times. it will play as it ordinarily does; doubling and accepting when appropriate. bkg plays all running game positions and those where one side is bearing off  with one or fewer points to cross  nearly perfectly. data from simulations can then be used to determine the expectation for the winning side as a function of various parameters of the original state. we have now done this for representative states of some of the simpler stateclasses and used the data for fitting curves of critical variables to the statistically expected outcome. the equations derived appear reasonable  and are working out quite well in practice. 
as data are collected and the evaluation functions improve  two things become possible. it is possible to keep track of how the prediction works out for the program's own play  which can be used as an indicator of which functions need to be tuned next. it is also possible to keep track of individual opponent's results nnd come to the conclusion that they don't appraise certain state-classes correctly  and use this information in future games. 
v. testing of bkg 
when testing bkg  we refer now to the version before the expectation models were put in  on typical beginners books  it gets the right answer in excess of 1 of the time. a much better appraisal of the program can be obtained by analyzing its successes and failures on more difficult tasks. for this we chose  the problems in a very fine intermediate level book  ho1 . there are 1 doable problems in this book  alt the time of these experiments  bkg could not do problems involving doubling decisions before disengagement . we have classified the problems according to the major knowledge required to get the right answer. this is a rather arbitrary way of looking at things  but it is helpful in trying to understand the strengths and lacks in 	the program. we divided the problems into seven categories: 
1  general positional  
1  running game: bearoff  
1  engaged: bearoff  
1  back game  this a special defensive posture   
1  timing  this involves advantages that presently exist going away because one side or the other must destroy 
his position   
1  defensive plays  
1  advanced defensive plays  including the return play . 
we followed the practice in scoring the results of giving bkg part credit for answers that were not perfectly correct but showed it understood the main point of the problem  although the execution was not perfect. we also deducted part credit when it got the correct answer without understanding what the main problem was. table i below shows the results of the tests. 
table i- tests of bkg on  better backgammon  
position class number right 	wrong 	% right pos i t i onai 
running bearoff 
fngaged bearoff 
back game 
t i m i ng 
advanced defense de fense 
total 1 
1 
1 
1 
g 
1 
1 1 
1 
1 
1 
1 
1 1 
1 1 
1 
1 
1 
1 
1 
1 
1 1 
1 
1 
1 
1 
1 
1 in evaluating these results  several things should be noted. the subject matter is relatively advanced  and would for the most part come up in only one of 1 or more games. there are usually on the order of three plausible answers to a problem. bkg is good enough in almost every case to know what these are; thus attaining a score of 1. or less could be regarded more or less as the result of chance. we can see that bkg is extremely good in running game play. also it has a good understanding of the relative positional advantages. however  its performance in other intermediate level aspects of the game is at best mediocre. it has heuristics to help it do bearing off while still engaged  but these are for run-of-the-mill situations  not for the more sophisticated ones in the test set. it has no specific understanding of the back game. since the objectives in the back game are rather different than anything else in backgammon  it will be necessary to implement a specific set of state-classes which recognize back-game potential and how to maintain and destroy it. the problem of timing is one that will be resolved soon. essentially  this requires having a measure of how many men are presently bound to essential roles in the current evaluation  and how many pips are available to be played by the remaining men before the important men will have to be moved. bkg's main knowledge of defense consists of its blot hitting knowledge. it does not understand the concept of coverage  i.e. controlling points on which an opponent's 

prohlem-solving -l: 	berliner 1 
blot may land in the next roll or two. it does not understand that at times it may be beneficial to expose a blot in dire circumstances or to make the  return  play. thus this series of tests has pinpointed some specific knowledge that bkg lacks and that is not subsumed in its present knowledge base. 
it is encouraging to note that even though we have just begun implementing the expectation models  bkg now gets correct 1 of the above set that it formerly got wrong. 

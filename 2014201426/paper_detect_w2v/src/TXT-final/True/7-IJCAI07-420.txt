
logical filtering is the problemof tracking the possible states of a world  belief state  after a sequence of actions and observations. it is fundamental to applications in partially observable dynamic domains. this paper presents the first exact logical filtering algorithm that is tractable for all deterministic domains. our tractability result is interesting because it contrasts sharply with intractability results for structured stochastic domains. the key to this advance lies in using logical circuits to represent belief states. we prove that both filtering time and representation size are linear in the sequence length and the input size. they are independent of the domain size if the actions have compact representations. the number of variables in the resulting formula is at most the number of state features. we also report on a reasoning algorithm  answering propositional questions  for our circuits  which can handle questions about past time steps  smoothing . we evaluate ouralgorithmsextensively on aiplanning domains. our method outperforms competing methods  sometimes by ordersof magnitude.
1 introduction
much work in ai applies system models whose state changes over time. applications use these dynamic-system models to diagnose past observations  predict future behavior  and make decisions. those applications must consider multiple possible states when the initial state of the system is not known  and when the state is not observed fully at every time step. one fundamental reasoning task in such domains is logical filtering  amir and russell  1 . it is the task of finding the set of states possible  belief state  after a sequence of observations and actions  starting from an initial belief state.
¡¡logical filtering in large deterministic domains is important and difficult. planning  monitoring  diagnosis  and others in partially observable deterministic domains estimate the belief state  e.g.   biere et al.  1; cimatti and roveri  1; bertoli et al.  1; petrick and bacchus  1   as part of performing other computations. this estimation is difficult because the number of states in a belief state is exponential in the number of propositional features defining the domain.
¡¡several approaches were developed that represent belief states compactly in logic  e.g.  bdds  bryant  1   logical filter  and database progression  winslett  1; lin and reiter  1   and update this representation. however  none of them guarantees compact representation  even for simple domains.  amir and russell  1   for instance  guarantees compactness and tractability only for sequences of strips actions whose preconditions are known to hold. most importantly  the straightforward approach to logical filtering  deciding if a clause should be in the belief state representation of time t + 1  based on the belief state of time t  was shown to be conp-complete  liberatore  1 .
¡¡in this paper we show that solving the update problem in its entirety is easier  done in poly-time  than creating the new belief state piecemeal. we present c-filter- the first exact  tractable logical filtering algorithm that can handle any deterministic domain. importantly  both time  to compute a belief state  and space  to represent it  do not depend on the domain size. furthermore  the number of variables in the resulting formula is at most n  the number of state features  compare this with n ¡¤ t  the number of variables used in bounded model checking  clarke et al.  1  .
¡¡we extend c-filter to nnf circuits  no internal negation nodes   and show that similar space and time bounds hold for this more restricted representation. we further show how to reason with an output circuit  including smoothing  queries about the past . our results are also useful from the perspective of representation-space complexity; they sidestep previous negative results about belief-state representation  section 1  and intractability results for stochastic domains.
¡¡the key to our advance lies in using logical circuits to represent belief states instead of traditional formulas. we show that updating a logical circuit formula amounts to adding a few internal connectives to the original formula. we take advantage of determinism: a feature is true after an action iff the action made it true or it was already true and the action did not change that. interestingly  our empirical examination suggests that other graphical representations  e.g.  bdds  do not maintain compact representation with such updates.
¡¡c-filter applies to many problems that require belief-state update  such as bounded model checking and planning with partial observability. the attractive nature of this approach is that we can apply standard planning techniques without fear of reaching belief states that are too large to represent.
1 logical filtering
we now describe the problem of logical filtering  tracking the state of the world   hereby referred to as filtering. imagine an assembly robot that can put items together in order to construct some machine. the parts are randomly oriented  and they must be brought to goal orientations for assembly. at the beginning  the parts are located on a conveyor belt. each part drifts until it hits a fence perpendicular to the belt  and then rotates so one of its edgesis aligned against the fence  see figure 1 . a sensor measures that edge  providing partial information about the part's orientation  partial  because the part can have some edges of equal length  and the sensor might be noisy . the robot can then rotate a part  by a certain  discrete amount  and place it back on the belt  or pick it up and try assembling it. we now define the problem formally.
definition 1  deterministic transition system  a transition system is a tupleis a finite set of propositional fluents  s   pow p  is the set of world states. a state contains exactly the fluents that are true in it. a is a finite set of actions  and r : s ¡Á a ¡ú s is the transition function.
executingaction a in state s results in state r s a . r may be partial. in our example  p = { onbelt part1   partofassembly part1   touch part1-e1   touch part1-e1   ... }  a = { pickup part1   assemble part1   rotate part1   ... } in the sequel we assume an implicit transition system.

figure 1: a conveyor belt: the triangle drifts down  hits the fence and rotates. the edge touching the fence is then measured.
¡¡our robot tries to keep track of the state of the world  but it cannot observe it completely. one possible solution is to maintain a belief state- a set of possible world states. every ¦Ñ   s is a belief state. the robot updates its belief state as the result of performing actions and receiving observations. we now define the semantics of filtering.
definition 1  filtering semantics  amir and russell  1   ¦Ñ   s  the states that the robot considers possible  ai ¡Ê a. we assume that observations oi are logical sentences over p.
1. filter: an empty sequence 
1. filter
1. filter o  ¦Ñ  = {s ¡Ê ¦Ñ | o is true in s}
1. filter
filterfilter oi  filter ai  ¦Ñ   
we call step 1 progression with a and step 1 filtering with o.
¡¡every state s in ¦Ñ becomes after performing action a. after receiving an observation  we eliminate every state that is not consistent with it.
¡¡figure 1 illustrates a belief-state update. imagine that the robot has an isosceles right triangle  edges of size 1    and one of the 1-edges is currently touching the fence. there are two possible orientations   a  and  b   left part . after rotating the triangle 1 degrees  each possible state is updated  middle part . if the world state was  a   we should see a 1edge again. otherwise  we expect to see the-edge. after observing a 1-edge  right part   the robot eliminates  b  from his belief state  leaving him only with  a . that is  the robot knows the orientation of the triangle.

figure 1: a belief-state update with a 1 ¡Ì1 triangle. left: possible initial states. middle: progressing with rotate 1 - rotating the triangle by 1  and putting it on the belt again. right: after observing length=1  state  b  is eliminated.
1 circuit filtering
filtering is a hard problem. there are 1|p| belief states  so na¡§ ve methods  such as enumeration  are intractable for large domains. following  amir and russell  1   we represent belief states in logic. their solution provides the foundations for our research  but it guarantees an exact and compact representation only for a few classes of models  e.g. restricted action models  belief-states in a canonical form . we use logical circuits  not flat formulas  in order to extend their results to all deterministic domains. in this section we describe our representation and explain how to update it with an actionobservation sequence  and how to reason with the result.
1 representation
a belief-state ¦Ñ can be represented as a logical formula   over some: a state s is in ¦Ñ iff it satisfies    s ¡Ä   is satisfiable . we call   a belief-state formula. we represent our belief state formulas as circuits.
definition 1  logical circuits  logical circuits are directed acyclic graphs. the leaves represent variables  and the internal nodes are assigned a logical connective. each node represents a formula- the one that we get by applying the connective to the node's children.
¡¡we allow the connectives ¡Ä ¡Å  .   nodes should have exactly one child  while ¡Ä ¡Å can have many. in corollary 1 we explain how to avoid internal   nodes  for nnf .
¡¡we use logic to represent r  too: a domain description is a finite set of effect rules of the form  a causes f if g   for a an action  f and g propositional formulas over p. w.l.g.  f is a conjunction of literals. the semantics of these rules is as follows: after performing a in state s  iterate through its rules. if the rule's precondition g holds in s  its effect f will hold in r s a . if this leads to a contradiction  a is not possible to execute. the rest of the fluents stay the same; if no preconditions hold  the state does not change  we can also make action failure lead to a sink state .
¡¡consider the triangle in figure 1. if the triangle is on the belt  action a = rotate 1 will rotate it  so the touching edge will change: e1 to e1  e1 to e1  e1 to e1. a's effect rules are:
 a causes touch e1  ¡Ä  touch e1  if onbelt   ¡Ä touch e1    a causes touch e1  ¡Ä  touch e1  if onbelt   ¡Ä touch e1    a causes touch e1  ¡Ä  touch e1  if onbelt   ¡Ä touch e1  
1 c-filter
we described how domains and belief-states are represented; we can now present our circuit-filtering algorithm  c-filter.
procedure c-filter
preprocess d   {ai actions  oi observations    an initial belief state over p  d domain description}
1: processdomain
1: for f ¡Ê p do explf := a new proposition f1
1: cb := time1    
process sequence1: for i = 1 to t do
1:	progressaction ai 
1:	filterobservation oi 
1: return cb ¡Ävf¡Êp f   explf 
procedure progressaction a 
update cb: a executed  thus was possible.
get f's next-value explanation:
	a caused f  or f held and a did not cause	f{a an action}
 
1: for f ¡Ê effects a  do
1:	cb := cb ¡Ä time1  poss a f   
1:time1  nextval a f   
1: for f ¡Ê effects a  do
procedure filterobservation o 
{o an observation over p}
1: cb := cb ¡Ä time1 o 
procedure time1 ¦× 
return an equivalent circuit over time 1{¦× a formula}
1: for f ¡Ê p in ¦× do replace f with the node pointed by explf 1: return ¦×

procedure processdomain
{d a domain description  ai actions}
extract  next value  and  possible  formulas
1:do
1:	nextval a f  := cause a f  ¡Å  f ¡Ä cause a  f   1
1: poss a f  :=   cause a f  ¡Ä cause a  f   1:  optional: simplify formulas figure 1: c-filter algorithm
algorithm overview
c-filter is presented in figure 1 and demonstrated in section
1. it receives an action-observation sequence  an initial belief state formula     over p  and a domain description d. it outputs the filtered belief state as a logical circuit.
¡¡the algorithm maintains a circuit data structure  and pointers to some of its nodes. a pointer to a node represents the formula which is rooted in that node  and they will be used interchangeably . we maintain pointers to the following formulas:  1  a formula cb  constraint base  - the knowledge obtained so far from the sequence  receiving observationsand knowing that actions were possible to execute constrains our belief state .  1  for every fluent f¡Êp  a formula explf; this formula explains why f should be true now  in figure 1  the node marked e tch1  is the explanation formula of touch e1  at time t  and the root node is the explanation at time t + 1 .
¡¡we keep the number of variables in our representation small  |p|  by allowing those formulas to involve only fluents of time 1. in a way  this is similar to regression: explf expresses the value of fluent f as a function of the initial world state  and cb gives the constraints on the initial state.
¡¡the belief state is always cb. in other words  a possible model should satisfy cb  and each fluent f can be replaced with the formula explf.
¡¡in the preprocessing phase  we extract data from the domain description  procedure c-filter  line 1 . we then create a node for each fluent  and initialize the explf pointers to them. we also create a circuit for the initial belief-state     using the explf nodes   and set the cb pointer to it  lines 1 . then we iterate through the sequence  update the circuit and the pointers with every time step  lines 1  see below   and finally return the updated belief state.
a closer look
the circuit is constructed as follows. in the preprocessing stage  we extract some useful formulas from the domain description. let effects a  be the set of fluents that action a might affect. for each f in this set  we need to know how a can affect f. let cause a f  be a formula describing when a causes f to be true. it is simply the precondition of the rule of a causing f to hold  if there are several  take the disjunction; if there are none  set it to false . that is  if s |= cause a f  and a is possible to execute  f will hold after it. cause a  f  is defined similarly.
	for example 	take a	=	rotate 1   section 1 .
effects a ={touch e1   touch e1   touch e1 }   and
cause a touch e1   = onbelt   ¡Ä touch e1  cause a   touch e1   = onbelt   ¡Ä touch e1   * 
¡¡procedure progressdomain then constructs the formula nextval a f   which evaluates to true iff f holds after a  given the previous state . intuitively  either a caused it to hold  or it already held and a did not affect it. similarly  the formula poss a f  states that a was possible to execute regarding f  i.e. did not cause it to be true and false at the same time.
¡¡after preprocessing  we iterate through the sequence. procedure progressaction uses those formulas to update the belief state: first  it constructs a circuit asserting the action was possible  corresponding to the poss formula  and adds it to cb  line 1 . then  it builds a circuit for the nextval formula. procedure time1 ensures the circuit uses only time-1 fluents. when we construct a new poss or nextval circuit  its leafs represent fluents of the previous time step; time1 replaces them by their equivalent explanation nodes. our circuit implementation is crucial for the efficiency of this replacement. instead of copying the whole formula  we only need to update edges in the graph  using the pointers . this way  we can share formulas recursively  and maintain compactness.
¡¡after all the new circuits were built  the explanation pointers are updated  line 1 ; the new explanation is the root of the corresponding nextval circuit  built earlier  line 1; see also section 1 . then we deal with the observation  procedure filterobservation : similarly  we use time1 to get a time-1 formula  and simply add it to cb.

figure 1: updating the explanation of touch e1  after rotate 1 
¡¡example: figure 1 shows an update of the explanation of touch e1  after the action rotate 1 . rectangles  on the bottom nodes  represent the explanation pointers of time t  before the action . the circuit in the image is the nextval formula  after procedure time1 replaced its fluents by the corresponding explanation nodes.
¡¡the ¡Å node is the root of the graph representing state of touch e1  after the action: the right branch describes the case that the action caused it to hold  and the left branch is the case that it held  and the action did not falsify it. in the next iteration  the pointer of touch e1  will point at this node.
¡¡note the re-use of some time-t explanation nodes; they are internal nodes  possibly representing large subformulas.
1 query answering with the end formula
c-filter returns an updated belief state  t  represented as a logical circuit. we are interested in satisfiability queries   t ¡Ä ¦× satisfiable  and entailment queries   t |= ¦×  or  t¡Ä ¦× unsatisfiable . in the following  we construct a circuit corresponding to the query and run inference on it.
query circuits
let ¦× be an arbitrary propositional query formula; we want to check whether  t¡Ä¦× is satisfiable. very similarly to an observation  we add ¦× to cb  and replace the fluents for their explanations. the new cb is our query circuit. queries are usually about time t  but the circuit structure allows more interesting queries  in particular smoothing- queries that refer to the past  e.g.  did f change its value in the last 1 steps  could the initial value of g be true  . note that every fluent in every time step has a corresponding node. if we keep track of those nodes  we can replace fluents from any time step by their explanations. if the queries are given in advance  this does not change the complexity. otherwise  finding a past-explanation node might take o logt  time. note that the same mechanism  tracking previous explanations  has many interesting applications  such as filtering in non-markovian domains.
sat for circuits
after building a query circuit  we check satisfiability. traditional approaches check circuit-sat by converting the circuit into a cnf formula. the approaches for doing so either grow the representation exponentially  duplicating shared subformulas  or grow the number of variables significantly.
¡¡instead  we run inference on the circuit itself. a number of works show that the structural information lost in a cnf encoding can be used to give sat procedures a significant performance improvement. using circuit sat solvers  we can solve the problem more efficiently and effectively in its original non-clausal encoding. several such algorithms have been proposed recently  taking advantage of the circuit structure  ganai et al.  1; thiffault et al.  1 . we use those  and a simple algorithm of our own  c-dpll.
¡¡c-dpll is a generalization of dpll. every iteration  an uninstantiated variable f is chosen  and set to true. the truth value is then propagated as far as possible  resulting in a smaller circuit  for example  if f had an or parent  it will be set to true as well . then  c-dpll is called recursively. if no satisfying assignment was found  it backtracks and tries f=false. if no assignment is found again  return unsat. c-dpll takes o |e|¡¤1l  time and o |e|  space for a circuit with |e| edges and l leaves.
1 extended example
we now give a detailed example of the whole process. interestingly  this example demonstrates how logical circuits can represent compactly a belief state that one cannot represent compactly using cnf formulas over the same variables.
¡¡our domain includes fluents {p1 ... pn odd}. the following sequence of actions makes odd equal to p1 ¨’ p1 ¨’ ...pn  the parity of the other fluents. our actions a1 ... an 1 are defined such that a1 sets odd := p1 ¨’ p1  and any other ai sets odd := odd ¨’ pi+1. formally:
 a1 causes odd if  p1 ¡Ä  p1  ¡Å   p1 ¡Ä p1  
 a1 causes  odd if    p1 ¡Ä  p1  ¡Å   p1 ¡Ä p1     ai causes odd if  odd ¡Ä  pi+1  ¡Å   odd ¡Ä pi+1  
 ai causes  odd if    odd ¡Ä  pi+1  ¡Å   odd ¡Ä pi+1   
¡¡applying the sequence a1 ... an 1 sets odd = p1 ¨’ ...pn. we now show how our algorithm maintains the belief state throughout the sequence.
preprocessing the domain:
in this phase we extract the poss and nextval formulas. we examine the action specifications: the only fluent which is affected is odd. a1 is executable when it does not cause both odd  odd.
cause a1 odd  =  p1 ¡Ä  p1  ¡Å   p1 ¡Ä p1 
cause a1  odd  =    p1 ¡Ä  p1  ¡Å   p1 ¡Ä p1  
poss a1 odd  =   cause a1 odd  ¡Ä cause a1  odd  
¡¡it is easy to see that both cannot hold simultaneously  and the formula can be simplified to true: indeed  a1 is always executable. similarly  all of our actions are always possible to execute  so the poss formulas are all equal true.
¡¡now  the nextval formulas. after executing a1  odd will be set to cause a1 odd  ¡Å  odd ¡Ä  cause a1  odd  .
¡¡this is equivalent to cause a1 odd . in other words  odd will be set to p1 ¨’ p1. similarly  after action ai odd will be set to pi+1 ¨’ odd. note  simplifying the formulas is not mandatory; the representation will be compact without it  too.
executing the actions:
imagine that we receive the  arbitrary  sequence a1 a1 ... an 1 odd ¡Ä  pn  performing n actions and receiving an observation . figure 1 describes how the algorithm updates the belief-state with this sequence. at time 1  1a  we create a node for every fluent  and another for true. the nodes represent the value of the fluent at time 1. we set a pointer  the rectangles  for each formula that we want to maintain: the formula for cb  constraints  is set to true because we do not have any initial knowledge. the explanation formula of each fluent is set to the corresponding node.
¡¡we then execute a1  arriving at time 1  1b . no constraint was added to cb  since the action is always executable. no explanation formula of pi changed  since a1 does not affect them. the only thing that changed is the state of odd: its new explanation is p1 ¨’ p1. we construct the graph for this formula  and update the explanation pointer to its root node. note: the image shows xor gates just for the sake of clarity. in fact  each of them should be replaced by five gates  as depicted in 1b.
¡¡executinga1 is similar  time 1  1c . we constructthe graph for odd's new value  odd ¨’ p1. note that we substitute the fluents in this formula  odd p1  by their explanations in time 1  i.e. the pointers of the previous time step.
¡¡we execute a1 ... an 1  and then observe odd ¡Ä  pn  1d. this is just an example observation; alternatively  you can think of it as querying whether it is possible that odd ¡Ä  pn holds now . first  we process the actions and update the explanation of odd. then we add odd ¡Ä  pn to our constraints  creating a new cb circuit and updating the pointer. finally  we return the circuit in 1d  along with the pointers. this is our updated belief state.
answering queries:
in 1e we show an example of truth-value propagation: if we assume that at time 1 p1=true and the rest are set to false  those values are propagated up and result in cb=true. that is  this assignment is consistent with our sequence.
1 analysis and complexity
1 correctness
theorem 1 c-filter is correct. for any formula   and a sequence of actions and observations 
{ s ¡Ê s that satisfy c-filter filterthat satisfy  } .
						     	
	   		   
 a  at time t=1: initial belief state   = true

 b  time t=1: after performing a1

 c  time t=1: after performing a1 a1

 d  time t= n-1 : after performing a1 .. an 1 and observing  odd ¡Ä pn 

figure 1:  e  propagating truth-values
¡¡recall that a state s satisfies formula   if s¡Ä  is satisfiable  section 1 . s is used as a formula and as a state.
¡¡proof sketch we present an effect model  and show how to update a belief-state  flat  formula with this model. we show that the filtering definition in section 1 can be reduced to consequence finding  in a restricted language  with this formula. then  we show that c-filter computes exactly those consequences.
definition 1 effect model:
for an action a  define the effect model of a at time t to be:
teff a t  = at ¡ú
poss a f t  ¡Ä  ft+1   nextval a f t  
poss a f t  =   cause a f t ¡Ä cause a  f t 
nextval a f t  = cause a f t ¡Å  ft ¡Ä  cause a  f t  at asserts that action a occurred at time t  and ft+1 means that f after performing a. ¦×t is the result of adding a subscript t to every fluent in formula ¦×  see section 1 for definition of cause a f  . the effect model corresponds to effect axioms and explanation closure axioms from situation calculus  reiter  1 . if the robot can recognize an impossible action  we can drop the assumption that actions are possible  and adopt a slightly different effect model.
¡¡recall that filter ¡¤  was defined over a set of states. we now define its analogue l-filter  which handles belief-state logical formulas.
definition 1  l-filter  let   a belief-state formula.
¡¡  l-filter a     = cnlt+1  t ¡Ä at ¡Ä teff a t     l-filter o     =   ¡Ä o where cnl ¦×  are the consequences of ¦× in vocabulary l. lt+1 =  l  t  ¡È pt+1    pt   for pt = {ft | f ¡Ê p} and
l  t  the language of  t; i.e.  lt+1 does not allow fluents with subscript t.
lemma 1 the result of applying l-filter a  for a ¡Ê a is a formula representing exactly the set of states filter a . more formally  let   be a belief state formula.
filter a  {s ¡Ê s | s satisfies  }  =
{s ¡Ê s | s satisfies l-filter a    }
¡¡that is  both definitions are equivalent  for lack of space  we do not present the proof here . as a result  we can compute filter using a consequence finder in a restricted language. however  this does not guarantee tractability. instead of using a consequence-finder  we show that c-filter computes exactly those consequences.
¡¡let ¦× :=  t ¡Ä at ¡Ä tt+1eff a t . according to our definition  l-filter a     = cnl  ¦× . we now observe that consequence finding is easy if we keep  t in the following form:
¡¡¡¡¡¡f cb and explf do not involve any fluent of time t.
¡¡we now show how to compute the consequences of such formulas. furthermore  we show that the resulting formula maintains this form  so we only need to check the form of the initial belief-state. luckily  this is not a problem; every initial belief-state can be converted to this form  in linear time  using new proposition symbols.
¡¡let ¦× be a formula in this form. ¦× states that  ft   explf  for every ft ¡Ê pt: we construct an equivalent formula  ¦×  by replacing every ft ¡Ê pt in teff a t  with the formula explf. notation:
¡¡therefore  we can find the consequences of ¦× instead. note that consequence finding in lt+1 is the same as using the resolution algorithm to resolve fluents of pt. we use this to compute:
 a t f  explg/gt  
	let	cb
 nextval a t f  explg/gt  .
the last formula can be re-written as cb
¡¡now note that c-filter maintains the belief-state formula exactly in that easy-to-compute form  namely cb ¡Ä
   cb and explf involve only special propositions  representing time-1  to avoid confusion  you might think of the new propositions in line 1 as finit  not f1 .
¡¡also  cb are exactly the constraint-base and explanation formulas after c-filter's progressaction. that is  cfilter correctly progresses the belief-state with actions. the proof for handling observations is similar. 
1 c-filter complexity
let  1 be the initial belief state  t the length of the actionobservation sequence  and |obs| the total length of the observations in the sequence. let actdesc be the longest description of an action a ¡Ê a  preconditions + effects .
theorem 1 allowing preprocessing of o |p|  time and space  or  alternatively  using a hash table   c-filter takes time o | 1| + |obs| + t ¡¤ actdesc  . its output is a circuit of the same size.
¡¡if the observations are always conjunctions of literals  we can drop |obs| from space complexity. if there are no preconditions  we can maintain a flat formula instead. note that this does not depend on the domain size  |p|. actdesc is usually small- especially if the actions in the domain affect a small number of fluents  and have simple preconditions.
¡¡proof sketch: initializing cb takes o | 1|  time. handling each action adds at most o actdesc  nodes and edges to the graph  and takes the same time: in the worst case  assuming no simplifications were done  we need to construct a graph for each of the action's causes formulas. finally  each time we receive an observation o we add at most o |o|  nodes and edges  resulting in total o |obs| .
corollary 1 we can maintain an nnf-circuit  no negation nodes  with the same complexity.
¡¡proof sketch the circuit's leaves represent literals  instead of propositions . we maintain explanation formulas for them. since  f   explf      f    explf   we can define expl f :=  explf. we take the nnf-form of every

figure 1: left: filtering time  sec  for c-filter  applied to block-world and grid domains of different sizes. the time is linear  and does not depend on the domain size  slight differences in the graph are due to hash-table implementation . right: comparison of filtering time  msec  for several methods  numbers represent domain size . note that this is log-scale.formula we use  observations  explanations  etc.   and replace every literal by its explanation. converting to nnf takes time linear in the formula's size; therefore  time and space complexities will not change  modulo a small constant . 
1 projection
projection is the problem of checking that a property holds after t action steps of an action system  starting from a belief state. generalizations allow additional observations.
¡¡our results from previous sections show that projection is doable by applying c-filter  generating the belief state at time t   t  adding the query and running our c-dpll solver . let m be maximal length of a single observation plus actdesc. usually m = o 1 . since  t includes o n  variables  and has overall size o n + mt   checking if a variable assignment is a model of  t takes time o n+mt . thus  testing satisfiability is np-complete in n  instead of n + mt  the size of the formula  or n¡¤t  the number of propositional variables that appear in an unrolling of the system over t steps; used in bounded model checking . we need to guess n variable assignments  and then apply a linear algorithm to check it. the following result refines earlier complexity results.
theorem 1  projection  let d be a domain with deterministic actions. the problem of answering whether all the states in filter ¦Ð     satisfy q  for belief state formula    sequence of actions ¦Ð and query q  is conp-complete in the number of state variables  n. we assume ¦Ð     actdesc and q are polynomial in n.
1 representation complexity
our results have implications for the theory of representationspace complexity. a simple combinatorial argument shows that there are belief states of n fluents that cannotbe described using logical circuit of size o 1n   i.e.  strictly smaller than some linear function of 1n. nevertheless  our results for cfilter show that those belief states that are reachable within a polynomial number of actions from an initial belief state are of size linear in t and the input size  initial belief state size  and longest action description .
¡¡also   amir and russell  1  showed that for every general-purposerepresentation of belief states there is a  possibly nondeterministic  domain  an initial belief state  and a sequence of actions after which our belief state representation is exponential in the initial belief state size. our results show that this does not hold for deterministic systems.
1 a note on non-determinism
c-filter can handle non-determinism in observations  but not in transition models. however  many real-life environments are inherently non-deterministic. one natural solution is to treat each non-deterministic action as a choice between several deterministic ones. for example  coin-flipping: flipt ¡ú  exactlyonecase ¡Ä
¡¡¡¡¡¡ case1 ¡ú headst+1  ¡Ä  case1 ¡ú  headst+1   where formula exactlyonecase specifies that exactly one of case1  case1 holds  we can use a binary encoding . unfortunately  the number of propositions grows linearly with t.
¡¡we can handle another  very limited  non-deterministic class without adding propositions  specifically   a causes p ¡Å q if g   g deterministic . the idea is to maintain a belief state in a different form  with  l ¡ú expll  for every literal l .
1 experimental evaluation
our filtering algorithm was implemented in c++. our implementation could also handle parametrized domain descriptions  such as strips. we tested it on ai-planning domains  figure 1 lists several  of various sizes and observation models. we generated long action-observation sequences with a random sequence generator  implemented in lisp   and ran inferenceon the results using our own c-dpll and noclause   thiffault et al.  1  . circuit sat solver.
blocks: 1ferry: 1grid: 1gripper: 1hanoi: 1logistics: 1movie: 1tsp: 1figure 1: overview of c-filter experiments: ai-planning domains  1+ fluents  1 steps . results presented as filtering time/ model finding time  both in msec .
¡¡figures 1  1  1 present some of the results. figure 1  left  shows that c-filter is linear in the sequence length; note that

figure 1: total time for finding a model  msec   for block-worlds of different size and number of observations per step.
time depends on the domain but not on the domain size. in both block-world and grid-world  filtering time almost does not change  even when the number of fluents grows 1 times larger  slight difference in the graph is due to hash-table implementation  instead of an array; the circuit size does not depend on this implementation and was the same .
¡¡the right part of figure 1 shows a comparison to other filtering methods. we compared our algorithm to  1  filter  amir and russell  1   in lisp    1  filtering by unrolling the system over t steps  using |p|t propositions    1  bddbased filtering  based on the buddy package  lind-nielsen  1 . c-filter outperformed them all  sometimes by orders of magnitude; note that the graph is log-scale.
¡¡comparison analysis: bdd sizes depend highly on variable ordering. even for some very simple circuits  the representation can have either linear or exponential size depending on the order  finding an optimal ordering is known to be np-complete . the long processing time at the beginning is due to heuristic methods that try to achieve a good ordering; after a while  a good ordering was reached  making processing faster. even with those heuristics  we could not process large    1  domains. filter and unroll were also slower  and could not process long sequences or large domains  also  filter can handle only a limited class of domains . unroll suffers from the frame problem  i.e. needs to explicitly state the fluents that do not change  ft   ft+1   and therefore depends on the domain size. c-filter  however  managed to handle large domains  hundreds of thousands of fluents   taking a few milliseconds per step.
¡¡figure 1 shows the time to find a model for the resulting circuits using a modified version of noclause. significantly  reasoning time grows only linearly with t. this allows practical logical filtering over temporal sequences of unbounded length. note that the more observations an agent gets  the more constrained his belief state is. therefore  it takes longer to find a satisfying model  also  the formula is larger .
1 conclusions
a straightforward approach to filtering is to create all the prime implicates  or all consequences  at time t + 1 from the belief state representation of time t. previous work  e.g.  liberatore  1   showed that deciding if a clause belongs to the new belief state is conp-complete  even for deterministic domains. this discouraged further research on the problem.
nevertheless  in this work we presented an exact and tractable filtering algorithm for all deterministic domains. our result is surprising because it shows that creating a representation of all of the consequences at time t + 1 is easier  poly-time  than creating the new belief state piecemeal.
¡¡several approaches were developed in the past to represent belief states in logic  e.g.  bdds   amir and russell  1    but none of them guaranteed compactness. the key to our advance was our logical circuits representation. we also showed how to maintain nnf-circuits.
¡¡the results obtainedhere have implications in many important ai-related fields. we expect our algorithms to apply to planning  monitoring and controlling  and perhaps stochastic filtering. we plan to explore these directions in the future.
acknowledgements this work was supported by the national science foundation career award grant iis 1. we thank the anonymous reviewers for their helpful comments.

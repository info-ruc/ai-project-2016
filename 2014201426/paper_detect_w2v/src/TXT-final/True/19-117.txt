 
   life-cycle engineering is the integration of the design process  which addresses primarily the system's performance  with analysis of the design's other attributes  including reliability  maintainability  lifecycle cost  and manufacturability. the advent of symbolic approaches to design integration reveals the requirement and opportunity of using higher-level analysis to select the optimum design. this opportunity is present only when human interaction is reduced sufficiently to permit several complete design and analysis cycles to take place. we have implemented a generic integration tool that has been demonstrated to significantly shorten the design cycle  and are studying its application to life-cycle engineering. this logic-based tool regards the requested attributes as a set of uninstantiated variables and invokes external computational programs  recursively if necessary  to achieve a proof consisting of the computed variable bindings. key words: software integration  engineering design  expert system. 
i introduction 
   in engineering design and analysis  knowledge of how to create the design is fragmented among numerous computational programs. these programs typically perform computer-aided design and other computational functions such as simulation modeling  dynamic analysis  and optimization. the programs are islands of automation within an environment that is not otherwise automated. design and analysis of the product require that they be integrated as defined by their input and output data relationships. because of the complexity of the interrelationships among the programs  numerous delays and errors occur during their integration. these delays and errors can increase costs  cause scheduling crises  and reduce design quality.  kowalik and chalfan  discuss this problem.  when the design is complete  it addresses only performance. usually no feasible alternatives are developed because of the high cost of the design cycle. when subsequent analyses reveal shortcomings in other attributes that may actually have more effect than performance on the life-cycle cost of the product  last-minute changes are made that often unnecessarily compromise performance. 
in order to rapidly generate numerous design 
copyright r  1 the 
1 	knowledge representation 
alternatives  we have formalized in an expert system the problem-solving knowledge required to integrate the components of the design process. the expert system  understands  the objectives of the analyst and executes all programs necessary to produce the desired design. this paper describes the expert executive  which we developed for preliminary design and are now applying to electronic circuit design  and describes how this work relates to the broader problem of life-cycle engineering. 
ii the integration problem 
   for the typical design and analysis problem  there is a set of programs that are logically interrelated by computed data values. this relationship can be represented as a directed graph. in electronic circuit design  as depicted in figure 1  an electronic computeraided design  ecad  program typically produces a 
parts list and a connectivity list. the bold rectangles represent computational programs  and the light ones represent input and output variables  as indicated by 
boeing company 
   
the arrows. the parts and connectivity lists are input to thermal and reliability analysis  maintainability  and life-cycle cost. the involvement of the designer typically ends when the performance of the circuit  as measured by the thermal analysis program  is satisfactory. subsequent analysis is outside the primary design cycle. outputs from thermal analysis are input to reliability  and so on. 
   in preliminary design of aerospace vehicles  four codes form the basis of analysis: weight  aerodynamics  propulsion  and performance. figure 1 depicts a typical configuration of these codes. for example  w1 is an output of the weight technology code and also an input to the aero technology code. some input variables  such as v  are not output by any of the technology codes in the given configuration. they are known as free design parameters. a typical task might 

be to compute the range of a vehicle. since the performance code requires inputs from the propulsion and aero codes  propulsion and aero must be run first. in turn  the weight code must be run before the aero code can be executed. when the range is finally obtained  the cycle begins again  based on perturbations of free design parameters. if a different vehicle type is considered  a different set of technology codes may be applied. 
   each program is  owned  and validated by a technology group  such as weights technology and propulsion technology for preliminary design  or 
ecad and reliability for electronic circuit design. in the absence of an automated integration program  technology groups interact to identity the appropriate technology codes to run  obtain input values from one another  run the codes  and analyze the results. the computed values are manually extracted from code outputs and inserted  possibly erroneously  as input values for other codes. since the typical design cycle requires several weeks  and multiple design concepts may be generated in parallel  technology analysts may be uncertain which version of which design they are addressing. because of the time required for the paper output to be analyzed and the appropriate values to be passed to other groups  and the scheduling problems for such a complex activity  often only one or two designs can be considered. it is then very difficult to justify the selection of one design over all other possible designs. because of the high cost of the preliminary design process with respect to the quality and quantity of designs produced  the need for an integrated approach to preliminary design has long been recognized: within the industry. however  earlier solutions failed due to the complexity of the problem  variability of codes  inflexibility of the procedural control structures embedded in the integration programs  and the administrative difficulties of validating new versions of the integrated codes within the various technology organizations. 
ill the expert executive for preliminary design 
   symbolic computing presented a new approach to this problem. kowalik et al.  have described a class of composite software systems that integrate knowledge-based processes and numerical processes into a single unified system. we hypothesized that if the general knowledge of how to run the technology codes and compute the values of design variables could be codified  then the specifics of the problem could be addressed relatively inexpensively and thereby provide a practicable integration capability. to investigate the feasibility of this approach  we developed a preliminary design tool with an expert executive  that contained symbolic knowledge of how to execute a set of computational programs. the expert executive assumes the support functions currently assigned to the technologists  thereby freeing them to perform design and analysis. by expediting the computation process  it provides more design alternatives. 
   the expert executive is currently being reimplemented in quintus prolog. the current knowledge base  which remains unchanged for all sets of computational programs  contains about 1 propositions. in addition  fact bases contain information about the inputs and outputs for each of the programs to be configured. the size of a fact base depends mostly on the number of inputs and outputs  since each is described by one fact. 
   the rules provide knowledge about solving a specific  user-defined problem. for example  the expert executive has several rules for finding the value of a variable. variable values are represented as a relation between a variable and its value. the knowledge base contains one such statement  or proposition  for each variable whose value is known through either user input or computation. as additional knowledge is acquired through computation or interaction with the user  additional value-of propositions are asserted into the knowledge base. 
   the fact base consists of input  output  and scriptname propositions. input propositions are in a format that translates to  the first input to the propulsion code is v  velocity .'' the sequence number indicates the sequence in which it is read by the computational program. output propositions are in a similar format  
	chalfan 	1 
   
which translates to  the fourth output from the aero code is ci1  coefficient-of-lift-1 .  script-name propositions provide a relation between the name of the computational program and the path to the script that executes the program. 
   the expert executive uses the following problemsolving paradigm:  to run a program  if all the inputs to the program are present  execute the program and return the result. otherwise find all the required input variables whose values are not known and consult the analyst for starting values. then  if all the needed inputs are still not present but there is another program  the outputs of which provide the missing inputs  run that program first.  
   this paradigm is implemented as follows. first there must be a rule for running the selected binary program. this rule may be translated as follows:  if all the values for the program's free design parameters are present  and the computation is performed  and output is obtained  and the output variables are paired with their values  then it is true that the program has been run and the result returned.  
   then  for each of the conditions there must be at least one rule with that condition as a conclusion. such a rule may be translated:  if the program is ready  all its inputs are present in the required sequence   and the script-name is known  and it is executed  and its output variables are paired with the computed values  and the computed values are asserted into the knowledge base  then it is true that results have been computed for the program.  in backward chaining to prove this rule true  the numeric computations are performed through a call to a unix shell. this call creates a process executing the named script.  in the original franz lisp implementation  this call was provided more genericaily by the function *process. . this script executes exactly the same copy of the validated program that is executed by the technology groups  thereby ensuring that data are valid and providing access to standalone  commercial software packages. also  all networking capabilities of the operating system are provided in this way. standard input and output for the script are temporarily reassigned to prolog  so that the object program reads from a prolog write routine  which writes program input values interleaved by carriage returns. program output is read analogously. when the ports are closed  the process dies. 
   this compute-result rule may fail because one of the inputs is not known. for this case there is a second rule  which translates:  if the program is not ready to run  and all the parents of the program  those programs whose output is input to the program  are found  and each of them is run  then it is true that results have been computed for the program.  
   since the rule for running the program requires that all required input values be present  the program may fail to execute on the first attempt. however  the side effects from the first attempt cause the input variables to be bound. on the next attempt  program execution will succeed. this rule is recursive  since in order to run the parent programs  it may be necessary to run the  grandparent programs. 
   the final element in this paradigm is consultation with the analyst. this is done by identifying the free design parameters whose values are unknown and requesting values for all of them at once. a menudriven user interface presents default values for all the requested variables and accepts user inputs  prompting for re-entry of values that are out of range and supplying help as requested. 
   because this paradigm is executed recursively  it can address any level of depth. since it executes the programs by starting up processes and passing inputs and outputs through ports  it can execute programs written in any language. the only applicationdependent component of the system is the fact base; the only requirement for the fact base is that it must name each input and output for each program and provide a sequence number in the argument list  so that the expert system can uniquely identify each variable and the computational codes can receive the variables in the correct sequence. since this information is explicitly given  the facts themselves need not be in any special sequence. 
   formal benchmarks have not yet been established for the expert executive. in its initial implementation in a logic-based  interpreted lisp system  increasing the number of input and output variables produced a 
   nonlinear increase in the execution time of the expert executive. even then  the elapsed time of 1 minutes of expert executive time  plus the sum of the times for the computational programs  for an actual vehicle design compared very favorably with the length of the design cycle without automated integration  which would be several weeks. we hope for improvement of at least an order of magnitude from use of compiled prolog. 
   because the primary advantage of the expert executive over a fortran executive program is expected to be the lower cost of modifying it to address new sets of computational programs  which requires one person for approximately 1 weeks for the fortran executive  the most significant benchmark for the expert executive will be its reconfiguration cost. 
reconfiguring the fact base for a new set of technology codes has required from 1 to 1 days.  we are currently automating the process of generating the fact base.  also  each program usually reauires a preprocessor and postprocessor to provide data format compatibility and to intercept dialogue; development of these has required about 1 day each. these values suggest that the cost of adding additional computational programs is linear. because the fact bases are entirely independent of the rule base  which is static  and a simple  straightforward representation is used for the fact base  we are optimistic that the expert executive will prove clearly superior in its reconfigurability. 
   development of new fact bases reauires that domain experts agree about the true logical identities of the input and output variables. this requirement is not caused by the use of an automated integration tool. even without automated tools  agreement is obtained either formally through software documentation or informally through telephone calls and scribbled notes. however  use of an automated tool makes this process more visible and moves it to the beginning of the design 
   
cycle. 
1 	knowledge representation 
   
iv the expert executive for life-cycle engineering 
   applying the expert executive to the broader lifecycle engineering problem requires incorporation of a broader range of analysis programs and cad software that can operate under the control of the expert executive. we have studied the general problem of the interaction between a commercial ecad system and another interactive software system  such as the expert executive. we have also looked at a specific ecad system and identified an approach to enabling interaction between it and the expert executive. two elements of this cad software distinguish it from other software programs previously made to interact with the expert executive:  1  the extraction of data from ecad systems for use by analysis programs and  1  the interface between the ecad man-machine interface  mmi  and the expert executive mmi. 
¡¡because cad systems generally use a proprietary internal data format  computed values cannot be written directly to the cad data base and an external format must be generated by executing a vendorsupplied data base extraction program. the resulting formatted file may then be used by special preprocessors to the analysis programs  in the same way that preprocessors and postprocessors have been generated for other technology codes. the extraction rogram supplied by the cad vendor provides the final imit on the data available for further analysis. while other data items may be available for direct use by cad vendor software  the only items available to the analysis programs are those in the external formatted file. the data formats provided by the extraction program do not necessarily match any universally adopted format and therefore require reformatting when one cad package is substituted for another. universal formats  such as the electronic data 
interchange format  would allow the substitution of cad packages with reduced data extraction effort. 
commercial cad programs contain a graphical 
mmi that will be required to interact with the mmi of the expert executive. certain vendor constraints generally limit the range of possible interactions; for example  most cad packages take control of the entire screen while they are active. since a key objective of integrating analysis into the design process is to be able to analyze the design earlier in the process  it will be necessary to define checkpoints at which analysis can be meaningful and interrupt the cad process at these points. 
   we have investigated these issues and are preparing to implement a prototype design workstation that will integrate commercial cad software with reliability  maintainability  and life-cycle cost analysis in order to rapidly explore the space of possible electronic circuit designs for a given set of requirements. we are also contemplating a mechanical cad application. 
v toward design optimization 
   the ability to generate a set of designs will require a further ability to select the best design for the requirements. we believe intuitively that key design attributes usually trade against one another; for example  if we want greater reliability  the product will cost more or require more maintenance. however  naft  found that if analysis is done earlier in the design process  significant improvements in a given attribute can be achieved at no cost in terms of the other attributes; the available design space was simply so large that it had not been adequately explored. exploring the design space is the true objective of automating the design process and incorporating it into life-cycle engineering. this same case illustrates the fact that we know very little about the trades between conflicting design attributes. for example  we would expect that designs for use in a space station and in a ground-based vehicle would differ fundamentally in their requirements for reliability  maintainability  life-cycle cost  and performance. 
   if the design requirements were made explicit  and the data relating to the attributes of existing systems were made available  it would be possible to incorporate some level of optimization into the design process. once a large design space is available  some degree of design optimization will be essential for lifecycle engineering. 

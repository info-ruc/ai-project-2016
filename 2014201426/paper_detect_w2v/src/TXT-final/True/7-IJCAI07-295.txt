
research on macro-operators has a long history in planning and other search applications. there has been a revival of interest in this topic  leading to systems that successfully combine macrooperators with current state-of-the-art planning approaches based on heuristic search. however  research is still necessary to make macros become a standard  widely-used enhancement of search algorithms. this article introduces sequences of macro-actions  called iterative macros. iterative macros exhibit both the potential advantages  e.g.  travel fast towards goal  and the potential limitations  e.g.  utility problem  of classical macros  only on a much larger scale. a family of techniques are introduced to balance this trade-off in favor of faster planning. experiments on a collection of planning benchmarks show that  when compared to low-level search and even to search with classical macro-operators  iterative macros can achieve an impressive speed-up in search.
1 introduction
research on macro-operators has a long history in planning and other search applications. recent years have shown a revival of this topic  leading to systems that successfully combine macro-operators with current state-of-the-art planning approaches based on heuristic search. however  macros have significant capabilities yet to be exploited. there is a need to continue the previous efforts on this topic  aiming to reach a point where macros would be considered to be a standard performance enhancement  e.g.  such as hash tables for fast detection of duplicate nodes .
모in this article  we introduce sequences of macro-actions called iterative macros. figure 1 illustrates the differences between low-level search  search with classical macros  and search with iterative macros. first  consider low-level search versus search with classical macros. macros add the ability to travel towards a goal with big steps  with few intermediate nodes expanded or evaluated heuristically. however  macros increase the branching factor  and often also the processing cost per node. inappropriate macros guide the search in a wrong direction  which increases the total search

figure 1: state expansion with atomic actions  left   atomic actions + macros  center   and atomic actions + iterative macros  right . each short line is an atomic action. each curved arrow is a macro-action.
time while solution quality decreases. addressing this performance trade-off is the key to making macros work.
모iterative macros are macros of macro-actions. they have similar potential benefits and limitations as classical macros  only on a much larger scale. iterative macros progress much faster down a branch of the search  with exponentially larger possible savings. on the downside  there can be exponentially more instantiations of iterative macros  with many of them leading to dead ends. an iterative macro is more expensive to compute being the sum of instantiatingeach contained macro. tuning the performance trade-off is more challenging than for classical macros.
모the model discussed in this paper extends the approach in botea et al. 1  which offers a framework for generating  filtering  and using macros at runtime. the contributions of this paper are:
1. iterative macros  a runtime combination of macros to enhance program performance 
1. new techniques to address the performance trade-offsfor iterative macros: algorithms for offline filtering  dynamic composition  i.e.  instantiating an iterative macro at runtime   and dynamic filtering  i.e.  pruning instantiations of an iterative macro at runtime ; and
1. experiments using standard planning benchmarks thatshow orders of magnitude speed up in several standard domains  when compared to low-level search and even to a search enhanced with classical macros.
모section 1 briefly reviews related work on macros. section 1 introduces the necessary definitions. section 1 introduces iterative macros and the algorithms for offline filtering  dynamic composition  and dynamic filtering. experimental results are given in section 1. section 1 contains conclusions and ideas for future work.
1 related work
related work on macros in planning dates back to the strips planner  fikes and nilsson  1 . subsequent contributions include off-line filtering of a set of macros  minton  1   partial ordering of a macro's steps  mooney  1   and generating macros able to escape local minima in a heuristic search space  iba  1 . in a problem representation with multi-valued variables  mccluskey and porteous  use macros to changethe assignment of a variable to a given value in one step.
모several recent contributions successfully integrate macros with state-of-the-art heuristic search planners such as ff  hoffmann and nebel  1 . vidal  composes macros at runtime by applying steps of the relaxed plan in the original problem. botea et al.  prune instantiations of macros based on their similarity with a relaxed plan. coles and smith  generate macros as plateau-escaping sequences. newton et al.  use genetic algorithms to generate macros. the contributions of vidal  and botea et al.  are the most closely related  since all three approaches exploit the similarity between a macro and a relaxed plan.
모application-specific macros have been applied to domains such as the sliding tile puzzle  korf  1   rubik's cube  korf  1; herna뫣dv몮olgyi  1   and sokoban  junghanns and schaeffer  1 . while interesting  a detailed discussion and comparison of all these approaches is beyond the scope of this paper.
1 framework and basic definitions
the basic framework of this work is planning as forward heuristic search. to guide the search  a relaxed plan that ignores all delete effects of actions is computed for each evaluated state  hoffmann and nebel  1 . search is enhanced with iterative macros as illustrated in figure 1  right  and detailed in section 1. the strategy for using iterative macros consists of three steps:  1  extract macro-operators from solutions of training problems   1  statically filter the set of macro-operators  and  1  use the selected macro-operators to compose iterative macros at runtime. steps 1 and 1 deal only with classical macro-operators. only step 1 involves the new iterative macros. the model of botea et al. 1 serves as a starting point for implementing the first two steps. it provides a framework for generating  filtering  and using classical macro-operators at runtime in planning. however  experiments with iterative macros showed that more powerful filtering capabilities were needed. the new enhanced method for filtering in step 1 is described in section 1.
모the rest of this section contains definitions of concepts used in the following sections. for simplicity  totally ordered macros are assumed  all definitions can be generalized to partial-order macros . the macro extraction phase builds macros with partial ordering of the steps. however  to save computation time  only one possible ordering is selected at runtime.
모let o be the set of all domain operators and a the set of all ground actions of a planning problem. a macrooperator  macro-schema  is a sequence of domain operators ms i  뫍 o together with a parameter binding : ms =
  ms ms ... ms l    .
모partially instantiating a macro can be defined in two equivalent ways as either  1  replacing some variables with constant objects or  1  replacing some operators with ground actions. the second definition is more appropriate for this work  since macros reuse actions from a relaxed plan and hence action-wise instantiation is needed. a partial instantiation of a macro is mi =   mi mi ... mi l      where   i 뫍{1 ... l}  :  mi i  뫍a뫈 mi i  뫍o .
모a total macro-instantiation  shorter  macro-instantiation  has all steps instantiated   i : mi i  뫍 a . macro-operators and macro-instantiations are the extreme cases of partial macro-instantiations. when the distinction is clear from the context  the term  macro  can refer to any of these.
모when instantiating one more step in a partial instantiation mi  it is important to ensure that the new action is consistent with all the constraints already existing in mi. more precisely  given a partial instantiation mi  a position i and a state s from which mi is being built  define the consistency set cons mi i s  as containing all actions a 뫍 a such that:
 1  a corresponds to the operator on the i-th position of mi   1  a does not break the parameter bindings of mi  and  1  if either i = 1 or the first i 1 steps are instantiated  then adding a on the i-th position makes this i-step sequence applicable to s. only actions from cons mi i s  can be used to instantiate the i-th step of mi. obviously  instantiating a new step can introduce additional binding constraints. instantiating steps in a macro can be done in any order. when step i is instantiated  its bindings have to be consistent with all previously instantiated steps  including positions larger than i.
모finally  let 붺 s a1 ...ak  be the state obtained by applying the action sequence a1 ...ak to state s. for the empty sequence such that ai cannot be applied to 붺 s a1 ...ai 1   then 붺 s a1 ...ak  is undefined.
1 iterative macros
this section describes a technique for speeding up planning using iterative macros. section 1 presents a method for statically filtering a set of macro-operators to identify candidates that can be composed to form iterative macros. section 1 focuses on integrating iterative macros into a search algorithm. methods that effectively address the challenging tasks of instantiation and pruning are described.
1 static filtering
the model introduced by botea et al.  was implemented and enhanced. botea et al. analyze solutions to a set of test problem instances to extract a potentially useful set of macro-operators. the macros are then ranked by favoring those that 1  appear frequently in solutions  and 1  significantly reduce the search effort required for each application.
two important limitations of this ranking model are that it ignores the interactions of macros when used together  and that it provides no automatic way to decide the number of selected macros.
모our enhancement first selects the top k macros  where k is a parameter  returned by the original procedure and then tries to filter this down to a subset that solves the training set most efficiently in terms of expanded nodes. since enumerating all subsets of a set with k elements is exponentially hard  we use an approximation method whose complexity is only linear in k. for each i from 1 to k  the training set is solved with macro mi in use. macros are reordered according to the search effort. more precisely  mi is better than mj if ni   nj  where nl is the total effort  expanded nodes  to solve the training set using macro ml. ties are broken according to the original ranking.
모based on the new ordering  the training set is solved using the top i macros  1 뫞 i 뫞 k. assume n is the total number of nodes expanded to solve the training set with no macros in use  nit the total effort to solve the training set with the top i macros  and b = arg min nit.
1뫞i뫞k
if nbt   n  then the learning procedure returns the top b macros. otherwise  no macros are learned for that domain.
모in the experiments described in section 1  small training instances are used  to keep the learning time low. k is set to 1  since the number of useful macros in those domains is typically less than 1. for larger domains  where more macros could be beneficial  a larger value of k might produce better results at the price of longer training time.
1 iterative macros in search
integrating iterative macros into a search algorithm raises two major challenges: instantiation and pruning. in the most general case  the total number of iterative macros applicable to a state is in the order of bd  where b is the number of classical macro instantiations applicable to a state  and d is the number of macros contained in an iterative macro. each instantiation can be expensive to compute  since its cost is the total cost of instantiating all the contained macros.
모if instantiation and pruning were performed separately  a large effort could be spent on building elements that would be rejected later. therefore a combined algorithm tries  for a given state  to build only one iterative macro which shows promise to take the search closer to a goal state. the guidance in building this iterative macro is given by the relaxed plan of the state being expanded. building a macro instantiation is founded on two simple  yet powerful ideas. first  when deciding how to instantiate a given step  heuristics are used to select an action that will allow a large number of relaxed steps to be subsequently inserted. second  for the steps not filled with relaxed plan actions  other actions are used that preserve the correctness and the variable bindings of the iterative macro. this completion is an important feature of the algorithm  since a relaxed plan often misses steps that have to be part of the unrelaxed solution.
모figure 1 shows the procedure for building an iterative macro in pseudo-code. it takes as input a global list of macro-
composeiterativemacro ms s rp  u 뫹  ;itm 뫹 empty sequence; while  true 
for  each ms 뫍 ms 
mi 뫹 instantiate ms 붺 s itm  rp   u ;
if  instantiating mi succeeded 
u 뫹 u 뫋  mi 뫌 rp ; // mark used steps itm 뫹 itm + mi; // concatenate break; // restart outer loop
if  no iteration of last for loop instantiated a macro  return itm;
figure 1: composing an iterative macro at runtime.
instantiate ms s rs  for  each a 뫍 cons ms 1 s   mi 뫹 matching a ms s rs ; if  |mi 뫌 rs| 뫟 threshold 
fill remaining gaps in mi; if  all steps of mi are instantiated 
return mi;
return failure;
figure 1: instantiating one macro-action.
schemas  ms   a current search state  s   and the relaxed plan computed for that state  rp . each iteration of the main loop tries to append one more macro to the iterative macro. the inner loop iterates through the global list of macro-schemas. as soon as instantiating such a macro-schema succeeds  the algorithm greedily commits to adding it to the iterative macro and a new iteration of the outer loop starts. this procedure automatically determines the length of an iterative macro  the number of contained macros .
모in the code  u is the set of all relaxed plan steps already inserted in the iterative macro. during subsequent iterations  the used relaxed steps will be ignored when the matching of a macro instantiation with a relaxed plan is computed. intuitively  the matching procedure tries to maximize the number of relaxed steps used in a macro-instantiation. more formal details on matching are provided later.
모figure 1 presents the instantiate procedure that instantiates one macro-action as part of an iterative macro. the input parameters are a macro-schema  ms   a search state  s   and a set of relaxed steps  i.e.  the original relaxed plan minus the already used steps . the main loop iterates through all actions that could be used as the first step of the macro ms  i.e.  are applicable to s and are instantiations of the first macro's operator .
	for each	action a 뫍 cons ms 1 s  	the method
matching a ms s rs  creates a partial instantiation of ms with first step a  followed by zero or more steps instantiated with elements from rs  and zero or more uninstantiated steps  see figure 1 and a discussion later . if the number of relaxed steps is below a given threshold  the corresponding partial instantiation is abandoned. otherwise  an attempt is made to fill the remaining gaps  uninstantiated steps  with any consistent actions. as soon as a complete instantiation is built  the method returns without considering any other possible out-
matching a ms s rs  mi 뫹 ms; // create local partial instantiation
mi 뫹 a; for  i = 1 to length ms  
if  cons mi i s  뫌 rs =   
continue; // leave mi i  uninstantiated
for  each rp 뫍 cons mi i s  뫌 rs 
undo the instantiation of mi i   if any; mi i  뫹 rp; count how many subsequent positions j
can be filled with elements from cons mi j s  뫌 rs;
select the element rp with the highest count value; undo the instantiation of mi i ; mi i  뫹 rp;
return mi;
figure 1: matching a macro instantiation with a relaxed plan.
comes. for simplicity  the pseudo-code skips the details of how the threshold is computed. an effective heuristic is to set the threshold to the largest matching encountered when the ms macro-schema is used as a parameter  regardless of the values of the other parameters a  s and rs.
모the matching attempts to use as many elements from rs as possible in a macro instantiation. an exact computation of the maximal value can be expensive  since it might require enumerating many possible instantiations of ms applicable to a state. instead  the greedy procedure presented in figure 1 tries  at step i 1 뫞 i 뫞 length ms   to commit to using a relaxed step rp for instantiating mi i . if no such step exists  i.e.  rs뫌cons mi i s  =     then mi i  is left uninstantiated. otherwise  an element from rs뫌cons mi i s  is selected using a heuristic test  see the pseudo-codefor details . in practice  the number of consistent actions quickly decreases as new steps are instantiated  since each new step can introduce additional binding constraints.
1 experimental results
classic and iterative macros were implemented on top of ff  hoffmann and nebel  1 . ff 1 handles both strips and adl domains  but not numericvariables  axioms  or temporal planning.
모this research was tested on a large set of benchmarks from previous international planning competitions. both strips  satellite  blocksworld  rovers  depots  zeno travel  driverlog  freecell  pipesworld no tankage nontemporal  pipesworld tankage nontemporal  and adl  promela dining philosophers  promela optical telegraph  airport  power supply restoration middle compiled-psr  representations were used.
모experiments were run on a 1ghz machine  with a cpu limit of 1 minutes and a memory limit of 1gb for each problem instance. planning with iterative macros  planning with classical macros  and planning with no macros were compared. to plan with classical macros  the length of an iterative macro was limited to one macro instantiation. results are shown for 1 of the 1 domains. in the two remaining domains  psr and pipes tankage  no macros were learned  since their performance on the training set was worse than low-level search  see section 1 for details .
모figure 1 shows the number of expanded nodes in each domain on a logarithmic scale for each of no macros  classical macros and iterative macros. note that some lines are missing a data point-this represents a problem instance that was not solved by that planner.
모when analyzing the expanded nodes performance  the tested application domains can roughly be split into two categories. in the first category of eight benchmarks  all 1  less driverlog freecell and pipesworld   planning with macrosis much better than low-level search. iterative macros are better than classical macros  with the notable exception of philosophers  where both kinds of macros perform similarly. in this application domain  classical macros are enough to achieve impressive savings  and there is little room for further improvement. in zeno travel  the savings in the search tree size come at the price of a relatively large increase in solution length. see figure 1 and a discussion later. when comparing iterative macros vs classical macros  in domains satellite  blocksworld  rovers  depots  and airport a reduction in the number of expanded nodes by at least an order of magnitude is seen for the hard problem instances.
모in the second category  the benefits of macros are more limited. in driverlog  macros are usually faster  but there are a few exceptions such as data point 1 on the horizontal axis  where classical macros fail and iterative macros are much slower than low-level search. in freecell  classical macros and iterative macros have similar performance in all instances. for many freecell problems  planning with macros is similar to planning with no macros. when differences are encountered  the savings are more frequent and much larger as compared to cases where macros are slower than low-level search. finally  in pipesworld no tankage the performance of macros compared to low-level search varies significantly in both directions. iterative macros are faster than classical macros  but the latter solve one more problem. no clear conclusion is drawn for this domain. further analysis of these three domains is left as future work.
모macros often lead to solving more problems than low-level search. given a domain  assume pim  pcm and p are the numbers of problems solved with iterative macros  classical macros  and no macros respectively. for our data sets and time constraints  the value of  pim  p pcm  p  is  1  in satellite   1  in blocksworld   1  in optical   1  in philosophers   1  in zeno travel   1  in driverlog  and  1  in freecell  and  1  in pipesworld.

figure 1: search effort as expanded nodes. problem sets are ordered so that the  no macros  curve is monotonically increasing.모figure 1 illustrates how macros affect the quality of solutions and the cost per node in search. each chart has 1 two-point clusters  one for each domain. first  consider the top chart. given a problem instance  assume lim  lcm  and l are the lengths of solutions when iterative macros  classical macros  and no macros are used respectively  rim = lim/l and rcm = lcm/l. the leftmost data point of a cluster shows the average  minimum  and maximum value of rim over the problem set of the corresponding domain. the rightmost data point shows similar statistics for rcm. macros slightly improve the average solution length in freecell and leave it unchanged in optical and philosophers. in all domains but zeno travel  the average overhead is at most 1% for iterative macros and at most 1% for classical macros.
모the bottom chart in figure 1 presents similar statistics for the cost per node instead of solution length l. to include a problem instance into the statistics  it has to be solved by both the correspondingtype of macros and the low-level search within a time larger than 1 seconds. we included the time threshold for better accuracy of the statistics. there always is a small noise in the reported cpu time and  if the total time is in the same order as the noise  the cost per node measurement becomes unreliable. no statistics could be collected for philosophers  both kinds of macros  and for blocksworld  iterative macros   where macros solve problems very fast.
모processing a node in low-level search includes computing a relaxed plan and checking whether that node has been visited before. macros add the overhead of their instantiation. even if much smaller than the expanded nodes savings shown in figure 1  the overhead can be surprisingly high. profiling tests have shown that the main bottleneck in the current implementation of macros is attempting to fill gaps in a partial instantiation  figure 1  line 1 . fortunately  this step can be implemented much more efficiently. when looking for a consistent action to fill a gap  the corresponding operator schema

   1   1   1   1   1   1   1   1   1   1   1 
figure 1: effects of macros on solution quality  top  and cost per node in search  bottom . the two-point clusters correspond in order to  1  satellite   1  optical   1  philosophers   1  rovers   1  depots   1  airport   1  blocksworld   1  zeno travel   1  driverlog   1  freecell  and  1  pipesworld.
is known from the structure of the macro. often  the values of all variables are already set by the previously instantiated steps. this would be enough to determine the corresponding instantiated action. however  to the best of our knowledge  no mapping from an operator together with a list of instantiated arguments to the resulting ground action is available in ff at search time. instead  our current implementation generates states along a macro instantiation and calls ff's move generator when a gap has to be filled. if an applicable action exists that is consistent with the current partial instantiation  it is used to instantiate the given step in the macro.
1 conclusion
this paper describes how macros of macro-actions  called iterative macros  can be used to speed up domain independent planning. techniques for static filtering  dynamic composition and pruning of iterative macros have been introduced to turn the trade-off between the benefits and the limitations of iterative macrosin favor of the former. experimentsin several standard benchmarks demonstrate impressive savings that iterative macros can achieve as compared to low-level search and even to a search enhanced with classical macros. worstcase behavior and solution quality remain acceptable.
모future work includes faster processing per node when searching with macros. another avenue of research is to investigate how iterative macros and relaxed plans interact with each other  and how macros can be used to improve the accuracy of the heuristic state evaluation. based on macros' success in classical planning  research should be done on using macros in areas such as temporal planning and planning with uncertainty.

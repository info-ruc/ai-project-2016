 
we present a logic which allows us to reason about acting  and more specifically about sensing  i.e. actions that acquire information from 
the real world  and planning  i.e. actions that generate and execute plans of actions. this logic takes into account the fact that  as it happens in real systems  actions may fail  and provides the ability of reasoning about failure handling in acting  sensing and planning. we see this work as a first step towards a formal account of systems which are able to plan to act  plan to sense and plan to plan  and therefore  to integrate action  perception and reasoning. 
1 	introduction 
the idea of using logic for reasoning about actions and plans has been extensively studied in the past. so far  most of this research has mainly focused on two issues. the first is the problem of providing an adequate axiomatization of actions that a system can perform in the external environment. the second is the problem 
of providing a powerful and efficient deductive planning mechanism able to generate plans automatically. the idea underlying most of this research is that a logic can be used to predict action executability and effects  and therefore to generate  good  plans  i.e. plans that when 
executed are likely to achieve the desired goals. 
모our research is related but different in focus. our work starts from an analysis of planning systems that work in real world applications. most of these systems  beyond plan generation  need to perform many different activities. for instance  they have to monitor executions  react to environmental changes  interleave planning  execution and perception  recover from failures  e.g. by replanning or by executing exception handling routines. in order to perform these activities  they need three basic capabilities: acting  sensing and planning. acting capabilities are usually provided by a repertoire of actuators which perform actions in the external environment  e.g. wheels  gripper fingers and hands . sensing capabilities are usually provided by a set of sensory devices which acquire information from the real world  e.g. sonars  odometers  cameras  microphones . plan-
sensing and planning 
luca spalazzi 
istituto di informatica 
university of ancona 
via brecce bianche  1 ancona 
italy 
ning capabilities are usually provided by planning modules which generate plans to achieve given goals  e.g. modules for plan search  interactive systems for plan reuse  and execute plans. a planning system has to activate  coordinate and control all these devices and modules several systems which control acting  sensing and planning have been proposed so far  see for instance  beetz and mcdermott  1; georgeffand lansky  1; simmons  1   and have been successfully applied in particular application domains  like mobile robots and fault diagnosis for real time systems . in spite of this fact  no principled and theoretical account has been given of the behaviours of these systems. 
모the goal of this paper is to provide a logic which allows us to represent and reason about acting  sensing and planning. the motivation is twofold. first  the logic can be used to provide a specification of real systems which allows us to understand their requirements. second  the logic can be used as a basic formal framework for building reasoning modules within real world applications. it can in fact be used to plan to act  plan to sense and plan to plan  and therefore to decide how to interleave acting  sensing and planning. we see this work as a first step towards a formal account of systems which are able to integrate reasoning  perception and action. 
모in order to achieve this goal  the logic we propose has some novel features. first  it is based upon an extended notion of action. the logic represents explicitly sensing actions  i.e. actions that acquire information and mod-
ify the state of knowledge of the agent  and planning actions  i.e. actions that generate and execute plans of 
actions. as a consequence  not only can the logic reason about the effects of actions in the real world  but also about the fact that a sensor has  not  been used to update the knowledge of the system about the world and the fact that the system has  not  a proper plan at hand which can be executed to try to achieve a given goal. second  in real systems  no action  even if apparently simple  is guaranteed to succeed. this is mainly due to the intrinsic complexity of reality  to the fact that the external environment is usually incompletely known and unpredictable  and to the fact that actuators  sensors and models of the world are not perfect. as a consequence  neither acting  nor sensing  nor planning is guaranteed to succeed. the logic we propose has in its language the basic operations for failure handling 

and can therefore reason about failure detection and recovery in acting  sensing and planning. 
모the paper is structured as follows. we describe the language of the logic in section 1 and its semantics in section 1. we give some axioms and theorems of the logic in section 1. we discuss some related work in section 1. 
1 	language 
the logic is a variation of process logic  harel ex a/.  
1   an extension of dynamic logic  harel  1 . in section 1 we describe a language for action. in sections 1 and 1 we extend the language to represent sensing and planning actions  respectively. 
1 	acting 
the syntax of the logic is based upon two sets of symbols: po  the set of atomic  or basic  propositions and 1o  the set of atomic  or basic  tactics. from vo and 1o we inductively construct the set v of propositions and the set t of tactics. v and t are the smallest sets such that: 

we use v  -  and  -  as abbreviations in the standard way and  in addition  we abbreviate - a - p to {a}p as in dynamic logic1. 
   propositions are either true or false in behaviours  we say that they are behaviour propositions   where  intuitively  a behaviour is a finite sequence of states of the world. for example  if w1  w1  w1  w1 and w1 are states  then w1 w1 w1 w1 w1 is a behaviour. a single state is a particular case of behaviour  w is the proposition which holds over any behaviour which consists of a sin-
gle state. the operator chop is applied to propositions p and q to yield a new proposition p chop q. chop is used to reason about concatenations of behaviours  where  for example  the concatenation of w1 w1 w1 and w1 w1 w1 is w1 w1 w1 w1 w1. p chop q holds in a behaviour b iff there exist two behaviours b1 and b1 such that the concatenation of by and b1 is b  p holds in b1 and q holds in b1- we extend the language with the operator last which is applied to a proposition p to yield a new proposition last p . 

last p  holds in a behaviour b iff p holds in the final state of b. 
모tactics represent actions. for instance  goto a  can be a basic  even if very complex  action which moves a 
     1  actually  the language allows for tactics that include conditional expressions of the form if p then a else b and loops of the form while p do a. for lack of space  in this paper we do not describe the full syntax. the language  as well as its semantics  can be easily extended. 
1 	temporal reasoning 

we define the usual construct ; for sequences of actions. in a;/  the second action is executed anyway  independently of the failure/success of the first action. notice that ; is a primitive construct in most of the logics proposed so far  e.g. in dynamic logic  harel  1   in process logic  harel et a/.  1   in  extended versions of  situation calculus  lesperance el al  1  and in all theories of actions  e.g. in  lifschitz  1 . this is due to the fact that ; constructs sequences without handling failure and these logics do not take into account failure. a sequential composition which takes into account failure is then. if the first action fails  then does not execute the second  but simply terminates execution with failure. then captures the behaviour of sequential executions in real systems where  if the first action fails  the second is not executed and control is passed to a module for failure recovery  or else is the construct for failure recovery. orelse a b  reacts to failure of a by executing b. repeat controls failure over the repeated execution of a tactic. it is recursively defined. it repeats the execution of a till a fails. if a never fails  execution does not terminate. notice that if it terminates  repeat a  always succeeds  
1
모모 more precisely  basic tactics are constructed from a set of terms  e.g. a  and a set of tactic symbols  that  intuitively represent action types  e.g. goto. for lack of space we skip the formal definition of the syntax of basic tactics. 

since orelse in the definition of repeat reacts to failure by executing   which always succeeds. 
1 	s e n s i n g 
we extend the language with a set c of symbols that we call sensors. for any sensor  we add a tactic and a proposition to the set of basic tactics and propositions. 

intuitively  sensors denote values which can be acquired through sensory devices. for instance  wall-distance can be the sensor which gets the value of the distance of the robot from the wall. we call sense c  a sensing action  for c . its intended meaning is  acquire the value of the sensor c . for example  sense wall-distance  can activate a sonar and/or a camera to acquire the value of wall-distance. 
모sensing actions formalize activities that real systems have to perform extensively. indeed  while most theories of actions are based on the assumption that  after acting is performed  the agent has at hand all the desired information about the new state of the world  this is not what happens in real systems. most often  in real systems  the only way to get to know some facts about the state of affairs is to activate sensory devices and acquire information from the external environment  i.e. to execute sensing actions. suppose for instance that a robot moves successfully to a given position a. at this point  the world around the robot has changed: its position has changed  as well as the distance from the wall  the distance from the nearest window  and so on. it is not realistic that the robot gets to know all these facts automatically after execution. for instance  after acting  knowledge about its position might be updated automatically  but it may have instead to measure  e.g. by a sonar or a camera  the distances from the wall  objects and landmarks to get to know their new values. real 
systems have therefore to execute sensing actions explicitly. for instance  suppose that goto a  is a tactic which does not update the value of the sensor wall-distance. a possible tactic which moves the robot to a and then acquires the value of the distance from the wall is the following. 
		 i  
a sensing action may fail. for instance  sense{wall-distance  may fail since the sonar may not work or the camera may fail to detect the wall. in example  1   if sensing fails then the value of wall-distance is not updated. 
모successful sensing actions update the state of knowledge of the agent since  at the end of their execution  the value of the sensor is acquired. this knowledge is expressed by the proposition sensed c   which holds in any behaviour which is the final state of a successful sensing action for c. the idea here is that sensed c  holds if we have just executed a successful sensing action for c and therefore the value of c is  up to date . for instance  consider the following propositions. 


proposition  1  states that goto a  does not update automatically the distance from the wall  i.e. after executing goto a  either with success or failure  ex goto a   t then we get to a final state where wall-distance is not up to date   l a s t  sensed{wall-distance   . proposition  1  is the analogous statement for the tactic goto b . the value of the sensor is up to date if the sensing action succeeds  proposition  1  . if we execute goto b  after sensing  then the value is not up to date  proposition  1  . indeed  the last action might change the actual distance from the wall. notice that the fact that the truth value of sensed c  changes does not depend on the fact that the value of c changes or not. for instance  propositions  1 - 1  may hold even if wall-distance is constantly the same before and after the executions of goto a   goto b  and sense wall-distance . 
1 	p l a n n i n g 
we add to the language a set ii of symbols  that we call names of tactics  which is based upon an initial set of 
symbols 뷇  and we extend the set of basic tactics and propositions as follows  

we call  a  the name of the tactic a. names of tactics denote tactics. for example  the name of goto a  denotes the syntactic expression goto a . the idea here is that planning generates a syntactic expression denoting a plan which can thereafter be executed. we call planfor -jr p  a plan generation action  of 뷇 for p . its intended meaning is:  generate a plan denoted by 붫 to achieve the goal p . for example  if robot-at-a is a proposition whose intended meaning is  the robot is in position a   then plan for {뷇  robot-at-a  can be a tactic that generates the name n which denotes the simple plan goto a . we call exec tr  a  plan  execution action  of it . its intended meaning is:  execute the 
plan denoted by tt  . for example  the intended meaning of exec{ugoto{a    is:  execute the plan denoted by  goto a   . we call plan generation and execution actions  planning actions. as an example of combination of planning actions  consider the following tactic which generates a plan and then executes it. 
		 1  
모since plan execution actions may perform actions in the real world  they may fail. failure in plan execution can be handled in different ways. most classical planners  e.g.  wilkins  1   handle failure by replanning  i.e. by searching for a new plan. reactive planners  e.g. 


1 	temporal reasoning 




1 	temporal reasoning 

where p and r are a fluent and a term  respectively. knowledge about perception is expressed by means of wffs of the form knows p a  and kref r  s   where * is a situation. technically  our approach is different since we have no situations in the logic. moreover  in this paper we have described a class of sensing actions which is less expressive than the class of perception actions defined in  lesperance et ai  1   however  the given language  semantics and axiomatization can be easily extended to include sensing actions about propositions and terms. conceptually  our work differs mainly in two aspects. first  our logic captures the fact that perception is a complex task that  when it has to be performed by real systems  is not guaranteed to succeed. actions of the form sense c  may actually fail to acquire information and therefore fail to produce knowledge. as a consequence  in our logic we do not have theorems analogous to kref r do readr s    which can be read as  after doing read  the agent knows the denotation of r   but we can prove theorem  t1   i.e.  if sensing sueceeds  then the agent has sensed c . second  our logic allows us to express and reason about planning actions  while  lesperance et ai  1  does not. 
모the closest work on planning actions is that described in  steel  1b   see also  steel  1a    where dynamic and epistemic logic are used to express formulas of the form  plan to do an action that achieves a goal  then do it . the main differences with our work are the following. first  in  steel  1b  plan generation is seen as  specialization  of  non operational  actions  i.e. actions which cannot be executed. we see instead plan generation as an executable action which constructs a plan. this corresponds to the fact that systems have planning modules which can be activated to generate plans. second  in  steel  1b   planning is seen as an action which does not affect the external environment while we do not rely on this assumption since many reactive planners have to generate plans by acting in the world. finally  our logic deals explicitly with failure handling in plan generations and executions. 
the logic we have proposed is based on work on mrg 
 giunchiglia et at.  1; traverso ei ai  1   a reactive planning system which executes tactics. at the moment  mrg is used in a large scale  real world application under development at irst. this application aims at the development of a system that has to control and coordinate mobile robots  navigating in unpredictable environments inhabited by humans and performing high level tasks  like transportation tasks in hospitals and offices. mrg tactics are executed by means of systems that perform sensing and acting  e.g. a reactive sensor and actuator controller for navigation tasks and a system for speech recognition  and by means of systems that generate and execute plans  e.g. path planners and activity schedulers. we plan to use the formal framework to extend the functionalities of mrg and to specify the requirements of the application under development. 
acknowledgments 
we thank fausto giunchiglia for his invaluable support  and for all his many conceptual and technical comments on early drafts of this paper. they have contributed to improve the paper significantly. we also thank luciano serafini for fruitful discussions. 

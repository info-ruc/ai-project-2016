 
to date  reactive robot behavior has been achieved only through manual programming. this paper describes a new kind of plan  called a  universal plan   which can be synthesized automatically  yet generates appropriate behavior in unpredictable environments. in classical planning work  problems were posed with unique initial and final world states; in my approach a problem specifies only a goal condition. the planner is thus unable to commit to any specific future course of events but must specify appropriate reactions for anticipated situations. an alternative conception is that one universal plan compactly represents every classical plan. which part of the universal plan is executed depends entirely on how the environment behaves at execution time. 
universal plans are constructed from state-space operator schemas by a nonlinear planner. they explicitly identify predicates requiring monitoring at each moment of execution  and provide for sabotage  serendipity and failure without requiring replanning. 
1. introduction 
1. scope of this paper 
the work described herein continues my efforts toward synthetic reactivity  i.e. the automatic synthesis of robot programs capable of realtime performance in an unpredictable and/or dynamic world. this paper presents a solution to the problem of achieving a satisfying integration of goal-directed advance planning and sensor-driven reaction  without resorting to human programming. 
by now  the problems with the so-called  classical approach  to planning are old news. without going into tedious detail: state space planning requires a great deal of information up front  is time-consuming  and delays the arrival of suitable actions; its plans must eventually be very detailed or else may risk failure; even so  they are brittle  being unsuited to temporal continuity and uncertainty. 	the 	core 	problem 	is 	one 	of 	overcommitment. 
the use of abstract plans  of partial plans  and of  reactive procedures   side-steps the early commitment problem by interleaving plan refinement and execution. the penalty is that acting on an incomplete plan may make the goal permanently unachievable: the planner may paint itself into a corner. 
the work reported in this paper is the first fruits of a larger project concerned with the integration of planning  executing  sensing  and reacting. as a first step  that project will drive a robot arm in an environment that is rather less cooperative than a blocks world. the focus of the work is not on the robotics but on the planning  however  and this paper will be even narrower  concentrating on the plan representation and interpreter i have developed. 
1. mischief in the blocks world 
we are to solve the following benchmark problem. 1 have cast this problem in terms of a blocks world  to clarify  by way of contrast with the familiar  the issues involved. 
　as in most blocks worlds  all the blocks are cubical and of unknown size; every block can be stacked on every other; and the usual 1on-1 stacking rules apply. in addition we have a robot arm with a hand as our only means of moving blocks. on the other side of the table from the robot there is a mischievous baby who will flatten block towers  snatch blocks out of the robot's hand  and even throw blocks at the robot. the robot may not snatch blocks back  may not touch the baby  and cannot keep anything out of the baby's reach. as partial compensation we are given an unlimited set of sensing devices. the robot is to achieve the usual tower of blocks: a on b on c. devise plan execution software enabling the robot to cope efficiently with this domain. 
	schoppers 	1 

this problem highlights some issues that are challenges to the state of the art in ai and robotics: 
  the robot's knowledge is incomplete  lacking the blocks' sizes. the missing information must be mitigated if the hand is to pick up any blocks. 
  the problem does not specify the current state of the world - neither the current locations of blocks  nor the position of the hand. 
  the environment is capricious  allowing failure  sabotage and serendipity. actions may not achieve their intended effects  and effects already achieved may not persist. 
these items all have to do with the robot's behavior in the face of uncertainty  whether due to ignorance or to a dynamic environment beyond the robot's control. the work reported here is the first example of problemindependent synthetic reactivity. 
1. solution approach 
accurate prediction being notoriously difficult  i have moved toward the other extreme  relying heavily on reaction. that in itself is not novel. the novelty of my approach arises from the fact that the representation i use to encode robot behaviors specifies appropriate reactions to every possible situation within a given domain  yet can be synthesized automatically and at moderate computational cost. 
universal plans convey highly conditional advice of the form: 
// a situation satisfying condition p should ever arise while you are trying to achieve goal g  then the appropriate response is action a. 
there is no commitment to any particular sequence of events; in fact  universal plans contain little sequence of any kind. instead  the task of the planner is to partition the set of possible situations on the basis of the reaction each situation requires. at execution time the actual situation is classified  and the response planned for that class of situation is then performed. thus the behavior of an agent executing universal plans depends critically on which situations arise at execution time. such reactivity allows universal plans to generate appropriate behavior even in unpredictable environments. 
the behavior of agents executing universal plans is also goal-directed. if the world is cooperative long enough  each action will have its expected effects and the net 
1 	reasoning 
behavior will be indistinguishable from that generated by a linear plan. no matter how the environment behaves  however  a universal plan always selects the action that would  in a cooperative world  move the current situation toward the goal. 
the difference between the classical planning approach and that of universal plans is summarized in figure 1. in 


	figure 1: 	plan monitoring vs planned reaction. 
classical planning work  problems are posed with a specific initial world state  and plans are restricted not only to a particular set of situations but also to a 
specific ordering on those situations. any predicates associated with individual actions are used only to determine whether an action has been completed  and whether it was successful. if so  the next action to be executed is determined from the sequence imposed by the planner  not from any knowledge of the environment. when an action fails to produce a 'go  outcome  the only recourse is to replanning  beginning with the newly produced situation. 
in my approach a problem specifies only the goal condition - no initial state and no unique final state - so that the planner cannot over-commit to a specific future course of events. instead the planner must anticipate possible situations and predetermine its reactions in those situations. the sensing module takes over the function previously served by sequencing  namely that of indexing into the set of available actions. and because the planner does not commit itself to a particular future  replanning is no longer necessary  no matter what serendipity  sabotage or failure takes place. 

　triangle tables are restricted to a subset of poasible situations but not to a sptcific ordering. see section s. 

the fact that universal plans can be generated automatically allows for a rather novel perspective: 
planning is the goal-directed selection of reactions to possible situations. 
this view bridges the chasm between goal-directed planning and situation-driven reaction. it makes all behavior reactive  but allows for rationality in the prior selection of reactions. the notion of an action's success becomes irrelevant to the process of plan execution; this reflects the intuition that no plan is knowably foolproof until after it has succeeded. just as success cannot be known until execution time  so the actual course of events cannot be known in advance: the idea of a procedure is an abstraction  practically applicable only in non-real-world environments. to realize plans as procedures is to equate plan structure with the seriality of behavior-through-time. in other words  some particular sequence of events is inescapable at execution time  but is a major over-commitment at planning time. 
1. inputs to the planner 
1. primitive actions 
that the planner must drive a real robot arm has some important consequences. for example: we can no longer pretend that it is irrelevant how big the blocks are. in fact we must consider how to cope with positions and distances in general. the approach i describe here is well below the level of abstraction adopted by previous blocks world planners  and is borrowed in part from the rex project at sri  cf. section 1 . 
the readings returned by all sensors are integers. the speed and acceleration values sent to the robot arm are also integers. in between  the most primitive actions are numeric functions. for example  if the arm is at x 
	r 	now 
and we want it to stop at x. in the shortest possible time  we define speed-up as in figure 1a. 
the functions for a slow-down stage are similar. 
whenever we get new values for x 	or v 	  or even 
	＜ 	now 	now 
for  the arm's speed and acceleration can be adjusted to suit. of course  a n d a r e constantly changing. thus  computing new arm motion parameters from current sensor readings establishes a feedback loop. 
we must also specify when each stage should be used 
 figure 1b . there are three relevant predicates: is the arm at its destination  moving in the right direction  moving as fast as its destination will allow  depending on the truth or falsity of these predicates  one of alow-down and speed-up will be imposed between sensors and effectors. 
notice that these primitive actions are very different from traditional plan primitives in that they represent i/o conditions to be maintained for some unspecified length of time  not conditions to be achieved in the world. how long a given constraint is in force depends entirely on the environment. moreover  there is no particular order in which speed-up and slow-down must be executed: that too is determined by the environment. 
at this point we must diverge from the rex project mentioned earlier. by design  figure 1b can be expressed as the  universal plan  of figure 1c. 
a synthesizer of universal plans must determine under what conditions the feedback functions should be imposed so as to achieve some condition in the world. how the necessary information is communicated to the planner is the topic of the next section  which proceeds with  actions  at the level of umove to x . the main point of the present section was to show that what lies below that level of abstraction is in fact identical to what lies above: even the most primitive sensori-motor feedback constraints can be controlled by universal plans. 


figure 1: 	implementing arm motions with feedback. 
	schoppers 	1 

1. action descriptions 
the task of decomposing block transfers into more primitive actions reveals an interesting ambiguity in the interpretation of  action . on the one hand  from the robotics perspective it is immediately obvious that five physical motions will suffice  namely: close the hand as far as possible; open the hand completely; lower the hand vertically as far as possible; raise the hand vertically to some maximum height; and move the hand horizontally until above some target location. each of these motions can be implemented straightforwardly by feedback functions as described in the previous section. hence the blocks world domain requires only five physical actions. on the other hand  capturing the blocks world at the level of such actions requires about 1 strips-like operator schemas. which are we to regard as an action: the actual motion  as identified by the function driving the arm  or what actually happens  as described by the operator schema  
contrary to ai tradition  i chose to conceive of actions in terms of the robotic functions used to realize them  and to regard operator schemas as effect descriptions. now the same action can produce multiple effects depending on the environment in which it is executed  cp.  side-effects  . raising the empty hand is precisely the same  action  as raising the hand while holding a block  yet their effects are different  and moreover  each effect is necessary at different times. the problems and benefits of planning with alternative effects cannot be detailed here  however. 

1 	reasoning 
when an action is described to the planner  figure 
ops   the pre- and post-conditions of its effects need not be complete: my planner utilizes an extension of the logic of ginsburg  counterfactuals  to infer missing preand post-conditions  e.g. that  to lower the hand around block x  the hand must be over x to begin with . 
1. domain constraints 
i will not discuss the logic that determines which world states are possible and impossible; it is intuitively obvious  e.g. if the hand is open it can't be holding anything . what is crucial  however  is that the planner can deal with partially-determined world states. that occasionally involves facts of the form  something is on block a . in predicate logic  and all previous blocksworld planners  such facts would be encoded as existentially quantified formulae within a world state model  and would give rise to considerable difficulties in ensuring a consistent world description. i solve this problem by using a possible-worlds tms  tms  to encode and compute with world descriptions. this particular tms will accept clauses of the form 

the fact  something is on block a  is encoded as -xlear a   which means that one of on b a  or on c a  must be true for the above clause to remain valid. there is no need for an explicit existential in the world description: there is an implicit existential in the restriction logic. 
the planner manipulates multiple tms instances  all sharing the same logic but having different truth value assignments. thus  the planner can represent partial knowledge of the world at any point in the plan. more will be said in section 1 about the importance of this for universal plan synthesis. 
1. the goal 
the problem to be solved is posed to the planner as a condition to be achieved  not as a particular world state. for the problem discussed in the next section the goal is on a b atop - how to stack a onto b and leave it there - and there are still 1 world states that satisfy this goal condition  the final location of c and the final state of the hand are variable . the initial state of the world is irrelevant at planning time. 

1. universal plans 
1. interpretation 
the plan interpreter finds the action that is relevant to the current state of the world by using the completed universal plan as a decision tree. the pre- and postconditions of operators are evaluated in the current real world  and so determine  at each node  which branch should be traversed next. exactly how these decisions are made will be detailed below. eventually the interpreter arrives at the currently appropriate action. just as that action's location in the tree specifies the path necessary to reach it  so its being chosen as appropriate specifies what conditions are true in the world. as long as those conditions remain true  the chosen action remains appropriate. when they change  the interpreter must search the tree again for the next appropriate action. 
granted  and it is not trivial. we can extract from the plan a series of partial world descriptions with specifications of an action appropriate to the worlds described. this procedure involves a  method of assumed preconditions . beginning with the root node conditions  assume them to be true  and note that no action is necessary. now proceed backwards along the root node conditions  assuming them to be false  and in each case see what action is necessary to reverse the falsified condition. assume the preconditions of this action  if any  to be satisfied. this generates a partial world description in which the action is appropriate. now assume that the preconditions of the selected action are false... and so on  recursively. the result is shown in figure 1. 
	schoppers 	1 

simplest case  only the last false condition in the active path will change to true  indicating that the current action has achieved its postconditions  and leading to what would be the next step for a classical sequential plan. it is also possible that some condition changes higher up in the tree. this corresponds either to serendipity or to sabotage. 
the decision tree form makes obvious the fact that every possible world state is provided for somewhere  simply because both outcomes of every predicate are classified eventually. hence the name   universal plan . an immediate consequence is that universal plans have no preconditions: they always apply. the kind of composition that produces universal plans is very different from the concatenation of sequential plan fragments. 
the stack a b  decision tree is never embodied as a data structure  but is merely a convenient description of how the interpreter executes a universal plan. the 
universal plan structure is used as a template from which a sequence of predicates is simultaneously extracted and evaluated  following the pattern of the above decision tree. 
1. hierarchy 
recall that in section 1 the lateraling action was itself expressed as a universal plan. hence  universal plans can be used to construct behaviors from the most primitive levels up. equally importantly  it follows that something viewed as an  action'1 by the stack a b  plan can in fact be another universal plan. the ability to reuse a universal plan as a primitive reaction at a higher level gives us a form of abstraction: the planner can remain ignorant of the conditions used within lateral. now it is easy to see that abstraction can also continue upwards beyond the stacking of individual blocks. the plan to build a tower of three blocks can be translated into the decision tree: 
on c.tabic    
t  on b c    
t  on a b    t  no-op 
             f  stack a.b  f  ttack b.c  f  unttack c  
by determining the currently appropriate block transfer action  and hence the currently appropriate arm motion  and hence the currently appropriate feedback constraint  this plan will achieve the a b c tower from any initial state  and no matter what serendipity or sabotage occurs in the meantime. notice also that this is the first plan representation capable of capturing the intuition that 
1 	reasoning 
block towers should always be built bottom-up. sequential plan representations provide no way to express this general heuristic  forcing it to become part of the planner's domain specific knowledge instead. 
1. competence 
in principle  once we have a universal plan for a nonconjunctive goal g  such as holding a   we actually have two ways to achieve g: the plan  and the  primitive  action a  in this case  grasp  that finally brings about g. how do we know which one to use if g becomes a goal in subsequent planning  
this problem is an artifact of poor plan representations such as the traditional sequential one. remember however that a universal plan is applicable in any initial situation. in particular  the universal plan p to achieve g applies also in situations to which a applies  whereas a's applicability remains restricted by its preconditions. 
consequently a  as a means of achieving g  is completely superseded by p  and might as well be forgotten. the construction of a universal plan represents a major increase in competence. 
1. p l a n synthesis 
the planner builds a universal plan by back-chaining from the goal condition  using the effect descriptions as goal reduction operators. there is a subtle difference from ordinary back-chaining  however: when a precondition becomes the goal of subsequent backchaining  the negation of that precondition must be true of all the situations occurring in that subplan. that is  the subplan to achieve on a b  need only consider worlds in which on a b  is not true. this is the planning-time version of the execution-time  method of assumed preconditions . back-chaining terminates when the accumulation of goals above the current locus of control either forces the satisfaction of the preconditions being examined  or leads to contradiction. it is not necessary to consider each possible world state individually: the planner may assign the same reaction to groups of states  considered en masse in the form of a world state schema. hence  universal plan synthesis is at least as efficient as synthesizing linear plans  see section 
1 . 
whenever an effect description has multiple preconditions  goal conflicts are possible. the reasoning required to resolve goal conflicts is complicated by both the new plan representation and the multiplicity of effects per action. details must be left for another paper. 
identifying preconditions with goals at planning time can be continued into execution time. when the decision-tree 

version of universal plan execution applies predicates to the environment  every false predicate is a failed precondition and hence a planning-time goal. thus  the locus of control at execution time explicitly determines the goals being pursued  so that even the agent's goals are subject to the environment. 
1. related work 
my 	experience 	with 	using 	georgeffs 	procedural 
reasoning system  prs   1  1  to control an autonomous mobile robot  was seminal for this work. the goal of that project was to reduce the amount of advance planning  and hence of advance over-commitment  by decomposing behaviors  by hand  into sequences of goals  and by selecting at run-time the behavior to achieve each goal. in some respects the project succeeded: in navigating the robot around an office building  the planner's floor map became a connection graph  containing no advance knowledge at all about widths of hallways and distances between doorways. that information was acquired en route from sensory input. in other respects  however  progress was less than satisfactory. if the robot sensors saw a doorway where none existed it would get stuck just as helplessly as if it had been measuring distance. it succeeded in eliminating dead reckoning by distance maps only to have it reappear as dead reckoning by connection graphs. armed with our knowledge of universal plans  we can now see that the prs work did not go quite far enough in its attempt to achieve reactivity: it experimented with situation-dependent selection of means to achieve goals  but not with situation-dependent adoption and abandonment of goals. the fundamental difficulty was the rigidity of prs's procedural control structure. nevertheless  prs's ability to eliminate dead reckoning from lower abstraction levels was instructive  and on subsequent analysis pointed to the importance of having actions whose duration depends on the sensed environment  and to a robotics-oriented view of motion. 
the rex project  1  1  was equally influential: the behavior of a situated automaton is always contingent on the state of the environment. indeed  the contingency assumes precisely the forms i have adopted for universal plans  with continuously evaluated predicates determining which numeric feedback function should be executed. my approach differs from that of the rex team in that universal plans are produced automatically  and are therefore symbolic and highly constrained structurally  while rex automata are handcoded. indeed  symbolic representation of a rex automaton's knowledge is considered not only 
　　1i am indebted to ken dove of advanced decision systems for the wording of this observation. 
superfluous but undesirable; instead  the automaton's state is a function of the entire contents of its memory. this lack of symbols is somewhat disconcerting from a planning point of view. the rex project is emphasising analysis of the information content of situated automata synthesized by hand; i am emphasising the automatic synthesis and control of reactive behavior. 
triangle tables ; l   1  are synthesized by extracting  from a conventional linear plan  the set of expected world states and the set of needed operators  then reorganizing the predicates involved to form an index into that set of operators. this reorganization increases the competence of the original plan  from coping with a specific set of situations in a specific order to coping with that set of situations in any order. thus  triangle tables were first to give the environment a hand in selecting the operator to be performed next. that in itself is not sufficient  see my comments on prs above   but it is a quirk of the rigidity of linear plans that selecting an operator instance also selects a control state. serendipitously  triangle tables allow the environment to dictate the interpreter's  apparent  goals. that feature is crucial  and has been made explicit by universal plans. 
1. critique 
1. computational complexity 
universal plans not only anticipate every possible situation in a domain but actually prescribe an action for every initial state; moreover  the prescribed action is usually optimal. these remarks suggest that universal plans must be limited to very small problem spaces. 
universal plan synthesis is not a graph search problem  however. the blocks world as i solved it has  1 possible world states  but the planner makes use of predicates and effect descriptions to decompose the problem space. in fact  universal plan synthesis is closer to a classification problem: given a set of possible situations  with an appropriate reaction already assigned to each situation  what is the complexity of producing a decision tree  in the best case the effort required to classify n distinct situations may be 1 log n  . only in the worst case  when each possible situation must be classified at a different leaf node  does the classification effort become o n . for comparison  the total effort expended by a planner that produced a new plan for each initial situation would be o n  at best. 
1. blocks world problems 
the current planner relies on a strips-like effects representation  restricting the plans to domains 
	schoppers 	1 
representable as state spaces  but this is not necessarily as serious as contemporary ai milieu might think. clearly  in my case the state space representation has not condemned me to a static and predictable environment  nor to dead reckoning  nor to complete knowledge of every world state considered. such limitations are artifacts of the reasoning engine  not of the problem representation. 
neither have i been condemned to instantaneous actions and discrete worlds. state spaces may be inadequate to reasoning about continuous processes  but when sensory information is exploited to control both the current action and the manner of its performance  the increased behavioral competence removes much of that burden from the reasoning engine. the inability to respond to continuous stimuli is an artifact of sensory deprivation. 
1. the sensing bottleneck 
sensing is the only reliable means to obtain feedback from the environment  but for many kinds of sensor  the rate at which readings can be converted to usable information is relatively slow. universal plan execution  however  relies on sensory feedback continuously  and needs predicates from a variety of sources. the problems are aggravated in domains requiring knowledge of objects other than the robot itself  such as the locations of blocks when those locations cannot be controlled. 
if some predicate can only be evaluated infrequently  only domain-dependent considerations can determine how the robot should proceed in the meantime. it may turn out that predicates near the root of the universal plan are less crucial  for example  or that it is more effective to temporarily ignore the values of some predicates than to monitor them closely. at least the decision tree form of universal plans makes very clear what predicates are relevant to each reaction  and so may facilitate the determination of how to proceed at each point. this in itself is a useful contribution. 
1. summary 
this paper has shown how to integrate goal-directed planning with situation-driven reaction in the case of robotic motion  namely by redefining plans so as to eliminate the over-commitment  inherent in procedural representations  to a particular course of events. given suitable sensory input  the resulting plan representation generates appropriate behaviors even in unpredictable environments  allowing the environment to determine the robot's current goals. this achievement encourages a new perspective on planning as choosing reactions for 
1 	reasoning 
situations that might arise  and on plans as never guaranteeing success. the universal plan structure replaces procedural indexing with sensory indexing; makes explicit the conditions under which actions are applicable; renders notions of success and failure irrelevant at execution time; and encourages hierarchy. 
acknowledgements 
this work has been supported in part by an internal 
r&d grant from advanced decision systems. i especially appreciate the encouragement they provided when ray ideas were still emerging. thanks also to stan rosenschein  mike georgeff  amy lansky and leslie 
kaelbling  sri ai  for allowing me to participate in their progress  and to john myers  sri robotics  for being a constructive critic of a first draft. 

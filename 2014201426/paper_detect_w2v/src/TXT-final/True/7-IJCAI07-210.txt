
we show how solution concepts in games such as nash equilibrium  correlated equilibrium  rationalizability  and sequential equilibrium can be given a uniform definition in terms of knowledge-based programs. intuitively  all solution concepts are implementations of two knowledge-based programs  one appropriate for games represented in normal form  the other for games represented in extensive form. these knowledge-based programs can be viewed as embodying rationality. the representation works even if  a  information sets do not capture an agent's knowledge   b  uncertainty is not represented by probability  or  c  the underlying game is not common knowledge.
1 introduction
game theorists represent games in two standard ways: in normal form  where each agent simply chooses a strategy  and in extensive form  using game trees  where the agents make choices over time. an extensive-form representation has the advantage that it describes the dynamic structure of the game-it explicitly represents the sequence of decision problems encountered by agents. however  the extensiveform representation purports to do more than just describe the structure of the game; it also attempts to represent the information that players have in the game  by the use of information sets. intuitively  an information set consists of a set of nodes in the game tree where a player has the same information. however  as halpern  has pointed out  information sets may not adequately represent a player's information.
¡¡halpern makes this point by considering the following single-agent game of imperfect recall  originally presented by piccione and rubinstein : the game starts with nature moving either left or right  each with probability 1. the agent can then either stop the game  playing move s  and get
email: moses ee.technion.ac.il

figure 1: a game of imperfect recall.
a payoff of 1  or continue  by playing move b. if he continues  he gets a high payoff if he matches nature's move  and a low payoff otherwise. although he originally knows nature's move  the information set that includes the nodes labeled x1 and x1 is intended to indicate that the player forgets whether nature moved left or right after moving b. intuitively  when he is at the information set x  the agent is not supposed to know whether he is at x1 or at x1.
¡¡it is not hard to show that the strategy that maximizes expected utility chooses action s at node x1  action b at node x1  and action r at the information set x consisting of x1 and x1. call this strategy f. let f be the strategy of choosing action b at x1  action s at x1  and l at x. piccione and rubinstein argue that if node x1 is reached  the player should reconsider  and decide to switch from . as halpern points out  this is indeed true  provided that the player knows at each stage of the game what strategy he is currently using. however  in that case  if the player is using f at the information set  then he knows that he is at node x1; if he has switched and is using f  then he knows that he is at x1. so  in this setting  it is no longer the case that the player does not know whether he is at x1 or x1 in the information set; he can infer which state he is at from the strategy he is using.
¡¡in game theory  a strategy is taken to be a function from information sets to actions. the intuition behind this is that  since an agent cannot tell the nodes in an information set apart  he must do the same thing at all these nodes. but this example shows that if the agent has imperfect recall but can switch strategies  then he can arrange to do different things at different nodes in the same information set. as halpern  observes  ' situations that  an agent  cannot distinguish  and  nodes in the same information set  may be two quite different notions.' he suggests using the game tree to describe the structure of the game  and using the runs and systems framework  fagin et al.  1  to describe the agent's information. the idea is that an agent has an internal local state that describes all the information that he has. a strategy  or protocol in the language of  fagin et al.  1   is a function from local states to actions. protocols capture the intuition that what an agent does can depend only what he knows. but now an agent's knowledge is represented by its local state  not by an information set. different assumptions about what agents know  for example  whether they know their current strategies  are captured by running the same protocol in different contexts. if the information sets appropriately represent an agent's knowledge in a game  then we can identify local states with information sets. but  as the example above shows  we cannot do this in general.
¡¡a number of solution concepts have been considered in the game-theory literature  ranging from nash equilibrium and correlated equilibrium to refinements of nash equilibrium such as sequential equilibrium and weaker notions such as rationalizability  see  osborne and rubinstein  1  for an overview . the fact that game trees represent both the game and the players' information has proved critical in defining solution concepts in extensive-form games. can we still represent solution concepts in a useful way using runs and systems to represent a player's information  as we show here  not only can we do this  but we can do it in a way that gives deeper insight into solution concepts. indeed  all the standard solution concepts in the literature can be understood as instances of a single knowledge-based  kb  program  fagin et al.  1; 1   which captures the underlying intuition that a player should make a best response  given her beliefs. the differences between solution concepts arise from running the kb program in different contexts.
¡¡in a kb program  a player's actions depend explicitly on the player's knowledge. for example  a kb program could have a test that says  if you don't know that ann received the information  then send her a message   which can be written if  bi ann received info  then send ann a message.
this kb program has the form of a standard if ...then statement  except that the test in the if clause is a test on i's knowledge  expressed using the modal operator bi for belief; see section 1 for a discussion of the use of knowledge vs. belief .
¡¡using such tests for knowledge allows us to abstract away from low-level details of how the knowledge is obtained. kb programs have been applied to a number of problems in the computer science literature  see  fagin et al.  1  and the references therein . to see how they can be applied to understand equilibrium  given a game ¦£ in normal form  let si ¦£  consist of all the pure strategies for player i in ¦£. roughly speaking  we want a kb program that says that if player i believes that she is about to perform strategy s  which we express with the formula doi s    and she believes that she would not do any better with another strategy  then she should indeed go ahead and run s. this test can be viewed as embodying rationality. there is a subtlety in expressing the statement  she would not do any better with another strategy . we express this by saying  if her expected utility  given that she will use strategy s  is x  then her expected utility if she were to use strategy s is at most x.  the  if she were to use s  is a counterfactual statement. she is planning to use strategy s  but is contemplating what would happen if she were to do something counter to fact  namely  to use s. counterfactuals have been the subject of intense study in the philosophy literature  see  for example   lewis  1; stalnaker  1   and  more recently  in the game theory literature  see  for example   aumann  1; halpern  1; samet  1  . we write the counterfactual  if a were the case then b would be true  as  b . although this statement involves an  if ...then   the semantics of the counterfactual implicationis quite different from the material implication a   b. in particular  while a   b is true if a is false might not be.
¡¡with this background  consider the following kb program for player i:
for each strategy s ¡Ê si ¦£  do if bi doi s  ¡Ä  x eui = x  
 then s.
this kb program is meant to capture the intuition above. intuitively  it says that if player i believes that she is about to perform strategy s and  if her expected utility is x  then if she were to perform another strategy s  then her expected utility would be no greater than x  then she should perform strategy s. call this kb program eqnf¦£  with the individual instance for player i denoted by eqnf¦£i  . as we show  if all players follow eqnf¦£  then they end up playing some type of equilibrium. which type of equilibriumthey play depends on the context. due to space considerations  we focus on three examples in this abstract. if the players have a common prior on the joint strategies being used  and this common prior is such that players' beliefs are independent of the strategies they use  then they play a nash equilibrium. without this independence assumption  we get a correlated equilibrium. on the other hand  if players have possibly different priors on the space of strategies  then this kb program defines rationalizable strategies  bernheim  1; pearce  1 .
¡¡to deal with extensive-form games  we need a slightly different kb program  since agents choose moves  not strategies. let eqef¦£i be the following program  where a ¡Ê pm denotes that a is a move that is currently possible. for each move a ¡Ê pm do if bi doi a  ¡Ä  x  eui = x     then a.
just as eqnf¦£ characterizes equilibria of a game ¦£ represented in normal form  eqef¦£ characterizes equilibria of a game represented in extensive form. we give one example here: sequential equilibrium. to capture sequential equilibrium  we need to assume that information sets do correctly describe an agent's knowledge. if we drop this assumption  however  we can distinguish between the two equilibria for the game described in figure 1.
¡¡all these solution concepts are based on expected utility. but we can also consider solution concepts based on other decision rules. for example  boutilier and hyafil  consider minimax-regret equilibria  where each player uses a strategy that is a best-response in a minimax-regret sense to the choices of the other players. similarly  we can use maximin equilibria  aghassi and bertsimas  1 . as pointed out by chu and halpern   all these decision rules can be viewed as instances of a generalized notion of expected utility  where uncertainty is represented by a plausibility measure  a generalization of a probability measure  utilities are elements of an arbitrary partially ordered space  and plausibilities and utilities are combined using ¨’ and    generalizations of + and ¡Á. we show in the full paper that  just by interpreting  eui = u  appropriately  we can capture these more exotic solution concepts as well. moreover  we can capture solution concepts in games where the game itself is not common knowledge  or where agents are not aware of all moves available  as discussed by halpern and re go .
¡¡our approach thus provides a powerful tool for representing solution concepts  which works even if  a  information sets do not capture an agent's knowledge   b  uncertainty is not represented by probability  or  c  the underlying game is not common knowledge.
¡¡the rest of this paper is organized as follows. in section 1  we review the relevant background on game theory and knowledge-based programs. in section 1  we show that eqnf¦£ and eqef¦£ characterize nash equilibrium  correlated equilibrium  rationalizability  and sequential equilibrium in a game ¦£ in the appropriate contexts. we conclude in section 1 with a discussion of how our results compare to other characterizations of solution concepts.
1 background
in this section  we review the relevant background on games and knowledge-based programs. we describe only what we need for proving our results. the reader is encouraged to consult  osborne and rubinstein  1  for more on game theory   fagin et al.  1; 1  for more on knowledge-based programs without counterfactuals  and  halpern and moses  1  for more on adding counterfactuals to knowledgebased programs.
1 games and strategies
a game in extensive form is described by a game tree. associated with each non-leaf node or history is either a player- the player whose move it is at that node-or nature  which can make a randomized move . the nodes where a player i moves are further partitioned into information sets. with each run or maximal history h in the game tree and player i we can associate i's utility  denoted ui h   if that run is played. a strategy for player i is a  possibly randomized  function from i's information sets to actions. thus a strategy for player i tells player i what to do at each node in the game tree where i is supposed to move. intuitively  at all the nodes that player i cannot tell apart  player i must do the same thing. a joint strategy for the players determines a distribution over paths in the game tree. a normal-form game can be viewed as a special case of an extensive-form game where each player makes only one move  and all players move simultaneously.
1 protocols  systems  and contexts
to explain kb programs  we must first describe standard protocols. we assume that  at any given point in time  a player in a game is in some local state. the local state could include the history of the game up to this point  the strategy being used by the player  and perhaps some other features of the player's type  such as beliefs about the strategies being used by other players. a global state is a tuple consisting of a local state for each player.
¡¡a protocol for player i is a function from player i's local states to actions. for ease of exposition  we consider only deterministic protocols  although it is relatively straightforward to model randomized protocols-corresponding to mixed strategies-as functions from local states to distributions over actions. although we restrict to deterministic protocols  we deal with mixed strategies by considering distributions over pure strategies.
¡¡a run is a sequence of global states; formally  a run is a function from times to global states. thus  r m  is the global state in run r at time m. a point is a pair  r m  consisting of a run r and time m. let ri m  be i's local state at the point  r m ; that is  if r m  =  s1 ... sn   then ri m  = si. a joint protocol is an assignment of a protocol for each player; essentially  a joint protocol is a joint strategy. at each point  a joint protocol p performs a joint action  p1 r1 m   ... pn rn m     which changes the global state. thus  given an initial global state  a joint protocol p generates a  unique  run  which can be thought of as an execution of p. the runs in a normal-form game involve only one round and two time steps: time 1  the initial state  and time 1  after the joint strategy has been executed.  we assume that the payoff is then represented in the player's local state at time 1.  in an extensive-form game  a run is again characterized by the strategies used  but now the length of the run depends on the path of play.
¡¡a probabilistic system   where r is a set of runs and associates a probablity ¦Ìi on the runs of r with each player i. intuitively  ¦Ìi represents player i's prior beliefs. in the special case where ¦Ì1 = ¡¤¡¤¡¤ = ¦Ìn = ¦Ì  the players have a common prior ¦Ì on r. in this case  we write just  r ¦Ì .
¡¡we are interested in the system corresponding to a joint protocol p. to determine this system  we need to describe the setting in which p is being executed. for our purposes  this setting can be modeled by a set g of global states  a subset g1 of g that describes the possible initial global states  a set as of possible joint actions at each global state s  and n probability measures on g1  one for each player. thus  a probabilistic context is a tuple a joint protocol appropriate for such a context ¦Ã if  for every global state   the joint actions that p can generate are in as. when p is appropriate for ¦Ã  we abuse notation slightly and refer to ¦Ã by specifying only the pair . a protocol and a context ¦Ã for which p is appropriate generate a system; the system depends on the initial states and probability measures in ¦Ã. since these are all that matter  we typically simplify the description of a context by omitting the set g of global states and the sets as of global actions. let r p ¦Ã   denote the system generated by joint protocol p in context ¦Ã.
if  then r  where r consists of a the run for each initial state  where rs is the run generated by p when started in state  for i = 1 ... n.
¡¡a probabilistic system  is compatible with a context if  a  every initial state in g1 is the initial state of some run in r   b  every run is the run of some protocol appropriate for ¦Ã  and  c  if is the set of runs in r with initial global state s  then  for j = 1 ... n. clearly r is compatible with ¦Ã.
¡¡we can think of the context as describing background information. in distributed-systems applications  the context also typically includes information about message delivery. for example  it may determine whether all messages sent are received in one round  or whether they may take up to  say  five rounds. moreover  when this is not obvious  the context specifies how actions transform the global state; for example  it describes what happens if in the same joint action two players attempt to modify the same memory cell. since such issues do not arise in the games we consider  we ignore these facets of contexts here. for simplicity  we consider only contexts where each initial state corresponds to a particular joint strategy of ¦£. that is  ¦²¦£i is a set of local states for player i indexed by  pure  strategies. the set ¦²¦£i can be viewed as describing i's types; the state ss can the thought of as the initial state where player i's type is such that he plays s  although we stress that this is only intuition; player i does not have to play s at the state ss . let g1¦£ = ¦²¦£1 ¡Á ... ¡Á ¦²¦£n. we will be interested in contexts where the set of initial global states is a subset g1 of g1¦£. in a normal-formgame  the only actions possible for player i at an initial global state amount to choosing a pure strategy  so the joint actions are joint strategies; no actions are possible at later times. for an extensive-form game  the possible moves are described by the game tree. we say that a context for an extensive-form game is standard if the local states have the form  s i   where s is the initial state and i is the current information set. in a standard context  an agent's knowledge is indeed described by the information set. however  we do not require a context to be standard. for example  if an agent is allowed to switch strategies  then the local state could include the history of strategies used. in such a context  the agent in the game of figure 1 would know more than just what is in the information set  and would want to switch strategies.

performing a joint action in as at the global state s is unique and obvious; otherwise  such information would also appear in the context  as in the general framework of  fagin et al.  1 .
1 knowledge-based programs
a knowledge-based program is a syntactic object. for our purposes  we can take a knowledge-based program for player
to have the form if ¦Ê1 then a1 if ¦Ê1 then a1
... 
where each ¦Êj is a boolean combination of formulas of the formbi   in which the  's can have nested occurrencesof b operators and counterfactual implications. we assume that the tests ¦Ê1 ¦Ê1 ... are mutually exclusive and exhaustive  so that exactly one will evaluate to true in any given instance. the program eqnf¦£i can be written in this form by simply replacing the for ... do statement by one line for each pure strategy in si ¦£ ; similarly for eqef¦£i .
¡¡we want to associate a protocol with a kb program. unfortunately  we cannot  execute  a kb program as we can a protocol. how the kb program executes depends on the outcome of tests ¦Êj. since the tests involve beliefs and counterfactuals  we need to interpret them with respect to a system. the idea is that a kb program pgi for player i and a probabilistic system ps together determine a protocol p for player i. rather than giving the general definitions  which can be found in  halpern and moses  1    we just show how they work in the two kb programs we consider in this paper: eqnf and eqef.
¡¡given a system  we associate with each formula   a set      ps of points in ps. intuitively       ps is the set of points of ps where the formula   is true. we need a little notation:
  if e is a set of points in ps  let r e  denote the set of runs going through points in e; that is r e  = {r :  m  r m  ¡Ê e }.
  let ki r m  denote the set of points that i cannot distinguish from 
ri m }. roughly speaking  ki r m  corresponds to i's information set at the point  r m .
  given a point  r m  and a player i  let ¦Ì i r m  be the probability measure that results from conditioning ¦Ìi on ki r m   i's information at  r m . we cannot condition on ki r m  directly: ¦Ìi is a probability measure on runs  and ki r m  is a set of points. so we actually condition  not on ki r m   but on r ki r m    the set of runs going through the points in ki r m . thus  ¦Ìi r m = ¦Ìi | r ki r m  .  for the purposes of this abstract  we do not specify ¦Ìi r m if ¦Ìi r ki r m    = 1. it turns out not to be relevant to our discussion. 
¡¡the kb programs we consider in this paper use a limited collection of formulas. we now can define      ps for the formulas we consider that do not involve counterfactuals.
  in a system ps corresponding to a normal-form game ¦£  if s ¡Ê si ¦£   then   doi s   ps is the set of initial points  r 1  such that player i uses strategy s in run r.
  similarly  if ps corresponds to an extensive-formgame  then   doi a   ps is the set of points  r m  of ps at which i performs action a.
  player i believes a formula   at a point  r m  if the event corresponding to formula   has probability 1 according to ¦Ìi r m. that is   r m  ¡Ê   bi   ps if
  so that conditioning on ki r m  is defined  and ¦Ìi r m      ps ¡É ki r m   = 1.
  with every run r in the systems we consider  we can associate the joint  pure  strategy s used in r.1 this pure strategy determines the history in the game  and thus determines player i's utility. thus  we can associate with every point  r m  player i's expected utility at  r m   where the expectation is taken with respect to the probability ¦Ìi r m. if u is a real number  then   eui = u  ps is the set of points where player i's expected utility is u;   eui ¡Ü u  ps is defined similarly.
  assume that   x  has no occurrences of  . then    x  x    ps = ¡Éa¡Êir    x/a   ps  where   x/a  is the result of replacing all occurrences of x in   by a. that is   x is just universal quantification over x  where x ranges over the reals. this quantification arises for us when x represents a utility  so that  x  x  is saying that   holds for all choices of utility.
¡¡we now give the semantics of formulas involving counterfactuals. here we consider only a restricted class of such formulas  those where the counterfactual only occurs in the form do  which should be read as  if i were to use strategy s  then   would be true. intuitively  dois true at a point  r m  if   holds in a world that differs from
 r m  only in that i uses the strategy s. that is  do is true at  r m  if   is true at the point  where  in run  uses strategy s and all the other players use the same strategy that they do at  r m .  this can be viewed as an instance of the general semantics for counterfactuals used in the philosophy literature  lewis  1; stalnaker  1  whereis taken to be true at a world w if   is true at all the worlds w closest to w where ¦× is true.  of course  if i actually uses strategy s in run r  then
. similarly  in an extensive-form game ¦£  the closest point to  r m  where do is true  assuming that a is an action that i can perform in the local state ri m   is the point  where all players other than player i use the same protocol in's protocol in r agrees with i's protocol in r except at the local state ri m   where i performs action a. thus  r is the run that results from player i making a single deviation  to a at time m  from the protocol she uses in r  and all other players use the same protocol as in r.
¡¡there is a problem with this approach. there is no guarantee that  in general  such a closest point  exists in the system ps. to deal with this problem  we restrict attention to a class of systems where this point is guaranteed to exist. a system  is complete with respect to context ¦Ã if r includes every run generated by a protocol appropriate for context ¦Ã. in complete systems  the closest point is guaranteed to exist. for the remainder of the paper  we evaluate formulas only with respect to complete systems. in a complete system ps  we define  to consist of all the points  r m  such that the closest point  to  r m  where i uses strategy s is in      ps. the definition of  is similar. we say that a complete sys extends  so that ¦Ìj a  = ¦Ìj a   for all a   r  for j = 1 ... n.
¡¡since each formula ¦Ê that appears as a test in a kb program pgi for player i is a boolean combination of formulas of the form bi   it is easy to check that if  r m  ¡Ê   ¦Ê  ps  then ki r m      ¦Ê  ps. in other words  the truth of ¦Ê depends only on i's local state. moreover  since the tests are mutually exclusive and exhaustive  exactly one of them holds in each local state. given a system ps  we take the protocol pgpsi to be such that  if  for some point  r m  in ps with i    =   we have  r m  ¡Ê   ¦Êj  ps. since ¦Ê1 ¦Ê1 ... are mutually exclusive and exhaustive  there is exactly one action aj with this property.
¡¡we are mainly interested in protocols that implement a kb program. intuitively  a joint protocol p implements a kb program pg in contextperforms the same actions as pg in all runs of p that have positive probability  assuming that the knowledge tests in pg are interpreted with respect to the complete system ps extending r. formally  a joint protocol p  de facto  implements a joint kb program
pg  halpern and moses  1  in a context if for every local state such that r ¡Ê r p ¦Ã  and  where ps is the complete system extending r p ¦Ã . we remark that  in general  there may not be any joint protocols that implement a kb program in a given context  there may be exactly one  or there may be more than one  see  fagin et al.  1  for examples . this is somewhat analogous to the fact that there may not be any equilibrium of a game for some notions of equilibrium  there may be one  or there may be more than one.
1 the main results
fix a game ¦£ in normal form. let pinf be the protocol that  in initial state ss ¡Ê ¦²¦£i   chooses strategy s; let 
. let strati be the random variable on initial global states that associates with an initial global state s player i's strategy in r. as we said  nash equilibrium arises in contexts with a common prior. suppose that ¦Ã =  g1 ¦Ì  is a context with a common prior. we say that ¦Ì is compatible with the mixed joint strategy  is the probability on pure joint strategies induced by s  under the obvious identification of initial global states with joint strategies .
theorem 1: the joint strategy s is a nash equilibrium of the game ¦£ iff there is a common prior probability measure ¦Ì on g1¦£ such that strat1 ... stratn are independent with respect to ¦Ì  ¦Ì is compatible with s  and pnf implements eqnf¦£ in the context  g1¦£ ¦Ì .
proof: suppose that s is a  possibly mixed strategy  nash equilibrium of the game ¦£. letbe the unique probability on g1¦£ compatible with is played  then the probability of a run where the pure joint strategy  t1 ... tn  is played is just the product of the probabilities assigned to ti by si  so stratare independent with respect to . to see that pnf implements eqnf¦£ in the context be a local state such that
  then 
so t must be in the support of si. thus  t must be a best response to  the joint strategy where each player
plays its componentof s. since i uses strategy t in r  the formula holds at . moreover  since
t is a best response  if u is i's expected utility with the joint strategy s  then for all t  the formula do
holds at  r 1 . thus   eqnf  where ps is the complete system extending r pnf  ¦Ã . it follows that
pnf implements eqnf¦£.
¡¡for the converse  suppose that ¦Ì is a common prior probability measure on g1¦£  strat1 ... strat are independent with respect to ¦Ì  ¦Ì is compatible with s  and pnf implements eqnf¦£ in the context ¦Ã =  g1¦£ ¦Ì . we want to show that s is a nash equilibrium. it suffices to show that each pure strategy t in the support of is a best response to. since ¦Ì is compatible with s  there must be a run r such that i.e.  player i chooses t in run r . it since pnf implements eqnf¦£  and in the context ¦Ã  eqnf¦£ ensures that no deviation from t can improve i's expected utility with respect to   it follows that t is indeed a best response. 
¡¡as is well known  players can sometimes achieve better outcomes than a nash equilibrium if they have access to a helpful mediator. consider the simple 1-player game described in figure 1  where alice  the row player  must choose between top and bottom  t and b   while bob  the column player  must choose between left and right  l and r :
	l	r
 1  1  1  1 t
b
figure 1: a simple 1-player game.
¡¡it is not hard to check that the best nash equilibrium for this game has alice randomizing between t and b  and bob randomizing between l and r; this gives each of them expected utility 1. they can do better with a trusted mediator  who makes a recommendation by choosing at random between  t l    t r   and  b l . this gives each of them expected utility 1. this is a correlated equilibrium since  for example  if the mediator chooses  t l   and thus sends recommendation t to alice and l to bob  then alice considers it equally likely that bob was told l and r  and thus has no incentive to deviate; similarly  bob has no incentive to deviate. in general  a distribution ¦Ì over pure joint strategies is a correlated equilibrium if players cannot do better than following a mediator's recommendation if a mediator makes recommendations according to ¦Ì.  note that  as in our example  if a mediator chooses a joint strategy  s1 ... sn  according to ¦Ì  the mediator recommends si to player i; player i is not told the joint strategy.  we omit the formal definition of correlated equilibrium due to aumman  here; however  we stress that a correlated equilibrium is a distribution over  pure  joint strategies. we can easily capture correlated equilibrium using eqnf.
theorem 1: the distribution on joint strategies is a correlated equilibrium of the game ¦£ iff pnf implements eqnf¦£ in the context  g1¦£ ¦Ì .
¡¡both nash equilibrium and correlated equilibrium require a common prior on runs. by dropping this assumption  we get another standard solution concept: rationalizability  bernheim  1; pearce  1 . intuitively  a strategy for player i is rationalizable if it is a best response to some beliefs that player i may have about the strategies that other players are following  assuming that these strategies are themselves best responses to beliefs that the other players have about strategies that other players are following  and so on. to make this precise  we need a little notation. let. let denote player i's utility if the strategy tuple s is played. we describe player i's beliefs about what strategies the other players are using by a probability ¦Ìi on s i. a strategy s for player by a probability ¦Ìi on
 for all. following osborne
and rubinstein   we say that a strategy s for player i in game ¦£ is rationalizable if  for each player j  there is a set zj   sj ¦£  and  for each strategy t ¡Ê zj  a probability measure ¦Ìj t on s j ¦£  whose support is z j such that
  s ¡Ê zi; and
  for each player j and strategy t ¡Ê zj  t is a best response to the beliefs ¦Ìj t.
¡¡for ease of exposition  we consider only pure rationalizable strategies. this is essentially without loss of generality. it is easy to see that a mixed strategy s for player i is a best response to some beliefs ¦Ìi of player i iff each pure strategy in the support of s is a best response to ¦Ìi. moreover  we can assume without loss of generality that the support of ¦Ìi consists of only pure joint strategies.
theorem 1: a pure strategy s for player i is rationalizable iff there exist probability measures ¦Ì1 ... ¦Ìn  a set
g1¦£  and a state  such that pinf  si  = s and pnf implements eqnf¦£ in the context .
proof: first  suppose that pnf implements eqnf¦£ in context . we show that for each state and player i  the strategy  is rationalizable. let zi =
;
that is  e s  consists consists of all initial global states where player i's local state is ss; let ¦Ìi s = ¦Ìi ¡¤ | e s    under the obvious identification of global states in g1 with joint strategies . since pnf implements eqnf¦£  it easily follows that s best response to ¦Ìi s. hence  all the strategies in zi are rationalizable  as desired.
¡¡for the converse  let zi consist of all the pure rationalizable strategies for player i. it follows from the definition of rationalizability that  for each strategy s ¡Ê zi  there exists a probability measure ¦Ìi s on z i such that s is a best response to ¦Ìi s. for a set z of strategies  we denote by z  the set {st : t ¡Ê z}. set g1 = z 1¡Á...¡Áz n  and choose some measure ¦Ìi on g1 such that ¦Ìi ¡¤ | e s   = ¦Ìi s for all s ¡Ê
zi.  we can take  where ¦Ás ¡Ê  1  and .  recall that pinf  ss  = s for all states ss. it immediately follows that  for every rationalizable joint strategy    both  and. since the states in g1 all correspond to rationalizable strategies  and by definition of rationalizability each  individual  strategy is a best response to ¦Ìi s  it is easy to check that pnf implements eqnf¦£ in the context
  as desired. 
¡¡we remark that osborne and rubinstein's definition of rationalizability allows ¦Ìj t to be such that j believes that other players' strategy choices are correlated. in most of the literature  players are assumed to believe that other players' choices are made independently. if we add that requirement  then we must impose the same requirement on the probability measures ¦Ì1 ... ¦Ìn in theorem 1.
¡¡up to now we have considered solution concepts for games in normal form. perhaps the best-known solution concept for games in extensive form is sequential equilibrium  kreps and wilson  1 . roughly speaking  a joint strategy s is a sequential equilibriumif si is a best response toat all information sets  not just the information sets that are reached with positive probability when playing s. to understand how sequential equilibrium differs from nash equilibrium  consider the game shown in figure 1.

figure 1: a game with an unreasonable nash equilibrium.
¡¡one nash equilibrium of this game has a playing downa and b playing acrossb. however  this is not a sequential equilibrium  since playing across is not a best response for b if b is called on to play. this is not a problem in a nash equilibrium because the node where b plays is not reached in the equilibrium. sequential equilibrium refines nash equilibrium  in the sense that every sequential equilibrium is a nash equilibrium  and does not allow solutions such as  downa  acrossb . intuitively  in a sequential equilibrium  every player must make a best response at every information set  even if it is reached with probability 1 . in the game shown in figure 1  the unique joint strategy in a sequential equilibrium has a choosing acrossa and b choosing downb.
¡¡the main difficulty in defining sequential equilibrium lies in capturing the intuition of best response in information sets that are reached with probability 1. to deal with this  a sequential equilibrium is defined to be a pair   consisting of a joint strategy s and a belief system ¦Â  which associates with every information set i a probability ¦Â i  on the histories in i. there are a number of somewhat subtle consistency conditions on these pairs pairs; we omit them here due to lack of space  see  kreps and wilson  1; osborne and rubinstein  1  for details . our result depends on a recent characterization of sequential equilibrium  halpern  1  that uses nonstandard probabilities  which can assign infinitesimal probabilities to histories. by assuming that every history gets positive  although possibly infinitesimal  probability we can avoid the problemof dealing with information sets that are reached with probaility 1.
¡¡to every nonstandard real number r  there is a closest standard real number denoted st r   and read  the standard part of r : |r   st r | is an infinitesimal. given a nonstandard probability measure ¦Í  we can define the standard probability measure st ¦Í  by taking st ¦Í  w  = st  ¦Í w  . a nonstandard probability ¦Í on g1 is compatible with joint strategy s if st ¦Í  is the probability on pure strategies induced by s. when dealing with nonstandard probabilities  we generalize the definition of implementation by requiring only that p performs the same actions as pg in runs such that st ¦Í  r    1. moreover  the expression  eui = x  in eqef¦£ is interpreted as  the standard part of i's expected utility is x   since x ranges over the standard real numbers .
theorem 1: if ¦£ is a game with perfect recall1 there is a belief system ¦Â such that  is a sequential equilibrium of ¦£ iff there is a common prior nonstandard probability measure ¦Í on g1¦£ that gives positive measure to all states such that strat1 ... strat are independent with respect to ¦Í  ¦Í is compatible with s  and pef implements eqef¦£ in the standard context  g1¦£ ¦Í .
¡¡this is very similar in spirit to theorem 1. the key difference is the use of a nonstandard probability measure. intuitively  this forces s to be a best response even at information sets that are reached with  standard  probability 1.
¡¡the effect of interpreting  eui = x  as  the standard part of i's expected utility is x  is that we ignore infinitesimal differences. thus  for example  the strategy might not be a best response to; it might just be an -best response for some infinitesimal . as we show in the full paper  it follows from halpern's  results that we can also obtain a characterization of  trembling hand  perfect equilibrium  selten  1   another standard refinement of nash equilibrium  if we interpret  eui = x  as  the expected utility for agent i is x  and allow x to range over the nonstandard reals instead of just the standard reals.
1 conclusions
we have shown how a number of different solution concepts from game theory can be captured by essentially one knowledge-based program  which comes in two variants: one appropriate for normal-form games and one for extensiveform games. the differences between these solution concepts is captured by changes in the context in which the games are played: whether players have a common prior  for nash equilibrium  correlated equilibrium  and sequential equilibrium  or not  for rationalizability   whether strategies are chosen independently  for nash equilibrium  sequential equilibrium  and rationalizability  or not  for correlated equilibrium ; and whether uncertainty is represented using a standard or nonstandard probability measure.
¡¡our results can be viewed as showing that each of these solution concepts sc can be characterized in terms of common knowledge of rationality  since the kb programs eqnf¦£ and eqef¦£ embody rationality  and we are interested in systems  generated  by these program  so that rationality holds at all states   and common knowledge of some other features xsc captured by the context appropriate for sc  e.g.  that strategies are chosen independently or that the prior . roughly speaking  our results say that if xsc is common knowledge in a system  then common knowledge of rationality implies that the strategies used must satisfy solution concept sc; conversely  if a joint strategy s satisfies sc  then there is a system where xsc is common knowledge  rationality is common knowledge  and s is being played at some state. results similar in spirit have been proved for rationalizability  brandenburger and dekel  1  and correlated equilibrium  aumann  1 . our approach allows us to unify and extend these results and  as suggested in the introduction  applies even to settings where the game is not common knowledge and in settings where uncertainty is not represented by probability. we believe that the approach captures the essence of the intuition that a solution concept should embody common knowledge of rationality.

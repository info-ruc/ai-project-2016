
dynamic programming algorithms provide a basic tool identifying optimal solutions in markov decision processes  mdp . the paper develops a representation for decision diagrams suitable for describing value functions  transition probabilities  and domain dynamics of first order or relational mdps  fomdp . by developing appropriate operations for such diagrams the paper shows how value iteration can be performed compactly for such problems. this improves on previous approaches since the representation combines compact form with efficient operations. the work also raises interesting issues on suitability of different representations to different fomdps tasks.
1 introduction
in the past years there has been an increased interest in developing relational or first order mdps. some examples include symbolic dynamic programming  sdp   boutilier et al.  1   the relational bellman algorithm  rebel   kersting et al.  1   approximate linear programming for fomdps  guestrin et al.  1; sanner and boutilier  1   approximate policy iteration  fern et al.  1   and inductive policy selection using first order regression  gretton and thiebaux  1 .
모among these  only sdp and rebel are exact solution methods. to our knowledge there is no working implementation of sdp because it is hard to keep the state formulas consistent and of manageable size in the context of situation calculus. compared with sdp  rebel provides a more practical solution. rebel uses simpler language  a probabilistic strips-like language  to represent fomdps  so that reasoning over formulas is easier to perform.
모inspired by the successful application of algebraic decision diagrams  add   bryant  1; bahar et al.  1  in solving propositionally factored mdps  hoey et al.  1; st-aubin et al.  1  we lift propositional adds to handle relational structure and use them in the solution of fomdps. the intuition behind this idea is that the add representation allows information sharing  e.g.  sharing between state partitions. if there is sufficient regularity in the model  adds can be very compact  allowing problems to be represented and solved efficiently.
모first order decision trees and even decision diagrams have already been considered in the literature  blockeel and de raedt  1; groote and tveretina  1  and several semantics for such diagrams are possible. in particular groote and tveretina  provide a notation for first order bdds that can capture formulas in skolemized conjunctive normal form and then provide a theorem prover based on this representation. in this paper we adapt and extend their approach to handle first order mdps. in particular  we extend the definitions to handle existential quantification and numerical leaves through the use of an aggregation function. this allows us to capture value functions using algebraic diagrams in a natural way. we also provide additional reduction transformations for algebraic diagrams that help keep their size small  and allow the use of background knowledge in reductions. we then develop appropriate representation and algorithms showing how value iteration can be performed using the decision diagrams.
모it is useful to compare our solutions to the propositional ones. the main difficulty in lifting the ideas is that in relational domains the transition function specifies schemas for conditional probabilities. the propositional solution uses the concrete conditional probability to calculate the regression function. but this is not possible with schemas. while one can first ground the domain and problem at hand and only then perform the reasoning  e.g.  sanghai et al.  1   this does not allow for solutions abstracting over domains and problems. like sdp and rebel our constructions do perform general reasoning and they do so by using decision diagrams.
모due to space constraints most proofs and some details are omitted from the paper.
1 markov decision processes
we assume familiarity with standard notions of mdps and value iteration  puterman  1 . in the following we introduce some of the notions and our notation. a mdp can be characterized by a state space s  an action space a  a state transition function pr sj|si a  denoting the probability of transition to state sj given state si and action a  and an immediate reward function r s   specifying the immediate utility of being in state s. a solution to a mdp is an optimal policy that maximizes expected discounted total reward as defined by the bellman equation. the value iteration algorithm uses the bellman equation to iteratively refine an estimate of the value function:

where vn s  represents our current estimate of the value
function and vn+1 s  is the next estimate.
모the main observation used by hoey et al.  is that if we can represent each of  and vk s  compactly using adds then value iteration can be done directly using this representation  avoiding the need to enumerate the state space which is implicit in the equation above.
모taking the next step  the sdp approach  boutilier et al.  1  was developed in the context of the situation calculus. stochastic actions are specified as a non-deterministic choice among deterministic alternatives. in this way one can separate the regression over action effects  which is now deterministic  from the probabilistic choice of action. on each regression step during value iteration  the value of a stochastic action parameterizedwith freevariablesx is determined in the following manner:
모where denote reward and value functions in the compact  case notation  of boutilier et al.  denotes the possible outcomes of  and  the choice probabilities for.
모after the regression  we need to maximize over the action parameters of each q-function to get the maximum value that could be achieved by using an instance of this action. in sdp  this is done by adding the negation of higher value partitions into the description of lower value partitions  leading to complex formulas and reasoning. finally  to get the next value function we maximize over the choice of action.
모the solution of rebel  kersting et al.  1  follows the same outline but uses a probabilistic strips-like language for representing fomdps. more importantly the paper uses a decision list  rivest  1  style representation for value functions. the decision list gives us an implicit maximization operator since rules higher on the list are evaluated first. as a result the object maximization step is very simple. on the other hand regression in rebel requires that one enumerate all possible matches between a subset of a state partition and action effects and reason about each of these separately.
1 first order decision diagrams
an algebraic decision diagram is a labeled directed acyclic graph where non-leaf nodes are labeled with propositional variables  each non-leaf node has exactly two children corresponding to true and false branches  and leaves are labeled with numerical values. ordered decision diagrams specify a fixed order on propositions and require that node labels respect this order on every path in the diagram. in this case every function has a unique canonical representation and diagrams have efficient manipulation algorithms  leading to successful applications  bryant  1; bahar et al.  1 .
모there are various ways to generalize adds to capture relational structure. one could use closed or open formulas in the nodes  and in the latter case we must interpret the quantifica-

figure 1: a simple fodd.
tion over the variables. we focus on the following syntactic definition which does not have any explicit quantifiers. definition of first order decision diagrams:
 1  we assume a signature with a fixed set of predicates and constant symbols  and an enumerable set of variables. we also allow to use an equality between any pair of terms  constants or variables .
 1  a first order decision diagram  fodd  is a labeled directed acyclic graph  where each non-leaf node has exactly two children. the outgoing edges are marked with values true and false.
 1  each non-leaf node is labeled with: an atom p t1 ... tn  or an equality t1 = t1 where ti is a variable or a constant.
 1  leaves are labeled with numerical values.
모figure 1 shows a fodd with binary leaves. left going edges represent true branches. to simplify diagrams in the paper we draw multiple copies of the leaves 1 and 1 but they represent the same node in the fodd.
모the semantics of first order formulas are given relative to interpretations. an interpretation has a domain of elements  a mapping of constants to domain elements  and for each predicate a relation over the domain elements which specifies when the predicate is true. there is more than one way to define the meaning of fodd b on interpretation i. in the following we discuss two possibilities.
모semantics based on a single path: a semantics for decision trees is given by blockeel and de raedt  that can be adapted to fodds. the semantics define a unique path that is followed when traversing b relative to i. all variables are existential and a nodeis evaluated relativeto the path leading to it. for example  if we evaluate the diagram in figure 1 on the interpretation i1 with domain {1 1} and relations {p 1  q 1  h 1 } then we follow the true branch at the root since  x p x  is satisfied  but we follow the false branch at q x  since  x p x  뫇 q x  is not satisfied. since the leaf is labeled with 1 we say that b does not satisfy i. this is an attractive approach  since it builds mutually exclusive partitions over states  and various fodd operations can be developed for it. however  for reasons we discuss later this semantics is not well suited to value iteration  and it is therefore not used in the paper.
모semantics based on a multiple paths: following groote and tveretina  we define the semantics first relative to a variable valuation 붽. given a fodd b over variables x and an interpretation i  a valuation 붽 maps each variable in x to a domain element in i. once this is done  each node predicate evaluates either to true or false and we can traverse a single path to a leaf. the value of this leaf is denoted by mapb i 붽 .
모we next define mapb i  = aggregate붽{mapb i 붽 } for some aggregation function. that is  we consider all possible valuations 붽  for each we calculate mapb i 붽  and then we aggregate over all these values. in  groote and tveretina  1  leaf labels are in {1} and variables are universally quantified; this is easily captured by using minimum as the aggregation function. in this paper we use maximum as the aggregation function. this corresponds to existential quantification in the binary case  and gives useful maximization for value functions in the general case. we therefore define: mapb i  = max붽{mapb i 붽 }.
모consider evaluating the diagram in figure 1 on the interpretation i1. the valuation {x/1 y/1} leads to a leaf with value 1 so the maximum is 1 and we say that i satisfies b.
모we define node formulas  nf  and edge formulas  ef  recursively as follows. for a node n labeled l n  with incoming edges e1 ... ek  the node formula nf n  =  뫈ief ei  . denote the true branch of a node n by n뫻t and the false branch by n뫻f. the edge formula for the true outgoing edge of n is ef n뫻t  = nf n  뫇 l n . the edge formula for the false outgoing edge of n is ef n뫻f  = nf n 뫇 l n . these formulas  where all variables are existentially quantified  capture reachability conditions for the node or edge.
	basic	reduction	of	fodds:	groote	and
tveretina  define several operators that reduce a diagram into  normal form . a total order over open predicates  node labels  is assumed. we describe these operators briefly and give their main properties.
모 r1  neglect operator: if both children of a node p in the fodd lead to the same node q then we remove p and link all parents of p to q directly.  r1  join operator: if two nodes p q have the same label and point to the same two children then we can join p and q  remove q and link q's parents to p .  r1  merge operator: if a node and its child have the same label then the parent can point directly to the grandchild.  r1  sort operator: if a node p is a parent of q but the label ordering is violated  l p    l q   then we can reorder the nodes locally using two copies of p and q such that labels of the nodes do not violate the ordering.
모define a fodd to be reduced if none of the four operators can be applied. we have the following:
theorem 1  groote and tveretina  1 
 1  let o 뫍 {neglect  join  merge  sort} be an operator and o b  the result of applying o to fodd b  then for any 붽  mapb i 붽  = mapo b  i 붽 
 1  if b1 b1 are reduced and satisfy  붽  mapb1 i 붽  = mapb1 i 붽  then they are identical.
property  1  gives soundness  and property  1  shows that reducing a fodd gives a normal form. this only holds if the maps are identical for every 붽 and this condition is stronger than normal equivalence. however  this weak normal form suffices for groote and tveretina  who use it to provide a theorem prover for first order logic.
모combining fodds: given two algebraic diagrams we may need to add the corresponding functions  take the maximum or use any other binary operation op over the values represented by the functions. here we adopt the solution from the propositional case  bryant  1  in the form of the procedure apply p q op  where p and q are the roots of two diagrams. this procedure chooses a new root label  the lower among labels of p q  and recursively combines the corresponding sub-diagrams  according to the relation between the two labels     =  or   .
모additional reduction operators: in our context  especially for algebraic fodds we may want to reduce the diagrams further. we distinguish strong reduction that preserves mapb i 붽  for all 붽 and weak reduction that only preserves mapb i . in the following let b represent any backgroundknowledgewe have about the domain. for example in the blocks world we may know that  x y  on x y  뫸  clear y  .
모 r1  strong reduction for implied branches: consider any node n with labelbe the variables in ef n뫻t .
if then whenever node n is reached then the true branch is followed. in this case we can remove n and connect its parent directly to the true branch. it is clear that the map is preserved for any valuation. a similar reduction can be formulated for the false branch.
모 r1  weak reduction removing dominated siblings: consider any node n such that if we can reach n we can also reach n뫻t. if n뫻t always gives better values than n뫻f then we should be able to remove n뫻f from the diagram. we start by giving a special case of this condition.
   let x be the variables that appear in nfthe variables in l n  and not in nf n . consider the condition  i1 :  which requires that every valu-
ation reaching n can be extended to reach n뫻t.
모let min n뫻t  be the minimum leaf value in n뫻t  and max n뫻f  be the maximum leaf value in n뫻f. consider next the additional condition  v1 : min n뫻t  뫟 max n뫻f . in this case regardless of the valuation we know that it is better to follow n뫻t and not n뫻f. if both i1 and v1 hold then according to maximum aggregation the value of mapb i  will never be determined by the false branch. therefore we can safely replace n뫻f with any constant value between 1 and min n뫻t  without changing the map. a symmetric operation can be applied exchanging the roles of n뫻t and n뫻f.
   in some cases we can also drop the node n completely and connect its parents directly to n뫻t. this can be done if  i1a :  where u are the
variables that appear in  the sub-diagram of the variables that appear in nf n  but not in n뫻t  and w the variables in l n  and not in or . this condition requires that for every valuation 붽1 that reaches n뫻f there is a valuation 붽1 that reaches n뫻t and such that 붽1 and 붽1 agree on all variables in n뫻t. it is easy to see that i1a follows from i1 if  i1b : no variable in y appears in the sub-diagram of n뫻t.
모an important special case of r1 occurs when l n  is an equality t1 = y where y is a variable that does not occur on the fodd above node n. in this case  the condition i1 holds since we can choose the value of y. therefore if v1 holds we can remove the node n connecting its parents to n뫻t and substituting t1 for y in the diagram n뫻t.
모 r1  general case: the conditions for replacing n뫻f with a constant and for droppingn completely can be relaxed. due to space constraints  we only sketch the details. i1 can be relaxed to   which requires that if n is reachable then n뫻t is reachable but does not put any restriction on the valuations  in contrast with i1 .

figure 1: a template for the tvd
let d = n뫻t   n뫻f which we can calculate using apply. v1 can be relaxed to  v1 : all leaves in d have non-negative values. but using v1 requires a condition stronger than i1.  r1  weak reduction removing dominated edges:
모consider a fodd with two nodes p q where q is in the sub-fodd of p뫻f and their formulas satisfy that if we can follow q뫻t then we can also follow p뫻t. in this case  if min p뫻t  뫟 max q뫻t  then mapb i  will never be determined by q뫻t so we can replace q뫻t with a constant between 1 and min p뫻t . if in addition we have min p뫻t  뫟 max q뫻f  then it is also safe to remove q completely. due to space constraints  we omit the details and the general case of r1.
모 r1  weak reduction by unification: consider a fodd b and two sets of variablesof the same cardinality. by  we denote the fodd resulting from replacing variables in x by the corresponding variables in y. now consider the foddwhich we can calculate using apply. if all leaves in this diagram are non negative then
 i mapb i  = map so we can safely replace b.
1 decision diagrams for mdps
we follow boutilier et al.  and specify stochastic actions as a non-deterministic choice among deterministic alternatives. we therefore need to use fodds to represent the deterministic domain dynamics of actions  the probabilistic choice among actions  and value functions.
모example domain: we use the logistics problem variant from  boutilier et al.  1  to illustrate our constructions for mdps. the domain includes boxes  trucks and cities  and predicates are bin box city   tin truck city   and on box truck  with their obvious meaning. the reward function  capturing a planning goal  awards a reward of 1 if the formula  b bin b paris  is true  that is if there is any box in paris.
모the domain includes 1 actions load unload  and drive. actions have no effect if their preconditions are not met. actions can also fail with some probability. when attempting load  a successful version loads is executed with probability 1  and an unsuccessful version loadf  effectively a nooperation  with probability 1. the drive action is executed deterministically. when attempting unload  the probabilities depend on whether it is raining or not. if it is not raining  raining  then unloads is executed with probability 1  1   and unloadf with probability 1  1 .
모the domain dynamics: are defined by truth value diagrams  tvds . for every action schema and each predicate schema the tvd is a fodd with {1} leaves. the tvd gives the truth value of in the next state when has been performed in the current state. we call a action parameters  and x predicate parameters. no other variables are allowed in the tvd.
모notice that the tvd simultaneously captures the truth values of all instances of in the next state. notice also that tvds for different predicates are separate and independent. this can be safely done even if an action has correlated effects  not conditionally independent  since the actions are deterministic.
모for any domain  a tvd for predicate can be defined generically as in figure 1. the idea is that the predicate is true if it was true before and is not  undone  by the action or was false before and is  brought about  by the action. tvds for the logistics domain in our running example are given in figure 1. all the tvds omitted in the figure are trivial in the sense that the predicate is not affected by the action. in order to simplify the presentation we give the tvds in their generic form and did not sort the diagrams.
모notice how we utilize the multiple path semantics with maximum aggregation. a predicate is true if it is true according to one of the paths specified so we get a disjunction over the conditions for free. if we use the single path semantics then a single path in a tvd must capture all possibilities for a predicate to become true in a state. thus different conditions must be tested sequentially and their bindings must be combined so the correspondingnotion of tvd is significantly more complicated.
모probabilistic action choice: multiple path semantics makes it hard to specify mutually exclusive conditions using existentially quantified variables and in this way specify a distribution. we therefore restrict the conditions to be either propositional or depend directly on the action parameters. notice that under this restriction any interpretation follows exactly one path  since there are no variables and thus only the empty valuation  so the aggregation function does not interact with the probabilities assigned. a diagram showing the choice probability for unloads in our logistics example is given in figure 1.
모reward and value functions: can be represented directly using algebraic fodds. an example is given in figure 1.
1 value iteration with fodds
the general first order value iteration algorithm works as follows: given as input the reward function r and the action model  we set v1 = r n = 1 and perform the following steps until termination:
 1  for each action type	  compute:
모. obj-max.
 1  vn+1 is obtained by maximizing over qn+1:
vn+1 = maxa qan+1.
모regression by block replacement: consider vn and the nodes in its fodd. for each such node take a copy of the correspondingtvd  where predicate parameters are renamed so that they correspond to the node's arguments and action parameters are unmodified. block replacement regression br-regress is the fodd resulting from replacing each node in vn with the corresponding tvd  with outgoing
모

figure 1: logistics domain: tvds  action choice probabilities  reward function  and regression.  a  b  the tvds for bin b c  and on b t  under action choice unloads b  t  .  c  d  the tvds for bin b c  and on b t  under action choice loads b  t  c  . note that c  must be an action parameter so that  d  is a valid tvd.  e  the tvd for tin t c  under action drive t  c  .  f  the probability fodd for the action choice unloads b  t  .  g  the reward function r and the value function v1.  h  regression of v1 through unloads b  t  .  i  multiply  h  with the choice probability fodd.  j  regression of v1 over unloadf b  t   multiplied with the probability.  k  the unreduced result of adding two outcomes for unload b  t  .  l  the reduced result after addition. notice that the left branch reduces to 1 by using both the recursive part of apply and r1. the middle part is dropped by r1.  m  multiply by 붺 = 1  perform object maximization  and add the reward to get qunload1 . notice that in object maximization we have also dropped the equality on the right branch by the special case of r1. it turns out that v1  the value function after first iteration  is the same as. in this case the diagram for unload dominates the other actions  not shown .  n  block replacement in computing v1 through action unloads b  t   .
모
edges connected to the 1  1 leaves of the tvd. one can show that block replacement preserves the map for any valuation w.r.t. corresponding states.
모however  naive implementation of block replacement may not be efficient. if we use block replacement for regression then the resulting fodd is not necessarily reduced or sorted. reducing and sorting the results may be an expensive operation. instead we calculate the result as follows. we traverse vn using postorder traversal  where in the recursive step we combine the tvd block of the corresponding node  which is a tvd with binary leaves  with the processed versions of its children  which are general fodds . if we call the parent b  the true branch child bt and the false branch child bf then their combination is equivalent to  b뫄bt +  1 b 뫄bf . the result can be calculated by several calls to the apply procedure. we can use strong reduction during block combination; weak reductions can only be applied after all blocks have been combined.
모object maximization: as mentioned above we get maximization over action parameters for free. we simply rename the action parameters using new variable names  to avoid repetition between iterations  and consider them as variables. the aggregation semantics provides the maximization. since constants are turned into variables additional reduction is typically possible at this stage. any combination of weak and strong reductions can be used.
모adding and maximizing over actions: these can be done directly using the apply procedure. recall that  is restricted to include only action parameters and cannot include variables. we can therefore calculate  in step  1  directly. how-
ever  the different regression results are independent functions so that in the sum we must standardize apart the different regression results before adding the functions  note that action parameters are still considered constants at this stage . similarly the maximization  in step  1  must first standardize apart the different diagrams. the need to standardize apart complicates the diagrams and often introduces structure that can be reduced. in each of these cases we first use the propositional apply procedure and then follow with weak and strong reductions.
모figure 1 traces several steps in the application of value iteration to the logistics domain. in order to simplify the presentation the diagrams are not completely sorted allowing equalities in arbitrary locations.
1 discussion
adds have been used successfully to solve propositional factored mdps. our work gives one proposal of lifting these ideas to fomdps. while the general steps are similar the technical details are significantly more involved than the propositional case. it is easy to see that our approach can capture probabilistic strips style formulations as in rebel  allowing for more flexibility in representation. however  it is more limited than sdp since we cannot use arbitrary formulas for rewards  transitions  and probabilistic choice  e.g. no universal quantification .
모an implementation and empirical evaluation are obvious next steps. also it would be interesting to investigate conditions that guarantee a normal form for a useful set of reduction operators  and improvements of the representation to achieve further compression.
acknowledgments
this work has been partly supported by nsf grant iis-1  and by a research semester fellowship award from tufts university.

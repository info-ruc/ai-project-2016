
in this paper  we describe a system that automatically converts narratives into 1d scenes. the texts  written in swedish  describe road accidents. one of the program's key features is that it animates the generated scene using temporal relations between the events. we believe that this system is the first text-to-scene converter that is not restricted to invented narratives.
the system consists of three modules: natural language interpretation based on information extraction  ie  methods  a planning module that produces a geometric description of the accident  and finally a visualization module that renders the geometric description as animated graphics.
an evaluation of the system was carried out in two steps: first  we used standard ie scoring methods to evaluate the language interpretation. the results are on the same level as for similar systems tested previously. secondly  we performed a small user study to evaluate the quality of the visualization. the results validate our choice of methods  and since this is the first evaluation of a text-to-scene conversion system  they also provide a baseline for further studies.
1 introduction
for a machine  text-to-scene conversion consists in synthesizing a 1d or 1d geometric description from a text and in displayingit. ideally  a text-to-sceneconverterwould recreate mental images we formwhen we read a text. this representsa demanding task involving semantic and cognitive capabilities and to many people seems both a far off and surreal fantasy. however  there have been a small number of systems that provided insights into the feasibility of it while at the same time showing significant limitations  adorni et al.  1; coyne and sproat  1; arens et al.  1 . first  all the systems are restricted to very simple narratives  typically invented by the authors themselves. furthermore  none of the authors report details on the text corpus they used or any precise description of the results. another significant point is that these systems all focus on spatial relations  while ignoring the temporal dimension completely. most of them are limited to recreating static scenes.
모in this paper  we describe a new version of the carsim system  johansson et al.  1; dupuy et al.  1   which is a text-to-scene converter that handles real texts and that we evaluated using quantitative methods. the program generates 1d graphics from traffic accident reports generally collected from web sites of swedish newspapers. one of its key features is that it takes time and temporal relations between events into account to animate the synthesized scene.
모the structure of this article is as follows: section 1 describes the carsim system and the application domain. section 1 details the implementation of the natural language interpretation module. then  in section 1  we turn to the spatial and temporal reasoning that is needed to construct the visualization. the evaluation is described in section 1. finally  we discuss the results and their implications in section 1.
1 the carsim system
narratives of a car accidents often make use of space descriptions  movements  and directions that are sometimes difficult to grasp for readers. we believe that forming consistent mental images is necessary to understand them properly. however  some people have difficulties in imagining situations and may need visual aids pre-designed by professional analysts.
모carsim is a computer program1 that addresses this need. it is intended to be a helpful tool that can enable people to imagine a traffic situation and understand the course of events properly. the programanalyzes texts describingcar accidents and visualizes them in a 1d environment.
모to generate a 1d scene  carsim combines natural language processing components and a visualizer. the language processing module adopts an information extraction strategy and includes machine learning methods to solve coreference  classify predicate/argument structures  and order events temporally. however  as real texts suffer from underspecification and rarely contain a detailed geometric description of the actions  information extraction alone is insufficient to convert narratives into images automatically. to handle this  carsim infers implicit information about the environment and the involved entities from key phrases in the text  knowledge about typical traffic situations  and properties of the involved entities. the program uses a visualization planner that applies spatial and temporal reasoning to  imagine  the entities and actions described in the text  and that tries to find the simplest configuration that fits the description.
1 a corpus of traffic accident descriptions
carsim has been developed using authentic texts. as a development set  we collected approximately 1 reports of road accidents from various swedish newspapers. the task of analyzing the news reports is made more complex by their variability in style and length. the size of the texts ranges from a couple of sentences to more than a page. the amount of details is overwhelming in some reports  while in others  most of the information is implicit. the complexity of the accidents described ranges from simple crashes with only one car to multiple collisions with several participating vehicles and complex movements. although our work has concentratedon the press clippings  we also have access to accident reports from the strada database  swedish traffic accident data acquisition  of v gverket  the swedish traffic authority.
모the next text is an excerpt from our test corpus. this report is an example of a press wire describing an accident.
   en bussolycka i s dra afghanistan kr vde p  torsdagen 1 d dsoffer. ytterligare 1 personer skadades i olyckan som intr ffade tidigt p  torsdagsmorgonen tv  mil norr om staden kandahar. bussen var p  v g fr n kandahar mot huvudstaden kabul n r den under en omk rning k rde av v gbanan och voltade  meddelade general salim khan  bitr dande polischef i kandahar. l get f r n gra av de skadade uppgavs som kritiskt.
tt-afp & dagens nyheter  july 1  1
   a bus accident in southern afghanistan last thursday claimed 1 victims. additionally  1 people were injured in the accident  which occurred early thursday morning twenty kilometers north of the city kandahar. the bus was on its way from kandahar towards the capital kabul when it left the road while overtaking and overturned  said general salim khan  assistant head of police in kandahar. the state of some of the injured was said to be critical.
the text above  our translation.
1 architecture of the carsim system
we use a division into modules where each one addresses one step of the conversion process  see figure 1 .
  a natural language processing module that interprets the text to produce an intermediate symbolic representation.
  a spatio-temporal planning and inference module that produces a full geometric description given the symbolic representation.
  a graphical module that renders the geometric description as graphics.

figure 1: system architecture.
모we use the intermediate representation as a bridge between texts and geometry. this is made necessary because the information expressed by most reports has usually little affinity with a geometric description. exact and explicit accounts of the world and its physical properties are rarely present. in addition  our vocabulary is finite and discrete  while the set of geometric descriptions is infinite and continuous.
모once the nlp module has interpreted and converted a text  the planner maps the resulting symbolic representation of the world  the entities  and behaviors  onto a complete and unambiguous geometric description in a euclidean space.
모certain facts are never explicitly stated  but are assumed by the author to be known to the reader. this includes linguistic knowledge  world knowledge  such as traffic regulations and typical behaviors   and geometric knowledge  such as typical sizes of vehicles . the language processing and planning modules take this knowledge into account in order to produce a credible geometric description that can be visualized by the renderer.
1 the symbolic representation
the symbolic representation has to manage the following trade-off. in order to be able to describe a scene  it must contain enough information to make it feasible to produce a consistent geometric description  acceptable to the user. on the other hand  the representation has to be close to ways human beings describe things to capture information in the texts.
모we used four concept categories that we ordered in an inheritance hierarchy. the representation is implemented using minsky-style   object-oriented   frames  which means that the objects in the representation consist of a number of predefined attribute/values slots. this ontology was designed with assistance of traffic safety experts. it consists of:
  objects. these are typically the physical entities that are mentioned in the text  but we might also need to present abstract or oneiric entities as symbols in the scene. each object has a type that is selected from a predefined  finite set. car and truck are examples of object types.
  events. they correspond intuitively to an activity that goes on during a period in time and here to the possible object behaviors. we represent events as entities with a type from a predefined set. overturn and impact are examples.
  relations and quantities. the objects and the events need to be described and related to each other. the most obvious examples of such information are spatial information about objects and temporal information about events. we should be able to express not only exact quantities  but also qualitative information  by which we mean that only certain fundamental distinctions are made . behind  fromleft  and during are examples of spatial and temporal relations.
  environment. the environment of the accident is important for the visualization to be understandable. significant environmental parameters include light  weather  road conditions  and type of environment  such as rural or urban . another important parameter is topography  but we have set it aside since we have no convenient way to express this qualitatively.
1 natural language interpretation
we use informationextraction techniques to interpret the text. this is justified by the symbolic representation  which is restricted to a limited set of types and the fact that only a part of the meaning of the text needs to be presented visually. the ie module consists of a sequence of components  figure 1 . the first components carry out a shallow parse: pos tagging  np chunking  complex word recognition  and clause segmentation. this is followed by a cascade of semantic markup components: named entity recognition  temporal expression detection  object markup and coreference  and predicate argument detection. finally  the marked-up structures are interpreted to yield the resulting symbolic representation of the accident. the development of the ie module has been made more complex by the fact that few tools or annotated corpora are available for swedish. the only significant external tool we have used is the granska pos tagger  carlberger and kann  1 .
1 entity detection and coreference
a correct detection of the involved entities is crucial for the graphical presentation to be understandable. we first search the likely participants among the noun phrases in the text by checking them against a dictionary. we then apply a coreference solver to link the groups that refer to identical entities. this results in a set of equivalence classes referring to entities that are likely to be participants in the accident.
모the coreference solver uses a hand-written filter in conjunction with a statistical system based on decision trees  danielsson  1 . the filter first tests each antecedentanaphor pair using 1 grammatical and semantic features to prevent unlikely coreference. the statistical system then uses 1 features to classify pairs of noun groups as coreferring or not. these features are lexical  grammatical  and semantic. the trees were induced from a set of hand-annotated examples using the id1 algorithm and a method inspired by soon et al. . we implemented a novel feature transfer mechanism that propagates and continuously changes the values of semantic features in the coreference chains during clustering. this means that the coreferring markables inherit semantic properties from each other. feature transfer  as well as domain-specific semantic features  proved to have a significant impact on the performance.
1 domain events
in order to produce a symbolic representation of the accident  we need to recreate the course of events. we find the events using a two-step procedure. first  we identify and mark up text fragments that describe events  and locate and classify their arguments. secondly  we interpret the fragments in order to produce event objects as well as the involved participants  spatial and temporal relations  and information about the environment. this two-step procedure is similar to other work that uses predicate-argument structures for ie  for example  surdeanu et al.  1 .
모we classify the arguments of each predicate  assign them a semantic role  using a statistical system  which was trained on about 1 hand-annotated examples. following gildea and jurafsky   there has been a relative consensus on the features that the classifier should use. we use a slightly different set; since we have no full parser  there are no features that refer to the parse tree. also  since the system is domain-specific  we have introduced a semantic type feature that takes the following values: dynamic object  static object  human  place  time  cause  or speed.
모similarly to the method described by gildea and jurafsky   the classifier chooses the role that maximizes the estimated probability of a role given the values of the target  head  and semantic type attributes:
.
if a particular combination of target  head  and semantic type is not found in the training set  the classifier uses a back-off strategy  taking the other attributes into account. in addition  we tried other classification methods  id1 with gain ratio  svms  without any significant improvement.
모when the system has located the references to domain events in the text  it can interpretthem; that is  we mapthe text fragments onto entities in the symbolic representation. this stage makes significant use of world knowledge  for example to handle relationships such as metonymy and ownership.
모since it is common that events are mentioned more than once in the text  we need to remove the duplicates in order not to introduce unnecessary animations. event coreference is a task that can be treated using similar methods as those we used for object coreference. however  event coreference is a simpler problem since the range of candidates is narrowed by the involved participants and the event type. to get a minimal description of the course of events  we have found that it is sufficient to unify as many events as possible  taking event types and participants into account.
모finally  we fill in the informationthat is lacking due to mistakes or underspecification using default and heuristic rules. thus  we have a complete description of the events and the participants.
1 temporal ordering of events
since we produce an animation rather than just a static image  we take time into account and we find the temporal relations between the events. although the planner alone can infer a probable course of events given the positions of the participants  and some orderings are deducible by means of simple ad-hoc rules that place effects after causes  such as a fire after a collision   we have opted for a general approach.

figure 1: architecture of the language interpretation module.모we developed a component based on the generic timeml framework  pustejovsky et al.  1 . we first create an ordering of all events in the text  where all verbs  and a small set of nouns  are considered to refer to events  by generating temporal links  orderings  between the words that denote the events. the links are generated by a hybrid system that consists of a statistical system based on decision trees and a small set of hand-written heuristics.
모the statistical system considers events that are close to each other in the text  and that are not separated by explicit temporal expressions. it was trained on a set of handannotated examples  which consists of 1 events and 1 temporal relations. the decision trees were produced using the c1 tool  quinlan  1  and make use of the following information:
  tense  aspect  and grammatical construct of the verb groups that denote the events.
  temporal signals between the words. this is a timeml term for temporal connectives and prepositions such as  when    after   and  during .
  distance between the words  measured in tokens  sentences  and in punctuation signs.
모the range of possible output values is the following subset of allen's relations: simultaneous  after  before  is included  includes  and none.
모after the decision trees have been applied  we remove conflicting temporal links using probability estimates derived from c1. finally  we extract the temporal relations between the events that are relevant to carsim.
1 inferring the environment
the environment is important for the graphical presentation to be credible. we use traditional ie techniques  such as domain-relevant patterns  to find explicit descriptions of the environment.
모as noted by the wordseye team  sproat  1   the environment of a scene may often be obvious to a reader even though it is not described in the text. in order to capture this information  we try to infer it using prepositional phrases that occur in the description of the events. we then use a na ve bayesian classifier to guess the environment.
1 planning the animation
we use a planning system to create the animation out of the extracted information. it first determines a set of constraints that the animation needs to fulfill. then  it goes on to find the initial directions and positions. finally  it uses a search algorithm to find the trajectory layout. since we use no backtracking  this separation into steps introduces a risk of bad choices. however  it reduces the computation load and proved sufficient for the texts we considered  enabling an interactive generation of 1d scenes and a better user experience.
1 finding the constraints
the constraints on the animation are created using the detected events and the spatial and temporal relations combined with the implicit knowledge about the world. the events are expressed as conjunctions of primitive predicates about the objects and their behavior in time. for example  if we state that there is an overtake event where o1 overtakeso1  this is translated into the following proposition:
 t1 t1.movessideways o1 left t1 
뫇passes o1 o1 t1  뫇 t1   t1
모in addition  other constraints are implied by the events and our knowledge of the world. for example  if o1 overtakes o1  we add the constraints that o1 is initially positioned behind o1  and that o1 has the same initial direction as o1. other constraints are added due to the non-presenceof events  such as
     nocollide o1 o1  뫖   t.collides o1 o1 t  if there is no mentioned collision between o1 and o1.
1 finding initial directions and positions
we use constraint propagation techniques to infer initial directions and positions for all the involved objects. we first set those directions and positions that are stated explicitly. each time a direction is uniquely determined  it is set and this change propagates to the sets of available choices of directions for other objects  whose directions have been stated in relation to the first one. when the direction can't be determined uniquely for any object  we pick one object and set its direction. this goes on until the initial directions have been inferred for all objects.
1 finding the trajectories
after the constraints have been found  we use the ida* search method to find a trajectory layout that is as simple as possible while violating no constraints. as heuristic function  we use the number of violated constraints multiplied by a constant in order to keep the heuristic admissible.
모the most complicated accident in our development contains 1 events  which results in 1 constraints during search  and needs 1 modifications of the trajectories to arrive at a trajectory layout that violates no constraints. this solution is found in a few seconds. most accidents can be described using only a few constraints.
모at times  no solution is found within reasonable time. typically  this happens when the ie module has produced incorrect results. in this case  the planner backs off. first  it relaxes some of the temporal constraints  for example: simultaneous constraints are replaced by neartime . next  all temporal constraints are removed.
1 evaluation
we evaluated the components of the system  first by measuring the quality of the extracted information using standard ie evaluation methods  then by performing a user study to determine the overall perception of the complete system. for both evaluations  we used 1 previously unseen texts  which had been collected from newspaper sources on the web. the size of the texts ranged from 1 to 1 tokens.
1 evaluation of the information extraction module
for the ie module  three aspects were evaluated: object detection  event detection  and temporal ordering of the events. table 1 shows the precision and recall figures.
prf붹=1objects111events111temporal relations  correct events 111temporal relations  all events 111table 1: statistics for the ie module on the test set.
모the evaluations of object and event detection were rather straightforward. a road object was considered to be correctly detected if a corresponding object was either mentioned in or implicit from the text  and the type of the object was correct. the same criteria applied to the detection of events  but here we also added the criterion that the actor  and victim  where it applies  must be correct.
모evaluating the quality of the temporal orderings proved to be less straightforward. first  to make it feasible to compare the graph of orderings to the correct graph  it must be converted to some normal form. for this  we used the transitive closure  that is  we made all implicit links explicit . the transitive closure has some drawbacks - for example  one small mistake may cause a large impact on the precision and recall measures if many events are involved. however  we found no other obvious method for normalizing the temporal graphs.
모a second problem to resolve was that of how to evaluate temporal orderings when the events are not all correctly detected. this difficulty arises when the event coreference resolution fails and multiple instances of the same event are re-
ported. because of this complication  we measured the link precision and recall for two cases: first  only those links that connect properly detected events; secondly  all links. we then compared the results.
모the results of the event detection is comparableto those reported in previously published work.  surdeanu et al.  1  reports an f-measure of 1 in the market change domain for a system that uses similar ie methods.1 although our system has a different domain  a different language  and different resources  their system is based on propbank   the figures are roughly similar. the somewhat easier task of detecting the objects results in higher figures  demonstrating that the method chosen works satisfactorily for the task at hand.
모we believe that the figures for the temporal relations will prove competitive. we are not aware of any previous result in automatic detection of temporal relations in ie. the figures also show that the difference between the methods of evaluation is relatively small  suggesting that both methods are useful when evaluating temporal orderings.
1 user study to evaluate the visualization
four users were shown the animations of subsets of the 1 test texts. figure 1 shows an example corresponding to the text from subsection 1. the users graded the quality of animations using the following scores: 1 for wrong  1 for  more or less  correct  and 1 for perfect. the average score was 1. the number of texts that had an average score of 1 was 1  1 percent   and the number of texts with an average score of at least 1 was 1  1 percent . these figures demonstrate that the chosen strategy is viable  especially in a restricted context like the traffic accident domain. however  interpretation of the figures is difficult since there are no previously published results. in any case  they provide a baseline for further studies  possibly in another domain.
모to determine whether the small size of our test group introduced a risk of invalid results  we calculated the standard deviation of annotations1  and we obtained the value of 1. replacing all annotations with random values from the same probability distribution resulted in a standard deviation of 1 on average. in addition  the pairwise correlation of the annotations is 1. this suggests that the agreement among annotators is enough for the figures to be relevant.
모during discussions with users  we had a number of unexpected opinions about the visualizations. one important example of this is the quantity of implicit information they infer from reading the texts. for example  given a short description of a crash in an urban environment  one user imagined a collision of two moving vehicles at an intersection  while another user interpreted it as a collision between a moving and a parked car.
모this user response shows that the task of imagining a situation is difficult for humans as well as for machines. furthermore  while some users have suggested that we improve the realism  for example  the physical behavior of the objects   discussions generally made it clear that the semi-realistic graphics that we use  see figure 1  may suggest to the user

1
모모we have assumed that the templettes that they use roughly can be identified with events.

	1	rpp xiji x빡i 1   where
we calculated this using the formula
 n  1 
xij is the score assigned by annotator j on text i  x빡i the average score on text i  and ni the number of annotators on text i.

figure 1: screenshots from the animation of the text above.that the system knows more than it actually does. since the system visualizes symbolic information  it may actually be more appropriate to present the graphics in a more  abstract  manner that reflects this better  for example via symbolic signs in the scene.
1 conclusion and perspectives
we have presented an architecture and a strategy based on information extraction and symbolic visualization that enables to convert real texts into 1d scenes. as far as we know  carsim is the only text-to-scene conversion system that has been developed and tested using non-invented narratives. it is also unique in the sense that it produces animated graphics by taking takes temporal relations between events into account.
모we have provided the first quantitative evaluation of a textto-scene conversion system  which shows promising results that validate our choice of methods and set a baseline for future improvements.
모in the future  we would like to extend the prototype system to deeper levels of semantic information. while the current prototype uses no external knowledge  we would like to investigate whether it is possible to integrate additional knowledge sources in order to make the visualization more realistic and understandable. two important examples of this are geographical and meteorological information  which could be helpful in improving the realism and in creating a more accurate reconstruction of the circumstances and the environment. another topic that has been prominentin our discussions with traffic safety experts is how to reconcile different narratives that describe the same accident.
acknowledgements
the first author wishes to thank margaret newman-nowicka for her numerous suggestions for improvement of this paper.
모this work is partly supported by grant number 1 from the spr kteknologi program of vinnova  the swedish agency of innovation systems.


almost all natural language generation  nlg  systems are faced with the problem of the generation of referring expressions  gre : given a symbol corresponding to an intended referent  how do we work out the semantic content of a referring expression that uniquely identifies the entity in question  this is now one of the most widely explored problems in nlg: over the last 1 years  a number of algorithms have been proposed for addressing different aspects of this problem  but the different approaches taken make it very difficult to compare and contrast the algorithms provided in any meaningful way. in this paper  we show how viewing the problem of referring expression generation as a search problem allows us to recast existing algorithms in a way that makes their similarities and differences clear.
1 introduction
a major component task in natural language generation  nlg  is the generation of referring expressions: given an entity that we want to refer to  how do we determine the content of a referring expression that uniquely identifies that intended referent  this is now a widely explored problem in the nlg literature; since at least  dale  1   the standard conception of this task has been as follows:
1. we assume we have a knowledge base that characterisesthe entities in the domain in terms of a set of attributes and the values that the entities have for these attributes; so  for example  our knowledge base might represent the fact that entity e1 has the value cup for the attribute type  and the value red for the attribute colour.
1. in a typical context where we want to refer to some ei  which we call the intended referent  there will be other entities from which the intended referent must be distinguished; these are generally referred to as distractors. so  for example  we may want to distinguish a particular cup from all the other items present in the context of a dining table.
1. the goal of referring expression generation is thereforeto find some collection of attributes and their values which distinguish the intended referent from all the potential distractors in the context.
over the last 1 years  a wide variety of algorithms have been proposed to deal with specific aspects of this problem. for example  while earlier algorithms focussed on the use of attributes that correspond to simple one-place predicates  as might be realised  for example  by means of adjectives such as red or large   later work attempts to address the use of relational predicates  as might be realised by prepositions such as in and next to   and other work looks at the incorporation of boolean operators such as not and and. consequently  we now have a considerable body of research in this area; however  it is difficult to establish just how these different algorithms relate to each other.
         this paper represents a first step towards consolidating the results in this area  with the aim of developing a framework within which different algorithms can be compared and assessed. the structure of the paper is as follows. in section 1  we provide a brief overview of work on the generation of referring expressions to date. in section 1  we borrow a standard approach used in artificial intelligence  ai  to represent problems in an elegant and uniform way  see  for example   simon and newell  1 ;  russell and norvig  1    sketching how gre algorithms can be expressed in terms of problem-solving by search. in section 1  we explore how the most well-known algorithms can be expressed in this framework. in section 1  we discuss how this approach enables a more fruitful comparison of existing algorithms  and we point to ways of taking this work further.
1 a brief review of work to date
although the task of referring expression generation is discussed informally in earlier work on nlg  in particular  see  winograd  1; mcdonald  1; appelt  1   the first formally explicit algorithm was introduced in  dale  1 . this algorithm  which we will refer to as the full brevity  fb  algorithm  is still frequently used as a basis for other gre algorithms. the fb algorithm searches for the best solution amongst all possible referring expressions for an entity; the algorithm derives the smallest set of attributes for the referent in question  producing a referring expression that is both adequate  in the sense that it provides enough information to do what it needs to do  and efficient  in the sense that it does not provide any more information than it needs to .
         this initial algorithm limited its application to one-place predicates.  dale and haddock  1  introduced a constraint-based procedure that could generate referring expressions involving relations  henceforth ir   using a greedy heuristic to guide the search.
         as a response to the computational complexity of greedy algorithms   reiter and dale  1; dale and reiter  1  introduced the psycholinguistically motivated incremental algorithm  ia . the most used and adapted algorithm  this is based on the observation that people often produce referring expressions which are informationally redundant; the algorithm uses a preference ordering over the attributes to be used in a referring expression  incorporating those attributes which rule out at least one potential distractor.
         in recent years there have been a number of important extensions to the ia. the context-sensitive extension  cs;  krahmer and theune  1   is able to generate referring expressions for the most salient entity in a context; the boolean expressions algorithm  be;  van deemter  1   is able to derive expressions containing boolean operators  as in the cup that does not have a handle; and the sets algorithm  set;  van deemter  1   extends the basic approach to references to sets  as in the red cups. some approaches reuse parts of other algorithms: the branch and bound  bab;  krahmer et al.  1   algorithm uses the full brevity algorithm  but is able to generate referring expressions with both attributes and relational descriptionsusing a graph-based technique.
         we have identified here what we believe to be the most cited strands of research in this area  but of course there are many other algorithms described in the literature: see  for example   horacek  1; bateman  1; stone  1 . space limitations prevent a complete summary of this other work here  but our intention is to extend the analysis presented in this paper to as many of these other algorithms as possible.
         all these algorithms focus on the generation of definite references. in principle  they would be embedded in a higher-level algorithm that includes cases for when the entity has not been previously mentioned  thus leading to an initial indefinite reference  or when the referent is in focus  thus leading to a pronominal reference . however  in practice  most work tends to focus exclusively on definite reference; see  dale  1; krahmer and theune  1; dale  1  for further discussion of the more general case.
1 gre from the perspective of problem solving
with so many algorithms to choose from  it would be useful to have a uniform framework in which to discuss and compare algorithms; unfortunately  this is rather difficult given the variety of different approaches that have been taken to the problem.
         within the wider context of ai   russell and norvig  1  present an elegant definition of a general algorithm for problem solving by search. the search graph consists of nodes with the components state and path-cost; a problem is represented by an initial-state  an expand-method which identifies new states in the search space  a queuingmethod which determines the order in which the states should be considered  and a path-cost-function which determines the cost of reaching a given state. in this framework  the search strategy is determined by the combination of queuing-method and path-cost-function used.
         in the following  we use this framework to provide a characterisation of existing gre algorithms in terms of problem solving by search. given an intended referent  a set of properties true of the intended referent 1 and the set of distractor entities from which we wish to distinguish the intended referent  we can conceptualise the search space as consisting of states that correspond to possible descriptions of the intended referent. each state has three components: a description that is true of the intended referent  the set of distractor entities that the description also applies to besides the intended referent  and the set of properties of the intended referent that have not yet been considered in describing the referent.
1. the initial-state is of the form h{} c pi  where c is the set of distractors in the initial context  and p is the set of all properties true of the intended referent.
1. the goal state is of the form h{뷂xp1 뷂xp1 ...} {} p1i  where the first term contains a set of properties of the intended referent that  by virtue of the second term  the set of distractors  being an empty set  distinguish the intended referent; p1 contains any properties of the intended referent not yet used in the description.
1. all other states in the search space are then intermediatestates through which an algorithm will move as it adds new properties to the description.
1. the search strategy is carried out by the expand-method and the queuing-method which together characterise the specific gre algorithm  for example  fb  gh or ia  that is used.
1. the path-cost-function allows us to route the search as required; this can be used to take account of salience weights  or to embody some kind of heuristic search.
for any given algorithm  not all of the methods and functions need to be implemented; in particular  we will see that some algorithms do not require a path-cost-function.
1 gre algorithms in terms of problem solving
we adopt here an object oriented formalism 1 since this allows the representation of dependencies between the algorithms by means of inheritance and overwriting.
to enable more fruitful comparisonof the different
gre algorithms  we want to distinguish those aspects of the algorithms which are true of all algorithms  and those which are unique to each particular algorithm. in section 1  we first describe the elements that are shared by all the algorithms; we then go on to describe the distinct aspects of each algorithm in turn.
1 common elements
following from the previous section  the definitions of the node and state classes are as shown in definition 1. this figure also shows the definitions for initial-state and goal  which remain constant across the algorithms.

definition 1: the node and state classes

class node {
s // state
path-cost // cost of the path to this node getstate  
{return s} // returns the state of the node
} class state {
l // set of chosen properties and/or relations
c // set of distractors
p // set of available properties and/or relations
} initialstate   {return new state   c p } // the goal is the empty set of distractors goal s  {
if s.c =   then return true else return false
}

         given these components  the main method makerefexp is then as represented in definition 1. this takes two arguments  which serve as the parameters that distinguish one algorithm from another: an expand method to create the successors of a given state  and a queue method  which defines how to insert nodes into the nodequeue. dependingon the order in which the nodes are inserted  different search strategies can be realized: for example  when the nodes are inserted at the front of the queue  the search strategy is depth-first; when the nodes are inserted at the end of the queue  the search strategy is breadth-first; when the nodes of the queue are sorted by the estimated distance to the goal  then the search type is best-first; and so on.
         in addition  we may require a number of generalpurpose methods which can be used by a number of different definition 1: the basic algorithm structure

makerefexp   {
// create a initial queue with a single node nodequeue 뫹  new node initialstate     while nodequeue 1=   do node 뫹 removefront nodequeue  if goal node.getstate    then
return node // success
end nodequeue 뫹 queue nodequeue expand node  
end
모return nil // failure }

algorithms. one such 'utility function' is the method rulesout  which takes a property or relation p and a set of distractors  and returns the set of distractors which are ruled out by p.
         with this machinery in place  we can now redefine the existing algorithms in terms of their core differences  which correspond essentially to different ways of expanding the search space.
1 the full brevity algorithm
the distinctive property of the full brevity  fb  algorithm is that it computes all combinations of the available properties p with increasing length  so that it may find the shortest combination that succeeds in identifying the intended referent.
         this behaviour is captured by the expand method shown in definition 1. the method creates a set of successors by creating a node for each property pi which has not so far been checked providedthat pi rules out at least onedistractor.
         the fb algorithm uses a breadth-first search implementation of the queue  as shown in definition 1. consequently  any solution for which goal returns true will have a minimal number of properties  since the breadth-first search considers smaller combinations of properties first.
         the fb algorithm uses the expand method  and createnode method which are shown in definition 1 and it is invoked by a call of makerefexp method which is shown in definition 1.
1 the incremental algorithm
the distinctive property of the incremental algorithm is that it reduces the computational complexity of constructing a
referring expression by considering properties to use in sequence from a predefined ordering of the available properties. the implementation of the expand method shown in definition 1 provides this behaviour.
         if the set of properties of the current state s.p is not empty  then the first property p according to the given or-
der o is chosen from the set of properties of the current state s.p  and a node is created with a new state by the method createnode. note that the createnode method is the same as that used in the fb algorithm and shown in definition 1.


definition 1: the full brevity algorithm
expand node  {
n 뫹  
s 뫹 node.getstate   foreach p 뫍 s.p do
모모n 뫹 n 뫋 { createnode  node p } end return n } createnode node  p  { s 뫹 node.getstate   out 뫹 rulesout p  s.c  if out 1=   then
return new node s.c   out  s.l 뫋 {p} 
모모모모모모모모모s.p   {p}  else return new node s.c  s.l  s.p   {p} 
}


definition 1: breadth-first queueing

queue actnodes newnodes  { // append the nodes at the end return actnodes 뫋 newnodes
}

         unlike the expand method used in the fb algorithm  however  the set of nodes returned here contains only one node. the main method applies the goal predicate to this node; if this returns true  then the node containing the state with the list of properties for the referring expression is returned.

definition 1: the incremental algorithm

o // predefined constant order of properties expand node  {
n 뫹  
s 뫹 node.getstate   if s.p 1=   then
p 뫹 choose the first p in o  where p 뫍 s.p
모n 뫹 n 뫋 { createnode node p  } end return n
}

1 extension of the ia to sets
the algorithms considered so far have been concerned with constructing descriptions for individual referents;  van deemter  1  introduced an algorithm which extends the
ia to sets. the extension is shown in terms of our framework in definition 1.
         note that  precisely because this algorithm is an extension of the ia algorithm  we reuse the expand method from that algorithm. consequently  the extension requires only the rewriting of the createnode method  whereby an attribute pi is only chosen when it does not rule out entities definition 1: the set algorithm
r // set of referents createnode node  p  {
out 뫹 rulesout p s.c  if    x 뫍 r&x 뫍 out &  x 뫍 c&x 뫍 out  then
return new node s.c   out s.l뫋{p} s.p   {p} 
모else return new node s.c  s.l  s.p   {p}  }

from the set of intended referents r and when it rules out at least one entity from the set of distractors c. if a property does not fulfil that condition  then a node with the current state is returned and the process is continued  as in the ia  with the next property.
1 gre involving relations
the algorithm for gre involving relations  ir  introduced by  dale and haddock  1  is constraint-based. the search strategy used to fulfil the constraints is a combination of a greedy search  which chooses the relation that leads to the smallest set of distractors  and depth-first search to describe the entities  that is  the intended referent as well as entities which are referenced in the relations.
the strategy can be explained best by means of an
and/or-tree  as shown in figure 1. here  the top node represents a state in which relational properties are to be considered as additions to the set of chosen properties. each search step consists of two stages: in the first stage  we choose the relation pi which rules out the largest number of distractors; in the second stage  each entity which is referenced by the chosen relation has to be described by repeating the process recursively. this is done in a depth-first manner  but if the related entity is not uniquely distinguished then the next pj that the intended referent participates in is chosen  and so on. this process continues until all entities are uniquely described  success  or no further relations can be chosen  failure .

figure 1: expansion tree for the ir algorithm
         the algorithm is represented in the problem solving paradigm as in definition 1. here  the expand method chooses a relation which rules out the largest number of distractors; it then calls the method createnode  which recursively calls makerefexp for each new referent contained in the relation.

definition 1: involving relations
r // referent expand node  { s 뫹 node.getstate  
pc 뫹 nil
// chosen relation is pc  where p rules out
// the largest number of distractors foreach p 뫍 s.p do
if pc = nil or
모|rulesout p s.c |   |rulesout pc s.c | then pc 뫹 p end
모end nodec 뫹 createnode node pc  if  nodec = nil  then return   else return {nodec} } createnode node  p  {
s 뫹 node.getstate   c 뫹 s.c  rulesout p s.c 
l 뫹 s.l 뫋 {p}
// extend description foreach r1 뫍 {rp|rp 뫍 referents p & rp 1= r} do
noder1 뫹 makerefexp r1 
if noder1 = nil then return nil // failure
모l 뫹 l 뫋 node.getstate  .l end
return new node c l s.p   {p} 
}

1 context-sensitive gre
 krahmer and theune  1  also introduced a number of extensions to the ia: the use of salience weights in order to add a definite article to the description for the most salient entity; contrastive propertiesin order to add properties which impose a contrast between two entities; and a relational extension  similar in spirit but not in form to that in the ir algorithm described above.
         again  as for the sets algorithm  the commonality with the ia algorithm surfaces as the reuse of the latter algorithm's expand method; only the createnode method needs to be rewritten  as in definition 1. to model this variant in our framework  we introduce the following additional methods  cf.  krahmer and theune  1  :
  contrastive takes a referent r and a property pi; it checks whether the property under consideration is contrastive.
  mostsalient takes a referent r  a set of properties  and a set of distractors; it checks whether every entity in the set of distractors has a lower salience weight than r.
1 conclusions and future work
in the foregoing  we have shown how a number of the most frequently discussed algorithms for the generation of referring expressions can be represented within a common framework. the framework is  we believe  an intuitively appealing one: the process of constructing a referring expression definition 1: context-sensitive algorithm
r // referent
createnode node  p  { s 뫹 node.getstate  
out 뫹 rulesout p s.c 
c 뫹 s.c   out l 뫹 s.l
if  out 1=   or contrastive r p   then
l 뫹 l 뫋 {p }
if v expresses a relation between r and r1 then
noder1 뫹 makerefexp r1 
모l 뫹 l 뫋 noder1.getstate  .l end
end if mostsalient r l c  then
l 뫹 l 뫋 { defart }
// the most salient rules out all distractors:
모c 뫹   end
모return new node c  l  s.p   {p}  }

is viewed as a search problem  where we effectively build a search space consisting of possible descriptions.
         there are three significant advantages to this approach.
         first  it allows us to determine what the algorithms have in common. this is particularly interesting in that it allows us to begin to assemble a collection of core functionalities that are usable in a variety of different approaches to gre. this is apparent not only in terms of the general framework  where  for example  the notions of states and their initialisation  the definition of what it is to be a goal state  and the overall algorithmic pattern  are shared  but in terms of 'helper' routines  such as rulesout and mostsalient  which can be modularised out of the essence of different algorithms and reused elsewhere.
         second  it makes it possible to see more clearly what the essential differences between the algorithms really are. in their original forms  these differences are obscured  due to the absence of a commonvocabularyfor expressingthe algorithms; by representing the algorithms within a common framework  it becomes easier to see where the algorithms differ  and where the differences are simply due to differences in notation or presentation. by using the framework of problem solving as search  we have effectively decomposed the algorithms into a number of key elements: a search srategy  represented by the queuing-method  and an expand-method  which encompasses two aspects of each algorithm: the basic strategy adopted and the particular kinds of referring expressions covered. furthermore  the expand-method decomposes into a general strategy for expansion  as found in  for example  the full brevity algorithm and the incremental algorithm   and a createnode method  which varies depending upon the kind of referring expression targetted.
         third  it allows us to see more clearly the logical space within which the algorithms reside  and to see ways of combining aspects of different algorithms. at its simplest  this is clearest with respect to the kind of search strategy used in the algorithms. present formulations conflate the choice of search strategy with the other aspects of the algorithm  such as how subsequent nodes in the search space are computed ; our approach separates out these different facets of the algorithms  and makes it much easier to see that the choice of search strategy is an independent decision. consequently  for example  we can easily experiment with a variant of the ir algorithm that uses breadth-first search rather than depth-first search.
         so far  we have used the framwework to express the most widely-known algorithms in the literature. preliminary examination of the algorithms in  krahmer et al.  1    van deemeter and krahmer  forthcoming   and  horacek  1  suggests that these will also be expressible within the framework described here. as we capture more algorithms in the framework  our intention is to tease out an inventory of basic constituent elements which can then be reassembled and integrated in different ways  so that we can derive a better understanding of the nature of the problem of referring expression generation.
acknowledgements
this work was carried out while the first author was a visiting researcherat macquarie university's centre for language technology; the visit was supported by macquarie university's research development scheme. we are grateful to the members of the centre for language technology who provided insightful comments on earlier presentations of this work  and to the anonymous ijcai reviewers for their helpful comments.

 
a single 1-d image is an ambiguom representation of the 1i  world many different scenes could have produced the same image -yet the human visual system is extremely successful at recovering a qualitatively correct depth model from this type of representation. workers in the field of computational vision have devised many distinct schemes that attempt to duplicate this ability of human vision; these schemes are collectively called  shape from ....  methods  e.g.  shape from shading  shape from texture  shape from contour . in this paper we argue that the distinct assumptions employed by each of these different schemes must be equivalent to providing a second  virtual  image of the original scene  and that all of these different approaches can be translated into a conventional stereo formalism. in particular  we show that it is frequently possible to structure the problem as that of recovering depth from a stereo pair consisting of a conventionial perspective image  the original image  and an orthographic image  the virtual image . we provide a new algorithm of the form required to accomplish this type of stereo reconstruction task. 
1 	i n t r o d u c t i o n 
the recovery of 1-d scene geometry from one or more images  which we will call the scene modeling problem  smp   has solutions that appear to follow one of three distinct paradigms: 
stereo; optic flow; and shape from shading  texture  and contour. 
모in the stereo paradigm  we match corresponding world/scene points in two images  and  given the relative geometry of the two cameras  eyes  that acquired the images  we can use simple trigonometry to determine the depths of the matched points . 
모in the optic flow paradigm  we use two or more images to compute the image velocity of depicted scene points. if the camera's motion and imaging parameters are known  we can again use simple trigonometry to convert velocity measurements in the image to depths in the scene . 
모in the shape from shading  texture  and contour  sstc  paradigm  we must either know  or make some assumptions about the nature of the scene  the illumination  and the imaging geometry. reference  contains an excellent collection of papers  many of which address the problem of how to recover depth from the shading  texture  and contour information visible in a single image. two distinct computational approaches have been employed in the sstc' paradigm:  a  integration of partial differ-
the work reported herein was supported by the defense advanced research projects agency under contract no. mda1-c-1. 
ential equations describing the relation of shading in an image to surface geometry in a scene  and  b  back-projection of planar image facets to undo the distortion in an image attribute  e.g.  edge orientation  induced by the imaging process on an assumed scene property  e.g.  uniform distribution of edge orientations . 
모our purposes in this paper are to provide a unifying framework for the scene modeling problem  and to present a new computational approach for recovering scene geometry from the shading  texture  and contour information present in a single image. our contribution is based on the following observation: regardless of the assumptions employed in the sstc paradigm  if a 1-d scene model has been successfully derived  it will generally be possible to establish a large number of correspondences between image and scene  model  points. from these correspondences we can compute a collineation matrix  and extract from the matrix the imaging geometry  . we can now construct a second image of the scene as viewed by the camera from some arbitrary location in space. it is thus obvious that any technique that is competent to solve the smp must either be provided with at least two images  or must make assumptions that are equiv alent to providing a second image. we can unify the various approaches to the smp by converting their associated assumptions and auxiliary information into the implied second image and employ the stereo paradigm to recover depth. in the case of the sstc paradigm  our approach amounts to  one-eyed stereo.  
1 shape f r o m one-eyed stereo 
most people viewing figure 1 get a strong impression of depth we can recover an equivalent depth model by assuming that we are viewing a projection of a uniform grid and employing the computational procedure to be described. in the remainder of this paper we will show how various simple modifications and variations of the uniform grid  as the implied second image  allow us to recover depth from shading  texture  and contour. 
모the one-eyed stereo paradigm can be described as a five-step process  as outlined in the paragraphs below. differences in the scenes and the image-formation processes will require variations in the particular procedures to be used  but the general approach will remain the same  
1 partition the image 
as with all approaches to the smp  the image must be segmented into regions prior to the application of a particular algorithm on any individual portion of the image. before the one-eyed stereo computation can be employed  the image must be segmented 


into regions that can be described by a single underlying model. the computation can then be carried out independently in each region  and the results knitted together. 
1 select a model 
for each region identified by the partitioning process  we must determine the underlying model that explains that portion of the image. surface reflectance functions and texture patterns are examples of such models. partitioning the image and selecting the appropriate models are difficult problems that are not addressed in this paper. witkin and kass  are exploring a new class of techniques that promises to provide answers to these questions. it will not be possible to recover depth where no single model can be associated with a particular image region. similarly  inaccurate or incorrect results can be expected if the partitioning or modeling is performed incorrectly. 
1 generate the virtual image 
the key to one-eyed stereo is using the model to fabricate a second  virtual  image of the scene. the idea is that the model often allows one to construct an image of the scene that is independent of the actual shape of the imaged surface. this allows the virtual image to be determined solely from knowledge of the model without making use of the original image. for example  the markings on the surface of figure 1 could have arisen from a projection of a uniform grid upon the surface  figure 1 . for all images that fit this model  we can use a uniform grid as the virtual image. the orientation  position  and scale of this grid will typically be unknown  and we will show how this information can be recovered from the original image. other models give rise to other forms of virtual images. 
1 determine correspondences 
in order to apply stereo techniques to determine depths  we must first establish correspondences between points in the real image and the virtual image. when dealing with textures  the process is typified by counting texels in each image from a chosen starting point. with shading  the general approach is to integrate intensities. several variations are described in the next section  and the difficulty of the procedure will depend on the nature of the model. 
1 compute depths using stereo 

figure 1: the virtual image of figure 1 
with two images and a number of point-to-point correspondences in hand  the techniques of binocular stereo are immediately applicable. at this point  the problem has been reduced to computing the relative camera models between the two images and using that information to compute depths by triangulation. the fact that the virtual image will normally be an orthographic projection required reformulation of existing algorithms for performing this computation. the appendix describes a new algorithm that computes the relative camera model and reconstructs the 1-d scene from eight point-correspondences between a perspective and an orthographic image. 
모the problem of recovering scene and imaging geometry from two or more images has been addressed by workers in both binocular stereo and monocular perception of motion  where tintwo projections are separated in time as well as space . various approaches have been used to derive equations for the 1-d coordinates and motion parameters; these equations are generally solved by iterative techniques    . oilman  presents a solution for recovering 1-d shape from three orthographic projections with established correspondences among at least four points. his  polar equation  allows computation of shape when the motion of the scene is restricted to a rotation about the vertical axis and arbitrary translation. nagel and neumann  provide a compact system of three nonlinear equations for the unrestricted problem when five point-correspondences between the two perspective images are known. more recently. huang  and longuet-higgins  have independently derived methods that only require the solution of a set of eight simultaneous linear equations when eight point-correspondences are known between two perspective images. in our formulation we are faced with a stereo problem involving a perspective and an orthographic image  and while the aforementioned references are related  none provides a solution to this particular problem. 
모the derivation described in the appendix was inspired by the formulation of longuet-higgins for perspective images. when either image nears orthography  longuet-higgins' method becomes unstable and is undefined if either image is truly orthographic moreover  his approach requires knowledge of the focal length and principal point in each image. our method was specifically derived for one orthographic and one perspective image whose internal imaging parameters may not be fully known. 
1 variations on the t h e m e 
in this section we illustrate how our approach is used with several models of texture  shading  and contour. where these models 

t. stratand m. fischler 1 

figure 1:  a  the original image 	 b  the virtual image 

don't match given scene characteristics  they may require additional modification. however  a qualitatively correct answer might still be obtainable by applying one of the specific models we discuss in the following subsections to what appears to be an inappropriate situation  or a situation where the validity of the assumptions cannot be established. 
1 	shape from texture 
surface shapes are often communicated graphically to humans by drawings like figure 1. these drawings can also be interpreted by one-eyed stereo. in this case  there is no need to partition the image; the underlying model of the entire scene is that the intersections of the lines are distributed in the form of a square grid. when viewed from directly above at an infinite distance  the surface would appear as shown in the virtual image of figure 1 regardless of the shape of the surface. this virtual image can be construed as an orthographic projection of the object surface from an unknown viewing direction. correspondences between the original and virtual images are easily established if there are no occlusions in the original image. select any intersection in the original image to be the reference point and pair it with any intersection in the virtual image. a second corresponding pair can be found by moving to an adjacent intersection in both images. additional pairs are found in the same manner  being careful to correlate the motions in each image consistently in both directions. when occlusions are present  it may still be possible to obtain correspondences for all visible junctions by following a non-occluded path around the occlusion. if no such path can be found  the shape of each isolated region can still be computed  but there will be no way to relate the distances without further information. other techniques used to graphically represent images of 1-d shapes may require other virtual images. figure 1a  for example  would imply a virtual image as shown in figure 1b. methods for recognizing which model to apply are needed  but are not discussed here. 
모once correspondences have been determined  we can use the algorithm given in the appendix to recover depth. we have presumably one perspective image and one orthographic image whose scale and origin are still unknown. the depths that will be recovered will be scaled according to the scale chosen for the virtual image1. the choice of origin for the orthographic image is arbitrary  and will result in the same solution regardless of thf point chosen as the origin. the appendix shows how to compute the orientation of the orthographic coordinate system relative 
'recall that  the original image does not contain the information necessary to recover the absolute size of the scene. 
figure 1: the streets in this scene resemble a projected texture. 
to the perspective imaging system as well as the displacement between the two  given the choice of origin for the orthographic view. 1-d coordinates of each matched point are then easily computed using back-projection. a unique solution will be obtained whenever the piercing point of the perspective image is known. a minimum of eight pairs of matched points are required to obtain a solution; depths can be computed for all matched points. 
모there exists a growing literature on methods to recover shape from natural textures  ll . we will now show how the constraints imposed by one particular type of natural texture can be exploited to obtain similar results by using one-eyed stereo. 
모consider the pattern of streets in figure 1. if this city were viewed from an airplane directly overhead at high altitude  the streets would form a regular grid not unlike the one used as the virtual image in figure 1. there are many other scene attributes that satisfy this same model. the houses in some cities would appear to be distributed in a uniform grid if viewed from directly overhead. in an apple orchard growing on a hillside  the trees would be planted in rows that are evenly spaced when measured horizontally. 
모ignoring the nontrivial tasks of partitioning these images into iso-textural regions  verifying that they satisfy the model  and identifying individual texels  it can be seen how these images can be interpreted using the same techniques as in the previous section. the virtual image in each case will be a rectangular grid  and can be considered as an orthographic view from an unknown orientation. correspondences can be determined by counting street intersections  rooftops  or apple trees. as before  one can solve for the relative camera model and compute depths of matched points. obviously  for the situations discussed here  we must be satisfied with a qualitatively-correct interpretation due to the difficulty of locating individual texels reliably and accurately  as well as the numerical instabilities arising from the underlying nonlinear transformation. 
1 	shape from shading 
for our purposes  surface shading can be considered the limiting case of a locally uniform texture distribution  as the texels approach infinitesimal dimensions  as seen near the horizon in figure 1 . to compute correspondences  we need to appropriately integrate image intensities in place of counting lines  since 


the image intensities can be seen to be related to the density of lines projected on the surface. the feasibility of this procedure depends on the reflectance function of the surface. 
모what types of material possess the special property that allows their images to be treated like the limit of the projected texture of the previous section  it must be the case that the integral of intensity in an image region is proportional to the number of texels that would be projected in that region. this can be described in terms of i and c  where i is the angle between the local surface normal and the light source  and e is the angle between the surface normal and the viewpoint. it can be seen that the number of texels projected onto a surface patch will be proportional to cos i  the cosine of the incident angle. at the same time  the surface patch  as seen from the viewpoint  will be foreshortened by cose  the cosine of the emit lance angle. thus  the integral of reflected light intensity over a region will be proportional to the flux of the light striking the surface if the intensity of the reflected light at any point is proportional to cosi/cose. horn  has pointed out that the material in the maria of the moon  and other rocky  dusty objects when viewed from great distances  possess a reflectance function that allows recovery of the ratio cosi/cose from the imaged intensities. this surface property has allowed unusually simple algorithms for computing shape-from-shading  so it is not surprising that it easily submits to one-eyed stereo as well. 
모to interpret this type of shading  we can construct a virtual image whose direction of view is the lighting direction  i.e.  taken from a  virtual camera* located at the light source . when the original shaded image is orthographic  we consider a family of parallel lines that lie in planes that include both the light source and the  distant  view point. when viewed from the light source  the image of the surface corresponding to these lines will also be a set of parallel lines regardless of the shape of the surface. these parallel lines constitute the virtual image. we will use the image intensities to refine these line-to-line correspondences to pointto-point correspondences. figure 1 shows the geometry for an individual line in the family. a little trigonometry shows that 
	a*' = at 	 1  
where 뺆s is a distance along the line in the real image and a*' is the corresponding distance along the corresponding lino in the virtual image. integrating this equation produces the following expression  which defines the point correspondences in the two 

to use this equation we must first compute cops/cose from the intensity value at each point along the line. this will  of course  be possible only when the reflectance function is constant for constant cosi/cose. with these point-to-point correspondences in hand  it is a simple matter of triangulation to find the 1-d coordinates of the surface points  given that we know the direction to the light source. we can explore the remainder of the surface by repeating the process for each of the successive parallel lines in the image. it still remains to tie each of the adjacent profiles together  as the scale factor of each profile has not been determined. knowledge of the actual depth of one point along each profile provides the necessary additional information. it is important to note that our assumptions and initial conditions are those used by horn; the fact that he was able to obtain a solution under these conditions assured the existence of a suitable virtual image for the one-eyed stereo paradigm. 
1 	shape from contour 
it is sometimes possible to extract a line drawing  such as shown in figure 1  from scene textures. parallel streets like those encountered in figure 1 give rise to a virtual image consisting of parallel lines when the cross streets cannot be located; terraced hills also produce a virtual image of parallel lines. correspondences between real and virtual image lines can be found by counting adjacent lines from an arbitrary starting point. this matches a virtual image line with each point in the real image. point-to-line correspondences are not sufficient to employ the stereo computation of the appendix to reconstruct the surface 
knowledge of the relative orientation between the two images 
 equivalent to knowing the orientation of the camera of the real image relative to the parallel lines in the scene  provides the necessary additional constraint; the surface can then be reconstructed uniquely through back-projection. without knowledge of the relative orientation of the virtual image  heuristics must be employed that relate points on adjacent contours so that a regular grid can be used as the virtual image. the human visual system is normally able to interpret images like figure 1 although just what assumptions are being made remains unclear. further study into this phenomenon may lead to the extraction of models suitable to the employment of one-eyed stereo on this type of image without requiring prior knowledge of the virtual orientation 

t. strat and m. fischler 1 i 

figure 1: this simple drawing has two reasonable interpreta-

tions. it is seen as curved roller-coaster tracks if the lines are assumed to be the projection of a rectangular grid  or as a volcano when the lines are assumed to be the projection of a circular grid. 
1 	distorted textures and unfriendly shading 
we have already noted that image shading can be viewed as a limiting  and  for our purposes  a degenerate  result of closelyspaced texture elements. in order to recover depth from shading  we must use integration to replace counting the texture elements that define the locations of the  grid lines  of our virtual image. the integration process depends on having a  friendly  reflectance function and an imaging geometry that allows us to convert distance along a line in the actual image to a corresponding distance along a line in the virtual image. 
the recovery of lunar topography from a single shaded image 
 1   as discussed in section 1  is one of the few instances in which  shape from shading  is known to be possible without a significant amount of additional knowledge about the scene; and even here we are required to know the actual reflectance function  the location of the  point  source of illumination  the depths along a curve on the object surface  and be dealing with a portion of the object having constant albedo. further  the reflectance function had to have just the property that we require to replace direct counting  i.e.  the reflectance function had to compensate exactly for the foreshortening  of distance due to viewing points on the object surface at an unknown tangent-plane orientation angle. most of the commonly encountered reflectance functions  such as lanibertian reflectance  do not have this friendly property  and it is not clear to what extent it is possible to recover depth from shading in such cases  e.g.  see pentland  and smith  . additional assumptions will probably be needed and the qualitative nature of the recovery will be more pronounced. just as in the case where a complex function can be evaluated by making a local linear approximation and iterating the resulting 
solution  it may be possible to deal with unfriendly  or even unknown  reflectance functions by assuming that they are friendly about some point  directly solving for local shape using the algorithm applicable to the friendly case  and then extending the solution to adjacent regions. we are currently investigating this approach. 
모the uniform rectangular grid and the polar grid that we used as virtual images to illustrate our approach to one-eyed stereo are effective in a large number of cases  because there are processes operating in the real world that produce corresponding textures  i.e.  grid-like textures that appear to be orthographical!y projected onto the surfaces of the scene . however  there are also textures that produce similar-appearing images  but are due to different underlying processes. for example  a uniform grid-like texture might have been created on a flat piece of terrain  which figure 1: view of surface reconstructed from figure i. 
then underwent geologic deformation in this case the virtual image needed to recover depth  or the recovery algorithm  must be different from the projective case. we have already indicated the problem of choosing the appropriate model for the virtual image  and as noted above  image appearance is probably not sufficient to make this determination some semantic knowledge about the scene is undoubtedly required. figure 1 shows an example in which two completely different interpretations of scene structure result  both believable  depending on whether we use the rectangular grid model  or the polar grid model. 
1 	e x p e r i m e n t a l results 
the stereo reconstruction algorithm described in the appendix has been programmed and successfully tested on both real and synthetic imagery. given a sparse set of image points and their correspondence in a virtual image  a qualitative description of the imaged surface can be obtained. 
모synthetic images were created from surfaces painted with computer-generated graphic textures. figure 1 shows a synthetic image constructed from a piece of a digital terrain model  dtm . the intersections of every 1th grid line constitute the set of 1 image points made available to the one-eyed stereo algorithm. their correspondences were determined by selecting an arbitrary origin and counting grid lines to obtain virtual image coordinates processing these pain by the algorithm in the appendix yields a set of 1-d coordinates in either the viewer-centered coordinate space  or the virtual image coordinate space  which  if correct  is aligned with the original dtm . figure 1 was obtained from the 1-d coordinates in the virtual image space by fitting a surface to these points using smith's surface interpolation algorithm   this gives a dense set of 1-d coordinates that can then be displayed from any viewpoint. the viewpoint that was computed by one-eyed stereo was used to render the surface as shown in figure 1. its similarity to the original rendering of the surface  fig. 1  illustrates the successful reconstruction of the scene. 
모the same procedure was followed when working with real photographs. using the photo of san francisco in figure 1  the intersections of 1 street intersections were extracted manually. those that were occluded or indistinct were disregarded. virtual image coordinates were obtained by counting city blocks from the lower-left intersection. the one-eyed stereo algorithm was then used to acquire 1-d coordinates of the corresponding image points in both viewer-centered and grid-centered coordinate systems. a continuous surface was fitted to both representations of these points. the location and orientation of the camera relative 


figure 1: perspective view of surface reconstructed from photograph of san francisco  figure 1  
to the grid were also computed. figure 1 shows the reconstructed surface from the derived location of the viewpoint of the original photo the numbers superimposed are the computed locations of the original 1 points. while several of the original points were badly mislocat.ed  the general shape of the landform is apparent. 
모there are several reasons why the algorithm can only provide a qualitative shape description. first  the problem itself can be some what sensitive to slight perturbations in the estimates of the piercing point or focal length. this appears to be inherent to the problem of recovering shape from a single image. how humans ran determine shape monocularly without apparent knowledge of the piercing point or semantic content of the scene remains unresolved. the second factor precluding precise  quantitative description of shape is the practical difficulty of acquiring large numbers of corresponding points. while the algorithm can proceed with as few as eight points  the location of the object will only be identified at those eight points. if a more complete model is sought  then additional points will be required to constrain the subsequent surface interpolation. 
모the task remains to evaluate the effectiveness of the iterative technique  described in section 1  for recovering  a  shape from shading in the case of scenes possessing  unfriendly  reflectance functions  and  b  shape from nonprojective and distorted textures. our experience with the process indicates that the key to these problems lies in the ability to establish valid correspondences with the virtual image. once these are available  reconstruction of the surface can proceed as outlined. 
1 	conclusion 
in this paper we have shown that  in principle  it is possible to employ the stereo paradigm in place of various approaches proposed for modeling 1-d scene geometry-including the case in which only one image is provided. we have further shown that  for the case of a single image  the approach could be implemented by: 
모 1  setting up correspondences between portions of the image and variations of a uniform grid; 
모 1  treating each image portion and its grid counterpart at a stereo pair  and employing a stereo technique to recover depth. 
 we present a new algorithm necessary to accomplish this step.  
모automatic procedures to partition the image  select the appropriate form of the virtual image  and establish the correspondences  are all difficult problems which were not addressed in this paper. nevertheless  we have unified a number of apparently distinct problems  which  individually  would still have to contend with these same pervasive problems  i.e.  partitioning  model selection  and matching . 

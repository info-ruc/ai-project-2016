
in machine translation  document alignment refers to finding correspondences between documents which are exact translations of each other. we define pseudo-alignment as the task of finding topical-as opposed to exact-correspondences between documents in different languages. we apply semisupervised methods to pseudo-align multilingual corpora. specifically  we construct a topicbased graph for each language. then  given exact correspondences between a subset of documents  we project the unaligned documents into a shared lower-dimensional space. we demonstrate that close documents in this lower-dimensional space tend to share the same topic. this has applications in machine translation and cross-lingual information analysis. experimental results show that pseudo-alignment of multilingual corpora is feasible and that the document alignments produced are qualitatively sound. our technique requires no linguistic knowledge of the corpus. on average when 1% of the corpus consists of exact correspondences  an on-topic correspondence occurs within the top 1 foreign neighbors in the lowerdimensional space while the exact correspondence occurs within the top 1 foreign neighbors in this this space. we also show how to substantially improve these results with a novel method for incorporating language-independent information.
1 introduction
electronic information is available in many different languages. if a user can only read greek  then the amount of information available online is somewhat limited compared to a user who understands english. therefore  in order to allow as many people to access as much information as possible  it is increasingly important to develop technologies that allow users to access information in a language-neutral fashion.
¡¡two language technologies have been developed to tackle this task. first  machine translation systems attempt to bridge the language barrier by translating content on demand. this approach is appropriate when someone has a known-relevant document in hand. when this is not the case  cross-lingual information retrieval systems allow users to query a corpus in their native language and retrieve documents in a foreign language. the results can then either be manually or machine translated. we offer a hybrid approach which embeds all documents in multiple languages into a single semantic space. by providing a language-neutral embedding space  we can collectively analyze a foreign collection of documents without being constrained to document-based and query-based analysis. for example  a user may be interested in clustering or visualizing all documents in every language simultaneously.
¡¡we will now define our collection alignment problem. assume that we are given two document collections. for example  consider one in english and one in mandarin. in addition  we are given some training correspondences between documents we know are exact translations of each other. for example  assume we have a handful of english documents manually translated into mandarin. our task is  for each english or mandarin document in the untranslated set  to find the topically most similar documents in the foreign corpus. this process results in a pseudo-aligned corpus.
¡¡our approach aligns the underlying topical structures of two parallel collections.1 given a parallel corpus  the lexicon and distribution of terms within each side of the corpus will be quite different. however  since the corpus is parallel  the underlying topical structure is likely to be very similar regardless of the underlying language.
¡¡we conceptualize this topical structure in the form of a manifold over documents  where documents that are topically related are 'close' to each other on the manifold. thus  we can view a corpus as a sample from some underlying manifold. we are interested in the case where the topical distributions between languages are very similar. here  our working hypothesis is that the true underlying topical manifolds of any two languages are isomorphic.
¡¡we use techniques from spectral graph theory to automatically pseudo-align documents in different languages. unlike machine translation systems  which focus on exact 1-to-1 alignments of documents or sentences  we instead focus on a looser sense of alignment  based on topical relevance. our results show that it is possible to recover topic and exact alignments of documents using a reasonably small set of training examples and very na¡§ ve linguistic processing. we also show how to improve these results with a novel method for incorporating language-independent information.
1 related work
parallel corpora are a fundamental concept in machine translation. traditionally  the alignment problem focuses on aligning sentences between two documents known to be exact translations  gale and church  1 . statistical machine translation systems require this level of granularity to learn relationships between words in different languages. our approach relaxes both the granularity and exact-translation constraints.
¡¡oftentimes  we know parallel corpora exist but do not have the correspondences. this happens frequently on the world wide web where entire hierarchies may be represented in several languages. the solution to this problem usually requires inspecting and aligning urls and structural tags in the documents  resnik and smith  1 . while this approach works well for structured and explicitly-linked data  when this information is missing or inexact  the solution may not work. our approach only requires relationships between the content within a language and is robust to noise.
¡¡another alternative to re-alignment uses external dictionaries to create probabilistic relationships between unaligned documents  resnik and smith  1 . while this technique is applicable to our task  we are interested in methods which do not require external resources such as dictionaries.
¡¡our work is also related to the task of aligning multidimensional data sets. when viewing documents as  say  english term vectors and mandarin term vectors  we can use techniques such as canonical correlation analysis or gaussian processes to compute a transformation between the spaces  hardoon et al.  1; shon et al.  1 . correspondences and translations can also be addressed in terms of graphical models  barnard et al.  1 . solutions using spectral graph theory are the most related to our work  carcassoni and hancock  1; ham et al.  1; shon et al.  1; verbeek and vlassis  1 . we apply these spectral techniques and extend them to include manifold-independent information.
1 collection alignment
our procedure for aligning corpora consists of two phases: representing monolingual document collections and aligning the monolingual representations. in the first phase  we consider a graph-based representation of the document collection. graphs provide intuitive and flexible collection models suitable for a variety of tasks such as classification and retrieval  diaz  1; zhu et al.  1 . the second phase is to find topically similar nodes in the foreign graph using labeled document alignments. we employ spectral graph theory to project documents in all languages into a single embedding space and align documents using distances in this joint embedding space.
1 representing document collections
graph-based representations of document collections view documents as nodes in a graph. edges in this graph exist between documents which share a property such as topic  genre  author  etc. because we are interested in topical alignment of collections  we will be focusing on topical edges. in this section  we will be discussing one method of detecting topical relationships. although others certainly exist  graph-based representations have consistent behavior across affinity measures  diaz  1 .
¡¡given a corpus containing n documents and |v | terms  one of the most popular document representations is the length|v | term vector. constructing the vector often requires a term-weighting scheme such as tf.idf. in our work  we will assume that document vectors are language models  multinomial term distributions  estimated using the document text  croft and lafferty  1 . by treating documents as probability distributions  we can use distributional affinity to detect topical relatedness between documents. specifically  we use the multinomial diffusion kernel  lafferty and lebanon  1 . given two documents i and j  the affinity is measured between the two distributions  ¦Èi and ¦Èj  as

where t is a parameter controlling the decay of the affinity. the diffusion kernel has been shown to be a good affinity metric for tasks such as text classification and retrieval.
¡¡a document graph for a particular language  then  is constructed by treating the n documents as nodes and  for each document  adding undirected  weighted edges to the k nearest neighbors as measured by the diffusion kernel. we represent these a document graph as the n¡Án adjacency matrix w. in our experiments  we fix t = 1 and k = 1. we use a simple maximum likelihood estimate for the document language models.
1 functions on graphs
because our alignment algorithm uses results from spectral clustering  we will briefly review some fundamentals before presenting our solution. a more thorough treatment of the material can be found in other sources  chung  1 .
¡¡we define a function f over the nodes of a graph as a length-n vector. we can measure the smoothness of this function as. this is known as the dirichlet sum and computes the difference in the function value between connected nodes.
¡¡the dirichlet sum can be written as ft d   w f where d is a diagonal matrix such that. the matrix ¦¤ = d   w is known as the combinatorial laplacian. we can introduce alternative laplacians to provide different measures of smoothness. in this paper  we will always use the approximate laplace-beltrami operator  lafon  1 . this is defined as 
	¦¤	=	i   d  1w  d  1	 1 
where we use the normalizing affinity matrix w  = d 1wd 1 with. this approximation provides a density normalization effect that we have found important when dealing with document collections.
¡¡the k eigenvectors associated with the lowest non-zero eigenvalues of the laplacian represent the functions f minimizing the dirichlet sum. in turn these eigenvectors can be used to embed documents in a lower dimensional space  belkin and niyogi  1 . if we let e represent the n ¡Á k matrix of these eigenvectors  we can represent each document i using the corresponding row vector of e. we then compute the euclidean distance between documents in the kdimensional space 
		 1 
1 aligning collections
we now define our collection alignment problem. assume that we are given two document graphs represented by the n ¡Á n adjacency matrices wx and wy. in addition  we are given m   n training correspondences between documents we know are exact translations of each other. we can reorganize the adjacency matrices so that the indexes of corresponding documents match and are located in the m¡Ám upper left blocks  wllx and wlly. our task is to find the most topically similar documents for the unlabeled 1 n   m  documents.
¡¡we use the manifold alignment method proposed by ham et al  ham et al.  1 . specifically  we are interested in finding the functions f and g minimizing the following objective 
		 1 
such that fi = gi for i   m. the pairs of functions minimizing this objective can be used to project documents into a single lower-dimensional space.
¡¡although both laplacians  ¦¤x and ¦¤y  are the same size  the indexes m ¡Ü i   n refer to potentially different documents. therefore  we build adjacency matrices with three sets of vertices: the first set of vertices is common between languages; these are the training instances with known alignment  1 ¡Ü i   m . the second set is documents from language x with unknown alignment  m ¡Ü i   n   and the third set is language y with unknown alignment  n ¡Ü i   1n m . this results in the  1n   m  ¡Á  1n   m  matrices 
		 1 
		 1 
notice that we are augmenting these graphs so that there are no edges to new nodes. we will see in section 1 how to incorporate language-independent knowledge we might have about the relationship to these foreign documents.
we can rewrite equation 1 using these augmented matrices 
		 1 
where h =  ftgt t and we define the composite laplacian matrix  ¦¤z = ¦¤ x + ¦¤ y. this can be seen as using the combined laplacian  ¦¤z  of a new graph with 1n   m nodes.
¡¡when viewing alignment as analyzing a larger graph  we notice that ¦¤z contains zero submatrices between unaligned nodes across languages. this is problematic since graph laplacian techniques exploit link structure to detect topics. in order to address this issue  we  seed  these submatrices with predicted alignments from a simple baseline. we represent the 1 n m  unaligned documents in an m-dimensional space. the elements of each document vector represent the affinity with the training documents. that is  we use the  n   m  ¡Á m lower left submatrices of wx and wy. we calculate the seed affinities by l1 normalizing the rows and computing wulx  wuly  t. this  n   m  ¡Á  n   m  matrix defines our initial predictions of the alignments between unaligned documents. we will refer to this as our baseline in experiments. in the case of these experiments  we place the prediction matrix in the middle-right/lower-middle blocks of w  x and w  y.
¡¡we can align documents by first projecting all 1n m documents into a lower-dimensional space and then computing distances in that lower-dimensional space. with enough labeled instances  the projection should improve the baseline predictions. we use the laplacian-based projection method described in section 1. given a document xi in language x  its predicted aligned pair in language y is the closest document in the embedding space. highly ranked documents  then  are likely to be topically related.
1 incorporating language-independent information
in many cases  documents contain language-independent information which can be exploited for alignment. examples include named entities  hyperlinks  and time-stamps. in this section  we extend ham's alignment algorithm to consider such manifold-independent information. specifically  we exploit the temporal information present in the document.
¡¡recall that we viewed our alignment as using the combined laplacian  ¦¤z  of a new graph with 1n m nodes. we would like to consider a second graph over these 1n   m nodes incorporating the language-independent knowledge. this graph will be defined so that edges occur when two documents share the same date; call this unweighted adjacency matrix wt. this gives us two laplacians  ¦¤z and ¦¤t over the large graph. we then measure the smoothness of the function h on both graphs 
		 1 
where the parameter ¦Ë allows us to weight the temporal information. here  our solution falls from embedding documents in a lower dimensional space defined by the lowest non-constant eigenvectors of ¦Ë¦¤z +  1   ¦Ë ¦¤t.
1. compute n ¡Á n affinity matrices for languages x and y
1. add the 1 nearest neighbors for each document to
wx and wy
1. compute the laplacians  ¦¤x and ¦¤y
1. compute the predicted alignments
1. construct the combined laplacian  ¦¤z
1. if language-independent information exists interpolate  1   ¦Ë ¦¤z + ¦Ë¦¤t
1. compute the k eigenvectors associated with the smallest non-zero eigenvalues; stack in matrix e

n	number of documents in one side of the parallel corpus
k dimensionality of the joint embedding space ¦Ë interpolation parameter for language-independent information
e n ¡Á k projection of all documents into kdimensional space
figure 1: pseudo-alignment algorithm. input are k and ¦Ë. the output is a set of distance between all unlabeled documents. the closest pairs represent predicted alignments.
¡¡when we evaluate our algorithms using parallel corpora  this temporal information is powerful but unrealistic. documents with shared topics will rarely have exactly the same date. therefore  we consider a corruption of the date information in our corpus. we accomplish this by corrupting the date information through the following process: for each document i  select a date d from a gaussian distribution whose mean is the date of document and a variance  ¦Ò. select a document j uniformly from amongst all of the documents on that date. construct an edge between i and j. repeat this process 1 times for each document. the parameter ¦Ò allows us to control the error in establishing links between documents. a low ¦Ò will result in constructing edges to 1 nodes which share the same date as i; a high ¦Ò will result in constructing edges to 1 nodes less temporally local to i. this has the effect of modeling documents on the same topic as being published on different but close dates.
¡¡we present a summary of our alignment algorithm in figure 1.
1 methods and materials
1 corpora
parallel corpora allow us to evaluate the document-level alignment for collections where the topical distributions are identical. we used two parallel corpora: an arabicenglish corpus of united nations documents and an english-
mandarin corpus of newswire documents. the arabicenglish corpus consists of 1k united nations documents manually translated into both languages  ma et al.  1 . because some dates were under-represented or missing  we only used documents between 1 and 1. the englishmandarin corpus consists of 1k chinese newswire documents published between august and september 1 and their machine translated representations in english  fiscus and wheatley  1 .
¡¡the english and arabic sides of the corpora were tokenized on whitespace and punctuation. no stopping or stemming was performed. the chinese corpora was tokenized using character unigrams. no additional segmentation or analysis was performed. after tokenization  documents were indexed using the indri retrieval system  strohman et al.  1 . we use only date stamps  not time stamps  as our languageindependent information.
¡¡one concern we had when using parallel corpora was that the graph structures would be identical. we found that  even for our machine translated corpus  the graphs were quite different. nevertheless  we conducted a set of experiments where random subsets of the nodes were removed from each side of the corpus. this is equivalent to having non-parallel collections with identical topical distributions.
1 evaluation
we train our algorithms by providing m example correspondences randomly selected from the collection; in our experiments  we present the number of training correspondence as a fraction of the corpus. we evaluate the re-alignment of parallel corpora using two measures. first  we consider the mean reciprocal rank  mrr  of the true match. that is  we compute distance from a document in language x to all documents in language y; the reciprocal rank of the true translation of this document gives us the score for this document. we use the mean reciprocal rank over all 1 n   m  testing documents.
¡¡we noticed that even at few training correspondences  though the mrr was quite low  on average the true translation in the top 1 documents   the qualitative matches appeared quite good. for example  the closest neighbors to a document about sri lanka-while not including the exact translation-contained documents about sri lanka. because our qualitative analysis suggested that mrr was underrepresenting our performance  we wanted to evaluate the topical alignment. fortunately  a subset of the english-mandarin corpus contains assessments for topical equivalence between documents. we therefore adapted the mrr measure to look for the top ranking on-topic document; we refer to this as tmrr.
1 results
our first set of experiments investigates the performance of our algorithms with respect to the training alignments. the number of eigenvectors was fixed at 1. figure 1 depicts learning evaluated by mrr for the arabic-english and english-mandarin corpora and tmrr for the englishmandarin corpus. the baseline algorithm uses only the distances to the training documents to predict alignments. our alignment algorithm uses both these predictions as well as information about the relationship between unaligned documents.

figure 1: mean reciprocal rank of the true translation for arabic-english alignment  left  and english-mandarin alignment  center . topic mean reciprocal rank for english-mandarin alignment  right . all algorithms used 1 eigenvectors.¡¡the results in figure 1 demonstrates that our alignment algorithm improves the baseline at few training documents. however  as the training size increases  this improvement disappears. we speculate that this task is such that  after a certain point  the number of training alignments provide enough information to adequately distinguish unaligned documents; the additional information encoded in the matrices wuux and wuuy do not add any discriminating information. in fact  because the laplacian-based alignment technique discards information in the projection  performance may suffer. this can be seen in performance curves for the arabic-english corpus. nevertheless  when training data is sparse  the structure extracted by the laplacian-based technique can be leveraged to improve on the baseline.
¡¡in all cases  both document-level and topical alignment are feasible even when only using content information. for example  at 1 training examples  we get the true alignment in the top 1 for the arabic-english corpus and the top 1 for the english-mandarin corpus. when looking at topical alignment  we can get an on-topic document in the 1 for the same number of training instances.
¡¡our first experiments evaluated the realignment of parallel corpora. we were interested in testing the robustness of our techniques to non-parallel corpora. in order to accomplish this  we first fixed the number of training correspondences  m  at 1. we also fixed the number of testing correspondences at 1. we then added 1 documents from each collection. these documents were selected such that some fraction of them were included as pairs of aligned documents. the remaining fraction were randomly sampled  potentially unaligned documents from the collections. varying the fraction of unaligned documents in the 1  we plotted the mrr for the test correspondences in figure 1. we notice that both our baseline and new algorithm are not effected by the addition of unaligned documents.
¡¡we evaluated our temporal alignment using several values for ¦Ò  the date corruption parameter ; we present results for the values {1 1}. we were interested in the performance over various values of ¦Ë. fixing the training correspondences at 1 and number of eigenvalues at 1. we varied the value of ¦Ë. we present these results in figure 1. here  the improvements gained by introducing temporal information are very dependent on the value of ¦Ë. obviously  at low values  the algorithms will reduce to the text-based alignment. however  the reduction in performance observed at the higher values for ¦Ë are likely due to documents being ranked exclusively by their temporal proximity.
¡¡we caution that the temporal corruption process introduces temporal dimensions to topics which are potentially atemporal. for example  there is no reason to believe that two doc-
english mandarin/mrr

figure 1: performance as a function of unaligned documents added to the collection. we fixed the training and testing set sizes to 1 and added 1 documents from each side of the corpus. of these 1  some fraction were not required to be aligned pairs.
english mandarin/tmrr

¦Ë
figure 1: incorporation of language-independent information. we fixed the number of training correspondences to be .1 of the collection and evaluated performance as a function of the weight  ¦Ë  placed on the language-independent information.
uments  one in english and one in mandarin  about cooking will be published on or around the same date. with this in mind  our experiment provide suggestive results with respect to the merit of temporal information for topical alignment. certainly in the cases where the user is interested in temporally salient topics  date information will be invaluable.
1 conclusion
in this paper  we hypothesized that the true underlying topical manifold of different languages are isomorphic. we treated parallel corpora as samples from this underlying manifold and represented the manifold structure using graphs.
¡¡we then described a semi-supervised algorithm for aligning parallel corpora. given a set of correspondences  we apply a spectral graph technique to embed the documents in a lower dimensional space. this essentially clusters the documents in each language and uses the correspondences to define a joint embedding over the entire space. using this joint embedding  we then evaluated our alignment using a document-matching measure  mrr  and as well as a topicmatching measure  tmrr . we demonstrated that our technique can retrieve the true translation of a document at relatively high ranking and an on-topic document near rank 1 at low numbers of training alignments.
¡¡this work suggests several interesting directions. first  although we considered only two languages  our framework easily allows the incorporation of additional languages. this would allow one to leverage topic information from different languages when defining the lower-dimensional topic space. second  we adopted parallel corpora for evaluation reasons. the alignment algorithm does not require that the unlabeled data be parallel. in fact  it would be very helpful to explore the robustness of our alignment method when the two collection have very different topic distributions. would they techniques perform well if documents in languages x and y were drawn from arbitrary  non-parallel collections  finally  these techniques can also be applied to multimedia situations where we want to align documents in different media.
1 acknowledgments
this work was supported in part by the center for intelligent information retrieval  in part by nsf grant #cns1   and in part by the defense advanced research projects agency  darpa  under contract number hr1-c-1. any opinions  findings and conclusions or recommendations expressed in this material are the authors' and do not necessarily reflect those of the sponsor.

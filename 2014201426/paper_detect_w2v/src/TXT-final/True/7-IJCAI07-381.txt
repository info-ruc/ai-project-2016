
forming effective coalitions is a major research challenge in the field of multi-agent systems. central to this endeavour is the problem of determining the best set of agents that should participate in a given team. to this end  in this paper  we present a novel  anytime algorithm for coalition structure generation that is faster than previous anytime algorithms designed for this purpose. our algorithm can generate solutions that either have a tight bound from the optimal or are optimal  depending on the objective  and works by partitioning the space in terms of a small set of elements that represent structures which contain coalitions of particular sizes. it then performs an online heuristic search that prunes the space and only considers valid and non-redundant coalition structures. we empirically show that we are able to find solutions that are  in the worst case  1% efficient in 1% of the time to find the optimal value by the state of the art dynamic programming  dp  algorithm  for 1 agents   using 1% less memory.
1 introduction
coalition formation  cf  is the coming together of distinct  autonomous agents in order to act as a coherent grouping. it has long been studied in cooperative game theory  osborne and rubinstein  1  and has recently become an important topic in multi-agent systems where a team of agents often need to maximise their individual or their collective efficiency. for example  agents often have to form efficient groups to buy goods in bulk or sensors have to decide on how to group together to monitor a given area  dang et al.  1 . given a set of agents 1 .. i .. a ¡Ê a  the cf process involves three computationally challenging stages:
1. coalition value calculation: for each subset or coalition c   a  calculate a value v c  indicating how beneficial that coalition would be if it was formed. note here that this requires processing 1a possible coalitions.
1. coalition structure generation: is the equivalent of the complete set partitioning problem  yeh  1 . this means computing the optimal set of coalitions cs  = argmaxcs¡Êcs v  cs   where a coalition structure cs ¡Ê cs is a partition of a into disjoint exhaustive coalitions  cs is the set of all such partitions
  i.e. each agent belongs to exactly one coalition   and . the search space here is
1. payment calculation: compute the transfers between the agents such that they are incentivised to stay in the coalition to which they are assigned. these payments will depend on the stability concept used  e.g. bargaining set  kernel  or the core  and finding these is usually npcomplete.
in this paper  we focus on the coalition structure generation problem. as in common practice in the literatrue  sandholm et al.  1; dang and jennings  1   we focus on characteristic function games  cfgs   where the value of every coalition c is given using a characteristic function v c . up to now  the most widely used algorithm to solve this problem is due to  yeh  1; rothkopf et al.  1 . their algorithm  which runs in ¦¨ 1a   is guaranteed to find the optimal solution and is based on dynamic programming  dp . however  the dp approach becomes impractical for agents with limited computational power  e.g. computing the optimal cs for 1 agents requires around 1¡Á1 operations . moreover  in the dynamic environments that we consider  agents do not typically have sufficient time to perform such calculations and  in many cases  an approach that gives a good approximation  in a reasonable time  is more valuable.
¡¡against this background  this paper describes a novel anytime search algorithm that uses heuristics to to generate the optimal or near-optimal  with a very tight bound  coalition structure. in more detail  the algorithm works by grouping the coalition structures according to the sizes of coalitions they contain  which we here term a configuration . for example  coalition structures {{1} {1}} and {{1} {1}} both follow the configuration {1}. hence  the space of all coalition structures is partitioned into smaller subsets where every element of a given subset have the same configuration. this is different from previous representations used by other anytime algorithms which looked at the space of interconnected coalition structures  sandholm et al.  1; dang and jennings  1   which necessitates searching a much bigger portion of the space than our method in order to find only integral worst case guarantees from the optimal solution . now  using the list of configurations of coalition structures and by estimating the average and upper bound of the solutions that exist within each configuration in this list  we are able to zoom in on the best configurations after searching a relatively minute portion of the search space  typically 1 ¡Á 1a 1 coalition structures . moreover  by refining the upper bound of every other configuration after searching the coalition structures of one configuration  we are able to reduce the time to find the optimal configuration still further by discarding those configurations that have a lower upper bound than the best value found so far.
¡¡this paper advances the state of the art in the following ways. first  we provide an anytime algorithm to compute the optimal coalition structure that is faster than any previous  anytime  algorithm designed for this purpose. second  we provide a novel representation for the search space based on coalition structure configurations. this approach permits the selection of a solution based either on the selection of coalition structures of particular configurations or on the time available to find the solution. third  our algorithm can provide non-integral worst case guarantees on the quality of any computed solution since it can estimate an upper bound for the optimal solution  and improve this estimate as it searches the space . finally  our algorithm is empirically shown to give solutions which are  at worst  1% of the optimal value in 1% of the time  in seconds  it takes the dp approach to find the optimal value  for 1 agents .
¡¡the rest of the paper is structured as follows. section 1 describes related work  work and section 1 details the formal model. section 1 details the algorithm and section 1 empirically evaluates it. section 1 concludes.
1 related work
yun yeh's dp algorithm  later rediscovered by rothkopf et al. for combinatorial auctions  is widely regarded as the fastest algorithm for coalition structure generation and so we use it to benchmark our algorithm. however  for the reasons outlined earlier  a number of researchers have sought to develop heuristics or anytime algorithms. in particular   shehory and kraus  1  devised an algorithm to find coalition structures constrained by certain coalition sizes. however  their algorithm does not guarantee to return the optimal value at any point  nor does it provide any means of measuring the efficiency of the coalition structure chosen. another approach is to assume that only v  cs  is known  as opposed to v c  in our case . in this case  improving on  sandholm et al.  1   dang and jennings  devised an algorithm that provides guarantees of the worst case bound from the optimal. in such algorithms  the search space consists of all coalition structures  see section 1  even if they are given the values of v c . moreover  they only guarantee integral bounds up to 1  which means they can guarantee  in the best case  to produce a bound which is only 1% of the optimal value. furthermore  as opposed to ours  their approach cannot avoid searching the whole space  in all cases  in order to guarantee the optimal solution. recently  our work  rahwan and jennings  1  reduced the time taken to cycle through these values without having to maintain the list of coalitions in memory. here  we build upon this approach to compute coalition structure values as well.
1 basic definitions
we now define the basic constructs used by our algorithm. let cls ¡Ê 1a be the list of coalitions of size s ¡Ê {1 ... a} such that cl is the set of coalition lists cls  see figure 1 for the configurations for 1 agents . moreover  let g1 g1 ... g|gcs| ¡Ê gcs be the set of all possible unique configurations  i.e. there are no two elements with the same coalition sizes . then  let f : gcs ¡ú 1cs be a function that takes a particular configuration and returns all the coalition structures of that configuration. we will denote n as a list where each element is a set of coalition structures of the same configuration. formally  n is defined as follows: n = {f g1  f g1  ... f g|gcs| }. where appropriate we will use n1 n1 ... n|gcs| ¡Ê n to note every element of n  see figure 1 for a graphical representation of n for 1 agents . finally  the optimal coalition structure is noted as cs . in the next section  we further expand on the above notation and describe how our algorithm searches the space.

figure 1: n for 1 agents with the elements f g  expanded.
1 anytime coalition structure generation
in this section we describe our algorithm for coalition structure generation. its input is the set cl for which v c  for all c ¡Ê cls and all cls ¡Ê cl is given  as well as the acceptable bound ¦Â ¡Ê  1  from the optimal value  if ¦Â = 1  we stop when the optimal solution is found and if ¦Â = 1 any known cs is returned . given this  our algorithm proceeds in three main stages. the first is a pre-processing stage that involves scanning the input to obtain the maximum and average values of every cls ¡Ê cl. these values are then used in the second stage which involves generating the list of unique g ¡Ê gcs and selecting the element f g  to search for cs . the third and most computationally costly stage involves determining the values of the cs ¡Ê f g  to find cs . we detail each of these stages in the following subsections. note that  within the first stage  a solution  the best found so far  can be returned and its quality is guaranteed to be |a|/1 of the optimal  i.e. 1% in the case of 1 agents .1 in either of the last two stages the optimal  i.e. ¦Â = 1  or a good enough  i.e. ¦Â   1  solution may be found and guarantees about the quality of the solution can be given in cases where the second stage completes.
1 stage 1: pre-processing
we will denote a coalition at index c in the list cl as clc where c ¡Ê 1 ... |cl| and an agent in a coalition at index k as c k . also  the vectors containing the maximum and average value of each cls are noted as maxs and avgs. the pre-processing stage  detailed in algorithm 1  calculates the maximum and average value of every cls ¡Ê cl. however  in so doing  it is also possible to search some elements of n. to start with  it is possible to get the value of the cs containing 1 coalition  i.e. the grand coalition {1 ... a}  from cla and the coalitions containing a coalitions  i.e. {{1} {1} ... {a}} by summing up the values of all coalitions in cl1. these are depicted as levels 1 and 1 in figure 1 . we therefore note the best of these two structures as since this is the most efficient cs found so far.
¡¡then  for each cls  we go through every element and record the maximum maxs = maxc¡Êcls v c    as well as the average. moreover  it is possible to cycle through cls and cla s at the same time since a pair of elements from each of these lists forms a coalition structure  see cl1 and cl1 in figure 1 and line 1 in algorithm 1 . however  in so doing  we must ensure that only pairs of disjoint coalitions  i.e. not containing the same agent  are chosen to form a cs. we ensure this property is upheld by indexing cls as per  rahwan and jennings  1   see figure 1 .1 this indexing mechanism actually results in each element c ¡Ê cls at index c ¡Ê  1 ... s  being exactly matched to an element.
¡¡moreover  at the same time  it is possible to compute  the value of all cs that follow a configuration g such that g = {1 ... 1 i} this is achieved by looking into each coalition in the pair when cycling through cls and cla s. for each such coalition  we retrieve the value of the coalitions of size 1 for each element in the coalition  i.e. the coalition is split into its constituent parts   sum these up and add them to the value of the other coalition and vice versa  see lines 1 and 1 in algorithm 1 .
¡¡in searching coalition structures in the two ways shown above  i.e. evaluating complementary sizes and coalitions containing 1s   we can actually search a part of the space  which gets smaller as the a increases . this is illustrated by figure 1 for 1 agents where the shaded configurations represent those that will be fully searched after scanning the input. moreover we will have already covered all coalition structures in case |a| ¡Ü 1 after the pre-processing stage. since the size of the input is of order o 1a   and the algorithm scans all of it  then it is bound to perform at least this many operations. the operations performed within the two loops  at lines 1 and 1 in algorithm 1  are all linear in time. hence  the complexity of the above algorithm is o 1a . note that we cannot yet

search space.
¡¡¡¡¡¡1in  rahwan and jennings  1   we use heuristics that guarantee that c as well as cls are in ascending order lexicographically.

figure 1: gcs with 1 agents where f g  for the shaded gs have been searched after scanning the input.

algorithm 1: the pre-processing stage.
guarantee that the best cs found so far  i.e.  returned by algorithm 1  is cs  since we have not yet ensured that all other unsearched configurations  i.e. other than the ones with two elements and those with repeated coalitions of size 1  have a value lower than. having obtained the values of the maximum and average of every coalition list  as well as
the best possible solution found so far  we next describe how to construct gcs and how to choose which element in n to search.
1 stage 1: constructing and choosing configurations
it is crucial that the algorithm finds the f g  which contains the cs we seek  which is not necessarily optimal  as quickly as possible  since n is large . there are two possible ways of doing this. first  we can choose those configurations to search which are most likely to contain the optimal value and  at the same time  allow us to prune the search space in case the optimal is not found. second  by updating the maximum value of every other g with more precise information gathered from previously searched g  it is possible to further prune the search space. before carrying out these operations  however  it is necessary that we first identify all possible configurations in gcs.
constructing unique configurations in gcs. the set of all configurations is equal to all the integer partitions that can be generated for the number of agents |a|  skiena  1 . for example  for the number 1  the possible integer partitions or configurations g is {1} {1} {1} {1 1} {1 1} {1 1}  and {1 1}. the growth rate of the set of configurations is¡Ì

known to be ¦¨ e¦Ð 1a/1/a   which is much lower than that of the input i.e. o 1a   where a is the number to be partitioned. fast recursive algorithms to generate such partitions already exist and we chose a standard algorithm from  kreher and stinson  1  to do so.
¡¡having obtained all possible configurations and given that we have computed all the maximum and average values of each coalition size in the pre-processing stage  it is now possible to calculate the upper bound  ubg   and average value  av gg  of every g corresponding to f g  ¡Ê n as well. this can be achieved by cycling through f g  and summing up the maximum and average values for every coalition size in the configuration. for example  for a configuration
g = {1 1}  we obtain ubg = max1 + max1 + max1 and av gg = avg1 + avg1 + avg1  which is actually the minimum1 value that a coalition structure with that configuration can take . moreover  for those sizes that are repeated  we can use the second best  third best  and so on until the end of the list. for example  for a configuration {1 1 1}  we would sum the maximum of cl1 with the second best of cl1 and the maximum of cl1 with the second and third best of cl1. this procedure gives us a more precise ub for the element  but requires searching the coalition lists for these values  which are not ordered in the input  which for size s is . the latter grows very quickly with s and since most elements of gcs will contain more of the smaller elements  such as 1  1 or 1   meaning we get more precise updates for most of the elements. we stop at s = 1 to limit the cost of searching values lower than maxs.
having obtained the ubg and av gg of all elements in
n  we compare the value found so far  with the   i.e. excluding previously searched configurations . if for all g  it means we have found
a suitable solution. otherwise  we proceed according to the steps described below.
choosing a configuration. having computed all possible configurations and knowing that it is possible to search each element of n  using the search procedure described in section 1   we now consider the procedure to choose the element of n to search. first  if it is found that the av gg for the element s  with the highest upper bound  i.e. ubg    is such that we choose the smallest of these elements. otherwise  we need to choose f g  that will prune most of the search space and  at the same time  be more likely to contain the required solution. to do this  we need to compute the expected gain  the amount of space that can be avoided after searching the element  and cost in searching each f g  ¡Ê n  one time . to estimate such parameters  we first need to estimate argmaxcs¡Êf g  v  cs  . this equates to the value lying between ubg and av gg of that element under absolute uncertainty.1 then  we need to compute  given estimates of other ubs  the size of the space that
 will be pruned as a result of the value obtained being greater than the ubs of other elements. this is performed for each  and the one with the maximum gain is chosen to be searched. the details are outlined in algorithm 1. next we consider how to improve our estimates of the ub which should allow us to further reduce the space to be searched online.

algorithm 1: selecting an element of gcs to be searched.
updating ub. as each element of n is being searched for cs   detailed in section 1   it is possible to compute the maximum value of certain combinations of sizes or splits  splitg ¡Ê 1g . these can be used then to update the ub of elements of n in a similar way to the procedure described in section 1. for example  while searching an element with configuration g = {1 1 1 1}  it is possible to find the maximum value of combinations such as {1 1} or {1 1} which can then be used to update the ub of {1 1 1}  and adding max1 + max1 + max1  and {1 1 1}  and adding max1  respectively. if the ub of that configuration is lowered when using the split  it is updated accordingly.
¡¡since the number of splits can be as large as 1|g|  including repeated splits   and computing the maximum value of each of them every time we compute v  cs  can be costly. therefore  we only compute maximum values for those splits whose value are not known so far. when the search starts  every g is initialised to be split in half. then as f g  is searched  the value of the splits to be tracked are computed as v  cs   see section 1 . after the search is complete  all are updated with the newly tracked split. moreover  all updated g add one more element from their own configuration to that split to create a new split to be tracked and remove the previous split from the list to be tracked in case it was there. these procedures gradually increase each g's list of splits to be tracked when searched  but also ensure all splits are never computed twice. next we describe how f g  is searched and how the value of the coalition structures and the splits are computed.
1 stage 1: searching an element of n
this stage is the main potential bottleneck since it could involves searching a space that could possibly equal the whole space of coalition structures  if all n is searched . however  using the heuristics described in section 1  we reduce the possibility of having to search all this space  see section 1 for the impact of this reduction . moreover  we provide heuristics here that allow us to minimise any redundant computations when cycling through this space. the latter procedure builds upon our previous work  rahwan and jennings  1  and allows us to construct coalition structures that are unique and fit a particular g  and at the same time  calculate the values of these structures. however  the main problem in constructing coalition structures is that if the procedure is performed na¡§ vely  repetitions will occur and cause the formation of redundant  as well as invalid  coalition structures. now  there are two main types of repetitions that can occur. first  a structure could contain coalitions that have the same agent s  in different coalitions  i.e. overlapping coalitions  and this would render the cs invalid. second  two structures could actually contain the same coalitions. this can happen when the configuration requires multiple coalitions of the same size such that the same coalition appears at different positions  since elements in g are in ascending order . our procedure  described below  avoids both types.
¡¡letbe a coalition located at position 1 ¡Ü k ¡Ü |g| of g  and let ak be a vector of agents where aik ¡Ü ak+1  from which the members of ck can be selected. finally  let mk : |mk| = |ck| be a temporary array that will be used to cycle through all possible instances of ck. the use of mk here is mainly to show that we do not need to keep in memory all the coalition structures that can be constructed  although we do need to cycle through all of the coalition structures in n . instead  we just need to maintain in memory one structure at a time. since we do not maintain the complete history of computed solutions  our algorithm has a memory requirement of o 1a   i.e. the size of the input  as opposed to the dp algorithm's o 1alog1   see  yeh  1; sandholm et al.  1   and hence our algorithm would take

figure 1: composing a coalition structure for 1 agents with configuration g = {1 1}. only 1% less memory than used by dp. avoiding overlapping coalitions. basically  for c1 we use m1 to cycle through all possible instances of  i.e.  through the set of combinations of size |c1| taken from the set a1  and for each coalition in m1 we use m1 to cycle through all possible instances of  i.e.  through the coalitions of size |c1| from the vector a1 = a1/c1   and for each of these possible coalitions  we use m1 to cycle through all the possible instances of  i.e.  through the coalitions of size |c1| out of the set: a1 = a1/c1   and so on  for every k = 1 ... |g|. in so doing  we avoid repeating the agents  i.e.  we avoid having coalition structures such as: {{1} {1}}  in any coalition fitting the configuration g. moreover  we use the fast indexing techniques provided by our previous work  rahwan and
jennings  1  to search all instances of ck.1
avoiding redundant coalition structures. redundant coalition structures  such as {{1} {1}} and {{1} {1}}  are only possible when we have repeated coalition sizes in the configuration  e.g g = {1 1} or g = {1 1 1} . formally  this can only happen when |ck| = |cj| where. now  since is ordered in an ascending fashion  see figure 1   and since we use mk to cycle through combinations of {1 ... |g|}  which ensures that the combinations are always in an ascending order   we can use the smallest element in the coalition  i.e.  ck1  as a key to identify the coalitions that we have already gone through. in more detail  as in  rahwan and jennings  1   mk will initially go through the coalitions that contain 1  see bottom of left-most column in figure 1   and this points to the first
 smallest  element in. since  then the smallest element in ck+1 must be greater than the smallest element in ck  i.e. ck1   and this ensures that ck+1 can never be equal to a previous instance of ck  particularly in the case where |ck+1| = |ck| .
after mk has cycled through the coalitions that contain
1  we move on to coalitions that do not contain 1  but contain 1  see figure 1 where the arrow moves from elements starting with one and goes up . this means the smallest eleis the second smallest element in and  since ak+1 = ak/ck  the smallest element in ck+1 might actually be the smallest element of. this would  in turn  certainly lead to a repeated coalition structure  because we have already been through the coalition structures that contain two coalitions of size |ck|  where one of them contains   and the other does not. in order to avoid this repetition  mk+1 needs to cycle through the combinations starting with 1  instead of those starting with 1  i.e. see that only the top three boxes in the second column in figure 1 are connected to the second box  from the bottom  in the first column . thus  when mk cycles through the combinations that do not contain elements 1 ...  j   1   but contain element j  mk+1 should cycle through the combinations starting with j and higher values. this is repeated until we reach the combinations that do not contain  and that is because mk+1 cannot contain a combination in which the smallest value is greater than this value. similarly  if we have more than two coalitions of the same size in a coalition structure  i.e.  if we have ci = ci+1 = ... = ci+x   then we repeat the same procedure until we reach the combinations that do not contain
.
¡¡while cycling through every c using mk  note that we also retrieve v c  and add these as we go through increasing values of k. in so doing we can also compute the value of splits that need to be tracked for that configuration  as discussed earlier . this can easily be done by keeping track of the maximum value of the coalition sizes dictated by the split. moreover  if the algorithm finds a coalition structure that has the required value  i.e. either within the required bound or equal to ubg  then it stops. finally  if after searching all elements of a particular g  the value of the best coalition structure found so far is higher than the   then we guarantee this is the optimal value. we summarise all the procedures described in section 1 in algorithm 1 and show how this leads to computing the optimal  or required  value.
sketch of proof of correctness. the algorithm generates all unique and valid solutions as described above. the algorithm is guaranteed to terminate with a solution since it gradually removes invalid configurations  in step 1   and searches remaining valid ones for the optimal coalition structure  after which it discards these configurations  in step 1  until the set of configurations is empty  as in step 1 .
1 empirical evaluation
having described all the parts of our algorithm  we now seek to evaluate its effectiveness by comparing it against the dp approach outlined earlier. in our experiments  the coalition values  i.e. v c   are randomly selected and scaled by the size of the coalition  similar to the distribution of values used by  larson and sandholm  1    thus representing the case where coalitions of bigger sizes have  on average  values that are higher than smaller ones. we recorded the time taken by our algorithm to find the re-
require: cl v c  c ¡Ê cl ¦Â ¡Ê  1 
1: initialise 
% see algorithm 1 and section 1.
1: return 
1:	% keep track of the maximum value.
1:	select g according to algorithm 1.
1:	giteration.cs	¡û	gcs/g	% discard this element for the next
1: csg = argmaxcs¡Êf g  v  cs   and update all  and  where % find the coalition structure in this
g  update the value of splits  and the upper bound of other elements of g
1:	if v  csg    vcsmax-- thensee section 1.
1:	 % set the best coalition to this one.
1:	if vub cs    ¡Ý ¦Â then % if we have reached ¦Â
1:	return
1:	else
1:
1:
1:	if
1:	end ifreturn cs  ¡û cs % the optimal structure.
1: return cs ¡û cs % the optimal structure.
algorithm 1: the near-optimal anytime coalition structure generation algorithm.
quired value which  in the worst case  lies between 1% and 1% of the optimal  i.e. ¦Â ¡Ê  1 1  . by worst case  we mean that the value selected will be  at worst  equal to ¦Â ¡Á v  cs  . thus  it may happen that we find the optimal solution  while only searching for a less efficient one. we choose to benchmark against the dp approach since the other existing anytime algorithms  i.e.  dang and jennings  1; sandholm et al.  1   only provide integral bounds and always need to search the whole search space to guarantee optimality. hence  our algorithm is the first to establish a benchmark for anytime heuristic algorithms that generate non-integral bounds and which do so without always needing to search the whole space of solutions.
¡¡here we focus on two experiments to show that our algorithm finds good enough solutions much faster than the dp approach takes to find the optimal and that the time taken to find near-optimal solutions decreases to a lower gradient as the number of agents increases. in order to test this  we recorded the time taken for various degrees of optimality sought  from 1 to 1  using our algorithm and compared them to the corresponding dp performance  see figure 1 .1as can be seen  the time taken by our algorithm in the case where it searches for the optimal  i.e. efficiency 1  increases exponentially faster by a samll constant factor greater than the dp algorithm and even performs better for small numbers of agents  less than 1 . moreover  when the algorithm seeks an efficiency below 1  it finds the solution much faster than the dp algorithm and this difference grows exponentially with increasing numbers of agents  since it searches a much smaller space than 1a . this implies that the trade-off

figure 1: average time taken for ¦Â ¡Ê  1 1 .
between the quality of the solution and the time taken gradually decreases for increasing numbers of agents  1ms for a = 1 ¦Â = 1 v/s 1ms for dp i.e. 1% of the time taken by dp . to understand why this happens  we recorded the percentage of the space that is searched in the worst case for increasing numbers of agents.

figure 1: percentage of the space searched in the worst case.
¡¡as figure 1 shows  the percentage of the space searched in the worst case to find the optimal solution as well as for ¦Â   1  decreases very rapidly as the number of agents increases. this shows that we actually find the solution mostly after scanning the input  see section 1  and that has a computational complexity of o 1a ! a possible reason for this result is the distribution of coalition values. since we use a uniform distribution to generate such values  we expect coalition structure values within each f g  ¡Ê n to follow a similar distribution  piece-wise linear in most cases  such that the upper bound calculated for each configuration is relatively close to the actual maximum value that can be found within an f g . hence  it is possible to find an approximately optimal value fairly quickly by choosing a f g  with a very high ubg  which our algorithm does . we will further investigate this result in future work and test this hypothesis by trying out other distributions and using probabilistic techniques.
1 conclusions
we have shown that it is possible to come up with nearoptimal solutions for extremely large search spaces of coalition structures by examining only a minute portion of the space  1 ¡Á 1a 1 . our solution relies on a number of techniques to achieve this. first  we use a novel representation of the search space based on configurations of coalition structures. second  we are able to cycle through the list of coalition structures without creating any redundant or invalid ones. altogether  these techniques have enabled us to reach a 1% efficient solution in 1% of the time to compute the optimal coalition structure using the dp approach for 1 agents  for larger numbers of agents  this improvement will be exponentially bigger . moreover  our approach also uses 1% less memory than the dp approach. future work will look at different coalition value distributions and identifying the theoretical bound established by searching elements of n using our technique.
acknowledgements
this research was undertaken as part of the aladdin  autonomous learning agents for decentralised data and information systems  project and is jointly funded by a bae systems and epsrc  engineering and physical research council  strategic partnership. we also thank the anonymous reviewers for their valuable comments.

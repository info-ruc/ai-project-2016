 
we describe a knowledge representation scheme called k-nht and a problem solving system called sniffer designed to answer queries using a k-net knowledge base. k-ntt uses a partitioned semantic net to combine the expressive capabilities of the first-order predicate calculus with linkage to procedural knowledge and with full indexing of objects to the relationships in which they participate. facilities are also included for representing taxonomies of sets and for maintaining hierarchies of contexts. snin-tr is a manager and coordinator of deductive and problem-solving processes. the basic system includes a logically complete set of natural deduction facilities that do not require statements to be converted into clause or prenex normal form. using 
sn'ii tfr's coroutine-based control structure  alternative proofs may be constructed in pseudo-parallel and results shared among them. in addition  snitf er can also manage the application of specialist procedures that have specific knowledge about a particular domain or about the topology of the k-ner structures  for example  specialist procedures are used to manipulate taxonomic information and to link the system to information in external data bases. 
introduction 
this paper describes a question answering system whose principal components are a network-based knowledge representation scheme called k-nl'l and a problem solving system called snii f i t   an acronym for semantic net interpretation facility fortified with e xternal routines   designed to answer queries using a k-nlt knowledge base. 
the goal of the effort has been to create a design that allows specialized representations and deductive .schemes to be used where they are effective  while providing  recourse to a logically complete natural deduction mechanism when necessary. snii-'r-.r has been designed with the intention that most o  the question answering work will be performed by special domain-dependent procedures these specialists can lake advantage o  the particular topology of the k-ni-.t structures designed to represent domain-specific types of knowledge. specialist procedures also allow snihi r to do certain types of problem solving usually considered outside the range of conventional deduction. tor example  specialists may be added that know how to extract information from conventional data bases or do scheduling and planning. in this paper we seek to indicate the handles for adding specialized knowledge while eoncntraiing on 'he fundamental issues of implementing natural deduction for nelwoik systems. 
snieeer and k-net are evolving systems  versions of which have been used as major components in larger systems developed in the sri artificial intelligence  enter  including  the ski speech understanding system  walker 1 . 
t currently at xerox palo alto research center. palo alto  california. to help the reader relate our work to other knowledge representation facilities and problem solving systems  we begin by presenting the distinguishing and characterizing features of our system before focusing on a more detailed overview that elaborates on these features and provides concrete examples. 
characterizing features of k-net 
k-nt i provides facilities for creating a partitioned semantic network of labeled nodes connected by labeled unidirectional arcs. a node represents an entity in the world being modeled and an arc represents a binary relationship between the nodes that it connects. i or example  the nodes .john and men in figure 1 represent a man john and the set of all men  respectively. the arc labeled v from joint to men indicates that john is an element of the set of men. relationships can be considered to be entities and be represented by nodes with  case  arcs pointing to the participants in the relationship. for example  node q represents the ownership relationship 
 situation  existing between john and the automobile  ole-black  over the time interval from tj to t1 
k-net can be characterized by the following list of features: 
* facilities are provided for representing multiple  worlds  and the relationships among them. in particular  the network can be paititioncd into subnets  called spaces . spaces can be hierarchically embedded by treating an entire space at one level in the hieiarchy as a single node in a space at the next higher level. a  context  mechanism exists that allows only a given sel of spaces to be  visible  to the retrieval procedures at any one time. fxamples of alternative worlds include those contained in a disjunction  or the world composed of the set of beliefs that john has about sally as opposed to the world composed of the set of beliefs that sally has about herself. 
* the expressive facilities of the representation scheme include those of the first order predicate calculus  including existential and universal quantification.  higher order predicates arc also tepesentiale in k-n{    but only tuvial interrelation facilities exist for them m snltihr   that is  the knowledge base can contain statements represented as negations   john does not love mary.    disjunctions   john loves either sally or sue.    
or implications   if sue answers john's phone call  then john will ask sue for a date.    and containing aibiliary nestings of existential and universal quantifiers   fvery boy has been in love sometime.  . 
* taxonomies of sets are modeled by the topology of the network so that they become the basic skeleton upon which the knowledge base is built. for example  one can directly represent the relationships  ford is an element of companies distinct from g.m.  and  mustangs is a subset of automobiles distinct from model-tv. one can also associate with a : et characteristic properties common to all elements of the set  such as  all mustangs are built by fold . 

knowledge repr.-1: fikes 1 

* procedures may be attached to the network to interface it to other knowledge sources such as conventional data bases or arithmetic algorithms. when called by snilflir  these procedures extend the network by creating new nodes and arcs representing the information acquired from the other sources. links to these procedures are explicitly represented in the network so that their existence and role can be reasoned about and discussed by the system. 
* the network provides indices that facilitate associative retrieval of the relationships in which any given knowledge base entity is involved. for example  retrieval of all females that john loves can be indexed through the node representing john  the node representing the set of loving relationships  or the node representing the set of females. the basic mechanism is one that allows immediate access to all of a node's incoming and outgoing arcs that are visible in any given set of spaces. 
characterizing features of sniiffer 
s n i r t r is a  natural  deduction system  as m bledsoe  ft ai.. 
1  that is given two net structures as input  one representing a knowledge base and the other representing a query  usually a translation of a question originally stated in english . it treats the query as a pattern and attempts to find instances of the pattern in the knowledge base  or equivalontly. it treats the query as a theorem to be proved and attempts to find instantiations for its existentially quantified variables. results are returned in the form of sets of  bindings  for the variables in the pattern. for example  the question  who does john love   is translated into a net structure representing the pattern  john loves x   or the theorem  1   loves john x     and snii mr returns bindings for x such as  x  mary . answers may either be retrieved from the knowledge base or derived using knowledge base theorems and procedures. 
snieeer can be characterized by the following list of features: 
* associative retrieval of relationships from the knowledge base is performed using the k-ni r indexing facilities. 
* lfficient. special purpose deductive procedures are used for extracting information from the k-nt i taxonomies. for example  if the knowledge base indicates that x is an element of the set of mustangs  that mustangs are a subset of the set of sports tars  and that sports cars are a subset of the set of automobiles  then sniieer can conclude that x is an automobile by using procedures that follow the chain of element of and stihsctof arcs  thereby bypassing the more cumbersome  general-purpose deductive machinery. 
* facilities-are included for answering questions and using knowledge base statements composed of conjunctions  disjunctions  and implications  containing arbitrarily embedded universally and existentially quantified variables. 
* queries and knowledge base statements are processed in the  natural  form in which they are input  without converting into a canonical form such as clause form or prenex normal form. this capability eliminates  explosive  conversions  such as converting the disjunction  aai ae  v  jacaf  v  gahai  into clause form which consists of 1 clauses each containing 1 disjuncts  and unnecessary conversions  such as conversion of a disjunctive question's complex disjuncts when one of its simple disjuncts can easily be shown to be true . in addition  the intuitiveness and heuristic value of the form in which statements are input  as implications  for example  is maintained. 
* a logically complete set of natural deduction rules are used that reason backwards from the question. these rules use such techniques as case analysis  hypothetical reasoning  and the establishing of subgoals. for example  to answer a question that is in the form of an implication  sniiffe r: might use hypothetical reasoning by assuming the implication's antecedent and then pursuing a proof of the consequent as a subgoal. 
* a flexible coroutine-based control structure allows the construction of alternative proofs  n a pseudo-parallel manner  with results being shared among the alternatives  bach partial proof has its own local scheduler to determine how its proof attempt should be continued. there is an executive scheduler that uses information supplied by the local schedulers to determine which partial proof is to be given control at each step. the various schedules provide the facilities necessary to allow reasonable heuristic guidance of the total deduction and retrieval process. 
* user-supplied procedures may participate in the attempt to find answers in two ways. fiist  procedures included in the k-nt r knowledge base may be invoked to access information in knowledge sources that are external to k-net. second  snieefr allows the inclusion of user-supplied procedures that extend the system's problem solving capabilities. such procedures may add heuristics to the deductive strategies or even integrate new knowledge sources into the system  such as data bases and planners. facilities are available to these procedures for creating  alternative proofs  manipulating schedules  altering priorities  and establishing  demons  so that the usei can create strategies that augment and interact with those that already exist in the system. 
* snifffr is implemented as a  generator   see teiteman  1  so that after returning an answer it can be restarted to seek a second answer to a query. for example  given the question  who owns a mustang   snifffr may first produce the answer  john   then be  pulsed  again to produce  mary   etc this style of answer production allows the user to examine each answer as it is produced and dynamically determine whether additional answers are needed. 
*  no  answers are determined by finding an affirmative answer to the question's negation. for example  if given the question  does john love mary    snifffr will attempt to prove  john does not love mary  in addition to attempting to prove  john loves mary . 
overview description of k-nkt 
in this section we will describe and illustrate how k-nkt is used to encode knowledge. throughout the section reference will be made to the example knowledge base shown in figure 1  which represents some facts about automobiles. 
taxonomies 
major portions of the semantics of a task domain can often be expressed naturally by a taxonomy of sets that indicates the major sets of objects in the domain and the relationships between the sets. the power of the taxonomy can be enhanced further by the inclusion of statements that specify necessary and/or sufficient conditions for membership in the sets. k-net provides the following facilities designed specifically for encoding such taxonomies. 
s arcs indicate  subset of  relationships. for example  the s arc in figure i from the men node to the humans node indicates that the set of men is a subset of the set of all humans. 
most subsets described in taxonomies are disjoint. arcs labeled ds are used in k-nl l to represent this disjointness property in a concise and easily interpretable manner. a ds 

knowledge r e p r . - 1 : 	fikes 
1 

arc from a node x to a node z indicates that the set represented by x is a subset of the set represented by z and that the x set is disjoint from any other set represented by a node with an outoing dsis arc to z. for example  the ds arcs in the figure  i.e.  figure 1  emanating from the humans and companies nodes indicate that the set of humans and the set of companies are disjoint subsets of the set of legal persons. 
since each node in most taxonomies represents a distinct entity  and in general an entity can be represented by any number of nodes in a k-nf  i  arcs labeled de  for  distinct element   are used to indicate that two or more nodes each represents a distinct element of a set. in particular  a de arc from a node x to a node z indicates that the entity represented by x is an element of the set represented by z and that the x entity is distinct from any othei entity represented by a node that has an outgoing de arc to z. lor example  the de arcs in the figure emanating from the  i.m. and lord nodes indicate that g.m. and ford are distinct members of the set 
of companies. 
f arcs are used to indicate  element of  relationships without making a commitment to distinctness. for example  fred  jill  and mary may be known to be distinct elements of 
riders  the set of people that rode to the airport in fred's car. if some fact is known about the driver of the car and the identity of the driver has not yet been determined  then a node i  representing the driver may be linked to set riders by an e arc. the node i  can be used to encode information about the unnamed driver without specifically indicating which of the distinct elements of riders is the driver. 
situations 
sniffer assumes that relationships other than elemcntof and subsetof are represented by nodes having outgoing case arcs pointing to the participants in the relationship  such as node 
i* in the figure  which represents the relationship  ford built 
lizzy  . t his representational convention allows an arbitrary amount of information to be stored with a relationship  using outgoing case aics  and allows associative retrieval of the relationship using the network's indexing facilities. such relationships are grouped by type into sets and these sets are considered to be subsets of the set of all  situations . for example. builds  the set of all situations in which building takes place  and implications are disjoint subsets of situations in the figure  and node v represents an element of the builds set. a particular building situation in which ford is the agent and llzzy is the object built.   the situation repres/ented by p look place over an intervall of time from starttime to find time 'these turne 
eases would be present in a more complete description of i'.  
spaces and vistas 
perhaps the primary feature that distinguishes k-nft from other semantic networks is that a net can be partitioned into subnets  and relationships among the subnets can be explicitly and easily represented  see llendnx. 1. all nodes and arcs in a k-net are  elements  of at least one  space   i.e.  subnet . in the figures  such spaces are depicted by boxes. for example  node in the figure and the pobj arc from v to lizzy are elements of the knowledge space. a space can be  and usually is  a node in some other space. for example  in the figure the con.se arc from node i points to a node in the knowledge space that is itself a space. when retrieving information from a network  it is convenient to have only a specified list of spaces  called a  vista   visible to the retriever. for example  the vista that would typically be used when retrieving information from the space pointed to by the conse arc in the figure consists of the space itself and the knowledge space. 
negations  disjunctions  and implications 
a representation scheme for negations  disjunctions  and implications must allow one or moie  woilds  to be described and a relationship to be asserted among  the worlds  e.g.  that at least one of them is true   k-nft's partitioning facilities provide the required capabilities for cieating just such a 
scheme. 
a negation occurring in some space s describes a collection of entities and relationships  and asserts that no collection satisfying the description can exist in the world represented by space s. we represent such a negation as shown in figure 1a by creating a space to describe the collection  and by adding the created space to space s as a node with an outgoing e arc to negations  the node that represents the set of all negation relationships. for example  the statement  g.m. does not build convertibles  would be represented using a 
space describing a collection consisting of an entity c  an elemenlof relationship between c and the set of convertibles  and a build relationship with agent g.m. and object c 
a disjunction occurring in a space s describes alternative collections of entities and relationships  and asserts that entities and relationships satisfying at least one of those descriptions exists in the world represented by space s. as shown in figure 1b  we describe each disjunct in a separate space and represent a disjunction as a set of such disjunct spaces. 
an implication occuiring in a space s describes two collections of entities and relationships  and asserts that if entities and relationships exist in the world lepresented by space s that satisfy the first of the two descriptions  the antecedent   then entities and relationships satisfying the second description  the consequent  also exist in that world. we represent an implication as shown in figure 1c by a node witli outgoing case aics to spaces containing the descriptions of the antecedent and consequent. more concrete examples of 
implications will be presented in the next section. 
q u a n t i f i c a t i o n 
one of the important features of k-nft is thai it provides facilities for repiesenting arbitrarily nested existential and universal quantifiers. fxistential quantification is a  built-in  concept in the sense that we take the occurrence of an element  i.e.. a node or arc  in a space to be an assertion of ihe existence with respect to that space of the entity or relationship represented by the element. in particular  if an element occurs in the system's  knowledge space   then that element represents the system's belief that a corresponding entity or relationship exists in the domain being modeled. 
  xistenlia! quantification and negation could be used to represent any universally quantified formula  vxc x p x  by making use of the following transformation: 
 vx€x l' x  =r -   v cx r x   == ~|. 1xcx ~r x   . 
the k-nff representation of the transformed formula is shown in figure a. 
although this representation is logically sound  it is extremely unappealing intuitively. the following transformation 
suggests a more attractive representation: 
	 vx c 	x lp x  	= 	 vx   x e 	x  =* p x   . 
that is. any universally quantified formula can be represented as an implication whose antecedent specifies the  typing  of the universally quantified variable and whose consequent 

knowledge 	p e p r . - 1 : 	flkes 
1 



specifies the statement that is being made about any entity that satisfies the type restrictions. 

overview description of sniffer 

a distinguishing feature of the universally quantified variable x in this implication is that it occurs in both the antecedent and the consequent. we have made use of this feature by adopting the convention in k net that if a node occurs in both the antecedent and the consequent spaces of an implication  then we consider it to be the representation of a universally quantified variable. i his convention is  in fact  used as the primary means of representing  universal quantification in our system. 
when the main connective of a formula is an implication  it is not necessary to embed the formula in another implication to represent the universal quantification. thai is: 

figure  . shows the k-nft representation of a concrete example of such an implication  namely the statement 'tor all m in the set of mustangs  there exists a b such that b is an element of the builds situations  the agent of b is ford  and the object built is m.  
arbitrary nesting  of quantifiers may be achieved by placing implications in the consequent spaces of other implications  hoi example: 

figure 1 summarizes the conventions for representing quantification by contrasting the k-m i representations of  :   ;x i' v  and  vxc x p x . 
procedural augmentation 
for many applications  it is important for the s  stem's knowledge base to include sources of information such as lelational data bases 1f arithmetic algorithms external to the 
k-nf.'i nets.  sec r e i k i   1. for anothri e ampk' i l an inference system designedl  to intenct with  a relational ilata base.  we h a v e adopted a set of conventions in k-nit for dcsciibmg links to such external knowledge souices. 
the links to external knowledge sources are represented by 
 theorems   i.e.. implications containing universally quantified variables  in the system's knowledge space that have the form exemplified by the network shown in figuie b. such theorems are intcipictcd to mean that if there is a successful application o  the indicated function to a set o  arguments that satisfy the description given in the antecedent  then the arguments and the results returned by the function can be used to create iclationships and entities satisfying the description given in the consequent. 
the particular theorem of figure 1 indicates that an application of in i hki isp's plus function can be used to produce new instances of the sums relation in the net. this theorem makes it unnecessary for all the instances of the sums relation to be explicitly represented in the knowledge base. when snifft-r attempts to match a pattern involving the sum of two numbers  it can use this theorem to form a call of the imils function and to translate the results of that call into the desired sums relationship. the manner in which snifffer uses knowledge about the applications set to create new relationships from the results of procedure calls is discussed below in the section on special purpose binder tasks. 
this section describes and illustrates the basic features used by snifffr in retrieving and denying information from k-nft structures. we begin by considering how snifffr is invoked and by illustrating  how it would go about solving two simple problems. attention is then turned to the overall control structure and to the operations performed by various components. 
introduction 
snifffr is given as input a vista representing a query  the ovista  and a vista representing the beliefs that are to be considered true while answering the query  the kvisia . fike other vistas  the ovist a and k vista are lists of spaces. in aggregate  the nodes and arcs of the various spaces in the ovist a describe a set of entities  i.e.  objects and relationships  whose existence is to be established in the k vist a. it a set of such entities can he found to exist  then sniffer returns a list of  bindings  that link the ovista descriptions to their kvisia instantiations. otherwise  snifffr attempts to prove that no such collection of entities can exist  so that a negative response can be given 
for example  figure 1 shows a k vista and a ovist a for the query  what company built lizzy  . gliven this ovista  snifffr seeks an element of the builds situations set having both lizzy as its object and an element of the companies set as its agent. the builds situation icpicsentcd by node i* in the kvista is found by using the incoming e aics to the builds node as an index  and a  yes  answei is generated with i* as the binding for node z and the lord node a the binding for node  x. the  yes  answer indicates that the question was based on a true pieunse  and the binding for x is the actual value that was sought. 
 jiven the k vis ia and ovist a shown in figure 1  snifffr must carry out a derivation to answer the query using the k vist a theorem  all mustangs were built by ford.  the theorem is found by indexing on the incoming e arcs to the builds node. a unification process detei mines that the relevant instance of the theorem is one in which the universally quantified variable m is replaced by olc-black. the theorem allows a new huilds situation lo be asserted if it can be shown that ole black is an element of the mustangs set. a subproblemcm is created to find that llement of relationship  and when the subproblcm is solved  the new builds situation is asserted ami the desired bindings are assigned. in particular  node    is again bound lo fold and z is bound to the newly derived builds situation. 
control structure 
as an introduction to sniitter control structure  consider the following simplified desciiption of how the system goes about answering queries 'i he basic process consists of selecting an unbound ovisia arc and finding a match for the selected arc in the k visi a. the matching  arc then implies matches for the nodes at each end of the selected ovisia arc. after each arc is bound  the process is repeated until all the arcs and nodes of the q vist a have been bound. 
this conceptually simple process is complicated by a number of factors. at each step in the process there are typically many alternatives that may be followed. for example  any of the unbound arcs in the ovist a might be selected for consideration and each of these might be successfully bound to many kvista arcs. another complicating factor is that some structures in the ovisia will have no matches in the kvis a  even though their existence is implied by statements in the kvista. deductive machinery must be invoked to derive explicit representations of these implied structures. 

knowledge r e p r . - 1 : 	flkes 
1 


figure 1 	existential and universal quantification 


within the deductive machinery  choices must be made between alternative strategies for pursuing a derivation and among the collection of kvisia statements that could possibly be used to derive the desired matching structure. 
the control structure that we have evolved for snifter allows these various alternatives to be pursued in a pseudo-parallel 
 best first  manner. k-net's partitioning facilities and intlrlisp's coroutines are used to create a system environment that allows each alternative to have its own subproblems  assumptions  and derived results  and for the choices among these alternatives to be guided by both built-in and user-supplied evaluation functions. 
the environment tree and task agendas 
snifter proceeds by building a tree of alternative proofs  each node of which represents a data environment that includes a set of choices of bindings for qvista elements and derivation strategies. each time a choice is to be made in an environment  an offspring environment is created and the results of the choice are established in the offspring. for example  if a binding for a qvis'ia element is found  then an offspring environment will be created in which the binding will be assigned. the search for additional bindings can then be continued in the parent environment  but s n i i m u is committed to the assigned binding in the offspring. 
included in each environment is a task agenda  pauaned after tin- ;agenda mechanism in krl-1  see bobiow and winagrad  i'm  that defines n priority levels and allows a list of tasks to be stored at each priority level. the sniittr executive typically proceeds by selecting an environment to give control to and then running the highest priority task on the selected environment's agenda. each task is composed of a usp function and a set of arguments upon winch the function is operating. typical tasks look for kvisia descriptions matching a given ovist a description or  if necessary  initiate derivations to deduce new explicit descriptions from implicit descriptions contained in kvista  theorems . 
the executive also has its own task agenda that is used to determine what to ih  at each step. initially  this agenda has three  asks on it; one to initialize an environment lice to seek  yes  answers to the query  one to initialize an environment tree to seek  no  answers to the query  and the one mentioned above that selects an environment  runs the task defined by that environment's agenda  and reschedules itself. 
the agenda associated with the top environment in an environment tree initially contains a single task that selects for consideration unbound arcs that lie in the qvista. each time the selector task is restarted  it selects another qvista arc  creates a  binder  task that will seek bindings for the selected arc  schedules the created task  and reschedules itself. 
when a binder task finds a kvista arc that is a  candidate  
 i.e.  potential  binding  it creates a new offspring environment in the environment tree that is a copy of the parent  assigns the binding in the offspring environment  and reschedules itself in the parent environment. hence  at any given step  each terminal environment in the tree includes a partially formed alternative answer to the query. 
provisions have been made for attaching  demon  functions to qvista nodes and spaces in an environment. demons attached to a qvista node  which are  fired  when a binding is assigned to the node  allow binder tasks to  pause  until other bindings have been assigned that can be used as indices. demons attached to a qvista space  which are fired when bindings have been assigned to all the arcs and nodes in that space  are useful in completing derivations and returning results. eor example  demons are attached to each qvisia space in the initial environment of an environment tree. 
knowedge 
when the last of these demons fires in an environment  bindings will have been assigned to all qvisia elements in that environment and an answer can be generated. the last demon causes the answer to be generated by scheduling an appropriate task on the executive's agenda. 
when an offspring environment is created  it inherits copies of its parent environment's data structures. including the agenda  demons  and list of assigned bindings. if a task or demon represents a  paused  coroutine that will be  resumed  when the task i:  run. then copying it conceptually produces a copy of the coroutine so that the original task or demon and the copy can run independently in their respective environments. i or example  if a binder task is in a state such that it will consider relationship ii as the next candidate binding and it is copied into an offspring environment's agenda. the'n the copy will also independently consider r as the next candidate binding. similarly  a demon can be independently filed in each environment in which bindings for all the space's elements have been assigned. this powerful 
capability is implemented using the  spaghetti stack  facilities found iii in'itri isp  uohmw and wej- l reit  1 . 
hinder tasks and user-supplied specialists 
the selector task in each environment's agenda selects unbound qytsi'a arcs and creates binder tasks that seek bindings for the selected arcs. the procedures used in the binder tasks embody the system's retrieval and derivational mechanisms. 
domain-specific augmentation 
the primary way in which snirt.r can be augmented and adapted to a particular problem domain is by providing additional procedures that can act as  expert  binder tasks for specialized classes of relationships. such experts may add heuristic guidance to the deduction process or add completely new sources of knowledge. 
eor example  a binder task for ownership relationships might add heuristic guidance by knowing that objects usually have a unique owner. this task would look for bindings by following indices from the object to its owner rather than from the person to all the objects he/she owns or from the set of all ownership relationships. 
another expert binder task might be written for the relationship between a person and his telephone number. rather than look for the person/number relationship in the 
k-nfl. this procedure might look it up externally in a phone book file. the procedure would then create new structures in the kvisia to encode the retrieved information and use this new structure in the binding. 
strategy selectors 
when a qvista arc has been selected  it is passed through a set of  strategy selectors   each of which is a function that can create a binder task for the arc and indicate whether additional selectors should be consulted. when a new function for finding bindings is added to the system  a strategy selector is written for it and added to the set of selectors. these strategy selectors provide a generalized form of pattern directed invocation of the binder tasks. 
when no  specialist  binder task is available for a selected arc  a general purpose binder task is created that can seek bindings for any relationship or its negation using natural deduction theorem proving strategies. it uses the net's indexing facilities to first find all atomic statements  i.e.  relationships other than disjunctions  implications  or negated 
r e p r . - 1 : 	pikes 
1 
conjunctions  that contain possible bindings for the selected arc and then all nonatomic statements thai can be used to derive bindings for the selected are. for example  the general purpose binder task for arc builds in figure 1a would consider incoming e and de arcs to the builds node as candidate bindings. 
ramification 
when a binder task finds a candidate binding  it can apply the following  ramification  rules to determine what other bindings aie directly implied by the candidate. first  if two arcs are lo be bound to each other  then the trom-node of the first arc must be bound to the from-node of the second arc and the lo-node of the first arc must be bound to the lo-node of the second arc. second  we assume that a node can have at most one outgoing case  i.e.  nontaxonomic  arc with any given arc label. therefore  if two nodes are to be bound to each other and both nodes have outgoing case arcs with a common label  then those case arcs must also be bound to each other. for example  if in figuic 1 arc . -   builds were the candidate binding for arc z~-t-- builds  then bindings would be implied for nodes z and  x  and for the agt and obj arcs. 
if a candidate binding implies a binding that is inconsistent with an existing binding  for example  one that assigns two different bindings to some ovinia node  where ds and de arcs in the taxonomies indicate that the two bindings represent distinct entities   then the candidate can be rejected and another one sought hence  this ramification process acts as a powerful and efhcienl tiller for candidate bindings as well as a producer of new bindings. 
self scheduling 
the decision as to which binder task should be given control in any given environment is made by allowing each such task to determine the priority level at which it is scheduled on the environment's task agenda. a task makes this determination by assessing the difficulty of finding  bindings for its ovinia arc based on estimates of the number of indices  i.e.  matching  arcs  available in the kvis'ia  knowledge about the semantics of the relationship being sought  knowledge about the effectiveness of the task's search method  etc. user supplied specialists may be written that are particularly adept at such assessments. the basic goal of the overall strategy is for the system to first seek bindings for those ovinia arcs that are most highly constrained. 
deriving bindings for element of and subsetof relationships 
included in snifti r are a set of  unctions embodying the semantics of the taxononuc relationships e  de  s  and ds. these functions provide the following  eight services: 
given a node representing some entity x  they can generate nodes representing entities y such that x is an element of y  y is an element of    x is a subset of y  or y is a subset of x. 
given two nodes representing entities x and y  they can determine whether   is an element of y  y is an element of x  x is a subset of y  or y is a subset of x. possible answers are  yes    no   and  unknown . 
the algorithms used follow chains of s and ds arcs applying recursive rules such as the following: 
two sets are disjoint if each of the nodes representing them has an outgoing ds arc to the same node  or if the sets are each subsets of disjoint sets. 
these functions are used in snifftr wherever information is needed about subsetof or klementof relationships. in particular  they are used by the general purpose binder task to find candidate bindings for e and s arcs  and during the ramification process to test potential bindings of qvista nodes as to whether the bindings can satisfy the klementof and subsetof relationships specified for them in the qvista. hence  these very important classes of deductions are carried out rapidly and  automatically  whenever they are needed  in a manner that requires none of the standard deductive machinery. 
derivations using kvista implications  disjunctions  and negated conjunctions 
when the general purpose binder task has considered all the 
 explicit  candidate bindings for a given arc  it uses the network's indexing facilities to find nonatomic statements  i.e.  implications  disjunctions  and negated conjunctions'  that describe relationships having the same form as the binding being sought. for example  arc b-c-  builds in figure 1 is used as the index for finding an implication containing a  build  relationship. such nonatomic statements are used as the baas for a derivation of the desired binding. 
applicability tests 
when such a nonatomic kvista statement is found  the general purpose binder task carries out an applicability test to determine if the statement can be used to derive a binding for the given ovinia arc. this lest involves unifying  i.e.  matching  the k vista statement with the ovinia statement in which the given ovinia aic is embedded and  when successful  produces a set of substitutions for universally quantified variables that define  he  instance  of the kvista statement applicable to finding the desired binding. 
several complications in doing the applicability test arise from the fact that ueithci kvis'ia nor ovinia statements are stored in a canonical form. loi example  a negated relationship in the antecedent of an implication can be used to derive a binding for an unnegated form of the relationship  but cannot he used to derive a binding for a negated form of the relationship. in this section  we will discuss the mechanisms in sniieeer for dealing with these complications. 
parity 	of 	embedded 	relationships 
 the applicability tester needs to deteimine what the logical signs are of the relationships  i.e.  terms  that a given kvista statement can be used to prove. for example  the statement can he rewritten in the following ways: 
and can therefore be used to prove x  ~y  ~u  or v. if  then  a binding is being sought for a relationship matching x  this statement may be useful in deriving the binding. however  the statement cannot be used to derive a binding for ~x. 
the logical signs of the relationships that a given statement can be used to derive correspond to the logical signs that the relationships have when the statement is converted into 
t double negations  negated disjunctions  and negated implications arc eliminated from both the kvista and qvista by simplification rules. 

knowledge r e p r . - 1 : 	fikes 

disjunctive normal form. for example  ihc disjunctive normal form of the statement given above is  the logical signs of x  y. u  and v in this form of the statement are the same as those that the statement can he used to prove. 
during the conversion to disjunctive normal form  only two conversion rules change a relationship's logical sign. namely: 

therefore  we can compute a  parity  for each relationship in 
' 
a statement to indicate the logical sign that it would have in 
| 
the statement's disjunctive normal form simply by counting 
' 
the number of negation spaces and antecedent spaces in which 
it is embedded. 	the parity associated 	in  ins way with 1
 
relationships allows a quick determination of whether a given 1
 
kvis'i a statement can be used to produce the desired binding. rarity of embedded variables 
 the applicability tester also needs to determine what type of quantifier  i.e.. existential or universal  is associated with each variable in the statement. for example  the statement  can also be written: 
  or 
 vx l' x  . if  then  a binding is being sought for an exiisienlially quantified ovist a node that is a participant in an k relationship  this statement may be useful in deriving the binding. however  the statement cannot be used to derive a binding for a universally quantified node that is a participant in an k relationship. 
the quantification types of the variables in the relationships that a given statement can be used to derive correspond to the quantification types that the variables have in those relationships when the statement is converted into prenex normal form. for example  the prenex normal form of the statement given above is 
r z  . the quantification types of x  y  and z in this form of the statement are the same as those that the statement can be used to derive. 
during the conversion to prenex normal form  only two conversion rules change a relationship's logical sign. namely: 

therefore  we can compute a  parity  for each variable in a statement to indicate the quantification type that it would have in the statement's prenex normal form simply by counting the number of negation spaces and antecedent spaces in which it is embedded. 
note that this is the same rule that is used for computing the parity of relationships! therefore. this single  computationally simple rule is used to define a parity for 
both arcs and nodes. the parity associated with an arc indicates the logical sign of the relationship represented by the arc  and the parity associated with a node indicates and is logically equivalent to unification. an attempt is made to find a set of substitutions that will allow two sets of descriptions to match as follows. the ovist a contains a description of the relationship that is being sought. when the process begins  a k vist a statement has been found that describes an existing or derivable relationship. the question being considered is whether a relationship that satisfies the description given in the kvisia statement will also satisfy the gvisia description. that question is answered by matching the two descriptions. if the match is successful  it defines a set of substitutions  for universally quantified variables  that must be made in the kvista description for it to describe a relationship that would also satisfy the ovisi'a description. these substitutions produce an  instance  of the kvisia statement thai can be used as a basis for a derivation. for example  if the selected ovinia arc is part of the relationship 
ota  and the candidate binding is in the consequent of then the instance  would be 
created. 
the basic rules that are used in doing the match are the following. when comparing the two descriptions  an existential in the k vist a can match only with an existential in the qytsi'a or a universal in the kvisia  and a universal in the ovist a can match only with a universal in the k vist a or an e x i s t e n t i a l in t h e ovist a. rememher that nodes lh:u are dements of kvista or o v i n i a spaces are considered to represent existentwlly mii.intit ied entitit-. these rules are derived directly from the rules for unification. the key observation is that the derived rules should correspond to the rules used for unification in a iefutalion proof where the match is being done using  the negation of the query. 
as an example of the use of parity during an applicability test  consider again the query shown in figme 1. the general pin pose binder task uses the ate b-c-   ghistlcls as an index to find implication i as a candidate statement to use in the derivation of a binding for  he arc 1.-q-- buiids. since both arcs have positive parity  a  builds  relationship derived from the implication will have the desired logical sign. the unification process produces pairings for nodes z   x  and m  and for the obj and agt arcs all the members of those pairs have positive paiity except mode m. node m's negative paiity indicates that it is universally quantified and can therefote be paired with an existential kvisia node having positive parity  namely ole blaek. the resulting substitution of ole-baek for 1 creates the instance of the implication that is used in the derivation. 
f.xtracting embedded structures 
when an applicable non-atomic kvista statement has been found  the derivation that is initiated can be thought of as one designed to  extract  the desired embedded relationship from the statement so that the relation or its negation can be asserted at the top level of the kvista and the desired binding can be assigned. for example  if the candidate binding is in the disjunct x of a disjunction xvy  then finding a solution to the subproblem  prove ~y  will allow x to be asserted and the binding to be assigned. 
rules 	for 	extraction 
whether the node represents a universally or existentially quantified variable. 
matching 	embedded 	structures 
the match process carried out by the applicability tester is a generalization of the ramification process described above the derivation is begun by creating the appropriate instance of the kvista statement  as indicated by the applicability test  and then applying the following extraction rules: 
note that the extraction rules for negated conjunctions and for implications are merely rewrites of the rule for disjunctions. 
if an instantiated implication contains a universally quantified variable  then that variable becomes part of the stibproblem produced by extracting either the antecedent or the consequent and is free to be bound during the process of solving the subproblem. for example  suppose the original implication is of the form and the instantiation is of the form ' h the consequent is to be extracted  then the subproblem has the form  find an   such that hx ;*   the assertion that is made when the subproblem is sol vetd is of the form q   binding of x  a . 
nesting 
if the relationship being extracted is embedded in a nesting of disjunctions  negated conjunctions  or implications  such as the i1 x    it is necessary to apply a sequence of extraction rules to complete the extraction. the rules are applied  top down  to the outermost disjunction  negation. or implication first  and all the desired extraction rules are applied before any of the suhpioblcms are worked on. hence  in the above example  a single subproblem is formed consisting of  solution of this subproblem causes assertion of the desired li  binding of    . doing the complete extraction in one step results in the extraction rules being applied only once  makes available to the deductive machinery all the constraints imposed by all the subproblems. and allows the subproblems to be worked on in whatever order seems the most advantageous. 
kvista and qvista extension spaces 
piocedures that carry out derivations such as the extractions described above require facilities for creating subproblems  making assumptions  and asserting derived results. we have used k-ntt's partitioning features to create such a set of derivation facilities that are available for use by any binder task. in particular  provisions have been made for adding spaces  called  extension spaces   to the ovist a or to the kvista in an environment. kvista extension spaces are used for making assumptions and for asserting derived results. 
qvista extension spaces are used for expressing subproblems. 
for example  consider an environment e1 where ki is the current  i.e.  most recently added  kvista extension space and a binder task for the qvisia implication  is initiating a derivation by assuming x and establishing y as a subproblem to be proved. the derivation is initiated by creating an environment k1 that is an offspring of environment ki  adding to the kvista in f1 a new extension space k1 containing a copy of x  adding to the qvista in 1 a new extension space q1 containing a copy of y  and attaching a demon to space q1 in 1. when bindings are assigned to all the elements of y  the demon is tired in the current environment  i.e.  the environment in which all of the bindings are assigned  and in that environment the demon removes space k1 from the kvista  removes space q1 from the ovist a  asserts    y in space ki  the new current kvista extension space   and assigns this newly derived result as the binding for the original qvisia implication. 
in order to maintain the relationship between derived results and the assumptions that were used to derive them  the following three rules are used in creating bindings and asserting results. 
the first rule is that in each environment only those binder tasks that are seeking bindings for arcs in the most recently added subproblem are allov.e.l to run. this rule helps prevent duplication of effort among environments and assures that effort within an environment created to pursue a particular derivation strategy will not be spent considering other strategies. 
the second rule restricts bindings assigned to elements of any given qvista space to be elements of kvisia spaces that existed at the time the qvisia space was created. in addition to preventing results derived with the aid of assumptions from being used as if they were independent of the 
assumptions  this restriction is used to maintain the nesting of quantified variables during derivations  as described in the sections below. 
the third rule attempts to assure the widest availability of derived results to as many subproblems in as many alternative proof paths as possible. it specifies that each derived relationship be asserted in the newest kvisia extension space in the set consisting of the space containing the statement used to initiate the derivation and those kvista spaces containing elements that were used as bindings to solve the subproblem created by the derivation. this rule allows a derived result whose derivation does not make use of the assumptions in recently added kvisia extension spaces to be added in an earlier extension space and therefore be made available to aid in the solution of subproblems created before the assumptions were made. 
use 	of extension 	spaces for 	doing 	extractions 
during the multiple level extraction process  the results of some subproblems may be used in the formation and solution of other subproblems. to make this possible and to prevent a subproblem's results from being used before that subproblem is solved  we maintain the order of the subproblems and their results by putting each one in a separate space and adding those spaces to qvista and kvista a as extensions in the order that the extraction rules are applied. for example  the extraction of r y  from 
will cause creation of the subproblem  prove i 
q y   and will produce the results  vxcx l  x  a ye a l  y  the results  vxf. x l' x  and the existence of an entity y that is an element of y cannot be used in the proof of v .    but can be used in the proof of p y aq y . this ordering constraint is maintained by creating extension spaces in the following order: 
ql: a qvisia extension containing p a  that accepts bindings from the kvisia that was current when the extraction was initiated. 
ki: a kvista extension containing  the results of proving l* ;i . 
q1: a qvista extension containing  that accepts bindings from ki and the initial kvisia. 
demons are attached to spaces ql and q1 that fire upon completion of the subproblem. those demons cause spaces ql and q1 to be removed from the qvisia  space ki to be removed from the kvisia  and the cumulative results    to be added to the then current 
kvisi a extension. 
special purpose binder tasks 
knowledge r e p r . - 1 : 	fikes the basic sniffer includes a collection of functions that form special purpose binder tasks in addition to the general purpose binder described above. the most important of these embody the derivation strategies for queries containing disjunctions  implications  and negated conjunctions. in this section we will describe this collection of functions. 
proving disjunctions  implications  and negated conjunctions 
ovist a queries are sometimes nonatomic  for example  consider the questions  were any mustangs built by ford   and  arc all red mustangs owned by playboys  . 
the system's special purpose binder tasks for nonatomic statements occuring in the qvista apply a strategy of decomposing the statement into alternative simpler subproblems using the following rules: 
to prove: 	generate 	n 	subproblems 	of the form: 

as was the case with the extraction rules discussed earlier  the subproblems created for negated conjunctions and for implications are merely rewrites of those produced for disjunctions  bach binder task selects an order in which to produce its subproblems so that the easier ones are produced first. 
each solution to each of the subproblems produces a set of bindings for the entire original statement being proved. eaeh time one of these binder tasks is run  it creates a subproblem in a newly created offspring environment and reschedules itself in the parent environment. in the offspring environment it adds a new extension space to k vista containing a set of assumptions  adds a new extension space to ovista containing an expression to be proved  and attaches a demon to the new qvisi a extension space. when the demon is fired by the solution of ihe subproblem in the ovisia extension space  it schedules a task that creates bindings for the entire original expression in the then current environment. 
if snfffr 1 k automatically sought inconsistencies between its knowledge base and assumptions that are made  then it would be sufficient to create a single subproblem from a disjunction. namely  assume the negation of all the disjuncts except one and then attempt to prove the remaining  one. however  since snffr does not automatically check assumptions for consistency  we must define two subproblems from a disjunction. namely  one that specifies a disjunct to be proved  say x1  and an assumption  and a 
second one that consists only of trying to prove that the assumption made in the first subproblem is false. however  the second subproblem is then attempting to prove the equivalent of the disjunction  which itself defines two subproblems  etc. therefore  in fact  n subproblems are defined and they have the form shown in the rule given above.  note that in an actual proof it is unlikely that many of these subproblems will be created since what appear to be the easiest ones are established first. only when the initial ones are found to be difficult to solve do others need to be attempted.  
the subproblem formation rules for implications differs from the rule for disjunctions in that the subproblems created from implications may involve universally quantified variables  represented by nodes that occur in both the implication's antecedent and consequent spaces . in each such subproblem  the nodes representing universally quantified variables are  assumed  in the kvista extension space created for the subproblem. they therefore represent an entity in the knowledge vista about which nothing is known except the 
other assumptions made by the subproblem. if the statement to be proved in the subproblem can be shown to be true about that entity  then it is true for all entities for which those assumptions are true. such a proof is sufficient to complete the subproblem and therefore prove the implication. 
por example  if snifper is attempting to prove that only insecure people own red mustangs  represented by the implication  if x is a red mustang  then x is owned by an insecure person    and the generator for implications creates a subproblem that assumes the implication's antecedent and attempts to prove its consequent  then the assumption for that subproblem would be that some newly created node x* represents an entity that is a red mustang  and the statement to be proved would be that the entity represented by x' is owned by an insecure person. 
function applications 
in a previous section we discussed the procedural augmentation of k-net through the use of the applications set. a special purpose binder task creates elements of the applications set in the kvista by calling the indicated function with the indicated arguments. this binder task is needed when a subproblem is created consisting of the antecedent of a kvisia implication that describes a  procedural attachment  lo the network. such subproblems describe an element of the applications set that can be created as soon as bindings are determined for each of the arguments. if the binder task is called before all the argument bindings have been determined  then it attaches demons to the unbound argument nodes that will restart the binder task when all of them have been bound. when all arguments are present  the procedure is called and new network structures are added to the kvisia to represent the result. 
the use of the application set allows a k-ni-t to explicitly represent meta-relationships between sets of relationships and the procedures that compute them. if a user has no need to represent such meta-rciationships explicitly  then procedural augmentation may be realized much more efficiently through the use of user-supplied binder tasks. por example  rather than include the theorem of figure 1b  a specialist for the sums relationship set may be added that knows how to call function plus and add new information to the kvista as described for applications. 
case analysis proofs 
there is an important class of problems that the deduction mechanisms we have described thus far cannot solve. namely  those that require a case analysis proof  sit lovcland and shekel. 1. *  jnd moore  i* 1  for example  consider the problem of pioving some relation r given a k vist a containing  ihe mechanisms we have described would go into an infinite loop attempting to solve this problem. what is needed is a case analysis mechanism that will  for example  attempt to prove r in the case where i* is true and then attempt to prove r again in the case where  is true. since r can be proved in both those cases and the kvista contains a statement indicating that either i* or q is true  the problem is solved. 
a major difficulty in creating a design for a case analysis proof mechanism is the development of a procedure for dehnmg the cases  every nonatomic statement in the kvista defines a candidate set of cases  e.g.  an implication x= y defines the set  therefore  the problem of defining ihe cases can be considered to be one of selecting an appropriate nonatomic kvisia statement. 

knowledge 	r e p r . - 1 : 	flkes 
1 

we are currently experimenting with the following scheme which appears to be an effective way of making the selection. it is based on the observation that for a case analysis proof to be necessary  it must not be possible  or be impossibly difficult  to complete a proof without the case assumptions. therefore  in each case the assumptions must be useful at some point in the proof. the key  then  to defining the cases for a case analysis proof is in the recognition during the attempt to construct a standard proof of the need for each of the assumptions in some potential set of cases. 
disjunctions in the kvista  for example  are selected to be the basis for a case analysis proof by recording each time one of the disjuncts is extracted  i.e.  contains a relationship that matches some relationship in the qvisia  during a proof attempt. if all the disjuncts of a particular instance of a disjunction have been extracted  then we can conclude that each of the disjuncts would be a useful case assumption and therefore that the disjunction could be the basis for a 
potentially successful case analysis proof. the same conclusion can be made when both the antecedent and the consequent of an implication or all the conjuncts of a negated conjunction have been extracted. 
when such a  fully extracted  kvisia statement is found  the first common parent of the environments in which the extractions were initiated is found  and a new task is added to that parent environment's agenda to initiate the case analysis proof. that proof attempts to derive bindings for the portion of the ovist a for which bindings were being derived each time one of the extractions was done. the task creates an offspring environment and in that environment assumes the first case  establishes the statements to be proved in a new qvista extension space  and attaches a demon to the new 
qvisia extension. the demon does the same thing for the next case. the last demon asserts the statements that have been proved in each case and assigns the appropriate bindings. 
note that in the example given above  any of the three 
kvisia statements could be used as the basis for a case analysis proof  e.g.. ~p and r is an acceptable set of cases . our selection procedure could find any one  or all  of them  depending on the order in which new environments are created in the environment tree. 
to achieve completeness  one must also consider cases defined by relationships that occur in the initial qvista in both a negated and unnegated form. for example  p x  and ~p y  occurmg in the qvisia define a useful set of cases {p  binding of x    ~p  bindmg of x  } when the binding of x along one proof path is the same as the binding of y along another path. 
concluding remarks 
the goal of this research is to provide a unified system that has powerful  general mechanisms and that can be made very efficient for solving the most frequently encountered problems in particular application areas. the central idea is to use specialized repiesentalions and deduction schemes where they can be effective  while having a logically complete mechanism to fall back on when the special mechanisms fail. 
in producing k-neti and snifffr  we have attempted to create convenient hooks for adding specialists  and useful building blocks from which those specialists can be constructed. these hooks include the links to procedures  and hence to other representation structures  that are included in k-nft  the pattern-directed strategy selectors in sniit fr that are capable of invoking user-supplied tasks  and snirtr's agenda control mechanism. the building blocks include the taxonomy derivation functions  the unification machinery  and the facilities for manipulating extension spaces. 
we plan to continue our experimentation with various specialist routines  both for the rapid handling of particular types of deduction and retrieval and for the extension of the system to include new types of problem solving activities  including reasoning with uncertainties and about processes. preliminary experience indicates that the facilities provided make this exploration manageable and productive. 
an important goal of future work with sniffer is to determine the effectiveness of its control mechanisms  particularly the use of intlrtisf coroutines and multiple level agendas. the use of these mechanisms to coordinate multiple types of problem solving activities is of particular interest to us  as is the use of heuristics to guide the allocation of resources among the various strategies that sniffer coordinates. we have only begun to gain experience in these areas. however  the modular control structure of sniffer and the strong cross-indexing of k-nft provide a very supportive environment for future explorations. 
acknowledgements 
the research reported in this paper was supported at ski by the advance research projects agency under contracts daag1-c-1 and daa g-1-c-ooi1 with the u.s. 
army research office. the xerox palo alto research center has provided support to the first author during the writing and preparation of this paper. nils nilsson has been an important contributor to the design of this system  particularly with regard to the deductive machinery. ann robinson. johnathon slocum  and mike wilber have been major participants in the overall implementation effort. danny bobrow has provided important critiques of our efforts to describe the work. 


proactive scheduling seeks to generate high quality solutions despite executiontime uncertainty. building on work in  beck and wilson  1   we conduct an empirical study of a number of algorithms for the job shop scheduling problem with probabilistic durations. the main contributions of this paper are: the introduction and empirical analysis of a novel constraint-based search technique that can be applied beyond probabilistic scheduling problems  the introduction and empirical analysis of a numberof deterministic filtering algorithms for probabilistic job shop scheduling  and the identification of a number of problem characteristics that contribute to algorithm performance.
1	introduction
classical models of scheduling assume all information is known and static. when faced with uncertainty  proactive scheduling techniques seek to incorporate models of the uncertainty in the off-line problem solving and to build solutions that can achieve a satisfactory level of performance at execution time.  beck and wilson  1  addressed the problem of job shop scheduling with probabilistic durations with two styles of algorithm both using monte carlo simulation to evaluate the probabilistic makespan of solutions. this paper builds on that work  making the following contributions:  i  a novel constraint-based search technique is introduced that performs a series of complete branch-and-bound searches on highly constrained problem models. the models are gradually relaxed with the cost of the best solution model found in the previous searches being used as an upper bound. experimental results show that the algorithm performs as well as the existing branch-and-bound style of search on small problems and significantly out-performsit on larger problems.  ii  a number of novel deterministic filtering algorithms are presented. on larger problems such algorithms out-perform the other algorithms tested. their performance is affected by the following two factors: the quality of the deterministic solutions found and the correlation between the deterministic and

﹛﹛ this material is based upon works supported by the science foundation ireland under grant no. 1/pi.1/c1 and by ilog  sa.probabilistic makespan of solutions.  iii  it is demonstrated that the method introduced by beck & wilson for the incorporation of uncertainty in deterministic problems can increase the correlation between deterministic and probabilistic makespan  providing an explanation for its strong performance.
﹛in the next section we briefly review previous work. the six search algorithms investigated in this paper are defined in section 1 and section 1 presents our experiments and results. in section 1  we present our conclusions.
1	background
the job shop scheduling problem  jsp  consists of a set a of activities each with a positive integer-valued duration  di. a is partitioned into jobs  and with each job is associated a total ordering on that set of activities. each activity specifies a resource on which it must execute without interruption. no activities that require the same resource can overlap in their execution. we represent this formally by a partition of a into resource sets. a solution consists of a total ordering on each resource set such that the union of the resource and job orderings is an acyclic relation on a. the makespan of a solution is the difference between the minimum start time and the maximum end time of all activities. finding a solution with minimum makespan is np-hard  garey and johnson  1 . an independent probabilistic job shop scheduling problem is a jsp where the duration di associated with an activity ai ﹋ a is a positive integer-valued random variable. these random variables are fully independent. di has expected value 米i = e di  and variance 考i1 = var di . the makespan make s  of solution s is therefore also a random variable. we fix a degree of confidence p  e.g.  we set p = 1 in the experiments. the minimum probabilistic makespan  d s   of a solution s is the smallest value d such that the probability that all jobs will finish before d is at least p. that is  d s  = min{d : pr make s  ≒ d  ≡ p}. an optimal probabilistic makespan is the minimum d s  over all solutions s.
﹛beck & wilson introduce an analytical model and develop two main results. first  it is demonstrated that monte carlo simulation can be used to find the probabilistic makespan for a solution and to find a lower bound on the probabilistic makespan of a partial solution. second  it is shown that a deterministic jsp instance can be constructed from a probabilistic jsp instance by setting the duration di of each activity to 米i+q考i and that  for the appropriatechoice of non-negativeq  the optimal makespan of the deterministic instance is a lower bound on the optimal probabilistic makespan of the corresponding probabilistic jsp. three algorithms are defined: a branch-and-boundapproachwhere monte carlo simulation is used at each node to find a lower bound  at internal nodes  or an upper bound at a leaf node on the probabilisticmakespan  and two deterministic filtering algorithm consisting of using either constraint-based search or tabu search to find a series of increasingly good deterministic solutions  each of which is simulated. empirical results indicated that the first algorithm was able to find optimal solutions only for very small problems  that for medium-sized problems the constraint-based filtering algorithmfound the best solutions  and for the largest problems the tabu-based filtering algorithm performed best. choosing q   1 led to stronger performance of the filtering algorithms. no empirically founded explanations were provided to explain the differences in problem solving performance.
1	algorithms for probabilistic jsp
in this section  we describe six algorithms for solving the probabilistic job shop scheduling problem.
1	approximately complete branch-and-bound
we implemented a branch-and-bound algorithm identical to that of beck & wilson except that we use stronger heuristics that make decisions on the sequence of activities in each resource set  see section 1 . we refer to this algorithm as the b&b-n as it performs branch-and-bound with simulation at each node.
1	iterative descending bound search
by setting activity durations based on a q value that ensures a lower bound on the probabilistic makespan  we can use standard constraint propagation on the deterministic durations to implicitly calculate a lower bound at each internal node. at each leaf node  simulation is used as in b&b-n to find the probabilistic makespan. rather than parameterize the algorithm with a fixed q value  we perform repeated tree searches with a descending q value. starting with a high q value  we begin a tree search. when the first leaf  e  is reached  simulation is used to find d se . it is likely that dq se   the minimum makespan of se in the corresponding deterministic problem  will be larger than d se . since we enforce dq se  ≒ d se   estimating d se  through simulation causes the search to backtrack to a interior node  i  very high in the tree. at node i  dq si  ≒ d se : si is the set of solutions in the subtree below node i and dq si  is a lower boundon the deterministic makespan of those solutions based on standard constraint propagation. with high q values  we commonly observe that there are very few nodes that meet this criterion and the search space is quickly exhausted. we then decrement the q value  e.g.  by 1  and start a new tree search. eventually  and often very quickly  we reach a q value such that there exists a full solution where dq se  ≒ d se . the probabilistic makespan of the best solution that has been b&b-dq-l  :
returns the solution with lowest probabilistic makespan
1  s  d   ↘ findfirstb&bsimleaves ﹢ 1 
1 q ↘ q1
1 while q ≡ 1 and not timed-out do
1  s  d  ↘ findoptb&bsimleaves d  q 
1 if s 1= nil then
1 s  ↘ s; d  ↘ d end
1 q ↘ q   qdec end
1 return s 
algorithm 1: b&b-dq-l
found by any point in the overall search is used  as in b&b-n  as an upper bound on subsequent search.
﹛algorithm 1 presents pseudocode for the basic algorithm. we make use of two functions not defined using pseudocode: findfirstb&bsimleaves c  q  creates a jsp with activity durations defined based on the q value and conducts a branch-and-bound search where monte carlo simulation is used for each leaf node and standard constraint propagation is used at interior nodes. the first solution that is found whose probabilistic makespan is less than c is returned. findoptb&bsimleaves c  q  does the same as findfirstb&bsimleaves c  q  except the solution with lowest probabilistic makespan is returned rather than the first one. if no solution is found  a nil value is returned. unless the q value is low enough that the deterministic makespan is a lower boundon the probabilisticmakespan  this functiondoes not necessarily return the globally optimal solution. we find a
﹛starting solution with q = 1 to serve as an initial upper bound on the probabilistic makespan. in practice  b&b-dq-l is run with a maximum cpu time. if q = 1 is reached within the time limit  this algorithm is approximately complete.
﹛we refer to this algorithm as b&b-dq-l as it does a series of branch-and-boundsearches with descendingq values and with simulation is used at the leaves of the tree.
1	branch-and-bound filtering algorithms
preliminary experiments with the branch-and-bound filtering algorithm presented by beck & wilson showed that a significant amount of simulation was being done early in the search when the upper bound on the deterministic makespan was relatively high. such solutions would seem to have little chance of being the optimalprobabilistic solution as the deterministic solution is very poor. we present two constraint-based filtering algorithms that seek to avoid these wasted simulations.
branch-and-bound timed better solution a simple methodis to spend a fixedamountof cpu time  tinitial to find a solution  s   with a low deterministic makespan dinitial using a fixed q value and constraint-based search. then search can be restarted using the same q value and using dinitial as an upper bound on the deterministic makespan. whenever a solution  s  is found such that dq s  ≒ dinitial  a simulation is run to evaluate the probabilistic makespan. the solution b&b-tbs q :
returns the solution with lowest probabilistic makespan
1  s  dinitial  ↘ findoptb&b ﹢ q tinitial 
1 d  ↘﹢
1 while termination criteria unmet and not timed-out do
1  s d  ↘ findnextb&b dinitial q tremaining 
1 d1 ↘ simulate s 
1 if
1 ↘	↘ end
end
1 return s 
algorithm 1: b&b-tbs
with the lowest probabilistic makespan is returned when either the entire tree has been searched or when the maximum allowed cpu time has expired. algorithm 1 contains pseudocode for this approach.
﹛as above  we make use of a number of functions not defined with pseudocode: findoptb&b c  q  t  creates a jsp with activity durations defined based on q and conducts a deterministic branch-and-boundsearch for up to t cpu seconds using c as an upper bound on the makespan. when the search tree is exhausted or the time-limit is reached  the best solution found  together with its makespan  are returned. no simulation is done. findnextb&b c  q  t  produces a sequence of solutions  one solution each time it is called  whose deterministic makespan is less than or equal to c. the problem is defined using the q value and t is the cpu time limit. the solutions produced are the leaves of the b&b search tree in the order encountered by the algorithm. the c value does not change. given enough cpu time  the algorithm will evaluate the probabilistic makespan of all solutions whose deterministic makespan is less than or equal to dinitial. finally  simulate s  runs monte carlo simulation on solution s and the probabilistic makespan is returned.
﹛the algorithm is called b&b-tbs for branch-and-bound timed better solution. the algorithm is not complete  as there is no guarantee that the optimal probabilistic solution will have a deterministic makespan less than dinitial.
branch-and-bound iterative best solution a more extreme filtering algorithm first finds an optimal deterministic solution and uses it as a filter for choosing the solutions to simulate. using a fixed q value  a solution with an optimal deterministic makespan  dq   is found and simulated. then we execute a series of iterations beginning with i = 1. for each iteration  all solutions  se  with deterministic makespan  are simulated and the one with
the lowest probabilistic makespan is returned. if an optimal deterministic solution cannot be found within the cpu time limit  the best deterministic solution found is simulated and returned  i.e.  only one simulation is done . algorithm 1 presents the pseudocode.
﹛the algorithm is theoretically complete. when i is large enough that the cost bound is greater than the deterministic makespan of all activity permutations  they will all be simb&b-i-bs q :
returns the solution with smallest probabilistic makespan
1  s  dinitial  ↘ findoptb&b ﹢ q t1   1 
d 	simulate s  
1 while not timed-out do
1 while termination criteria unmet do
1  s dq  ↘ findnextb&b 
	d	i/
if d   d  then
s  ↘ s; d  ↘ d
end
end
1 i ↘ i + 1 end
1 return s 
algorithm 1: b&b-i-bs
ulated. however  i would have to grow unreasonably large and therefore we treat this algorithm as  practically  incomplete. we refer to this algorithm as b&b-i-bs for branchand-bound-iterative-best solution.
1 local search filtering algorithms we also experiment with two local search filtering algorithms analogous to the constraint-based algorithms above except that tabu search is used in place of constraint-based search.
tabu timed better solution	for a fixed q and for a fixed
cpu time  tinitial  a solution with the lowest deterministic makespan  dinitial  possible is sought. search is then restarted and whenever a solution  s  is found that has a deterministic makespan dq s  ≒ dinitial  simulation is used to evaluate the probabilistic makespan. the solution with the lowest probabilistic makespan is returned. the pseudocode for tabu-tbs is the same as that for b&b-tbs  algorithm 1  with the following changes. the function findnexttabu c q t  replaces findnextb&b c q t ; it produces a sequence of solutions whose deterministic makespan is less than c. the findbesttabu c q t  function replaces findoptb&b c q t ; tabu search is run for up to t cpu seconds and the solution with the lowest deterministic makespan that is less than c is returned. we call this algorithm tabu-tbs for tabu-timed better solution.
tabu iterative best solution the core tabu search implementation does not necessarily use the entire cpu time. we can therefore create an iterative tabu-based solver for the probabilistic jsp similar to b&b-i-bs. in the first phase  using the overall time limit less one second  tabu search is used to find a good deterministic solution  based on a fixed q value. that solution is then simulated. any remaining time is spent generating solutions with a deterministic makespan within a fixed percentage of the initial solution's deterministic makespan. as with b&b-i-bs  iterations are run with increasing i value starting with i = 1. in each iteration  solutions found by the tabu search whose deterministic makespan are within 1 + i/1 of the initial deterministic makespan are simulated. the solution with the lowest probabilistic makespan is returned. the algorithm is termed tabu-i-bs for tabu-iterative-best search. the pseudocode for this algorithm is the same as that for b&b-i-bs  algorithm 1  with the same substitutions that were made for tabu-tbs.
1	core algorithm details
the branch-and-bound algorithms described use texturebased heuristics  beck and fox  1  to decide on the the pair of activities to sequence and which sequence to try first. when constraint propagationis used  i.e.  all b&b algorithms except b&b-n   we use temporal propagation  timetables  le pape et al.  1   edge-finder  nuijten  1   and the balance constraint  laborie  1 .
﹛the tabu search is the same one used by beck & wilson: the tsab algorithm of  nowicki and smutnicki  1 . 1 empirical investigations
our empirical investigations aim to evaluate and investigate the performance of the algorithms. in particular  we are interested in algorithm scaling with problem size and uncertainty level and with the usefulness of representing uncertainty information using q values.
1	experimental details
we use foursets of probabilisticjsps of size {1℅1℅1℅ 1℅ 1} with three uncertainty levels uj ﹋{1 1 1}. a deterministic problem is generated using an existing generator  watson et al.  1  with integer durations drawn uniformly from the interval  1  1 . three probabilistic instances are then produced by setting the mean durations 米i to be the deterministic durations and by uniformly drawing the standard deviation 考i from the interval  1 uj米i . the distribution of each duration is approximately normal. for each problem size  we generate 1 deterministic problems which are transformed into 1 probabilistic instances.
﹛given the stochastic nature of the simulation and the tabu search algorithm  each algorithm is run 1 times on each problem instance with different random seeds. each run has a time limit of 1 cpu seconds. each monte carlo simulation uses 1 trials. for b&b-tbs and tabu-tbs  tinitial is 1 cpu seconds.
﹛for the heuristic techniques  a deterministic duration is assigned to each of the activities based on the q value. we experiment with the same four q values used by beck & wilson as displayed in table 1. the b&b-dq-l algorithm requires an initial value of q  q1  and a decrement  qdec. for all except the largest problems  we used q1 = 1 and qdec = 1. preliminary experiments with the 1℅1 problems indicated that q1 = 1 resulted in long runs with no solutions due to a large search space with few if any solutions. to avoid such runs  we used q1 = 1  for which solutions could be found.
﹛the probabilistic makespans are based on confidence level p = 1. our primary evaluation criterion is the mean normalized probabilistic makespan  mnpm  that each algorithm achieves: mnpm is a set of problem instances  d a l  is the mean probabilistic
q1q1q1q1﹟b1nq1+q1	paverage	考1
b	ai﹋羽 i
﹟n average	考i
ai﹋羽table 1: the q-values used  following beck & wilson. n is the number of jobs and b = 1.
makespan found by algorithm a on l over 1 runs  dlb l  is the lower bound on the probabilistic makespan for l. for all problems except 1 ℅ 1  the dlb is found by solving the deterministic problems to optimality using the q1 durations  see section 1 of  beck and wilson  1  . for the 1℅1 problems  the optimal solutions could not be found and so the dlb values represent the best deterministic solutions found. these values  therefore  are not a true lower bound.
﹛the hardware used for the experiments is a 1ghz pentium 1 with 1 m of main memory running linux redhat 1.
all algorithms were implemented using ilog scheduler 1. 1 results
table 1 presents the results of our experiment. each cell is the mean over 1 independent runs of 1 problems. the observed mean standard deviations for each cell are small: the maximum over all cells is less than 1% of the corresponding mean makespan  while the mean over all cells is less than 1%. we did not observe a large difference among the q values provided q   1 and therefore present the results for q1.
problem sizeunc. levelalgorithmsb&b completeb&b heuristictabundq-ltbsi-bstbsi-bs1℅1.1.1*1*111111*1*11111.1*111111℅1.1.1.1.1.1.1.111111111.1.1.1.1.1.1℅1.1.1.1.1.1.1.111111111.1.1.1.1.1.1℅1 111111111111111.1.1.1.1.1.1table 1: the mean normalized probabilistic makespans for each algorithm. '*' indicates a set of runs for which we have  with high confidence  found close-to-optimal makespans. ' ' indicates problemsets for which normalizationwas donewith approximate lower bounds. the lowest mnpm found for each problem set are shown in bold.
﹛for the 1 ℅ 1 problems  a number of algorithms find lower mean probabilistic makespans than b&b-n despite the fact that b&b-n terminates before the limit on cpu time and therefore finds approximately optimal solutions. this is an artifact resulting from algorithms that simulate the same solution multiple times. in b&b-n  a particular solution is only simulated once. in other algorithms  the same solution may be simulated multiple times leading to a bias to lower probabilistic makespan values. based on the theoretic model of beck & wilson  these values still correspond to approximately optimal solutions.
1	analysis
overall the empirical results agree with those presented by beck & wilson. here  we will focus on investigations of b&b-dq-l and of the behavior of the heuristic algorithms.
branch-and-bound descending-q leaves
b&b-dq-l out-performs b&b-n across all problem sets even when it is not able to reach q = 1. as an indication of the numberof iterations  the mean minimum values q for each problem size are: 1 ℅ 1 : 1  1 ℅ 1 : 1  1 ℅ 1 : 1  1 ℅ 1 : 1.
﹛for b&b-dq-l  the deterministic durations defined by the q value serve to guide and prune the search for each iteration and  therefore  as with the heuristic algorithms  see below   the search is heuristically guided to the extent that solutions with low deterministic makespans also have low probabilistic makespans. however  the characteristics of the solutions found by the search are unclear. ideally  we would like the search with high q to find solutions with very goodprobabilistic makespans both because we wish to find good solutions quickly and because the probabilistic makespan values are used to prune subsequent search. analysis indicates that the first solution found by b&b-dq-l is consistently better than the first solution foundby b&b-n and for the larger problems  1℅1 and 1℅1  the relative increase in solution quality over subsequent iterations is greater for b&b-dq-l.
heuristic algorithms
to investigate the performance of the heuristic algorithms  we look at the performance differences coming from using the q values  and the extent to which the performance of the heuristic algorithms depends on two factors: their ability to find good deterministic solutions and the underlying correlation between deterministic and probabilistic makespans in the experimental problems.
the effectof theq values using a non-zeroq value almost always results in better performance. this appears to be particularly true when either the uncertainty or the problem size increases. table 1 shows the difference between mean normalized probabilistic makespan when using q1 and q1. on a few problem sets  negative values indicate that the runs with q1 deliver a better mean solution. however  by far the majority of the values are greater than 1 and their magnitude increases with both uncertainty and problem size  indicating increasingly good relative performance on the q1 problems. we show below that one explanation for this performance is that problem instances with q   1 have a greater correlation between deterministic and probabilistic makespans.
finding good deterministic makespans we hypothesize that the performance of the heuristic techniques  and b&bdq-l  is partially dependent upon the ability to find solutions with low deterministic makespans. we looked at two measures of the performance of b&b-i-bs and tabu-i-bs: the quality of the best deterministic solutions found and the number of iterations. because b&b-i-bs performs systematic search of all deterministic solutionswith makespanbelow a given threshold  we hypothesize that on problem sets where
problem sizeunc. levelb&btabutbsi-bstbsi-bs1℅1.1.1111.1.1.11.1-1111℅1.1.1111-11.1.11.1.1.1.1℅1.11-11111111.1.1.1.1℅1 11111111111.1.1.1.1table 1: the difference between the mean normalized probabilistic makespans for runs using q1 and using q1. the higher the value  the more the q1 runs out-performed the q1 runs.
it outperforms tabu-i-bs  it will also have found better deterministic solutions and/or be able to systematically search solutions up to a higher threshold. in contrast  for problem sets where tabu-i-bs outperforms b&b-i-bs  it will be due to finding better deterministic solutions.
﹛table 1 presents data using q = q1. the mean normalized deterministic makespan  mndm  is the calculated as follows:
mndm. the notation is as above with the addition of dq min l b&b-i-bs   the lowest deterministic makespan found by the b&b-i-bs algorithm over all runs on problem l. mndm  therefore  provides a relative measure of the mean deterministic makespans from the two algorithms: the higherthe value  the worse is the average makespan found relative to b&b-i-bs. the second measure  iters  is the mean number of iterations performed by each algorithm.
problem sizeunc. levelb&b-i-bstabu-i-bsmndmitersmndmiters1℅1.1.111111.11.111℅1.1.111111.11.111℅1.1.111111.11.111℅1.1.111111.11.111table 1: the mean normalized deterministic makespan  mndm  and number of iterations  iters  for b&b-i-bs and tabu-i-bs.
﹛table 1 is consistent with our hypotheses. for those problems sets with large performance differences  i.e.  1 ℅ 1 and 1℅1  in probabilistic makespan  the better performing algorithm does find better deterministic makespans.
the correlation between deterministic and probabilistic makespan the explanatory power of an algorithm's ability to find good deterministic makespans is  by itself  insufficient unless there is a correlation between the good deterministic and good probabilistic makespans. it is reasonable to expect that the level of uncertainty has an impact on any correlation: at low uncertainty  the variations in duration are small  so we can expect the probabilistic makespan to be relatively close to the deterministic makespan. when the uncertainty level is high  the distribution of probabilistic makespans for a single solution will be wider  resulting in a lower correlation. we hypothesize that this impact of uncertainty level contributes to the observed performance degradation  see table 1  of the heuristic techniques with higher uncertainty levels.
﹛we generated 1 new 1 ℅ 1 deterministic jsp problem instances with the same generator and parameters used above. the standard deviation for the duration of each activity in the 1 instances were generated independently for each of five uncertainty levels uj ﹋ {1 1 1 1} resulting in a total of 1 problem instances. for each instance and each of the four q values above  we randomly generated and simulated 1 deterministic solutions. using r  r development core team  1   we measured the correlation coefficient  r  for each problem set.
unc. levelq1q1q1q1.1.1.1.1.1.1.1.1.1.111111.1.1.1.11111table 1: the correlation coefficient comparing deterministic and probabilistic makespans for a set of 1 ℅ 1 probabilistic jsps. each cell represents the correlation coefficient for 1 deterministic  probabilistic pairs.
﹛table 1 supports our hypothesis. as the uncertainty level increases  the correlationbetweenthe deterministic makespan and corresponding probabilistic makespan lessens. the strength of the correlation is somewhat surprising: even for the highest uncertainty level  r is more than 1 for q1 and q1. this suggests that the heuristic algorithms can be successfully applied to problem with higher uncertainty levels provided the appropriate q value can be found.
﹛the correlation results in table 1 also provide an explanation for the effect of the q values: they increase the correlation between deterministic and probabilistic makespans.
1	conclusion
in this paper  we presented and conducted empirical analysis of a number of algorithms to proactively solve the job shop scheduling problem with probabilistic durations. our empirical studies have demonstrated that a novel algorithm  b&b-dq-l  based on iteratively reducing a parameter that determines the validity of the lower bound results in equal performanceon small problems and much better performance on larger problems when compared to the previous branchand-boundtechnique. however  highest performancewas observed in heuristic algorithms based on using the deterministic makespan to filter the solutions which are to be simulated. it was argued  using detailed analysis of the experimental data and results from an ancillary experiment  that the performance of these algorithms is affected by their ability to find good deterministic makespans and the correlation in the problems between the quality of deterministic and probabilistic makespans. the correlation data on problems with higher uncertainty suggest that such algorithms may scale well to such problems. central to the success of the heuristic algorithms was the use of a q value that governs the extent to which uncertainty  i.e.  the variance  was represented in the durations of activities in deterministic problems. it was shown that such an incorporation of uncertainty data leads to a stronger correlation between deterministic and probabilistic makespans  and suggests a corresponding ability to find better probabilistic makespans.

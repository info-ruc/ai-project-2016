An Action Description Language for Iterated Belief Change

Aaron Hunter and James P. Delgrande

Simon Fraser University

Burnaby, BC, Canada

{amhunter, jim}@cs.sfu.ca

Abstract

We are interested in the belief change that occurs
due to a sequence of ontic actions and epistemic
actions. In order to represent such problems, we
extend an existing epistemic action language to al-
low erroneous initial beliefs. We deï¬ne a non-
Markovian semantics for our action language that
explicitly respects the interaction between ontic ac-
tions and epistemic actions. Further, we illus-
trate how to solve epistemic projection problems in
our new language by translating action descriptions
into extended logic programs. We conclude with
some remarks about a prototype implementation of
our work.

1 Introduction
Reasoning about the effects of actions is an important prob-
lem in logical AI. Action formalisms are often deï¬ned for
reasoning about so-called ontic actions that change the state
of the world. However, sensing actions have also been in-
corporated in the epistemic extensions of several notable for-
malisms [Shapiro et al., 2000; Lobo et al., 2001; Son and
Baral, 2001; Jin and Thielscher, 2004]. In such extensions,
the effects of sensing actions are deï¬ned in terms of belief re-
vision. However, simply supplementing an action formalism
with a revision operator is not sufï¬cient; the iterated belief
change caused by a sequence of ontic actions and sensing
actions can not be determined iteratively [Hunter and Del-
grande, 2005]. Informally, the interpretation of a sensing re-
sult may be inï¬‚uenced by the preceding sequence of ontic
actions. In this paper, we deï¬ne an action formalism where
the belief change caused by a sequence of actions respects the
non-elementary interaction between ontic actions and sensing
actions.

In order to ground the discussion, we frame our results in
an epistemic extension of the action language A [Gelfond and
Lifschitz, 1993]. We base the semantics of our action lan-
guage on the belief evolution operators of [Hunter and Del-
grande, 2005]; our results can be seen as an application of the
belief evolution methodology in an action formalism. The
two main contributions of this paper are as follows. First,
we introduce an action formalism that is suitable for reason-
ing about iterated belief change where the interpretation of

sensing results depends on the preceding actions. In the pro-
cess, we generalize an existing epistemic extension of A by
allowing erroneous beliefs and non-Markovian belief change.
The second contribution of this paper is the introduction of a
method for solving belief evolution problems through answer
set planning. Using this method, we can implement a solver
for epistemic projection problems in our action language.

2 Motivating Example

We present a commonsense example involving iterated belief
change due to action, and we will return to this example pe-
riodically throughout the paper. The example that we present
is framed in the context of a zoo, where a certain crocodile
must be fed every morning. The crocodile is fed from a bag
of food that either contains whole chickens or whole ducks;
the contents of the food bag varies throughout the year. The
crocodile is never sick after eating chicken; even if it is ini-
tially sick we suppose that eating chicken makes it feel better.
However, the crocodile will become sick if it eats two ducks
in row. The crocodile will always eat the food it is given. The
ï¬rst zoo keeper to arrive in the morning typically feeds the
crocodile by giving it one unit of food.

Suppose that Bob the zoo keeper arrives in the morning
for work. Bob believes that the crocodile is unfed when he
arrives, and he believes that the food bag contains chickens.
Suppose that Bob feeds the crocodile, then observes that it
becomes sick. We suggest that Bob should conclude that his
initial beliefs were incorrect; the sickness of the crocodile in-
dicates that it has actually eaten two ducks. We are interested
in using an action description language to formally model the
belief change that occurs in problems of this form.

3 Preliminaries
3.1 Action Language A
We brieï¬‚y review the syntax and semantics of the action lan-
guage A, as introduced in [Gelfond and Lifschitz, 1993].

An action signature is a pair (cid:2)F, A(cid:3) where F denotes a
ï¬xed set of ï¬‚uent symbols and A denotes a ï¬xed set of action
symbols. A state is a propositional interpretation over F, S
denotes the set of all states, and |Ï†| denotes the set of states
satisfying the formula Ï†. A literal is either an element of F or
an element of F preï¬xed with the negation symbol. Let Lits
denote the set of all literals. We use the upper case letter A

IJCAI-07

2498

to range over actions, the lower case letters f, g to range over
literals, and the lower case letter s to range over states.
Deï¬nition 1 An effect proposition of the language A is an
expression of the form

A causes f if g1 âˆ§ Â· Â· Â· âˆ§ gp
where A âˆˆ A, f âˆˆ Lits and each gi âˆˆ Lits.

A set of effect propositions is called an action description.
Every action description AD deï¬nes a transition relation on
states as indicated in the following deï¬nition.

Deï¬nition 2 Let AD be an action description, let s, s(cid:2) be
states and let A be an action symbol. Then Î¦AD(s, A, s(cid:2)) if

E(A, s) âŠ† s(cid:2) âŠ† E(A, s) âˆª s

where E(A, s) is the set of literals such that f âˆˆ E(A, s)
if and only if (A causes f if g1 âˆ§ Â· Â· Â· âˆ§ gp) âˆˆ AD and
s |= g1 âˆ§ Â· Â· Â· âˆ§ gp.
Intuitively, the transition relation maps a pair (s, A) to a new
interpretation s(cid:2) that is exactly like s except for the values of
the ï¬‚uents affected by A.

3.2 Action Language AK
Our epistemic extension of A will be based on the language
AK of [Lobo et al., 2001]. In this section, we brieï¬‚y sum-
marize the action description portion of AK . We remark that
the complete speciï¬cation of AK also includes queries, plans,
and non-deterministic action effects. We restrict attention to
the portion of the language that is deï¬ned in this section.

A belief state is a set of states. The syntax of AK is ob-
tained by extending A with sensing actions, with effects given
by propositions of the form

A causes to know f if g1 âˆ§ Â· Â· Â· âˆ§ gp.

(1)
The semantics of AK associates an epistemic transition rela-
tion Î¦L
AD with every action description AD. An epistemic
transition relation is a set of triples (cid:2)Îº, A, Îºâˆ—(cid:3) where A is
an action symbol and Îº, Îºâˆ— are belief states. The relation
Î¦L
AD is deï¬ned as follows. If A is a non-sensing action, then
(Îº, A, Îºâˆ—) âˆˆ Î¦L
AD if and only if Îºâˆ— is obtained by updating
each world in Îº in accordance with the semantics of A. If A
is a sensing action described by (1), then (Îº, A, Îºâˆ—) âˆˆ Î¦L
AD
just in case one of the following conditions holds.

1. Îºâˆ— is the subset of Îº where g1 âˆ§ Â· Â· Â· âˆ§ gp and f hold
2. Îºâˆ— is the subset of Îº where g1 âˆ§ Â· Â· Â· âˆ§ gp and Â¬f hold
3. Îºâˆ— is the subset of Îº where Â¬(g1 âˆ§ Â· Â· Â· âˆ§ gp) holds

Informally, (Îº, A, Îºâˆ—) âˆˆ Î¦K
belief state after executing the action A with belief state Îº.

AD means that Îºâˆ— is a possible

3.3 Feeding the Crocodile in AK
We illustrate how to represent
the crocodile problem.
The crocodile problem can be described in terms of the
actions F eed and LookAtCroc, along with the ï¬‚uents
C hicken, F ullChicken, F ullDuck and S ick. Informally,
C hicken is true if the food bag contains chickens, whereas

F ullChicken and F ullDuck indicate what the crocodile has
eaten. Action effects are described as follows.

F eed causes F ullChicken if C hicken
F eed causes Â¬S ick if C hicken
F eed causes F ullDuck if Â¬C hicken
F eed causes S ick if F ullDuck âˆ§ Â¬C hicken
LookAtCroc causes to know S ick if S ick.

Bobâ€™s initial belief state is Îº = |Â¬F ullChicken âˆ§
Â¬F ullDuck âˆ§ C hicken|. We are interested in Bobâ€™s new
beliefs after performing the actions F eed and LookAtCroc.
After feeding the crocodile, Bobâ€™s new belief state Îº(cid:2) is a
subset of |Â¬S ick|. As a result, after looking at the crocodile,
the semantics of AK deï¬nes Bobâ€™s ï¬nal belief state to be
âˆ…. Hence, performing revision without considering the action
history leads Bob to hold a vacuous set of beliefs, despite the
fact that there are plausible world histories that support Bobâ€™s
observation. This problem can be avoided by introducing an
appropriate belief change operator.

3.4 Belief Evolution
One way to address erroneous beliefs in AK would be to
introduce an AGM revision operator âˆ— [AlchourrÂ´on et al.,
1985], and then deï¬ne Bobâ€™s new beliefs to be Îº(cid:2) âˆ— S ick.
However, under this approach, it is possible that Bobâ€™s ï¬nal
belief state will contain states satisfying S ick âˆ§ C hicken.
This is the case, for example, if âˆ— is the Dalal operator [Dalal,
1988]. We suggest that such states should not be possi-
ble, because Bob is aware that sickness never follows eating
chicken. Informally, Bobâ€™s observation after feeding should
cause him to revise his initial belief state. Belief evolution
operators have been proposed to model this kind of reasoning
[Hunter and Delgrande, 2005]. We brieï¬‚y present a simpli-
ï¬ed version of belief evolution.

Let Î¦ be a transition relation as in Deï¬nition 2. We asso-
ciate a belief projection operator (cid:10) with Î¦ as follows. For any
belief state Îº and action A,

Îº (cid:10) A = {s(cid:2) | (s, A, s(cid:2)) âˆˆ Î¦ for some s âˆˆ Îº}.

Now suppose that âˆ— is an AGM revision operator. We will
actually let âˆ— take a set of states as an argument rather than
a formula, but it is clear that AGM revision can equivalently
be formulated in this manner. We deï¬ne the belief evolution
Â¯
operator â—¦ associated with (cid:10) and âˆ— presently. Let
A denote
a ï¬nite sequence of non-sensing actions, and let Ï† denote a
propositional formula. Deï¬ne Ï†âˆ’1( Â¯
A) to be the set all states
Â¯
s such that
A gives a path from s to a state where Ï† is true.
Deï¬ne â—¦ as follows:

Îº â—¦ (cid:2) Â¯

A, Ï†(cid:3) = Îº âˆ— Ï†âˆ’1( Â¯

A) (cid:10) Â¯
A.

Hence, belief evolution operators essentially revise the ini-
tial belief state before applying the effects of non-sensing
actions. In [Hunter and Delgrande, 2005], belief evolution
operators are deï¬ned for arbitrary sequences of sensing and
non-sensing actions. To simplify the discussion in the present
paper, however, we restrict attention to sequences involving a
single, terminal sensing action. It would be straightforward
to extend our results to allow arbitrary action sequences by
using the full deï¬nition of belief evolution.

IJCAI-07

2499

4 An Action Language for Belief Change

4.1 Syntax

Our language is obtained by making a slight modiï¬cation to
AK . Let A = O âˆª N where O âˆ© N = âˆ…. We refer to O as
the set of sensing actions and we refer to N as the set of non-
sensing actions. The symbol O ranges over sensing actions
and the symbol A ranges over non-sensing actions.
Deï¬nition 3 Propositions of AB have the following forms:

1. A causes f if g1 âˆ§ Â· Â· Â· âˆ§ gp
2. O causes to believe Ï† if g1 âˆ§ Â· Â· Â· âˆ§ gp

where A âˆˆ N, O âˆˆ O, each gi âˆˆ Lits, and Ï† is a formula.

Note that the effect of a sensing action is now a formula rather
than a ï¬‚uent symbol.

4.2 Semantics
The semantics of AB is deï¬ned with respect to pointed belief
states and epistemic action sequences. A pointed belief state
is a pair (cid:2)s, Îº(cid:3) where s âˆˆ S and âˆ… (cid:13)= Îº âŠ† S. The state s
represents the actual state of the world and Îº represents the set
of states believed to be possible. A pointed knowledge state is
a pointed belief state (cid:2)s, Îº(cid:3) where s âˆˆ Îº. An epistemic action
sequence is a sequence A1, . . . , An, O where each Ai âˆˆ N
and O âˆˆ O. With each action description AD, we associate
an epistemic transition relation Î¦AD. For easy of readability,
we write Î¦AD as a function that takes a pointed belief state
and an epistemic action sequence as arguments, and it returns
a new pointed belief state.

Let O âˆˆ O and let s âˆˆ S. Deï¬ne EFF (O, s) to be the
conjunction of every formula Ï† that occurs in a proposition
of the form

O causes to believe Ï† if g1 âˆ§ Â· Â· Â· âˆ§ gp

where s |= g1âˆ§Â· Â· Â·âˆ§gp. We are now in a position to deï¬ne the
semantics of AB. Note that, for any action description AD,
the non-sensing portion of AD describes a transition relation
which in turn deï¬nes a projection operator (cid:10). We refer to
(cid:10) as the projection operator deï¬ned by AD, and we restrict
attention to deterministic actions. The following deï¬nition
assumes a ï¬xed underlying revision operator âˆ—.

Deï¬nition 4 Let AD be an action description with corre-
sponding projection operator (cid:10). Let â—¦ be the belief evolution
operator obtained from (cid:10) and âˆ—. For every pointed belief state
(cid:2)s, Îº(cid:3), deï¬ne Î¦AD((cid:2)s, Îº(cid:3), (cid:2)A1, . . . , An, O(cid:3)) = (cid:2)s(cid:2), Îº(cid:2)(cid:3) where

A, EF F (O, s(cid:2))(cid:3).

1. s(cid:2) = s (cid:10) A1 (cid:10) Â· Â· Â· (cid:10) An
2. Îº(cid:2) = Îº â—¦ (cid:2) Â¯
Hence, the transition relation associated with AD returns a
new pointed belief state. The new actual world is obtained by
Â¯
A. The new belief
updating s by the non-sensing actions in
state is obtained by belief evolution.

The content of Deï¬nition 4 for action sequences of length

1 is as follows.

1. For non-sensing A: Î¦AD((cid:2)s, Îº(cid:3), A) = (cid:2)s (cid:10) A, Îº (cid:10) A(cid:3).
2. For sensing O: Î¦AD((cid:2)s, Îº(cid:3), O) = (cid:2)s, Îº âˆ— EF F (O, s)(cid:3).

For longer action sequences, we use belief evolution to revise
the initial belief state before determining the effects of A.

Example (contâ€™d) The crocodile example can be represented
in AB by taking the representation from Â§3.3 and replac-
ing the causes-to-know proposition with the corresponding
causes-to-believe proposition. Note that S ickâˆ’1(F eed) is
the set |F ullDuck âˆ§ Â¬C hicken|. Therefore, according to
the semantics of AK , the ï¬nal belief state should be

Îº âˆ— |F ullDuck âˆ§ Â¬C hicken| (cid:10) F eed.

Regardless of the operator âˆ—, Bobâ€™s new belief state will be
non-empty and it will only include states where the food bag
contains duck.

4.3 Reliable Action Descriptions
Note that the crocodile example only involves propositions of
the form: O causes to believe Ï† if Ï†. Observations of this
form can be understood to represent reliable observations. In
general, we say that an action description AD is reliable if
g1 âˆ§ Â· Â· Â· âˆ§ gp |= Ï† for every sensing effect proposition in AD
with the form

O causes to believe Ï† if g1 âˆ§ Â· Â· Â· âˆ§ gp.

By contrast, the action description would not be reliable if it
contained the proposition

LookAtCroc causes to believe Sick .

In this case, looking at the crocodile causes the agent to be-
lieve it is sick, whether or not it is actually sick.

Reliable action descriptions describe infallible sensing ac-
tions. The following proposition formalizes the fact that, if
an agent has correct knowledge of the world, then the conclu-
sions drawn from reliable observations must also be correct.

Â¯
A, it follows that Î¦AD((cid:2)s, Îº(cid:3),

Proposition 1 Let AD be a reliable action description and
let (cid:2)s, Îº(cid:3) be a pointed knowledge state. For any epistemic
Â¯
A) is a pointed
action sequence
knowledge state.
4.4 Representing AK
We can give a translation from AK action descriptions to re-
liable AB action descriptions.
Deï¬nition 5 Let AD be an action description in AK . The
AB action description Ï„ (AD) is obtained from AD by re-
placing every sensing proposition with sensing effect f and
precondition Ïˆ by the following propositions:

O causes to believe f âˆ§ Ïˆ if f âˆ§ Ïˆ
O causes to believe Â¬f âˆ§ Ïˆ if Â¬f âˆ§ Ïˆ
O causes to believe Â¬Ïˆ if Â¬Ïˆ.

The following proposition illustrates the correspondence

between the given epistemic action languages.
Proposition 2 Let AD be an AK action description, let O
be a sensing action in AD and let Îº be a belief state. Then
AD(Îº, O, Îº(cid:2)) if and only if there is some s âˆˆ Îº such that
Î¦K
Î¦Ï„ (AD)((cid:2)s, Îº(cid:3), O) = (cid:2)s, Îº(cid:2)(cid:3).
Proposition 2 illustrates that AK action descriptions are in-
terpreted disjunctively, by determining all possible outcomes
Îº(cid:2) under the assumption that the actual world is in Îº.

IJCAI-07

2500

4.5 Comparison with Related Formalisms
Son and Baral deï¬ne an alternative extension of A,
in
which sensing effects are given by propositions of the form
O determines f [Son and Baral, 2001]. We can deï¬ne a
translation Ïƒ from AS to AB by replacing each such propo-
sition with two propositions: O causes to believe f if f
and O causes to believe Â¬f if Â¬f.

Proposition 3 Let AD be a set of Son-Baral propositions.
Restricted to pointed knowledge states, the transition relation
Î¦Ïƒ(AD) is equivalent to the corresponding Son-Baral transi-
tion relation.
Hence, AB subsumes both of the epistemic extensions of A.
Moreover, AB is the only one of the three extensions that
allows erroneous beliefs and respects the interaction between
sensing actions and ontic actions.

In the epistemic Situation Calculus, belief is deï¬ned
through a ranking function on initial states that persists as
ontic actions are executed [Shapiro et al., 2000]. For any sit-
uation s, the belief set Bel(s) is the set of minimally ranked
situations consistent with all sensing actions executed. If we
restrict attention to Situation Calculus theories where action
effects are deterministic and the initial situations all corre-
spond to distinct states, then we have the following result.

Proposition 4 If A is an ontic action and O is a sensing
action, then there is a belief evolution operator â—¦ such that
Bel(do(O, do(A, S0)) = Bel(S0) â—¦ (cid:2)A, O(cid:3).

It follows that we can translate action theories in the epis-
temic Situation Calculus into equivalent action descriptions
in AB. The same can not be said for the epistemic Fluent
Calculus, where sensing results satisfy the AGM postulates
[Jin and Thielscher, 2004]. Our work suggests that, in some
action domains, simply revising the current belief state leads
to unintuitive results. To represent such domains, we would
need to deï¬ne belief evolution operators directly in the Fluent
Calculus. This would be straightforward to do.

5 Implementation Considerations

In this section, we illustrate how we can solve problems in-
volving iterated belief change due to action through answer
set planning. We proceed as follows. First, we deï¬ne a re-
vision operator based on path length. Next, we introduce an
informal procedure that can be used to solve belief evolution
problems with respect to this operator. We then present a
translation from AB to answer set programming to illustrate
how the procedure can be automated.

5.1 Topological Revision Operators

A transition relation on states can be used to deï¬ne a natural
AGM revision operator. Let Î¦ be a transition relation, and
let Îº, Î± be sets of states. For technical reasons, we assume
that every state in Î± is reachable from Îº by a ï¬nite path in
Î¦. Deï¬ne Îº âˆ— Î± to be the subset of elements of Î± that can
be reached by a minimum length Î¦-path. Under the assump-
tion that every state in Î± is reachable from Îº, it follows that
âˆ— deï¬nes an AGM revision operator; we refer to this as the
topological revision operator deï¬ned by T .

We are interested in topological revision operators for two
reasons. First, topological revision operators do not require
any external notion of similarity:
they depend only on the
underlying transition system. Second, topological revision
operators are well-suited for the implementation that we pro-
pose in the next sections. We do not wish to imply, however,
that topological revision is appropriate for all action domains;
topological revision is only appropriate for domains where er-
roneous beliefs can be explained by action occurrences.

Example (contâ€™d) We extend the crocodile example by in-
troducing a new action called E xchangeF ood which toggles
the value of the ï¬‚uent C hicken. This new action allows an
agent to change the food available to feed the crocodile. Con-
sider the crocodile example extended with this new action,
and suppose that âˆ— denotes the topological revision operator.
We saw earlier that Bob needs to evaluate the expression

Îº âˆ— |F ullDuck âˆ§ Â¬C hicken|.

By deï¬nition, we need to ï¬nd the subset of |F ullDuck âˆ§
Â¬C hicken| that can be reached by a minimal length path
from Îº. As such, the result of the revision is
Îº (cid:10) E xchangeF ood (cid:10) F eed.

Therefore, Bobâ€™s ï¬nal belief state is

Îº (cid:10) E xchangeF ood (cid:10) F eed (cid:10) F eed.

Informally, Bob explains the fact that the crocodile is sick by
postulating that the chicken was replaced with duck, and the
crocodile was already fed once. This is a plausible conclu-
sion in this example. Postulating actions to explain observa-
tions can also lead to non-trivial inferences in some action do-
mains. For example, if we extend the example further to allow
Bob to keep an inventory of the number of ducks remaining,
then topological revision would suggest that he should reduce
the total by two ducks after he observes the crocodileâ€™s sick-
ness.

Topological revision is essentially a form of abduction, in
which an agent looks for the shortest sequence of actions that
can explain an observation. To be clear, we are not suggesting
that this is suitable for all action domains. However, it is
appropriate for extended crocodile-type domains where there
are plausible exogenous actions explaining an observation.

5.2 Belief Evolution Under Topological Revision

In this section, we illustrate that belief evolution under topo-
logical revision can be reduced to ï¬nding shortest paths. We
start by considering a single non-sensing action. Let Îº denote
a belief state, let A denote an action symbol, and let Ï† denote
a formula. We are interested in determining

Îº â—¦ (cid:2)A, Ï†(cid:3) = Îº âˆ— Ï†âˆ’1(A) (cid:10) A.

Figure 1 illustrates how this is calculated with the topo-
logical revision function. The ï¬gure shows a large box rep-
resenting Ï†âˆ’1(A); these are the states that can reach |Ï†| by
executing the action A. The circle inside Ï†âˆ’1(A) represents

IJCAI-07

2501

Ï†âˆ’1(A)

'


&



shortest path . . .

$


%
'
&

|Ï†|

@
@@RA

Îº

'




&
$
%

Figure 1: Visualizing Topological Evolution

the subset that is minimally distant from Îº, which in this con-
text means the elements that can be reached from Îº by a min-
imal length path. In other words, the circle inside Ï†âˆ’1(A)
represents Îº âˆ— Ï†âˆ’1(A). This gives a simple procedure for
computing Îº â—¦ (cid:2)A, Ï†(cid:3).

1. Determine Ï†âˆ’1(A).
2. Let P AT H denote the set of shortest paths from Îº to

Ï†âˆ’1(A).

3. Let Îº0 be the set of terminal nodes on paths in P AT H.
4. Let Îº1 = Îº0 (cid:10) A.

Clearly Îº â—¦ (cid:2)A, Ï†(cid:3) = Îº1. Hence, this procedure allows us
to compute the outcome of belief evolution for trajectories of
length 1. Note that steps 1,3 and 4 are straightforward; to im-
plement a solver, we need some mechanism for determining
the set of shortest paths from Îº to Ï†âˆ’1(A).

5.3 Translation to Answer Set Programming
Answer set planning refers to the approach to planning in
which a problem is translated into an extended logic program
where the answer sets correspond to plans [Lifschitz, 1999].
Many action languages have been translated into logic pro-
gramming for answer set planning. We demonstrate how one
existing translation can be modiï¬ed for our purposes.

We need a translation from A into logic programming. Our
translation is obtained by modifying a well known translation
from C [Lifschitz and Turner, 1999]. Let AD be an action
description in the action language A. For any natural number
n, we deï¬ne an associated logic program Ï„n(AD) with the
property that answer sets for Ï„n(AD) correspond to paths of
length n in the transition relation described by AD. The lan-
guage of Ï„n(AD) consists of two disjoint classes of atoms,
deï¬ned as follows. For each i â‰¤ n and each f âˆˆ F, the lan-
guage of Ï„n(AD) contains an atom f (i). For each i < n and
each A âˆˆ A, the language of Ï„n(AD) contains an atom A(i).
The logic program Ï„n(AD) consists of the following rules:

1. for every proposition in AD of the form

A causes (Â¬)f if g1 âˆ§ Â· Â· Â· âˆ§ gp

$
%

for each i < n, Ï„n(AD) contains the rules

(Â¬)f (i + 1) â† A(i), g1(i), . . . , gp(i)

2. if B is either an action atom or B is f (0) for some f âˆˆ

F, then Ï„n(AD) contains the rules

Â¬B â† not B
B â† not Â¬B

3. for every f âˆˆ F and i < n, Ï„n(AD) contains
f (i + 1) â† not Â¬f (i + 1), f (i)
Â¬f (i + 1) â† not f (i + 1), Â¬f (i)

4. for every i < n, and every pair of distinct action symbols

A1, A2, Ï„n(AD) contains the rules

Â¬A1(i) â† A2(i).

The ï¬rst two sets of rules are taken directly from Lifschitz and
Turnerâ€™s translation of C[Lifschitz and Turner, 1999]. Rule
(3) states that all ï¬‚uents are inertial, and (4) states that at most
one action occurs at each point in time.
Proposition 5 A complete set X is an answer set for Ï„n(AD)
if and only if it has the form

n(cid:2)

{f (i) | f âˆˆ si} âˆª

nâˆ’1(cid:2)

{A(i) | A = Ai}

i=0

i=0

for some path (cid:2)s0, A0, s1, . . . , Anâˆ’1, sn(cid:3) in the transition re-
lation described by AD.
Hence every answer set for Ï„n(AD) corresponds to a path in
the transition relation.

For the purpose of planning, it is useful to add a few rules
to Ï„n(AD) that restrict the admissible answer sets. Let K be
the conjunction of literals k1 âˆ§ Â· Â· Â·âˆ§ kp. Deï¬ne Ï„n(AD, K) to
be the logic program obtained by adding the following rules
to Ï„n(AD): k1(0), . . . , kp(0). It is easy to see that the an-
swer sets for Ï„n(AD, K) correspond to all paths of length n
which start in a state where K is true. We are interested in
using answer sets to solve |K| â—¦ (cid:2)A, f (cid:3), where â—¦ is given by
the projection operator and the topological revision operator
deï¬ned by AD.

To simplify the discussion, we assume that, for each A,
the action description AD contains at most one proposition
in AD of the form

A causes f if g1 âˆ§ Â· Â· Â· âˆ§ gp.

If such a proposition exists for the action A, then deï¬ne
PRE (A, f ) = g1 âˆ§Â· Â· Â·âˆ§gp. Otherwise, deï¬ne PRE (A, f ) =
âŠ¥.
Proposition 6 If s âˆˆ S, f âˆˆ Lits, and A âˆˆ A, then

s (cid:10) A |= f â‡â‡’ s |= PRE (A, f ) âˆ¨ (f âˆ§ PRE (A, Â¬f ).

It follows that f âˆ’1(A) = |PRE (A, f )âˆ¨(f âˆ§ PRE (A, Â¬f ))|.
We are now in a position to give a basic procedure for the
implementation of a belief evolution solver. Given K, A, and
f , deï¬ne evol(K, A, f ) to be the pair of belief states returned
by the following procedure.

IJCAI-07

2502

1. Set n = 1.
2. Determine all answer sets for Ï„n(AD, K).
3. Let P AT H be the corresponding set of paths.

4. Remove from P AT H every path where the ï¬nal state

fails to satisfy PRE (A, f ) âˆ¨ (f âˆ§ PRE (A, Â¬f ).
(a) If P AT H = âˆ…, set n = n + 1 and goto 2.
(b) If P AT H (cid:13)= âˆ…, then continue.

5. Let Îº0 denote the set of ï¬nal states in P AT H.
6. Let Îº1 = {s (cid:10) A | s âˆˆ Îº0}.
7. Return (cid:2)Îº0, Îº1(cid:3).

Proposition 7 If K is a conjunction of literals, A âˆˆ A and
f âˆˆ Lits, then evol(K, A, f ) = |K| â—¦ (cid:2)A, f (cid:3).

Following the given approach, there are two computational
problems to be solved. First, we need to ï¬nd all answer sets
for a given logic program at step 2; this can be accomplished
by using an existing answer set solver such as smodels or
DLV. The second computational task involves checking if
each ï¬nal state entails f âˆ’1(A).

Solving |K|â—¦(cid:2)A, f (cid:3) allows us to solve projection problems
for a restricted class of action descriptions in AB . In particu-
lar, let AD be an action description where the precondition of
every sensing proposition is empty and the effect is a literal
f . In this case,

Î¦AD((cid:2)s, |K|(cid:3), (cid:2)A, O(cid:3)) = (cid:2)s (cid:10) A, |K| â—¦ (cid:2)A, f (cid:3)(cid:3).

The actual state can be computed by the standard translation
from A into logic programming, and the belief state can be
computed as above.

We have a prototype implementation of the solver outlined
in this section. The present version of the solver implements
our algorithm in a straightforward manner, using smodels
to determine the answer sets at step 2. In fact, the solver is
slightly more powerful than the approach that we have out-
lined, because it allows sensing effects to be represented by
an arbitrary formula rather than a single literal. We have only
restricted attention to literal sensing effects in the present pa-
per to simplify the presentation. We are currently working
on extending the solver to deal with multiple observations,
which introduces new complications if the observations are
inconsistent. When completed, our solver will join the FLUX
solver for the Fluent Calculus on a short list of implemented
tools for solving problems involving iterated belief change
caused by actions.

6 Discussion

Reasoning about iterated belief change caused by action re-
quires more than an action formalism supplemented with a
revision operator. The interpretation of a sensing action may
depend on the preceding ontic actions, so action formalisms
incorporating sensing actions need to deï¬ne belief change in
a manner that considers the entire action history.

We have considered an approach to the representation of it-
erated belief change in an action formalism by extending the
action language A with sensing actions. Our extension dif-
fers from existing extensions in that we allow agents to have

erroneous beliefs. Moreover, by deï¬ning the semantics in
terms of belief evolution operators, we are able to respect the
non-elementary interaction between ontic actions and sensing
actions. To solve belief change problems in our action lan-
guage, we presented a procedure for automating the solution
of belief evolution problems through answer set planning.

In future work, we would like to extend the language to
permit a wider range of sensing effects.
In particular, we
would like to be able to reason about the beliefs of multiple
agents performing actions that affect each agentâ€™s beliefs in
a different manner. Action domains of this form can be rep-
resented by allowing formulas of modal doxastic logic to be
the effects of actions. The semantics of such formulas can be
deï¬ned with respect to multi-agent belief structures [Herzig
et al., 2004]. We are currently working on a multi-agent ex-
tension based on modal logic.

References
[AlchourrÂ´on et al., 1985] C.E. AlchourrÂ´on, P. G ardenfors,
and D. Makinson. On the logic of theory change: Par-
tial meet functions for contraction and revision. Journal of
Symbolic Logic, 50(2):510â€“530, 1985.

[Dalal, 1988] M. Dalal.

knowledge base revision.
pages 475â€“479, 1988.

Investigations into a theory of
In Proceedings of AAAI88,

[Gelfond and Lifschitz, 1993] M. Gelfond and V. Lifschitz.
Representing action and change by logic programs. Jour-
nal of Logic Programming, 17:301â€“321, 1993.

[Herzig et al., 2004] A. Herzig, J. Lang, and P. Marquis. Re-
vision and update in multi-agent belief structures. In Pro-
ceedings of LOFT 6, 2004.

[Hunter and Delgrande, 2005] A. Hunter and J.P. Delgrande.
Iterated belief change: A transition system approach. In
Proceedings of IJCAI05, pages 460â€“465, 2005.

[Jin and Thielscher, 2004] Y. Jin and M. Thielscher. Repre-
In Proceedings of

senting beliefs in the ï¬‚uent calculus.
ECAI04, pages 823â€“827, 2004.

[Lifschitz and Turner, 1999] V. Lifschitz and H. Turner.
In

Representing transition systems by logic programs.
Proceedings of LPNMR99, pages 92â€“106, 1999.

[Lifschitz, 1999] V. Lifschitz. Action languages, answer sets
and planning. In K.R. Apt, V.W. Marek, M. Truszczyn-
ski, and D.S. Warren, editors, The Logic Program-
ming Paradigm: A 25-Year Perspective, pages 357â€“373.
Springer-Verlag, 1999.

[Lobo et al., 2001] J Lobo, G. Mendez, and S.R. Taylor.
Knowledge and the action description language A. Theory
and Practice of Logic Programming, 1(2):129â€“184, 2001.
[Shapiro et al., 2000] S. Shapiro, M. Pagnucco, Y. Lesper-
ance, and H.J. Levesque. Iterated belief change in the situ-
ation calculus. In Proceedings of KR 2000, pages 527â€“538.
Morgan Kaufmann Publishers, 2000.

[Son and Baral, 2001] T. Son and C. Baral. Formalizing
sensing actions: A transition function based approach. Ar-
tiï¬cial Intelligence, 125(1-2):19â€“91, 2001.

IJCAI-07

2503


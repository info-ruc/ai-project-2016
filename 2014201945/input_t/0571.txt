                                 Complete MCS-Based Search:
                Application to Resource Constrained Project Scheduling

                                           Philippe Laborie
                                                 ILOG
                            9, rue de Verdun, 94253 Gentilly Cedex, France
                                            plaborie@ilog.fr

                    Abstract                            In this article, we present a pure constraint programming
                                                      approach based on the exploration of a complete search tree to
    This paper describes a simple complete search for prove that the project cannot be achieved within a given dead-
    cumulative scheduling based on the detection and  line or to exhibit a feasible project if one exists. The search
    resolution of minimal critical sets (MCS). The    procedure is based on the detection and resolution of minimal
    heuristic for selecting MCSs relies on an estima- critical sets (MCS) [Laborie and Ghallab, 1995] at each node
    tion of the related reduction of the search space. of the search. MCSs are carefully chosen using a heuristic
    An extension of the search procedure using self-  that tries to minimize the size of the search space. During
    adapting shaving is proposed. The approach was    the search, strong constraint propagation is enforced using
    implemented on top of classical constraint propaga- classical scheduling constraint propagation techniques such
    tion algorithms and tested on resource constrained as time-tabling, edge-Ô¨Ånding, precedence energy and balance
    project scheduling problems (RCPSP). We were      constraints [Laborie, 2003].
    able to close more than 15% of the previously open  Next section recap the deÔ¨Ånition of the resource con-
    problems of the PSPLIB [Kolisch and Sprecher,     strained project scheduling problem and introduces some no-
    1996] and improve more than 31%  of the best      tations. Section 3 describes our basic search procedure as
    known lower bounds on those heavily studied prob- well as the heuristic to select MCSs. Section 4 extends the
    lems. Other new results on open-shop and cumula-  basic search procedure to perform self-adapting shaving. The
    tive job-shop scheduling are reported.            last part of the paper consists of experimental results on clas-
                                                      sical benchmarks (general RCPSP, open-shop and cumulative
                                                      jobshop problems). For general RCPSP, we show that our ap-
1  Introduction                                       proach closes more than 15% of previously open instances
The  resource constrained project scheduling problem  and improves more than 31% of best known lower bounds of
                                                                                [                       ]
(RCPSP) is one of the most general scheduling problem that the famous PSPLIB instances Kolisch and Sprecher, 1996 .
is extensively studied in the literature. It consists in schedul- The same approach using exactely the same settings was used
                                                                                          [
ing a project, which is a set of activities linked with prece- to close all the hard open-shop instances of Gueret¬¥ and Prins,
                                                          ]
dence constraints, by means of a set of limited resources 1999 in less than 5s CPU time and to improve the best known
while minimizing the total duration of the project. The de- lower bounds and close several instances of cumulative job-
                                                           [           ]
cision variant of the RCPSP, i.e., the problem of determining shop Nuijten, 1996 .
whether there exists a feasible project of makespan smaller
than a given deadline, is NP-hard in the strong sense. The 2 Model and notations
RCPSP is a very popular and frequently studied NP-hard op- The resource constrained project scheduling problem
timization problem and the last 20 years have witnessed a (RCPSP) can be formally stated as follows. A project is
tremendous improvement of both heuristic and exact solu- made of a set of activities A linked by precedence con-
tion procedures (cf. e.g. the recent surveys given in [De- straints. Precedence constraints can be represented by a di-
meulemeester and Herroelen, 2002; Hartmann and Kolisch, rected acyclic graph G = (A, E) where each node in A rep-
2005]). The currently best lower bounds on the makespan resents an activity and each arc (A, B) ‚àà E represents a
for the general RCPSP are based on solving linear programs precedence constraint between A and B. Let d(A) denote
using adequate cutting planes [Brucker and Knust, 2000; the Ô¨Åxed duration of activity A ‚àà A and s(A) (resp. e(A))
Baptiste and Demassey, 2004]. State-of-the-art techniques denote the decision variable representing the start (resp. end)
for upper-bounds rely on meta-heuristics such as Genetic Al- time of activity A. A set of discrete capacity resources R is
gorithms, Ant Colony Optimization or Large Neighborhood considered, each resource R ‚àà R having a maximal avail-
Search. Many scheduling problems such as job shop, cumula- able capacity Q(R) over the entire scheduling horizon. Each
tive job shop and open-shop can be modeled as special cases activity A ‚àà A requires a non-negative quantity q(A, R) of
of RCPSP.                                             resource R. The problem is to Ô¨Ånd a feasible instantiation sof the activity start times such that precedence and resource DeÔ¨Ånition 2 (Resolvers of a minimal critical set) If œÜ ‚äÜ
constraints are satisÔ¨Åed and the schedule makespan is mini- U(R) is a MCS, we call resolvers of œÜ the set of temporal
mal. More formally:                                   constraints Res(œÜ) = {u  v : (u, v) ‚àà œÜ2, u 6= v}.
             minimize    max e(A)                       As described in [Laborie and Ghallab, 1995], the set of re-
                         A‚ààA                          solvers Res(œÜ) of a MCS œÜ can be simpliÔ¨Åed so as to remove
           subject to :                               those resolvers œÅ ‚àà Res(œÜ) for which there exists another
                                                               0                         0
             ‚àÄA  ‚àà A,    0 ‚â§ s(A)                     resolver œÅ ‚àà Res(œÜ) such that œÅ ‚áí œÅ given the current
                                                      temporal network. Indeed, in such case, the resolver œÅ is re-
                         e(A) = s(A) + d(A)
                                                      dundant. Such a simpliÔ¨Åcation procedure can be achieved in
          ‚àÄ(A, B) ‚àà E,   e(A) ‚â§ s(B)                  O(k3) if k is the size of the MCS using the naive Algorithm
                          X
     ‚àÄR ‚àà R, ‚àÄt ‚àà Z+,          q(A, R) ‚â§ Q(R)         1. Line 7 allows removing resolver u  v if there exists w
                                                      such that u  v ‚áí u  w or u  v ‚áí w  v. In what fol-
                         A‚ààS(t)
                                                      lows, we assume that the set of resolvers of a MCS has been
  where S(t) is the set of activities executing at time t: simpliÔ¨Åed.

          S(t) = {A ‚àà A, s(A) ‚â§ t < e(A)}             Algorithm 1 Resolver simpliÔ¨Åcation algorithm
  A resource requirement of activity A on resource R is a 1: procedure SIMPLIFY RESOLVERS(œÜ)
triple u = (A, R, q) where q = q(A, R) > 0. If u =     2:    Res(œÜ) ‚Üê ‚àÖ
(A, R, q) is a resource requirement, we will denote A(u) = A 3: for all u in œÜ do
the activity of u, R(u) = R the required resource, q(u) = q 4:  for all v in œÜ \ {u} do
the required quantity, s(u) (resp. e(u)) will denote the start 5:  keep uv ‚Üê TRUE
(resp. end) time of the activity of u. We will also denote 6:      for all w in œÜ \ {u, v} do
U(R) =  {u/R(u) =   R} the set of resource requirements 7:            if s(v)  s(w) or e(w)  e(u) then
on resource R. If œï ‚äÜ U(R) is a subset of resource require- 8:           keep uv ‚Üê  FALSE
                                         P             9:                break
ments on a resource R, we will denote q(œï) = u‚ààœï q(u)
the global resource consumption of R by activities in œï. 10:       if keep uv then
                                                      11:             Res(œÜ) ‚Üê  Res(œÜ) ‚à™ (u  v)
3  Search                                             12:    return Res(œÜ)
3.1  Branching scheme                                   At each search node, our branching scheme consists in se-
Our branching scheme assumes that a temporal network rep- lecting a MCS œÜ and branching on its possible resolvers in
resenting the relations between the time-points of all activ- the children nodes until there is no more MCS. This approach
ities (start and end) using the point algebra of [Vilain and is clearly complete.
Kautz, 1986] is maintained during the search. In our im-
plementation, this is ensured by the precedence graph con- 3.2 Heuristics
straint of ILOG SCHEDULER  [ILOG, 2005]. We denote    As all the resolvers consist of temporal constraints of the form
{‚àÖ, ‚â∫, , =, , , 6=, ?} the set of qualitative relations be- x  y where x and y are two time-points (start or end of an
tween time points. If u and v represent two resource require- activity), we are interested in an estimation of the size of the
ments, we will denote u  v if and only if e(u)  s(v). search space after posting such a precedence constraint. The
  The branching scheme relies on the notion of minimal crit- fraction of the search space that is preserved when adding a
ical sets (MCS) and their resolvers as introduced in [Laborie precedence constraint is estimated using the complementary
and Ghallab, 1995]. A MCS is a minimal set of resource re- of the commitment measure introduced in [Laborie, 2003].
quirements on the same resource R that could be executed si- Let x and y be two time-points with respective lower and
multaneously and would, in this case, over-consume resource upper bound for time value: [xmin, xmax] and [ymin, ymax].
R. MCSs are a natural generalization to cumulative schedul- The size of the search space is estimated by the Cartesian
ing of the pairs of activities conÔ¨Çicting for the same unary product of the domain of the two variables, that is, the area
resource in disjunctive scheduling.                   of the rectangle [xmin, xmax], [ymin, ymax]. The size of the
DeÔ¨Ånition 1 (Minimal critical set) A minimal critical set on search space that is preserved when adding the constraint
a resource R is a subset œÜ ‚äÜ U(R), such that:         x   y is the part of that rectangle above the line x = y as
                                                      illustrated in Figure 1. The fraction of the search space that is
 1. Q(R) < q(œÜ)                                       preserved can thus be estimated as follows. Let:
 2. ‚àÄœï ( œÜ, q(œï) ‚â§ Q(R)
                                                             A = (ymax ‚àí ymin + 1)(xmax ‚àí xmin + 1)
 3. V         s(u) ‚â∫ e(v) is consistent with the current
      (u,v)‚ààœÜ√óœÜ                                              B = (y    ‚àí x    + 1)(y   ‚àí x    + 2)
    temporal network                                               max    min      max     min
                                                         C     = max(0, (y   ‚àí x   )(y    ‚àí x    + 1))
  Informally, the different ways to resolve a minimal critical min       min    min   min    min
set consist in posting a precedence constraint between any Cmax = max(0, (ymax ‚àí xmax)(ymax ‚àí xmax + 1))
two of its activities.                                  The fraction is then equal to:                y              x=y                    is the preserved search space so far in the current (partial)
             y
             max                                      MCS;  œÜ‚àó is the best MCS so far and p‚àó = preserved(œÜ‚àó) is
                               Preserved
                               search                 the preserved search space of the best MCS so far. The pro-
                               space                  cedure at line 1 calls the MCS rating and selection process
                                                      on each resource. At line 6, to rate and select MCSs for a
             ymin                                     given resource, the procedure Ô¨Årst sorts the relevant sets of
                                                      requirements v at lines 7 and 9 by decreasing order of q(v),
                                                      using id(v) to break ties in order to ensure that each MCS is
                                  x                   scanned only once, starting with the smallest MCSs, that is,
                 x           x
                 min         max                      the ones containing the most greedy requirements. The pro-
   Figure 1: Preserved search space when adding x  y cedure at line 23 returns TRUE if and only if a given require-
                                                      ment u can possibly overlap all the requirements of a partial
                                                      MCS given the current temporal network. The procedure at
                                                      line 28 computes the incremental increase of preserved space
                          B ‚àí C    ‚àí  C               due to the insertion of a new requirement u in the current
       preserved(x  y) =       min    max            MCS  œÜ. The value of preserved has been described in sec-
                                2 ¬∑ A                 tion 3.2. The main recursive function for selecting MCSs is
  In the example of Figure 1, this gives A = 30, B = 56, described at line 12.
Cmin = 6, Cmax = 2, and preserved(x  y) = 24/30.
  If œâ is the size of the search space below the current search Algorithm 2 MCS selection algorithm
node, the size of the search space after posting a temporal
                                                       1: procedure SELECT  MCS
constraint x  y can be estimated by œâ ¬∑ preserved(x  y).
                                                       2:    p‚àó ‚Üê +‚àû
If œÜ is the MCS that is selected to be resolved at the cur-
                                                       3:    for R in R do
rent search node, the size of the search space to explore be-
                                                       4:       SELECT  MCS(R)
low the current node can thus be estimated as the sum of
                                                       5:    return œÜ‚àó
the sizes of the search space below each child node, that is:
   P
œâ ¬∑  œÅ‚ààRes(œÜ) preserved(œÅ). Therefore, preserved(œÜ) =
P                                                      6: procedure SELECT  MCS(R)
  œÅ‚ààRes(œÜ) preserved(œÅ) estimates the fraction of the search 7: Sort U(R) by decreasing q
space that is preserved when choosing œÜ as the next MCS to 8: for all u in U(R) do
solve1. Our heuristic simply chooses to resolve next the MCS 9: Sort Unranked(u) by decreasing q
œÜ that minimizes preserved(œÜ) that is, the one that mini- 10: for u in U(R) do
mizes our estimation of the size of the explored search space. 11: RSELECT MCS(R,(u),q(u),0)
Next section provides more details about the MCS selection
algorithm.                                            12: procedure RSELECT   MCS(R,œÜ,q,p)
                                                      13:    if q > Q(R) then                 . œÜ is a MCS
3.3  MCS selection algorithm                          14:       if p < p‚àó then     . œÜ is the best MCS so far
At each search node, the MCS selection procedure develops 15:      p‚àó ‚Üê p
a tree of partial MCSs where the current partial MCS œÜ is 16:      œÜ‚àó ‚Üê œÜ
extended adding one resource requirement in each child node. 17: else               . œÜ needs to be extended
By deÔ¨Ånition of preserved(œÜ), it is clear that œÜ0 ‚äÇ œÜ ‚áí 18:     u ‚Üê Last(œÜ)
preserved(œÜ0) ‚â§ preserved(œÜ). Thus, if œÜ‚àó is the best MCS 19:   for all v in Unranked(u) do
found so far, once a partial MCS œÜ has been reached such that 20:  if IS UNRANKED(v,œÜ)  then
preserved(œÜ‚àó) ‚â§ preserved(œÜ), the sub-tree of the MCS 21:             dp ‚Üê DELTA   PRESERVED(v,œÜ)
selection tree rooted at œÜ can be abandoned.          22:             RSELECT   MCS(R,œÜ‚äïv,q+q(v),p+dp)
  The algorithm for selecting and branching on a MCS is
more precisely described in Algorithm 2 using the following 23: procedure IS UNRANKED(u,œÜ)
notations: id(u) is a unique index associated with resource 24: for all v in œÜ do
requirement u used to break ties. Unranked(u) represents 25:    if u  v or v  u then
all the resource requirements v that can possibly overlap u 26:    return FALSE
given the current temporal constraints, and that are such that 27: return TRUE
q(v) <  q(u) or q(v) = q(u) and id(v) < id(u). œÜ is
the (partial) MCS that is currently being extended. A (par- 28: procedure DELTA PRESERVED(u,œÜ)
tial) MCS is represented by a list of resource requirements: 29: dp ‚Üê 0
œÜ = (u1, ..., uk). We denote uk = Last(œÜ) and deÔ¨Åne the 30:  for all v in œÜ do
operator ‚äï as follows: œÜ‚äïu = (u1, ..., uk, u); q = q(œÜ) is the 31: dp ‚Üê dp + preserved(u,v) + preserved(v,u)
consumption of the current (partial) MCS; p = preserved(œÜ) 32: return dp

  1Note that this is of course only a rough estimate and in particu-
lar, the estimated fraction preserved(œÜ) can be greater than 1. The best MCS œÜ‚àó that has been scanned by the above pro-cedure is selected as the one to be solved at the current search self-adaptation in such a way that on average, among the last
node. This MCS is simpliÔ¨Åed using Algorithm 1 and the h shaving attempts, Œ±h lead to the inference of a new prece-
search explores all of its resolvers œÅ ‚àà Res(œÜ‚àó) in the child dence. Whenever the number of successful shaving s among
nodes by decreasing order of preserved(œÅ). This order has the last h ones deviates from Œ±h, the parameter Œ≤ is adapted
no effect when the schedule is not feasible as in this case the accordingly: if s < Œ±h, Œ≤ is decreased by Œ≤ and if s > Œ±h,
complete search tree needs to be explored but it helps Ô¨Ånding Œ≤ is increased by Œ≤. For all our experiments with shaving,
a solution quicker when a solution exists.            we took h = 20, Œ± = 0.75,  = 0.01 and start with Œ≤ = 1.

4  Self-adapting shaving                              5   Experimental evaluation
Shaving techniques [Torres and Lopez, 2000] provide a The approach has been implemented on top of ILOG
good framework for strengthening constraint propagation and SCHEDULER 6.1 using the timetable, disjunctive, edge-
avoiding late failures to be discovered in the search tree. They Ô¨Ånder, precedence energy and balance constraints [ILOG,
are all based on the following principle: if adding a constraint 2005]. All the experiments described in this section were
C in the current node of the search leads to a failure of the run on a Dell Latitude D600 laptop, 1.4 GHz. Detailed
propagation, then, constraint ¬¨C can be inferred. Due to the results such as individual lower bounds for each prob-
cost of propagating a constraint C and the potential number lem instance and new optimal solutions are available at
of constraints C to try to shave on, shaving techniques are in http://scheduler.ilog.fr/.
general computationally expensive.
  To improve the pruning of the search tree, we implemented 5.1 Results on general RCPSP
the following shaving technique based on MCSs. If a MCS We evaluated our approach on the instances of the PSPLIB
œÜ with resolvers Res(œÜ) = {œÅ1, ..., œÅk, œÅk+1} is such that [Kolisch and Sprecher, 1996] with 60, 90 and 120 activities
‚àÄi ‚àà  [1..k], adding œÅi in the current schedule leads to a (resp. sets J60, J90, J120). For each instance, we solve the
failure of the propagation, then œÅk+1 can be inferred. The feasibility problem of Ô¨Ånding a schedule with a makespan
complexity for shaving a given MCS œÜ of size n is thus in lower than T , starting with a legal lower bound for T 3 and
O(n2P ) where P is the cost of full constraint propagation incrementing T until either the problem is shown to be feasi-
at the current node. Potentially, there is of course an ex- ble (in this case, T is the optimal makespan) or a given time
ponential number of MCSs to shave on at each search node limit for solving the problem with makespan T is exceeded
and we can expect that many of those MCS do not allow in- (in this case, T is a legal lower-bound but the search stops
ferring any precedence constraint. An idea to speed-up the without providing any legal upper-bound).
shaving process is thus to only try shaving on a subset of In a Ô¨Årst series of experiments, we use the basic search de-
MCSs for which the probability to infer a precedence con- scribed in section 3 without shaving with a time limit of 300s.
straint is greater than a given threshold Œ±. Parameter Œ± is The previous best lower and upper bounds we compare with
an input of the shaving algorithm. We can roughly esti- are the ones reported in the PSPLIB together with the recent
mate that the probability that adding a precedence constraint improvements on the J60 instances reported in [Baptiste and
x   y in the current schedule will lead to a failure of the Demassey, 2004]. The results are summarized on Table 1
propagation is proportional2 to 1 ‚àí preserved(x  y). If with the following columns:
œÅm  = argmaxœÅ‚ààRes(œÜ)preserved(œÅ) is the resolver of the
MCS  œÜ with maximal preserved search space, we are inter- #O : number of instances previously open
ested in the MCSs that get a high probability that all their re- #I : number of improved lower bounds (% of #O)
solvers but œÅm will fail, that is, if we assume all the probabil- AGR: average gap (distance from the lower to the upper

ities are independent, the ones such that Œ†œÅ‚ààRes(œÜ)\{œÅm}(1 ‚àí   bound) reduction when a bound is improved
preserved(œÅ)) is greater than a given threshold. For those #C : number of closed instances (% of #O)
MCSs, if the threshold is close enough to 1, we can as-
sume that preserved(œÅ) is small enough so that the Ô¨Årst or-  Inst. #O   #I    (%I)  AGR  #C    (%C)
                                                             J60   98   39  (39.8%) 62.9% 21 (21.4%)
der approximation Œ†œÅ‚ààRes(œÜ)\{œÅm}(1 ‚àí preserved(œÅ)) ‚âà
1 ‚àí P             preserved(œÅ) is reasonable.                J90  129   51  (39.5%) 58.4% 26 (20.2%)
      œÅ‚ààRes(œÜ)\{œÅm}                                          J120 390   88  (22.6%) 47.0% 38  (9.7%)
  To summarize, we thus only consider for shaving those      ALL  617  178  (28.8%) 53.0% 85 (13.8%)
MCS scanned by the procedure described in Algorithm 2 that
are such that preserved(œÜ) ‚àí preserved(œÅm) ‚â§ Œ≤, Œ≤ be- Table 1: Results on RCPSP without self-adapting shaving
ing a threshold. The computation of this criterion only adds with a time-limit of 300s
a negligible overhead related with the maintenance of œÅm for
each MCS in the MCS selection procedure. Due to the nu- Out of the 617 previously open instances, we are able to
merous approximations, Œ≤ is not taken to be constant (theo- improve 178 lower-bounds with an average gap reduction of
retically equal to 1 ‚àí Œ±). The threshold Œ≤ is computed by 53% and to close 85 instances.
                                                        To show the effect of self-adapting shaving, we run a ver-
  2Note that this estimation is exact at the extreme points when sion of our approach using self-adapting shaving with the
preserved(x  y) = 0 (propagation will fail for sure) and when
preserved(x  y) = 1 (propagation cannot fail because x  y has 3For instance the lower-bound of the PERT of temporal con-
already been discovered given the current domains of x and y). straints       Inst. #O   #I   (%I)  AGR   #C   (%C)                 Inst. #O   #I    (%I)  AGR  #C    (%C)
       J60   98  40  (40.8%) 62.6% 22  (22.4%)               J60   98   44  (44.9%) 72.4% 26 (26.5%)
       J90  129  52  (40.3%) 58.3% 26  (20.2%)               J90  129   54  (41.9%) 66.0% 30 (23.3%)
       J120 390  90  (23.1%) 47.3% 38   (9.7%)               J120 390   95  (24.4%) 48.1% 40 (10.3%)
       ALL  617  182 (29.5%) 53.1% 86  (13.9%)               ALL  617  193  (31.3%) 61.1% 96 (15.6%)

Table 2: Results on RCPSP with a self-adapting shaving and Table 3: Results on RCPSP with a self-adapting shaving and
a time-limit of 300s                                  a time-limit of 1800s

same time-limit of 300s. The results are summarized on Ta-   Instance UB  Optim. Instance UB  Optim.
                                                             gp06-03 1255 1255*  gp09-02 1112 1110*
ble 2. Out of the 617 previously open instances, we are able gp06-07 1290 1290*  gp09-03 1117 1115*
to improve 182 lower-bounds with an average gap reduction    gp06-09 1243 1243*  gp09-06 1093 1093*
of 53.1% and to close 86 instances. The main conclusion is   gp06-10 1254 1254*  gp09-07 1097 1090*
                                                             gp07-01 1159 1159*  gp09-08 1106 1105*
that, within the same time-limit, the addition of self-adapting gp07-02 1185 1185* gp09-09 1126 1123*
shaving slightly increases the performances. The two curves  gp07-04 1167 1167*  gp09-10 1120 1110*
below respectively show, on a particular instance (J60 5 2), gp07-06 1193 1193*  gp10-01 1099 1093*
the number of search nodes with a given depth in the search  gp07-08 1180 1180*  gp10-02 1099 1097*
                                                             gp07-09 1220 1220*  gp10-03 1081 1081*
tree and, for each node depth, the ratio between the number  gp08-02 1135 1135*  gp10-04 1089 1077*
of selected MCSs that effectively lead to the inference of a gp08-04 1154 1153*  gp10-05 1080 1071*
new precedence and the total number of MCSs selected for     gp08-06 1116 1115*  gp10-06 1072 1071*
                                                             gp08-07 1126 1126*  gp10-07 1081 1079*
shaving. One clearly see that in the region of the search space gp08-08 1148 1148* gp10-08 1098 1093*
where most of the nodes are concentrated (between depths     gp08-10 1161 1161*  gp10-09 1120 1112*
10 and 35), this ratio is effectively close to the target ratio gp09-01 1135 1129* gp10-10 1092 1092*
of 0.75. In this instance, 4667 nodes where explored, 4843
MCSs where selected for shaving and among them, 3291 ef- Table 4: Results on open-shop with a self-adapting shaving
fectively lead to the inference of a new precedence.  and a time-limit of 5s
    350
    300                                               approach, with the same settings as in previous section on
    250                                               the open-shop problems instances proposed in [Gueret¬¥ and
    200                                               Prins, 1999]. Those instances are considered to be very
    150                                               hard instances of open-shop problems and serve as classi-
    100                                               cal benchmark in open-shop scheduling (see for instance re-
     50         Number of nodes                       cent work in [Blum, 2005]). The benchmark consists of 80
      0
       0    5   10  15   20  25   30  35   40         instances ranging from 3 jobs √ó 3 machines problems until
                                                      10 jobs √ó 10 machines problems. Out of these 80 problems,
                    Search depth                      34 instances are still open. Using our approach, we were able
      1                                               to close all those instances in less than 5s CPU time. The op-
    0.8                                               timal makespan for the 34 previously open instances is sum-
                                                      marized on Table 4 where the column UB corresponds to the
    0.6                                               currently best known upper-bound for which no optimality
    0.4                                               proof did exist.
                 Actual shaving ratio
    0.2          Target shaving ratio                   We also experimented with the open instances of the
      0                                               benchmark of [Brucker et al., 1997]. We closed 3 of
       0    5   10  15   20  25   30  35   40         these 6 open instances: namely j8-per0-2    (optimal
                                                      makespan: 1052), j8-per10-0  (optimal makespan 1017)
                    Search depth
                                                      and j8-per10-1   (optimal makespan 1000).
  Given that self-adapting shaving slightly improves the per-
formances within the same time limit of 300s, we used this 5.3 Results on cumulative jobshop problems
conÔ¨Åguration with an extended time-limit of 1800s. The re-
sults are summarized on Table 3. Out of the 617 previously We tested our approach, with the same settings, on the cu-
open instances, we improve 193 lower-bounds (that is more mulative job-shop problem benchmark described in [Nuijten,
than 31% of the previously open instances) with an average 1996]. These instances are derived from classical jobshop
gap reduction of 61.1% and close 96 instances (that is more scheduling problems by multiplying the number of jobs (and
than 15% of the previously open instances).           thus the number of activities) and the capacity of the re-
                                                      sources by a given factor (√ó2 or √ó3). Our results are summa-
5.2  Results on open-shop problems                    rized on Table 5 where LB is the lower bound using the con-
Open-shop problems can be represented as a special cases sistency checking described in [Nuijten, 1996] and NewLB
of RCPSP where all resources have a unit capacity and ad- the new lower bound of our approach. We were able to close
ditional unary resources are used to model the fact that ac- the ft06√ó2 and ft06√ó3 instances as well as to improve
tivities of the same job cannot not overlap. We tested our 12 lower bounds out of these 38 open instances.
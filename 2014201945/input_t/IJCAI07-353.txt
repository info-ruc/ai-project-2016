                                            Loopy SAM

                      Ananth Ranganathan, Michael Kaess, and Frank Dellaert
                  Center for Robotics and Intelligent Machines, College of Computing
                                    Georgia Institute of Technology
                                 {ananth,kaess,dellaert}@cc.gatech.edu

                    Abstract
    Smoothing approaches to the Simultaneous Local-
    ization and Mapping (SLAM) problem in robotics
    are superior to the more common Ô¨Åltering ap-
    proaches in being exact, better equipped to deal
    with non-linearities, and computing the entire robot
    trajectory. However, while Ô¨Åltering algorithms that
    perform map updates in constant time exist, no
    analogous smoothing method is available. We aim
    to rectify this situation by presenting a smoothing-
    based solution to SLAM using Loopy Belief Prop-   Figure 1: The Gaussian Markov Random Field (GMRF) correspond-
    agation (LBP) that can perform the trajectory and ing to an illustrative Smoothing and Mapping (SAM) problem with
    map updates in constant time except when a loop   30 poses in the robot trajectory. Poses in the graph are shown as
    is closed in the environment. The SLAM prob-      circles and landmarks as squares.
    lem is represented as a Gaussian Markov Ran-
    dom Field (GMRF) over which LBP is performed.
                                                      repeated marginalization of poses, recently introduced tech-
    We prove that LBP, in this case, is equivalent to
                                                      niques such as the Sparse Extended Information Filter (SEIF)
    Gauss-Seidel relaxation of a linear system. The in-
                                                      [Thrun et al., 2004] and the Thin Junction Tree Filter (TJTF)
    ability to compute marginal covariances efÔ¨Åciently
                                                      [Paskin, 2003] present approximations to keep the informa-
    in a smoothing algorithm has previously been a
                                                      tion matrix sparse. The sparsity of the representation allows
    stumbling block to their widespread use. LBP
                                                      for a constant time update of the Ô¨Ålter.
    enables the efÔ¨Åcient recovery of the marginal co-
    variances, albeit approximately, of landmarks and   In contrast to the above Ô¨Åltering approaches which only
    poses. While the Ô¨Ånal covariances are overconÔ¨Å-   compute the current robot pose with the map, a smoothing
    dent, the ones obtained from a spanning tree of the approach recovers the complete robot trajectory and the map.
    GMRF are conservative, making them useful for     The smoothing information matrix naturally stays sparse over
    data association. Experiments in simulation and us- time without the need for any approximations. Further,
    ing real data are presented.                      smoothing can incorporate new information about past robot
                                                      poses as opposed to Ô¨Åltering approaches that cannot update
                                                      a pose after it has been marginalized out. Even though the
1  Introduction                                       number of variables increases continuously for smoothing, in
The problem of Simultaneous Localization and Mapping  many real-world scenarios, especially those involving explo-
(SLAM) is a core competency of robotics which has at- ration, this larger matrix still contains far less entries than in
tracted a large amount of attention. The classical solution to Ô¨Ålter-based methods [Dellaert, 2005][Eustice et al., 2005].
the SLAM problem uses an Extended Kalman Filter (EKF) Filters are more efÔ¨Åcient then smoothing only when a limited
[Smith and Cheeseman, 1987] that maintains the joint distri- number of structure points is observed repeatedly. However,
bution on the current robot pose and the landmarks in the map even in this case the inability to correct previous poses may
in the form of a Gaussian distribution. Since updating the co- lead to poor results.
variance matrix of this distribution requires O(n2) time, the The crucial limitation of all the above approaches based on
EKF algorithm does not scale to large maps. Recent work the information form of the Gaussian is that recovering an es-
on the SLAM problem has focussed on improving the time timate of the map and robot pose involves a matrix inversion,
complexity of the solutions. One commonly used technique and hence, is computationally infeasible for large systems.
is to update the information form of the Gaussian distribu- Indeed, in the case of the Ô¨Åltering approaches such as the
tion. Though the information matrix becomes dense through SEIF, obtaining even the mean involves a matrix inversion.

                                                IJCAI-07
                                                  2191The solution is obtained in these cases through an iterative In addition, our algorithm is incremental and largely runs in
process that solves a linear system wherein only a constant O(1) time, which are advantages over Graphical SLAM.
number of iterations is performed at each step so as to main-
tain the runtime bounds of the algorithm. This approximation 2 Smoothing and Mapping
is based on the assumption that the SLAM solution evolves
                                                      We begin by reviewing the SAM framework as given in [Del-
only slowly over time so that a relinearization of the problem
                                                      laert, 2005]. In the smoothing framework, our aim is to re-
at each time step is not required. The iterative method, how-
                                                      cover the maximum a posteriori (MAP) estimate for the entire
ever, still does not yield the covariance, which is needed for    Œî
maximum-likelihood data association and also as an estimate trajectory X = {xi : i ‚àà 0 ...M} and landmark locations
                                                                 Œî
of the uncertainty in the landmark locations and pose. (the map) L = {lj : j ‚àà 1 ...N}, given the landmark mea-
  This paper deals with the use of Loopy Belief Propagation    Z =Œî {z : k ‚àà 1 ...K}            U =Œî {u }
(LBP) [Weiss and Freeman, 1999] to obtain an approximate surements    k             and odometry       i .
                                                      This can be computed by maximizing the joint posterior on
solution to the SLAM problem, including the marginal co-                              P (X, L|Z)
variances on the map and pose. We consider the case wherein the trajectory and landmark locations
the map consists of a set of features, and build on the Smooth-    ‚àó  Œî
                                                                  Œò   =   argmax P (X, L|Z, U)        (1)
ing and Mapping (SAM) approach as introduced in [Dellaert,                   Œò
2005], which updates the joint distribution on the robot tra-
                                                               Œî
jectory and the map using the square root information form where Œò = {X, L} is the set of unknown variables, i.e the
of the Gaussian distribution. Our approach is based on the robot trajectory and landmark locations. The posterior can be
fact that the SAM problem can be treated from the graph- factorized using Bayes law as
ical model viewpoint as a Gaussian Markov Random Field
                                                         P (X, L|Z, U) ‚àù   P (Z, U|X, L)P (X, L)
(GMRF)  [Winkler, 1995] on which inference can be per-
                                                                                  M
formed using LBP.                                                            P (x0) i=1 P (xi|xi‚àí1,ui)
                                                                       ‚àù           K                 (2)
  We provide a constant time update algorithm, which we                                  P (zk|xi ,lj )
call the WildÔ¨Åre algorithm, for estimating the map and robot                         k=1       k   k
trajectory, including the marginal covariances. While a naive Here P (xi|xi‚àí1,ui) is the motion model, parameterized by
                             O(n)                                 u     P (z |x ,l )
implementation of LBP requires    time to update the  the odometry i,and   k  ik jk is the landmark measure-
marginal distributions, where n is the number of nodes in the ment model, assuming that the correspondences (ik,jk) are
graph, the WildÔ¨Åre algorithm discards negligibly small mes- known. The prior on the initial pose P (x0) is taken to be a
sages between nodes. Subsequently, only those nodes which constant, usually the origin, while the priors on the remaining
have either received or sent signiÔ¨Åcant messages get updated. poses and landmark locations are assumed to be uniform.
We show that the number of nodes involved in a signiÔ¨Åcant We assume Gaussian motion and measurement models, as
message exchange is O(1) unless a signiÔ¨Åcant event (such as is standard in the SLAM literature. The motion model is
loop closing) occurs when the complete graph may get up- given as xi = fi(xi‚àí1,ui)+wi,wherewi is zero-mean Gaus-
dated, increasing the time bound to O(n).             sian noise with covariance matrix Qi. Similarly, the measure-
                                                                            z = h  (x ,l )+v         v
  Relinearization of the GMRF graph, which is required ment equation is given as k k ik jk    k where k is
since the SAM problem is non-linear in general, is performed normally distributed zero-mean measurement noise with co-
in constant time using a technique similar to the WildÔ¨Åre al- variance Rk.
gorithm in that only nodes that have changed are relinearized. In practice, only linearized versions of the motion and mea-
Moreover, it need only be done periodically when the differ- surement models are considered, for example for use in the
ence between the current estimate and the linearization point Extended Kalman Filter (EKF) approach to SLAM [Smith et
exceeds a speciÔ¨Åed threshold. As before, relinearization may al., 1990], with multiple iterations being used to obtain con-
take linear time after a signiÔ¨Åcant update of the GMRF graph. vergence to the minimum. In the following, we will assume
  We prove that LBP on a GMRF is equivalent to Gauss- that either a good linearization point is available or that we are
Seidel relaxation and provides the exact MAP estimates of working on one iteration of a non-linear optimization method.
the nodes. The covariances are, however, overconÔ¨Ådent due It can be shown [Dellaert, 2005] that this results in a sparse
to the approximate nature of the inference. As a conservative linear least squares problem in Œ¥Œò
                                                                       
approximation, the covariances obtained by restricting infer-            M
ence to a spanning tree of the GMRF graph can be used to ‚àó                     i‚àí1         i        2
                                                       Œ¥Œò   =   argmin      F    Œ¥xi‚àí1 + G Œ¥xi ‚àí ai +
perform data association.                                                      i           i        Qi
                                                                  Œ¥Œò     i=1
  In terms of related work, closest are the relaxation based                                     
                                                                    K
approaches given in [Duckett et al., 2000; Frese and Duckett,              ik       jk        2
                                                                        H  Œ¥xi + J  Œ¥lj ‚àí ck        (3)
2003]. However, these are unable to compute the marginal                  k    k    k   k     Rk
covariances on the poses and landmarks. Graphical SLAM              k=1
[Folkesson and Christensen, 2004] is another method that      i‚àí1
                                                      where Fi   is the sparse Jacobian of fi(.) at the lineariza-
builds a graphical model of the smoothing problem. Our ap-
                                                               x0       a =Œî x0 ‚àí f (x0  ,u )
proach shares many common features with Graphical SLAM, tion point i‚àí1 and i  i    i  i‚àí1  i is the odome-
                                                                                      ik     jk
including the ability to modify data association on the Ô¨Çy, try prediction error. Analogously, Hk and Jk are respec-
and increase efÔ¨Åciency by eliminating variables judiciously. tively the sparse Jacobians of hk(.) with respect to a change

                                                IJCAI-07
                                                  2192  x      l                                (x0 ,l0 )         K
in ik and jk , evaluated at the linearization point ik jk , where is a constant of proportionality.
       Œî          0  0                                  Using this formulation, we can write the edge potentials
and ck = zk ‚àí hk(xi ,lj ) is the measurement prediction                     ‚àí1
                   k  k                               from (5) as œà(xi,lj) ‚àùN  (yij ; Œ∑ij , Œõij ) ,whereyij is the
error. ||.||Œ£ is the Mahalanobis distance with respect to the       T
                                      i               vector [ xi lj ] , and we have dropped the index k from the
covariance matrix Œ£ andweusethematrixGi = ‚àíId√ód , d
                                                      corresponding pair {ik,jk} for convenience. The distribution
being the dimension of xi, to avoid treating Œ¥xi specially.
                                                      parameters are then given as
  The solution to the least squares problem (3) is given by                
           

                                          T                            Œ∑i           Hi
the linear system AŒ¥Œò ‚àí b =0where  A  =  J J  is the               Œî    ij           k    ‚àí1
                                                                Œ∑ij =   j     =      j   Rk  ck       (8)
Hessian matrix, J being the system Jacobian matrix obtained            Œ∑ij          Jk
                                                                                     
           

by assembling the individual measurement Jacobians, and            ii   ij                          T
     T                                                           Œõ     Œõ            Hi         Hi
b = J e where e is the vector of all the measurement errors. Œî     ij   ij           k    ‚àí1     k
                                                          Œõij =    ji   jj    =      j   Rk      j    (9)
                                                                 Œõij  Œõij           Jk         Jk
SAM as a Markov Random Field
                                                      and the potentials on the edges linking two poses are deÔ¨Åned
We now show that inference on the posterior (2) can be per- analogously.
formed by placing the SAM problem in a Markov Random    The GMRF potentials on the singleton cliques are similarly
Field (MRF) framework. The graph of an MRF is undi-                      ‚àí1
                                                      deÔ¨Åned as œÜ(yi)=N    (yi; Œ∑i, Œõi) where yi ‚àà{X, L},and
rected and its adjacency structure indicates which variables           ‚àí1
                                                      Œ∑i =ŒõiŒºi, Œõi = P    follows from (5) and (7). The poten-
are linked by a common factor (a measurement or constraint).           i
                                                      tials œÜ(yi) represent the beliefs on the unknowns and if only
  A pairwise MRF is described by a factored probability den-
                                                      a uniform prior exists on an MRF node yi, both Œ∑i and Œõi can
sity given as
                                                    be set to zero. Note that setting Œõi to zero is equivalent to
          P (X, L) ‚àù   œÜ(yi)    œà(yi,yj)        (4)   having a Gaussian prior with inÔ¨Ånite covariance.
                     i
                            {i,j}                     Belief Propagation
where the second product is over the pairwise cliques {i, j}, The goal of belief propagation in our case is to Ô¨Ånd the
counted once. The posterior (2) can be modeled as a pair- marginal probability, or the belief, P (yi) of a node yi ‚àà Œò=
wise MRF where the singleton cliques correspond to marginal {X, L} in the SAM graph. A complete characterization of
prior distributions or singleton measurements (such as GPS) the belief propagation algorithm for GMRFs is beyond the
on the unknown variables and the edge cliques correspond to scope of this paper, but we provide the high-level equations
the motion and measurement likelihoods respectively.  and data Ô¨Çow below. Details can be found in [Weiss and Free-
  For the linear case considered in the previous section, these man, 1999].
equations translate to                                  The beliefs are computed using a message passing algo-
                      1        2                      rithm wherein each node passes messages to its neighbors
       ‚àí ln œÜ(yi) ‚àù    xi ‚àí Œºi
                      2        Pi                     and in turn uses its incoming messages to compute its belief.
                      1  i‚àí1         i        2       While belief propagation is guaranteed to compute the correct
  ‚àí ln œà(xi‚àí1,xi) ‚àù    F   Œ¥xi‚àí1 + G Œ¥xi ‚àí ai (5)
                      2  i           i        Qi      beliefs only if the graphical model does not contain loops, it
                      1                               has been proven that it Ô¨Ånds the correct MAP solution for
                          ik       jk         2
  ‚àí ln œà(xi ,lj ) ‚àù    H  Œ¥xi  + J  Œ¥lj ‚àí ck        Gaussian graphical models even in the presence of loops, i.e
          k   k       2   k   k    k   k      Rk
                                                      the means of the beliefs are correct while the covariances are
where yi ‚àà{X, L}. This gives us a Gaussian Markov Ran- incorrect in general [Weiss and Freeman, 1999].
dom Field (GMRF) corresponding to the linearized SAM    LBP works by repeatedly computing the messages and be-
problem. Note that in the context of the SAM problem, the liefs for every node in the graph starting with constant mes-
singleton clique factors are most often set to unity except for sages [Weiss and Freeman, 1999], either in synchronous or
the Ô¨Årst pose, which is clamped to the origin.        asynchronous fashion. This sweep over the graph is iterated
                                                      until the beliefs converge. Denoting the current iteration by
3  Loopy Belief Propagation for SAM                   a discrete time superscript t, the belief parameters (the infor-
                                                                                    y
We use Loopy Belief propagation (LBP) on the SAM GMRF mation vector and matrix) for node i are given as
                                                                      t                t‚àí1
to solve the linear system (3) and obtain not only the MAP          mi   =   Œ∑i +    mji             (10)
values of the unknown variables but also the covariances.                        j‚ààN
                                                                                  i
For ease of computation, we use the information form of the           t                 t‚àí1
Gaussian to specify the single and pairwise clique potentials       Mi   =Œõi   +      Mji            (11)
in the GMRF given by (5), wherein these are expressed using                      j‚ààNi
the information vector Œ∑ and the information matrix Œõ,and and the parameters of the message Mij (yj) from node yi to
we deÔ¨Åne the information form as                    node yj as
                                                                                            ‚àí1
        ‚àí1        Œî            T    1 T                      t       j    ji   ii    t    t‚àí1
      N   (x; Œ∑, Œõ) =exp C  + Œ∑ x ‚àí  x  Œõx      (6)        mij  =   Œ∑ij ‚àí Œõij Œõij + Mi ‚àí Mji
                                    2                                                           
                                                                                   i     t    t‚àí1
                                                                                  Œ∑ij + mi ‚àí mji     (12)
where C is an additive constant. If Œõ is full-rank, equation                                 
                                                             t       jj    ji  ii    t     t‚àí1 ‚àí1  ij
(6) corresponds to a Gaussian density as                   Mij  =Œõij   ‚àí  Œõij Œõij + Mi ‚àí Mji     Œõij (13)
           N (x;Œõ‚àí1Œ∑, Œõ‚àí1)=N   (x; Œº, P )       (7)   where use has been made of the deÔ¨Ånitions in (8) and (9).

                                                IJCAI-07
                                                  2193Algorithm 1 The WildÔ¨Åre algorithm for LBP               The WildÔ¨Åre algorithm has O(1) running time since in
 1. Push the most recently added nodes and their neighbors in the most situations the number of edges with large message devi-
    SAM graph G(V,E) onto the queue Q                 ations is O(1). However, this is not true when special events
 2. Do until Q is empty                               such as loop closures occur as shown in Figure 2. In such
                                                                                                    O(n)
                                           t          instances, the complete graph is updated resulting in
     (a) Pop node y from Q and compute messages Myk for all
        k ‚ààN                                          complexity. Note that no special clause is required to handle
             y using (12-13)                          these instances - the algorithm automatically updates all the
          Mt  ‚àíMt‚àí1   >      k    Q
     (b) If yk    yk     , push onto                  nodes in the graph as the message deviations do not die down.
     (c) Update the belief B(y) using (10-11)           Relinearization of the SAM graph, which involves comput-
                                                      ing the clique potentials at new linearization points, can also
                                                      be performed using the WildÔ¨Åre algorithm, the only differ-
                                                      ence being that the deviations of the node beliefs from their
                                                      respective linearization points are now used instead of the
                                                      message deviations. In this case, however, two variants are
                                                      possible. One technique is to delay relinearization until the
                                                      belief deviations are greater than a certain threshold for some
                                                      given proportion of nodes in the graph. As this proportion
                                                      approaches unity, relinearization becomes O(n) but is per-
                                                      formed only very rarely. A second strategy is to perform re-
                                                      linearization at regular time intervals so that it remains O(1).
                                                      The choice between these strategies depends on the type of
                                                      application, the environment, and size of the SAM graph.
                                                        We now have all the components to describe the Loopy
                                                      SAM  algorithm. At each step, a new pose node, new mea-
                                                      surement links and possibly new landmark nodes, are added
Figure 2: The WildÔ¨Åre algorithm only updates nodes with signif- to the SAM GMRF. A Ô¨Åxed number of LBP iterations are
icant message deviations, starting from the most recently added then performed using the WildÔ¨Åre algorithm to update the be-
node. In normal operation (left) only the frontier of the graph is
updated. However, during loop closings (right) most of the graph liefs on the nodes. Periodically, relinearization is performed,
is updated. Updated poses are shown in brown (dark) while the un- again using a variant of the WildÔ¨Åre algorithm. The means
changed nodes are in yellow (light). The robot is moving counter- of the pose and landmark nodes in the SAM GMRF, obtained
clockwise starting at the bottom.                     from the belief information vector and matrix at each node,
                                                      correspond to the MAP solutions for the trajectory and the
                                                      map respectively.
4  Constant Time Loopy SAM
Each iteration of LBP as deÔ¨Åned above is O(n) where n is the 4.1 Marginal Covariances
number of nodes in the graph. This is too slow to be useful, We now show how to recover the approximate marginal co-
especially since the trajectory is included in the node count. variances of the nodes from the LBP beliefs. An important
We can, however, improve this bound to O(1) for incremen- use of the covariances is to bound the search area for possible
tal operation, i.e. when new nodes or edges are added to the correspondences in data association. This is usually done us-
GMRF.                                                 ing the projection of the combined pose and landmark uncer-
  The key observation to getting a constant time algorithm is tainty into the measurement space, the computation of which
that at each step only a few of the nodes get updated, i.e. ex- requires knowledge of the marginal covariances of the poses
perience an actual change in their values, and these nodes and landmarks.
are the ones that have been recently added to the graph. If The inverse of the belief information matrix at each node
we commence the belief updation sweep in every iteration in the SAM GMRF gives the marginal covariance. While in
of LBP from the most recently added node, the new mes- general the belief obtained from LBP can be overconÔ¨Ådent
sages are initially seen to deviate from their previous values or underconÔ¨Ådent, it has been proven to be always overcon-
by large amounts. However, these deviations become smaller Ô¨Ådent for Gaussian MRFs with pairwise cliques [Weiss and
as we move further back in the graph. Once the message de- Freeman, 1999]. OverconÔ¨Ådent covariances cannot be used
viations become negligible (smaller than some pre-speciÔ¨Åed for data association since this results in many valid corre-
signiÔ¨Åcance threshold), the beliefs no longer change and the spondences being rejected. A Ô¨Årst conservative approxima-
remaining nodes need not be updated.                  tion would be to use the inverse of the diagonal blocks of the
  The WildÔ¨Åre algorithm, so called because the message de- system Hessian matrix as the marginal covariances. However,
viations from the previous iteration spread like wildÔ¨Åre from this results in overly conservative estimates.
their point of origin and gradually become negligible, is illus- A better approximation can be obtained by restricting mes-
trated in Figure 2. The algorithm implementation features a sage passing to a spanning tree of the SAM GMRF. Since the
queue onto which nodes with signiÔ¨Åcant message deviations spanning tree is obtained by deleting edges from the GMRF
on incoming edges are pushed. A summary of the algorithm and inference on it is exact, we get a conservative estimate of
is given in Algorithm 1.                              the true marginal covariances that is also better than our Ô¨Årst

                                                IJCAI-07
                                                  2194                                                                            Update time per step

                                                                    Update
                                                             0.16   Messages
                                                                    Beliefs
                                                             0.14

                                                             0.12

                                                              0.1

                                                             0.08
                                                             Time  (sec)

                                                             0.06

                                                             0.04

                                                             0.02

                                                                  500 1000 1500 2000 2500 3000 3500 4000 4500 5000
                                                                               Steps
                                                      Figure 4: Runtime for a simulation consisting of 5000 steps. The
                                                      times for the message and belief computation, and the total update
                                                      step are shown. All times were obtained on a 1.8GHz Linux machine
                                                      using an implementation of the algorithm in Ocaml. Note the two
                                                      spikes (one at the very end) corresponding to loop closures.

Figure 3: (top) A spanning tree of the GMRF graph, with edges col- system Jacobian J,ande is the corresponding measurement
ored blue (dark), for a linear simulation. (bottom) Covariances for error. This result is true since we have
                                                                                  
the same simulation - ground truth is shown in blue (thin dark), over- t t‚àí1             t‚àí1    ‚àíi
conÔ¨Ådent LBP covariances are shown in green (light), and conserva- mj ‚àí mij = Œ∑j +     mkj  = mj
tive covariance estimates obtained by restricting BP to the spanning             k‚ààNj \i
tree are shown in red (thick dark).
                                                              ‚àíi
                                                      where mj  is the estimate of mj without considering node
                                                                       t     t‚àí1      ‚àíi         ‚àíi ‚àíi
order approximation. Maintenance of the spanning tree and yj, and similarly Mj ‚àí Mij = Mj .SinceMj yj  =
                                                        ‚àíi
message passing on it require extra work. However, the span- mj holds by the deÔ¨Ånition of the information form of the
ning tree can be extended at each step in O(1) so that, with Gaussian, substituting these identities and the deÔ¨Ånitions of Œ∑
the use of the WildÔ¨Åre algorithm, the overall scheme still re- and Œõ from (8-9) into the message equation (12) gives us the
mains constant time. Figure 3 illustrates the nature of this result (15).
approximation.                                          Using (15) in the belief equation (10), we get
                                                                                       
                                                             mt   =   Œ∑ +     J T e  ‚àí     A  y‚àíi
5  Loopy SAM and Gauss-Seidel Relaxation                       i       i       kj i kj       ij j
                                                                          j‚ààN          j‚ààN
We prove in this section that computing the MAP solution                     i           i
using LBP for a GMRF is equivalent to a modiÔ¨Åed form of                                ‚àíi
                                                                  =   Œ∑i + bi ‚àí   Aij yj             (16)
Gauss-Seidel relaxation, which is commonly used to solve                      j‚ààN
linear systems. Relaxation has previously been used in the                       i
context of SLAM [Duckett et al., 2000] but is not capable of which closely corresponds to the relaxation equation (14).
recovering the marginal covariances, a short-coming that LBP Hence, the MAP computation in LBP is simply a modiÔ¨Åed
overcomes. The equivalence of the MAP portion of LBP and version of Gauss-Seidel relaxation.
relaxation is an interesting result that connects our technique
with a well-understood method from linear algebra.    6   Results
  Relaxation solves the linear system AŒ¥Œò‚àíb =0, encoun-
tered in Section 2, by iterating over a set of equations, each Linear Gaussian Simulations
of which updates the value of exactly one unknown using the We Ô¨Årst present the results of applying our approach in a con-
current estimate of all the others                   trolled simulation devoid of non-linearities. The simulation
              Aiiyi =   bi ‚àí   Aij yj          (14)   consisted of an environment with randomly placed, uniformly
                            j=i                      distributed landmarks. The robot followed a large 8-shaped
                                                      Ô¨Ågure in this environment and the run included two loop clo-
                                        y     y  ‚àà
where the sum is over all the variables except i,and i sures at the ‚Äúwaist‚Äù of the 8-Ô¨Ågure.
Œò={X, L}
           as before.                                   Figure 4 gives the results for a linear simulation consist-
                                              y
  We begin our proof by noting that the message from j to ing of 5000 steps, i.e. a trajectory of length 5000. The total
y
 i given by (12) can be re-written as                 number of nodes in the SAM GMRF was 6742. It can be
                t       T         ‚àíi                                          O(1)
              mji  =   Jkiek ‚àí Aij yj          (15)   veriÔ¨Åed that the algorithm is , and the two spikes in the
      ‚àíi                                              graph corresponding to the loop closures are also clearly vis-
where yj is the estimate of yj without considering the node ible. The spikes occur since the LBP update makes a sweep
yi, k is the index of the measurement linking yi and yj in the through the whole graph in these instances.

                                                IJCAI-07
                                                  2195
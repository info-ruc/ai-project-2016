                               A  Novel   Local   Search   Algorithm     for
                 the  Traveling    Salesman    Problem     that  Exploits   Backbones     ¬†
                                    Weixiong  Zhang   and  Moshe  Looks
                             Department  of Computer  Science  and Engineering
                                   Washington   University in Saint Louis
                                       Saint Louis, MO  63130,  USA
                                       Email:  zhang@cse.wustl.edu

                      Abstract                          on LS. Today, the best LS algorithms for the TSP are its vari-
                                                        ants, which include chained and iterated LK algorithms [11;
     We present and investigate a new method for the    9; 6]. These algorithms can provide high-quality, near opti-
     Traveling Salesman Problem (TSP) that incorpo-     mal solutions for problems with several thousand cities [9]. It
     rates backbone information into the well known     is nontrivial to Ô¨Ånd solutions better than those from the Lin-
     and widely applied Lin-Kernighan (LK) local search Kernighan family. Nonetheless, improving these algorithms
     family of algorithms for the problem. We consider  is of practical importance; even small improvements can have
     how heuristic backbone information can be obtained substantial Ô¨Ånancial impacts for many applications, as in man-
     and develop methods to make biased local pertur-   ufacturing, where selected TSP tours need to be routinely tra-
     bations in the LK algorithm and its variants by ex- versed.
     ploiting heuristic backbone information to improve
                                                          A major deviation of most modern LS variants from the LK
     their efÔ¨Åcacy. We present extensive experimental re-
                                                        algorithm is the use of starting tours that are closely related
     sults, using large instances from the TSP Challenge to the previous local minimum or the best tour found so far,
     suite and real-world instances in TSPLIB, showing
                                                        rather than independently generated [9]. Such starting tours
     the signiÔ¨Åcant improvement that the new method can
                                                        can be typically generated by perturbations to the Ô¨Ånal tours of
     provide over the original algorithms.              previous runs using neighborhood structures different from the
                                                        ones used by the main procedure. For instance, double-bridge
1   Introduction                                        4-Opt moves have been used extensively for this purpose [9].
Given a set of cities and the distances between them, the trav- The intuition behind using chained starting tours in an it-
eling salesman problem (TSP) is to Ô¨Ånd a complete, minimal- erated LS is that high-quality local minima tend to reside
cost tour visiting each city once. The TSP is a well-known in a small vicinity of a neighborhood structure. Therefore,
NP-hard problem with many real-world applications, such as it is more effective and efÔ¨Åcient to search for a better lo-
jobshop scheduling and VLSI routing [5]. The TSP has often cal minimum from a known one. This intuition is sup-
served as a touchstone for new problem-solving strategies and ported by the observation that local minima of a good LS
algorithms; and many well-known combinatorial algorithms method usually share many common partial structures [1; 2;
were Ô¨Årst developed for the TSP, including the Lin-Kernighan 10]. Such observations have also led to the ‚Äúbig valley‚Äù hy-
local search algorithm [10]. In this paper, we consider the sym- pothesis [1], which suggests that high-quality local minima
metric TSP, where the distance from a city to another is the tend to have many edges in common, forming a single clus-
same as the distance in the opposite direction.         ter around the optimal tour(s), and that a better local minimum
  Local search (LS) algorithms have been shown very effec- tends to have more common edges shared with an optimal so-
tive for the TSP. In LS algorithms for the TSP, one deÔ¨Ånes a lution than a worse local minimum.


neighborhood structure of tours, in which tour ¬° is a neigh- Besides the iterated LS methods, common structures of lo-


                ¬°                    ¬°¬§¬¢
bor of tour ¬°¬£¬¢ if can be changed into  by some local   cal minima have been exploited in at least two other ways. The
perturbation, such as by exchanging a pair (2-Opt) or triplet Ô¨Årst is reduction [10], which Ô¨Årst collects a small set of local
(3-Opt) of edges between cities [9; 10]. Starting from a com- minima and then locks in the edges appearing in all of them
plete tour, LS repeatedly improves the current tour until it is in the subsequent runs. This method has two effects: it can
the best among its neighbors; such a tour is called a local min- speed up the search, as the problem becomes smaller, and pro-
imum.  This process can be applied multiple times using dif- vides a means of directing search among a set of otherwise
ferent initial tours. Although LS algorithms do not guaran- indistinguishable tours [10]. In [10], Lin and Kernighan re-
tee the optimality of the best solution found, they have been ported experimental results on instances up to 318 cities using
routinely applied in practice, and are among the best methods reduction. The second and more recent way to exploit common
for the TSP. The best known LS algorithm for the TSP is the structures of local minima is called tour merging [2]. Given a
Lin-Kernighan (LK) algorithm [10]. Since its inception three set of local minima, this method constructs a graph containing
decades ago, this classic algorithm has inspired much research the union of their edges. Thanks to the large number of shared
                                                        edges among the local minima, the resulting graph is sparse.
   ¬• The research was supported NSF grant EIA-0113618.  An optimal tour within the sparse graph is then uncovered asan approximate solution, which is very often optimal. Our re- pass this problem was inspired by the fact that many ap-
cent algorithm on maximum satisÔ¨Åability (max-SAT) also ex- proximation algorithms for the TSP, the LK algorithm and
plicitly exploited the information in a cluster of local minima its variants in particular, have superior performance. They
and incorporated it in the Walksat algorithm [15], resulting in can often reach local minima that are within a small per-
a signiÔ¨Åcant performance improvement on diverse large max- centage of a global optimum and have common structures
SAT  problems [16]. The current research was inspired by these shared with a global optimal solution, as discussed in [1;
previous results.                                       9]. Therefore, we can treat local minima as if they were op-
  Our research was also motivated by the recent advances in timal to compute pseudo-backbone frequencies to approximate
characterizing typical case features of combinatorial problems the true backbone frequencies. We call this general approach
by their phase transitions and backbones [7; 12]. A problem backbone guided local search or BGLS.
of fundamental importance and practical interest is to utilize We deÔ¨Åne the pseudo-backbone frequency of an edge as


inherent problem information, such as phase transitions and the frequency of its appearances in the local minima sampled.
                                                                                                       ¬°


backbones, in a search algorithm to cope with problem difÔ¨Å- Thus, if ¬† is the set of local minima, and a given edge ap-


                                                                           ¬†                               ¬°


culty. The research along this line is limited. Besides the pub- pears in a subset ¬†¬£¬¢ of , the pseudo-backbone frequency of


                                                                 ¬†¬•¬¢¬¶¬§ ¬ß¬®¬§ ¬†¬©¬§
lished work of utilizing backbone information in local search is simply ¬§ .
for SAT and max-SAT  [16], previously published results in- Which local minima to use will affect the quality of the
clude exploiting phase transitions in tree search problems in an pseudo-backbone frequencies. Ideally, we want the local min-
approximation algorithm [13] and applying heuristic backbone ima to be an unbiased sample of all high-quality approximate
information in a systematic search for SAT [3].         solutions. One leading factor in reaching such an ideal is the
  Our new method explicitly exploits the structure of the local set of initial tours: the more distinct the starting tours are, the
minima of LS algorithms, namely the possible backbone infor- more different the Ô¨Ånal tours will generally be. Therefore, even
mation embedded in the local minima, to improve the perfor- though local minima reached from greedily generated starting
mance of the algorithm. Here, a backbone variable for a TSP tours are superior to those reached from random starting tours,
refers to an edge between two cities that appears in all optimal a pseudo-backbone constructed from the latter generally leads
TSP  tours. Unlike the reduction and tour merging methods, to better overall performance.
our new heuristic does not freeze the common edges in all lo- Pseudo-backbone information can be incorporated in LS al-
cal minima in subsequent searches; it rather applies estimated gorithms to ‚Äúbias‚Äù the search. In LS, moves are evaluated by
backbone information to guide a local search to the region of the difference between the total cost of the edges to be removed
the search space that is more likely to have better approximate, from the tour and the total cost of the edges to be added. If this
and hopefully optimal, solutions. SpeciÔ¨Åcally, we treat local value is positive, the move is taken. In backbone guided search,
minima from a local search as if they were optimal solutions, we can make biased moves in two different ways; one only uses
and use edge appearance frequencies to estimate the probabil- pseudo-backbone frequencies and the other combines pseudo-


ities of backbone variables. We then apply the estimated back- backbone frequencies and the distances between cities. Let
                                                        



bone probabilities to alter the perturbations made by the local be the set of backbone edges of a TSP and  the set of


search algorithm so that a variable having a higher backbone local minima from which pseudo-backbone frequencies were
                                                                            
probability will be less likely to be swapped out of the current computed. Let  and be the candidate set of edges to be


tour than a variable having a smaller backbone probability, and removed and added, respectively, at a step of searching for a


                                                        


                                                                                             
conversely, will be more likely to be swapped in.        -Opt move. We prefer to replace  by if has a smaller


  The paper is organized as follows: in Section 2, we describe possibility of having more backbone variables than  . If we


the general idea of backbone-guided local search for the TSP. assume edges to be independent of each other, we prefer to


                                                                                       



                                                                       ¬¶  ¬§ "!$#%&')(*,+¬¶ 


We  then in Section 3 discuss the backbone-guided LK algo- replace  by if




                                                                          

                                                        



                                                                       


                                                                      ¬§ "!
                                                          -!


rithms. We present the experimental results in Section 4, dis- ¬§ , where       is the backbone frequency of edge


                                                         
                                                                                           
cuss related work in Section 5, and conclude in Section 6.  , computed from the set of local minima . This method has
                                                        been shown effective on maximum satisÔ¨Åability [16].
2   Backbone   Guided   Local Search                      Unfortunately, local search based exclusively on local per-
If all backbone variables of a TSP were known, they could pro- turbations using merely pseudo-backbone frequencies is not
vide a useful clue to how edges between two cities should be very effective on the TSP. One possible factor contributing to


swapped in or out during a local search. If an edge is a part of this discrepancy between the TSP and max-SAT is the differ-
                                                                                                01/3254 6.8789!


the backbone, i.e., it appears in all optimal solutions, obviously ent sizes of their search spaces. The TSP has ./
                                                                                   :;¬§)2<=<*>@?!A¬ß8.
the edge should be swapped in if it is not included in the cur- states in its search space, where ¬§ is the num-


rent tour. Moreover, we can extend the concept of backbone to ber of edges for an < city TSP. These states are embedded in
backbone frequency of an edge, which is the percentage of op- a constraint structure, in which, for example, taking one edge


timal solutions that have the edge. This means that a backbone preventing many other edges from being taken. In comparison,
                                                                                                   <
edge has a backbone frequency of one and an edge that does the search space of max-SAT has only .)7 states for Boolean
not appear in any optimal solutions has a backbone frequency variables. The estimated backbone frequencies could thus be
of zero. Therefore, the backbone frequency of an edge is an in- less reliable on the TSP than on max-SAT. The deÔ¨Åciency of
dicator of how often that edge should be swapped in (or out) if local perturbations based purely on pseudo-backbone frequen-
it is (or it is not) part of the current tour. This can be exploited cies indicates that the actual intercity distances should not be
as a heuristic for selecting edges in local search.     ignored for the TSP. This constitutes one of the main differ-
  Unfortunately, exact backbone frequencies are hard to come ences between backbone-guided local search for the TSP and
by without solving the problem exactly. The idea to by- that for max-SAT.  In the LK algorithm, moves are evaluated by summing the it is impossible to ignore potential  -Opts involving only un-
costs of the edges to be removed from the current tour, and changed cities, as when moving between successive rounds of
subtracting the sum of the costs of the edges to be added. The ILK with only a single search method. Our solution to this has
same evaluation principle can be applied in backbone guided been to alternate between BGLK and regular LK at a higher
LS, but with cost computed differently. Instead of taking the level of granularity: one of these search mechanisms is em-




cost of a given edge to be the distance between two cities, ¬† , ployed until it ‚Äúfails‚Äù, at which point we begin employing the


                   ? >¬§¬£ !
it is taken to be ¬†¬¢¬°   , where p is the pseudo-backbone alternate mechanism until it too ‚Äúfails‚Äù, then switch back to the
frequency of that edge. Thus, the cost of an edge will decrease original, and the alternation repeats. In this context, we have
linearly in proportion to its pseudo-backbone frequency. The deÔ¨Åned failure at going through  rounds (restarts) of optimiza-


extreme cases are edges not in the pseudo-backbone, which tion without Ô¨Ånding an improved tour. For our experiments, we


                                                               


                     ;2¬¶¬•                                        2¬®¬ß¬ß¬¶.¬©¬•     ¬ß


have their original costs (¬£ ), and edges in all local minima, have set , where  is the number of cities.


                         $2  ?
which their costs set to zero (¬£ ).
  When  this method is used, the results can be improved even 4 Experimental Evaluation
more  by carrying out regular LK search using original dis- We have carried out two sets of experiments to study differ-
tances from the local minima found by the biased search. This ent ways of applying pseudo-backbone information in BGLS.
is effective because the biased search actually searches in a new In our experiments we used random instances from the TSP
TSP instance that has been created from the original by apply- Challenge suite [8], which includes problem classes of uniform
ing a ‚Äúpseudo-backbone transform‚Äù to its edge weights. Local Euclidean (Uniform), clustered Euclidean (Clustered), and dis-
minima in this new instance will not generally correspond to tance matrix (Matrix). We have also used the large instances
local minima in the original, so continued search of the origi- from the TSPLIB [14].
nal graph will improve the results, even after biased search has We compared BGLK and IBGLK against LK, ILK, the
reached a local minimum.                                reduction method of [10], and the search space smoothing
  Furthermore, pseudo-backbone information can be em-   method of [4]. The smoothing method is related because it
ployed to generate starting tours. It is known that the effec- modiÔ¨Åes the distances of TSP instances in an attempt to make


tiveness and speed of local search can be improved by using it easier for local search to eventually reach local minima of


                                                                                          ¬¢


                                                                                            2 
 ¬§ 
 > 
 ¬§ 


greedy starting tours [9]. The greedy tour construction begins higher quality. It uses a Ô¨Åxed formula, 
 , to


                                                                                 ¬¢


                                                                                
       
 
by randomly picking a starting city, and adding the shortest transform distance from 
 to , where is the average distance




edge exiting the city to the tour. Then, edges are greedily over all original distances, and  takes a series of decreasing
                                                                              ?
added one-by-one until the tour is complete. We can mod- values, typically ¬°¬°¬° to help slowly move from an ini-
ify this process to naturally utilize the pseudo-backbone by tially ‚Äúsmooth‚Äù instance, in which all distances look similar
redeÔ¨Åning the ‚Äúbest‚Äù edge in terms of the pseudo-backbone- to one another, to the actual problem. We implemented this
transformed weights, rather than the original weights. This method in the LK algorithm for the test.
gives us a greedy pseudo-backbone tour generation heuristic. The particular version of LK-based algorithms that we used
3   Backbone   Guided   LK  and  ILK                    was implemented and provided by Johnson and McGeoch, de-
                                                        scribed and analyzed in [9]. We leave the details of the im-
Applying the above ideas and considerations to LK, we have
                                                        plementation to its original description, while simply pointing
the backbone guided LK algorithm (BGLK). Similar to LK,
                                                        out that all of our tests were carried out with the default settings
BGLK  runs many cycles, each of which starts from a new start-
                                                        for this implementation, namely length-20 neighbor lists for all
ing tour and reaches a local minimum. Different from LK,
                                                        levels of the search, don‚Äôt-look bits, and the 2-Level Tree tour
BGLK   has two phases. The Ô¨Årst is a learning phase that runs
                                                        representation. We incorporated the reduction method and the
a Ô¨Åxed number of iterations of original LK with random start-
                                                        space smoothing method in LK to generate two variants. We
ing tours. The local minima from these runs are used to com-
                                                        have also followed Johnson and McGeoch [9] in conÔ¨Åguring


pute pseudo-backbone frequencies. The second is a backbone-


                                    


                                                                                   ¬•¬ß      ¬ß
                                                        ILK, allowing it the most Ô¨Çips, ? , where is the problem
guided improvement phase where biased -Opts are utilized.
                                                        size. This is our baseline ILK algorithm, abbreviated as ILK-1-
In addition, in the second phase, biased starting tours can be
                                                        run. In addition, we used two different conÔ¨Ågurations of ILK


used as well to improve local minima and speed up the search.
                                                                                            ¬©¬ß
                                                        in our experiments: the best of Ô¨Åve runs of . iterations (i.e.,
In our experiments, we found that setting aside 30% of the total
                                                        ILK with four random restarts), which is named as ILK-5-runs,
runs for learning was generally effective.

                                                        and the best of ten runs of ¬ß iterations, which is called ILK-10-
  A  few issues must be dealt with to combine pseudo-
                                                        runs. We conÔ¨Ågured IBGLK as follows. It Ô¨Årst runs 30 rounds
backbone utilization with ILK, the iterated LK algorithm, in
                                                        of ILK, each of which starts from a random tour and is allowed


deriving iterative BGLK (IBGLK). First, pseudo-backbone


                                                        *¬ß ?¬•
                                                        ¬ß    iterations. It then executes 70 rounds of ILK with biased
must be constructed from ‚Äúunbiased samples‚Äù of local minima.
                                                        moves and biased greedy initial tours, each of which is also


Since each local minimum found via ILK typically differs in


                                                                *¬ß ?¬•
                                                        allocated ¬ß  iterations. All algorithms used the same total
only a small number of edges from its progenitor, a sampling
                                                        number of Ô¨Çips to give a relatively fair comparison.
of local minima from such a chained process is biased, and
                                                          Our experiments were run on 1.6 and 2.0 GHz AMD Ath-
should not be averaged into the backbone. To deal with this,
                                                        elon machines with 2 gigabytes of memory. All runtimes are
we construct a backbone in our experiments from 30 indepen-
                                                        normalized for a 500 Mhz Alpha, as described in [9], so that
dent rounds, i.e., restarts, of ILK, each of which is allowed a
                                                        our results and the previous results can be directly compared.
smaller number of iterations, such as 1% of the total number of
iterations. Another issue is that we would like to follow each 4.1 The TSP Challenge suite
round of BGLK  by a round of regular search using the orig- We experimentally validate our claim that BGLS allows local
inal distances. However, since BGLK uses ‚Äúweighted‚Äù costs, search methods to reach better local minima, using problem            N=1000     N=3162     N=10K     N=31K                      N=1000   N=3162    N=10K     N=31K
     Opti 0.74   ‚Äî   0.70   ‚Äî   ‚Äî     ‚Äî    ‚Äî     ‚Äî            Optimal 0.74 ‚Äî  0.70  ‚Äî    ‚Äî    ‚Äî    ‚Äî    ‚Äî
     LK   1.38  (8.8) 1.56 (33.0) 1.79 (83.2) 1.83 (232.9)   ILK-1-run 0.82 (58) 0.78 (294) 0.81 (1619) 0.89 (8371)
  U  Redu 1.30  (5.2) 1.59 (18.1) 1.80 (43.8) 1.84 (117.0) U ILK-5-run 0.77 ‚Äî 0.80  ‚Äî   0.80  ‚Äî   0.85  ‚Äî
     Smoo 1.21   ‚Äî   1.46   ‚Äî  1.58   ‚Äî   1.55   ‚Äî           ILK-10-run 0.78 ‚Äî 0.82 ‚Äî   0.86  ‚Äî   0.98  ‚Äî
     BGLK 1.07 (12.1) 1.15 (53.4) 1.2 (147.0) 1.19 (441.2)    IBGLK  0.77 (78) 0.77 (411) 0.77 (2311) 0.77 (11760)
     Opti 0.54   ‚Äî   0.59   ‚Äî   ‚Äî     ‚Äî    ‚Äî     ‚Äî            Optimal 0.54 ‚Äî  0.59  ‚Äî    ‚Äî    ‚Äî    ‚Äî    ‚Äî
     LK   1.81 (226.9) 3.42 (625.0) 5.67 (1241.7) 5.63 (3013.3) ILK-1-run 0.55 (1469) 0.62 (6645) 0.84 (22859) 1.14 (88077)
  C  Redu 1.51 (103.8) 3.36 (290.7) 5.19 (494.9) 6.01 (1132.8) C ILK-5-run 0.54 ‚Äî 0.62 ‚Äî 0.76 ‚Äî   1.06  ‚Äî
     Smoo 2.16   ‚Äî   3.70   ‚Äî  6.08   ‚Äî   6.08   ‚Äî           ILK-10-run 0.54 ‚Äî 0.63 ‚Äî   0.73  ‚Äî   1.01  ‚Äî
     BGLK 1.30 (322.3) 2.54 (1032.3) 4.90 (2120.8) 4.58 (5238.7) IBGLK 0.55 (1281) 0.62 (5764) 0.78 (23311) 0.94 (93759)
     Opti 0.02   ‚Äî   0.00   ‚Äî  0.00   ‚Äî    ‚Äî     ‚Äî            Optimal 0.02 ‚Äî  0.00  ‚Äî   0.00  ‚Äî    ‚Äî    ‚Äî
     LK   2.45 (19.9) 3.87 (63.1) 5.30 (339.3) ‚Äî ‚Äî           ILK-1-run 0.58 (106) 1.34 (860) 2.70 (8230) ‚Äî ‚Äî
  M  Redu 2.24 (16.0) 3.72 (49.1) 5.19 (270.3) ‚Äî ‚Äî        M  ILK-5-run 0.85 ‚Äî 1.34  ‚Äî   2.09  ‚Äî    ‚Äî    ‚Äî
     Smoo 1.60   ‚Äî   2.79   ‚Äî  4.27   ‚Äî    ‚Äî     ‚Äî           ILK-10-run 0.89 ‚Äî 1.94 ‚Äî   3.44  ‚Äî    ‚Äî    ‚Äî
     BGLK 0.90 (30.9) 1.77 (79.0) 2.58 (405.0) ‚Äî ‚Äî            IBGLK  0.20 (139) 0.79 (1221) 1.48 (11360) ‚Äî ‚Äî

Table 1: Comparison of LK, reduction, smoothing and BGLK Table 2: Comparison of ILK (ILK-1-run), its variations (ILK-
on problems from the Challenge suite on Uniform (U), Clus- 5-run and ILK-10-run), and IBGLK on problems from the
tered (C) and matrix (M) problem instances. The numbers are Challenge suite. The legend and interpretation of the table are
tour costs over Held-Karp bounds in %, and normalized CPU the same as those for Table 1.
times in seconds (in parentheses).
                                                        to improve tour quality. IBGLK‚Äôs performance appears to re-
instances from the Challenge suite. We examine the results main constant (i.e., 0.77%) relative to the Held-Karp bound as
from four different perspectives.                       the problem size increases, while ILK‚Äôs performance degrades.
  In the Ô¨Årst test, we compared BGLK against LK, LK with Although IBGLK runs longer than ILK, due to the extra time
reduction, and LK with search space smoothing. The LK algo- needed to construct and apply the pseudo-backbone, the over-
rithm has 100 runs; the reduction method uses an initial prob- head never exceeds 50% of ILK‚Äôs runtime, and it appears that
ing stage of 30-run of LK, followed by 70-run of LK with re- IBGLK‚Äôs and ILK‚Äôs runtimes are asymptotically close to each


duction; the smoothing method has 20 runs total, each of which other. For clustered problem class, IBGLK, ILK and its vari-


                       2   ¬°¬°¬°  ?
runs LK Ô¨Åve times, for           . These algorithms all ations‚Äô performances are compatible with one another. Inter-
used greedy initial tours and had a total of 100 runs. BGLK estingly, IBGLK actually runs faster than ILK on some of the
executes an initial 30-run of LK, using random starting tours, clustered instances. For this instance class, IBGLS‚Äôs lack of
to learn pseudo-backbone, and then 70 runs of LK with biased signiÔ¨Åcant improvement over ILK can be attributed to the fact


moves  and biased initial tours. The sizes ¬ß of problem in- that ILK is already effective and close to the optimum; there


stances are 1000, 3162, 10000, and 31623, increased by a fac- is little room for improvement. On the distance matrix class,


     ¬°
       ¬•
tor of ? , following the scheme proposed and used in [9]. For similar to BGLK versus LK, IBGLK is signiÔ¨Åcantly superior to
each problem class and size, 100 random problem instances ILK on each of the individual instances of different sizes, and


were used for each algorithm. Table 1 shows the averaged re- reduces average tour costs by more than 0.6% on the largest


                                                           2  ?¬•  ¬• ¬•¬•
sults. For comparison, percent over the Held-Karp bounds for ( ¬ß    ) instances tested. In addition, among ILK and
optimal tours is listed when known.                     its variants, ILK-1-run has the fastest running times, and its
  As shown, while the reduction and smoothing methods pro- two variants are 5%-10% slower.
vide modest improvements over LK in certain instance classes In the third experiment, we considered relatively small in-
and sizes, they are respectively the worst among all algorithms stances of 1,000 cities and compared the local minima from
tested on the Euclidean and clustered Euclidean classes. In LK, ILK and IBGLK against the optimal solutions. We used
contrast, BGLK is consistently superior, outperforming all the 100 instances for each of the problem classes in the Challenge
other three methods across all instance classes and sizes. The suite. For each instances and each algorithm, we averaged
improvement of BGLK over these algorithms varies from 0.3% three runs with different random seeds. As the result shows,
to 1.7% on the largest problem instances of these classes. Note IBGLK generally produces solutions of higher quality on aver-
that the average running time of BGLK was no more than twice age. Interestingly, it seems that more powerful search methods
the time by LK. Interestingly, BGLK actually ran faster than produce not only better, but more diverse solutions, as quanti-
LK  on some instances, presumably due to its faster focus on Ô¨Åed by the standard deviations of the Hamming distances be-
promising areas. Note also that the reduction method‚Äôs run- tween the structures of local minima and the optimal solutions
ning times signiÔ¨Åcantly less than that of IL, while the smooth- (data not shown). Figure 1 graphically shows relative perfor-
ing method‚Äôs runtimes are essentially identical to LK‚Äôs. mances of ILK and IBGLK on individual instances in the test,
  In the second experiment, we compared IBGLK against   indicating that IBGLK is favorable to ILK on most of the prob-
ILK (ILK-1-run) and its two variants (ILK-5-runs and ILK-10- lem instances.
runs). We used the same problem instances as in the Ô¨Årst exper- Additional insight can be gained by an inspection of the
iment, and computed the results the same way as in that exper- anytime behavior of these algorithms. As shown in Figure 2,
iment. The results are shown in Table 2, where we adopted the BGLK‚Äôs anytime behavior is remarkably different from that
same reporting scheme as in Table 1. As shown, the two ILK of LK and its variants. To begin with, LK outpaces BGLK,
variations do not provide much improvement over the baseline since LK is being run from greedy starting tours, while BGLK
ILK, while IBGLK is able to push signiÔ¨Åcantly closer to opti- must be run from random tours to construct a reliable pseudo-
mal than ILK for most cases where ILK does not perform very backbone (see Section 3). But once BGLK begins using the
well. For uniform Euclidean instances, as ILK does not reach pseudo-backbone to guide the search, its rate of descent in-
the optimum for these instances, IBGLK has a good chance creases, and the tables are turned on their performance. Qual-                     Uniform                           Clustered                         Matrix
     0.0025                             0.0008                            0.006

                                        0.0006                           0.0055
      0.002
                                        0.0004                            0.005
     0.0015
                                        0.0002                           0.0045

      0.001                               0                               0.004

     0.0005                            -0.0002                           0.0035
                                       -0.0004                            0.003
                                      Difference  in Quality
    Difference  in Quality 0                                            Difference  in Quality
                                       -0.0006                           0.0025
     -0.0005
                                       -0.0008                            0.002

      -0.001                            -0.001                           0.0015
        -0.1 -0.05 0    0.05  0.1  0.15   -0.06 -0.05 -0.04 -0.03 -0.02 -0.01 0 0.01 0.02 0.03 0.04 0 0.01 0.02 0.03 0.04 0.05 0.06 0.07 0.08


               Difference in Distance to Optimal  Difference in Distance to Optimal Difference in Distance to Optimal


                                                                                                ¬°¬† ¬•


Figure 1: Comparison of local minima from ILK and IBGLK for 100 problems with 1,000 cities each. Points with  indicate


                                                ¬¢¬†¬¶¬•
that IBGLK‚Äôs solutions are of higher quality, points with + indicate that IBGLK‚Äôs solutions are closer to optimal. Both axes
are normalized.

                                                                        % over the Held-Karp bound runtime in seconds
itatively similar anytime performance results have been found Name ILK-1 ILK-5 ILK-10 IBGLK Optimal ILK-1 IBGLK
on large problem sizes and when comparing IBGLK with ILK. dsj1000 0.61 0.62  0.62   0.62  0.61   2097   2066
                                                         pr1002   0.89 0.89  1.04   0.89  0.89    300   345
4.2   Instances from the TSPLIB                          si1032   0.15 0.08  0.08   0.08  0.08    610   772
                                                         u1060    0.65 0.67  0.67   0.67  0.65    870   873
Table 3 contains the results for ILK, its variants, and IBGLK, vm1084 1.37 1.35 1.35 1.35 1.33    403   403
on all the instances in the TSPLIB that have at least 1,000 pcb1173 0.97 0.98 0.97  0.96  0.96    161   213
                                                         d1291    1.31 1.23  1.18   1.26  1.18   1099   1086
cities. On many of the instances, unfortunately, ILK is al- rl1304 1.55 1.55 1.55   1.55  1.55    457   504
ready at or near the optimum, so there is very little room for rl1323 1.66 1.66 1.65 1.65 1.65    470   582
                                                         nrw1379  0.47 0.51  0.43   0.49  0.43    274   440
improvement. Again, in most places where further improve- Ô¨Ç1400  1.74  1.74  1.74  1.74   1.74  22548  19317
                                                         u1432    0.44 0.38  0.38   0.29  0.29    319   617
ments are possible, IBGLK produces them. On this set of in- Ô¨Ç1577 1.68 1.66  1.66  1.66   1.66   9072  10430
stances, IBGLK championed on 20 of them (the ones in bold d1655   1.19 0.92  0.95   0.91  0.91   1808   1869
                                                         vm1748   1.35 1.38  1.35   1.36  1.35    893   829
and underlined), whereas ILK and its variants came Ô¨Årst on u1817  1.08 1.13  1.17   1.06  0.90    468   680
12 instances (with some overlaps). Note that on the largest rl1889 1.74 1.64 1.55   1.77  1.55   1028   1110
                                                         d2103    1.44 1.44  1.44   1.44  1.44   3407   8669
instances (the ones with more than 10,000 cities), IBGLK pro- u2152 0.96 0.77 0.79  0.81  0.62    597   808
duces signiÔ¨Åcant gains over ILK. The runtimes were from our u2319 0.13 0.13  0.13   0.06  0.02   1182   2091
                                                         pr2392   1.27 1.28  1.37   1.36  1.22    503   715
AMD   Athelon machines and then normalized to a 500MHz   pcb3038  0.91 0.88  0.93   0.94  0.81    854   1178
                   [ ]                                   Ô¨Ç3795   1.04  1.04  1.05  1.07   1.04  45789  52460
Alpha as suggested in 9 .                                fnl4461  0.66 0.67  0.69   0.63  0.55   1613   2505
                                                         rl5915   1.58 1.62  1.58   1.62  1.56   2963   4766
5   Related  Methods   and Discussions                   rl5934   1.53 1.39  1.56   1.54  1.38   3714   5250
                                                         pla7397  0.61 0.72  0.63   0.63  0.58   18338 20716
The most closely related work is our previous work on back- rl11849 1.13 1.17 1.21  1.15  1.02   9421  15301
bone guided Walksat for maximum satisÔ¨Åability [16]. The  usa13509 0.78 0.76  0.83   0.72  0.66   20829 26339
                                                         brd14051 0.61 0.63  0.66   0.58  ‚Äî      28587 35048
backbone guided local search developed here for the TSP fol- d15112 0.66 0.68 0.72  0.63  0.52   21481 29709
lows the same principles developed there; and thus can be d18512  0.63 0.64  0.70   0.59  ‚Äî      21995 31916
                                                         pla33810 0.68 0.66  0.70   0.65  ‚Äî     148387 150455
viewed as an innovative extension to the work in [16]. This pla85900 0.56 0.58 0.62 0.52  ‚Äî     256808 247597
research was also inspired by and builds upon the previous re- # of bests 12 11 12  20
sults of the ‚Äúbig valley‚Äù hypothesis on the clustering of local
minima from the family of the Lin-Kernighan algorithm and Table 3: Comparison of all instances in TSPLIB with at least
its variants [1; 2; 10].                                1,000 cities. Numbers are tour costs over Held-Karp bounds in
  Two  pieces of previous work resemble BGLK in some way. % and normalized runtimes in seconds (for a 500 Mhz Alpha).
The Ô¨Årst is the reduction method by Lin and Kernighan [10].
As discussed earlier, reduction ‚Äúlocks in‚Äù the common edges
in all local minima. This has two effects: it can speed up the swapped out of the current tour during the search, albeit with a
search, as the problem becomes smaller, and provides a means slim possibility. This allows more tours be explored while still
of directing search among a set of otherwise indistinguishable maintaining a focused search.
tours. The main limitation of this method is that it is brittle, The second related work is search space smoothing [4],
depending on the quality of the ‚Äúlocked in‚Äù edges. If a ‚Äúlocked which was brieÔ¨Çy described in Section 4. Gu and Huang


in‚Äù edge turns out not to be part of the backbone, no optimal only experimented with this idea with a 2-Opt algorithm and


                                                ¬§¬£¬¶¬• !
tour will be found. Moreover, information such as ‚Äúedge  on small random Euclidean problems with no more than 100
appears in 90% of all local minima‚Äù cannot be utilized, thus it cities. They did not compare their method to other techniques.
simply disregards potentially useful information of backbone Our results in Section 4 showed that smoothing outperforms
frequencies. The results in [10], up to 318 cities, is too lim- LK on uniform and matrix instances. However, it is less efÔ¨Å-
ited to provide a fair assessment of this method. Our results in cient than BGLK and ILK.
Section 4 revealed that reduction is not competitive.     Although both smoothing and backbone guided search all
  BGLS  is more general than reduction by providing a remedy modify distances, they are fundamentally different. First, mod-
to the problem of brittleness and making use of information ifying distances is just one of the end products of the backbone
embedded  in backbone frequencies. BGLS is a random strat- guided search for the TSP. In fact, when applied to maximum
egy, in which edges that appear in all local minima may still be satisÔ¨Åability, backbone guided local search did not change
                     Learning and Inference over Constrained Output

              Vasin Punyakanok           Dan Roth         Wen-tau Yih          Dav Zimak
                                    Department of Computer Science
                              University of Illinois at Urbana-Champaign
                       {punyakan, danr, yih, davzimak}@uiuc.edu


                    Abstract                          tional random Ô¨Åelds [Lafferty et al., 2001], Perceptron-based
                                                      learning of structured output [Collins, 2002; Carreras and
    We study learning structured output in a discrimi- M`arquez, 2003] and Max-Margin Markov networks which
    native framework where values of the output vari- allow incorporating Markovian assumptions among output
    ables are estimated by local classiÔ¨Åers. In this  variables [Taskar et al., 2004].
    framework, complex dependencies among the out-
                                                        Incorporating constraints during training can lead to solu-
    put variables are captured by constraints and dictate
                                                      tions that directly optimize the true objective function, and
    which global labels can be inferred. We compare
                                                      hence, should perform better. Nonetheless, most real world
    two strategies, learning independent classiÔ¨Åers and
                                                      applications using this technique do not show signiÔ¨Åcant ad-
    inference based training, by observing their behav-
                                                      vantages, if any. Therefore, it is important to discover the
    iors in different conditions. Experiments and theo-
                                                      tradeoffs of using each of the above schemes.
    retical justiÔ¨Åcation lead to the conclusion that using
    inference based learning is superior when the lo-   In this paper, we compare three learning schemes. In
    cal classiÔ¨Åers are difÔ¨Åcult to learn but may require the Ô¨Årst, classiÔ¨Åers are learned independently (learning only
    many examples before any discernible difference   (LO)), in the second, inference is used to maintain struc-
    can be observed.                                  tural consistency only after learning (learning plus inference
                                                      (L+I)), and Ô¨Ånally inference is used while learning the pa-
                                                      rameters of the classiÔ¨Åer (inference based training (IBT)). In
1  Introduction                                       semantic role labeling (SRL), it was observed [Punyakanok
Making decisions in real world problems involves assigning et al., 2004; Carreras and M`arquez, 2003] that when the lo-
values to sets of variables where a complex and expressive cal classiÔ¨Åcation problems are easy to learn, L+I outperforms
structure can inÔ¨Çuence, or even dictate, what assignments are IBT. However, when using a reduced feature space where the
possible. For example, in the task of identifying named enti- problem was no longer (locally) separable, IBT could over-
ties in a sentence, prediction is governed by constraints like come the poor local classiÔ¨Åcations to yield accurate global
‚Äúentities do not overlap.‚Äù Another example exists in scene in- classiÔ¨Åcations.
terpretation tasks where predictions must respect constraints Section 2 provides the formal deÔ¨Ånition of our problem.
that could arise from the nature of the data or task, such as For example, in Section 3, we compare the three learning
‚Äúhumans have two arms, two legs, and one head.‚Äù       schemes using the online Perceptron algorithm applied in the
  There exist at least three fundamentally different solutions three settings (see [Collins, 2002] for details). All three set-
to learning classiÔ¨Åers over structured output. In the Ô¨Årst, tings use the same linear representation, and L+I and IBT
structure is ignored; local classiÔ¨Åers are learned and used share the same decision function space. Our conjectures of
to predict each output component separately. In the sec- the relative performance between different schemes are pre-
ond, learning is decoupled from the task of maintaining struc- sented in Section 4. Despite the fact that IBT is a more pow-
tured output. Estimators are used to produce global out- erful technique, in Section 5, we provide an experiment that
put consistent with the structural constraints only after they shows how L+I can outperform IBT when there exist accu-
are learned for each output variable separately. Discrimina- rate local classiÔ¨Åers that do not depend on structure, or when
tive HMM, conditional models [Punyakanok and Roth, 2001; there are too few examples to learn complex structural depen-
McCallum  et al., 2000] and many dynamic programming  dencies. This is also theoretically justiÔ¨Åed in Section 6.
based schemes used in the context of sequential predictions
fall into the this category. The third class of solutions in- 2 Background
corporates dependencies among the variables into the learn-
ing process to directly induce estimators that optimize a Structured output classiÔ¨Åcation problems have many Ô¨Çavors.
global performance measure. Traditionally these solutions In this paper, we focus on problems where it is natural both
were generative; however recent developments have pro- to split the task into many smaller classiÔ¨Åcation tasks and to
duced discriminative models of this type, including condi- solve directly as a single task. In Section 5.2, we consider thesemantic role-labeling problem, where the input X are nat- 3 Learning
ural language features and the output Y is the position and We present several ways to learn the scoring function pa-
type of a semantic-role in the sentence. For this problem, rameters differing in whether or not the structure-based in-
one can either learn a set of local functions such as ‚Äúis this ference process is leveraged during training. Learning con-
phrase an argument of ‚Äôrun‚Äô,‚Äù or a global classiÔ¨Åer to pre-
                                                      sists of choosing a function h : X ‚àó ‚Üí Y‚àó from some hy-
dict all semantic-roles at once. In addition, natural structural
                                                      pothesis space, H. Typically, the data is supplied as a set
constraints dictate, for example, that no two semantic roles
                                                      D  =  {(x , y ), . . . , (x , y )} from a distribution P
for a single verb can overlap. Other structural constraints, as 1 1        m   m                      X ,Y
                                                      over X ‚àó √ó Y‚àó. While these concepts are very general, we fo-
well as linguistic constraints yield a restricted output space in cus on online learning of linear representations using a variant
which the classiÔ¨Åers operate.                         of the Perceptron algorithm (see [Collins, 2002]).
  In general, given an assignment x  nx to a collec-
                                 ‚àà  X                   Learning Local ClassiÔ¨Åers: Learning stand-alone local
tion of input variables, X = (X , . . . , X ), the struc-
                              1       nx              classiÔ¨Åers is perhaps the most straightforward setting. No
tured classiÔ¨Åcation problem involves identifying the ‚Äúbest‚Äù
                                                      knowledge of the inference procedure is used. Rather, for
assignment y ‚àà  Yny to a collection of output variables
                                                      each example (x, y) ‚àà D, the learning algorithm must en-
Y = (Y  , . . . , Yn ) that are consistent with a deÔ¨Åned struc-
       1       y                                      sure that f (x, t) > f 0 (x, t) for all t = 1, . . . , n and all
ture on Y. This structure can be thought of as constraining    yt         y                      y
                                                      y0 6= y . In Figure 3(a), an online Perceptron-style algorithm
the output space to a smaller space C(Yny ) ‚äÜ Yny , where   t
     ‚àó      ‚àó                                                                                       [
    Y     Y                                           is presented where no global constraints are used. See Har-
C : 2  ‚Üí 2   constrains the output space to be structurally Peled et al., 2003] for details and Section 5 for experiments.
consistent.                                             Learning Global ClassiÔ¨Åers: We seek to train classiÔ¨Åers
  In this paper, a structured output classiÔ¨Åer is a function so they will produce the correct global classiÔ¨Åcation. To this
      nx       ny
h :  X    ‚Üí   Y  , that uses a global scoring function, end, the key difference from learning locally is that feed-
     nx    ny
f : X   √ó Y   ‚Üí  IR to assign scores to each possible ex- back from the inference process determines which classiÔ¨Åers
ample/label pair. Given input x, it is hoped that the correct to modify so that together, the classiÔ¨Åers and the inference
output y achieves the highest score among consistent outputs: procedure yield the desired result. As in [Collins, 2002;
            yÀÜ = h(x) = argmax f(x, y0),        (1)   Carreras and M`arquez, 2003], we train according to a global
                       y0‚ààC(Yny )                     criterion. The algorithm presented here is an online proce-
                                                      dure, where at each step a subset of the classiÔ¨Åers are up-
where nx and ny depend on the example at hand. In addition, dated according to inference feedback. See Figure 3(b) for
we view the global scoring function as a composition of a set details of a Perceptron-like algorithm for learning with infer-
                                              nx
of local scoring functions {fy(x, t)}y‚ààY , where fy : X √ó ence feedback.
{1, . . . , ny} ‚Üí IR. Each function represents the score or Note that in practice it is common for problems to be mod-
conÔ¨Ådence that output variable Yt takes value y:      eled in such a way that local classiÔ¨Åers are dependent on part
                              ny                      of the output as part of their input. This sort of interaction can
                                                      be incorporated directly to the algorithm for learning a global
          f(x, (y1, . . . , yny )) = fyt (x, t)
                             Xt=1                     classiÔ¨Åer as long as an appropriate inference process is used.
                                                      In addition, to provide a fair comparison between LO, L+I,
  Inference is the task of determining an optimal assign- and IBP in this setting one must take care to ensure that the
ment y given an assignment x. For sequential structure learning algorithms are appropriate for this task. In order to
of constraints, polynomial-time algorithms such as Viterbi remain focused on the problem of training with and without
or CSCL [Punyakanok and Roth, 2001] are typically used inference feedback, the experiments and analysis presented
for efÔ¨Åcient inference. For general structure of constraints, concern only the local classiÔ¨Åers without interaction.
a generic search method (e.g., beam search) may be ap-
plied. Recently, integer programming has also been shown
to be an effective inference approach in several NLP applica- 4 Conjectures
tions [Roth and Yih, 2004; Punyakanok et al., 2004].  In this section, we investigate the relative performance of
  In this paper, we consider classiÔ¨Åers with linear rep- classiÔ¨Åer systems learned with and without inference feed-
resentation. Linear local classiÔ¨Åers are linear functions, back. There are many competing factors. Initially, if the lo-
            y    y             y      dy
fy(x, t) = Œ±  ¬∑ Œ¶ (x, t), where Œ± ‚àà IR   is a weight  cal classiÔ¨Åcation problems are ‚Äúeasy‚Äù, then it is likely that
vector and Œ¶y(x, t) ‚àà IRdy is a feature vector. Then, learning local classiÔ¨Åers only (LO) can yield the most accu-
it is easy to show that the global scoring function can rate classiÔ¨Åers. However, an accurate model of the structural
be written in the familiar form f(x, y) = Œ± ¬∑ Œ¶(x, y), constraints could additionally increase performance (learning
                   n
       y            y   yt                            plus inference (L+I)). As the local problems become more
where Œ¶ (x, y) =   t=1 Œ¶ (x, t)I{yt=y} is an accumula-
tion over all outputP variables of features occurring for class difÔ¨Åcult to learn, an accurate model of the structure becomes
y, Œ± =  (Œ±1, . . . , Œ±|Y|) is concatenation of the Œ±y‚Äôs, and more important, and can, perhaps, overcome sub-optimal lo-
Œ¶(x, y) = (Œ¶1(x, y), . . . , Œ¶|Y|(x, y)) is the concatenation cal classiÔ¨Åers. Despite the existence of a global solution, as
of the Œ¶y(x, y)‚Äôs. Then, the global classiÔ¨Åer is      the local classiÔ¨Åcation problems become increasingly difÔ¨Å-
                                                      cult, it is unlikely that structure based inference can Ô¨Åx poor
          h(x) = yÀÜ = argmax Œ± ¬∑ Œ¶(x, y0).            classiÔ¨Åers learned locally. In this case, only training with in-
                     y0‚ààC(Yny )                       ference feedback (IBT) can be expected to perform well.                                                      Claim 4.1 With a Ô¨Åxed number of examples:
         Algorithm ONLINELOCALLEARNING
                     X,Y     ‚àó    ‚àó m                   1. If the local classiÔ¨Åcation tasks are separable, then L+I
             INPUT: D    ‚àà {X √ó Y  }                      outperforms IBT.
             OUTPUT: {fy}   ‚àà H
                         y‚ààY                            2. If the task is globally separable, but not locally sepa-
                            y
             Initialize Œ±y ‚àà IR|Œ¶ | for y ‚àà Y             rable then IBT outperforms L+I only with sufÔ¨Åcient ex-
             Repeat until converge                        amples. This number correlates with the degree of the
               for each (x, y) ‚àà DX,Y do                  separability of the local classiÔ¨Åers.
                 for t = 1, . . . , ny do
                              Œ±y    y
                   yÀÜt = argmaxy ¬∑ Œ¶ (x, t)           5   Experiments
                   if yÀÜt 6= yt then
                      y     y    y                    We present experiments to show how the relative performance
                     Œ± t = Œ± t + Œ¶ t (x, t)
                      y     y    y                    of learning plus inference (L+I) compares to inference based
                     Œ±ÀÜt = Œ±ÀÜt ‚àí Œ¶ÀÜt (x, t)
                                                      training (IBT) when the quality of the local classiÔ¨Åers and
                                                      amount of training data varies.
             (a) Without inference feedback
                                                      5.1  Synthetic Data
                                                      In our experiment, each example x is a set of c points in d-
        Algorithm ONLINEGLOBALLEARNING                                                                d
                   X,Y     ‚àó    ‚àó m                   dimensional real space, where x = (x1, x2, . . . , xc) ‚àà IR √ó
            INPUT: D   ‚àà {X  √ó Y }                           d
            OUTPUT: {fy}   ‚àà H                        . . . √ó IR and its label is a sequence of binary variable, y =
                       y‚ààY                                              c
                                                      (y1, . . . , yc) ‚àà {0, 1} , labeled according to:
            Initialize Œ± ‚àà IR|Œ¶|
            Repeat until converge
                             X,Y                          y = h(x) = argmax    yifi(xi) ‚àí (1 ‚àí yi)fi(xi),
             for each (x, y) ‚àà D do                                       c
                                                                     y‚ààC(Y ) Xi
               yÀÜ = argmax    ny Œ± ¬∑ Œ¶(x, y)
                         y‚ààC(Y  )                              c                   c
               if yÀÜ 6= y then                        where C(Y ) is a subset of {0, 1} imposing a random con-
                                                           1
                 Œ± = Œ± + Œ¶(x, y) ‚àí Œ¶(x, yÀÜ)           straint on y, and fi(xi) = wixi +Œ∏i. Each fi corresponds to

                                                      a local classiÔ¨Åer yi = gi(xi) = Ifi(xi)>0. Clearly, the dataset
              (b) With inference feedback             generated from this hypothesis is globally linearly separable.
                                                      To vary the difÔ¨Åculty of local classiÔ¨Åcation, we generate ex-
                                                      amples with various degree of linear separability of the lo-
Figure 1: Algorithms for learning without and with infer- cal classiÔ¨Åers by controlling the fraction Œ∫ of the data where
ence feedback. The key difference lies in the inference step h(x) 6= g(x) = (g1(x1), . . . , gc(xc))‚Äîexamples whose la-
(i.e. argmax). Inference while learning locally is trivial bels, if generated by local classiÔ¨Åers independently, violate
and the prediction is made simply by considering each la- the constraints (i.e. g(x) ‚àà/ C(Yc)).
bel locally. Learning globally uses a global inference (i.e. Figure 2 compares the performance of different learning
argmaxy‚ààC(Yny )) to predict global labels.            strategies relative to the number of training examples used.
                                                      In all experiments, c = 5, the true hypothesis is picked at ran-
                                                      dom, and C(Yc) is a random subset with half of the size of
  As a Ô¨Årst attempt to formalize the difÔ¨Åculty of classiÔ¨Åca- Yc. Training is halted when a cycle complete with no errors,
tion tasks, we deÔ¨Åne separability and learnability. A classi- or 100 cycles is reached. The performance is averaged over
Ô¨Åer, f ‚àà H, globally separates a data set D iff for all exam- 10 trials. Figure 2(a) shows the locally linearly separable case
                              0         0    n
ples (x, y) ‚àà D, f(x, y) > f(x, y ) for all y ‚àà Y y \ y where L+I outperforms IBT. Figure 2(c) shows results for the
and locally separates D iff for all examples (x, y) ‚àà D, case with the most difÔ¨Åcult local classiÔ¨Åcation tasks(Œ∫ = 1)
                                        0    ny
fyt (x, t) > fy(x, t) for all y ‚àà Y \ yt, and all y ‚àà Y \ y. where IBT outperforms L+I. Figure 2(b) shows the case
A learning algorithm A is a function from data sets to a H. where data is not totally locally linearly separable(Œ∫ = 0.1).
We say that D is globally (locally) learnable by A if there In this case, L+I outperforms IBT when the number of train-
exists an f ‚àà H such that f globally (locally) separates D. ing examples is small. In all cases, inference helps.
  The following simple relationships exist between local and
global learning: 1. local separability implies global separa- 5.2 Real-World Data
bility, but the inverse is not true; 2. local separability implies In this section, we present experiments on two real-world
local and global learnability; 3. global separability implies problems from natural language processing ‚Äì semantic role
global learnability, but not local learnability. As a result, it is labeling and noun phrase identiÔ¨Åcation.
clear that if there exist learning algorithms to learn global sep-
arations, then given enough examples, IBT will outperform Semantic-Role Labeling
L+I. However, learning examples are often limited either be- Semantic role labeling (SRL) is believed to be an important
cause they are expensive to label or because some learning task toward natural language understanding, and has imme-
algorithms simply do not scale well to many examples. With diate applications in tasks such Information Extraction and
a Ô¨Åxed number of examples, L+I can outperform IBT.
                                                         1Among the total 2c possible output labels, C(¬∑) Ô¨Åxes a random
                                                      fraction as legitimate global labels.           1                                             80

        0.95                                             75

         0.9
                                                         70
        0.85


        Accuracy                                         65
         0.8                                            F1
                                     LO
        0.75                         L+I                 60
                                     IBT
         0.7
           0    2000  4000 6000  8000  10000             55                                   LO
                   # Training examples
                                                                                              L+I
                                                                                              IBT
                                                         50
                  (a) Œ∫ = 0, d = 100                        3        4         5         6        7
                                                          10        10       10        10       10
                                                                   Separability (# Features)

        0.85                                          Figure 3: Results on the semantic-role labeling (SRL) problem. As
                                                      the number of features increases, the difÔ¨Åculty of the local classiÔ¨Å-
                                                      cation problem becomes easier, and the independently learned clas-
         0.8                                          siÔ¨Åers (LO) perform well, especially when inference is used after
                                                      learning (L+I). Using inference during training (IBT) can aid perfor-
        0.75                                          mance when the learning problem is more difÔ¨Åcult (few features).
        Accuracy

                                     LO
         0.7                         L+I                  [AM-LOC in my will].
                                     IBT              Here A0 represents leaver, A1 represents thing left, A2 rep-
          1000   2000    3000   4000    5000          resents benefactor, AM-LOC is an adjunct indicating the lo-
                   # Training examples                cation of the action, and V determines the verb.
                                                        We model the problem  using classiÔ¨Åers that map con-
                 (b) Œ∫  . , d
                     = 0 15  = 300                    stituent candidates to one of 45 different types, such as
                                                      fAO  and fA1 [Kingsbury and Palmer, 2002; Carreras and
          1                                           M`arquez, 2003]. However, local multiclass decisions are in-
                                                      sufÔ¨Åcient. Structural constraints are necessary to ensure, for
         0.9                                          example, that no arguments can overlap or embed each other.
                                                      In order to include both structural and linguistic constraints,
                                                      we use a general inference procedure based on integer linear
         0.8                                          programming [Punyakanok et al., 2004]. We use data pro-


        Accuracy                                      vided in the CoNLL-2004 shared task [Carreras and M`arquez,
                                                          ]
         0.7                         LO               2003 , but we restrict our focus to sentences that have greater
                                     L+I              than Ô¨Åve arguments. In addition, to simplify the problem, we
                                     IBT              assume the boundaries of the constituents are given ‚Äì the task
         0.6
           0    2000 4000  6000  8000  10000          is mainly to assign the argument types.
                   # Training examples                  The experiments clearly show that IBT outperforms lo-
                                                      cally learned LO and L+I when the local classiÔ¨Åers are in-
                  (c) Œ∫ = 1, d = 100                  separable and difÔ¨Åcult to learn. The difÔ¨Åculty of local learn-
                                                      ing was controlled by varying the number of input features.
Figure 2: Comparison of different learning strategies in various With more features, the linear classiÔ¨Åer are more expressive
degrees of difÔ¨Åculties of the local classiÔ¨Åers. Œ∫ = 0 implies locally and can learn effectively and L+I outperforms IBT. With less
linearly separability. Higher Œ∫ indicates harder local classiÔ¨Åcation. features the problem becomes more difÔ¨Åcult and IBT outper-
                                                      forms L+I. See Figure 3.
Question Answering. The goal is to identify, for each verb in Noun Phrase Labeling
the sentence, all the constituents which Ô¨Åll a semantic role, Noun phrase identiÔ¨Åcation involves the identiÔ¨Åcation of
and determine their argument types, such as Agent, Patient, phrases or of words that participate in a syntactic relation-
Instrument, as well as adjuncts such as Locative, Temporal, ship. SpeciÔ¨Åcally, we use the standard base Noun Phrases
Manner, etc. For example, given a sentence ‚Äú I left my pearls (NP) data set [Ramshaw and Marcus, 1995] taken from the
to my daughter-in-law in my will‚Äù, the goal is to identify dif- Wall Street Journal corpus in the Penn Treebank [Marcus et
ferent arguments of the verb left which yields the output: al., 1993].
    [A0 I] [V left ] [A1 my pearls] [A2 to my daughter-in-law] The phrase identiÔ¨Åer consists of two classiÔ¨Åers: one that   100                                                  We begin by deÔ¨Åning the growth function to measure the
                                                      effective size of the hypothesis space.

    80                                                DeÔ¨Ånition 6.1 (Growth Function) For a given hypothesis
                                                      class H consisting of functions h : X ‚Üí Y, the growth func-
                                                      tion, NH(m), counts the maximum number of ways to label
    60                                                any data set of size m:


  F1                                                    NH(m) =      sup    |{(h(x1), . . . , h(xm)) |h ‚àà H}|
                                                                           m
    40                                                           x1,...,xm‚ààX
                                                        The well-known VC-style generalization bound expresses
    20                                                expected error, , of the best hypothesis, hopt on unseen data.
                                                      In the following theorem adapted from [Anthony and Bartlett,
                                         L+I
                                         IBT          1999][Theorem 4.2], we directly write the growth function
     0
      0            2           4           6          into the bound,
    10           10          10          10
              Separability (# Features)               Theorem 6.2 Suppose that H is a set of functions from a set
                                                      X  to a set Y with growth function NH(m). Let hopt ‚àà H
Figure 4: Results on the noun phrase (NP) identiÔ¨Åcation prob- be the hypothesis that minimizes sample error on a sample of
lem.                                                  size m drawn from an unknown, but Ô¨Åxed probability distri-
                                                      bution. Then, with probability 1 ‚àí Œ¥

detects the beginning, f[, and a second that detects the end,           32(log(N  (2m)) + log(4/Œ¥))
                                                                                H                     (2)
f] of a phrase. The outcome of these classiÔ¨Åers are then com-  ‚â§ opt + r                        .
bined in a way that satisÔ¨Åes structural constraints constraints                     m
(e.g. non-overlapping), using an efÔ¨Åcient constraint satisfac- For simplicity, we Ô¨Årst describe the setting in which a sep-
tion mechanism that makes use of the conÔ¨Ådence in the clas- arate function is learned for each of a Ô¨Åxed number, c, of
siÔ¨Åers‚Äô outcomes [Punyakanok and Roth, 2001].         output variables (as in Section 5.1). Here, each example has
                                                                                             d          d
  In this case, L+I trains each classiÔ¨Åer independently, and c components in input x = (x1, . . . , xc) ‚àà IR √ó . . . √ó IR
                                                                                     c
only during evaluation, the inference is used. On the other and output y = (y1, . . . , yc) ‚àà {0, 1} .
hand, IBT incorporates the inference into the training. For Given a dataset D, the aim is to learn a set of linear scor-
                                                                                                d
each sentence, each word position is processed by the clas- ing functions fi(xi) = wixi, where wi ‚àà IR for each
siÔ¨Åers, and their outcomes are used by the inference process i = 1, . . . , c. For LO and L+I, the setting is simple: Ô¨Ånd
to infer the Ô¨Ånal prediction. The classiÔ¨Åers are then updated a set of weight vectors that, for each component, satisfy
based on the Ô¨Ånal prediction not on their own prediction be- yiwixi > 0 for all examples (x, y) ‚àà D. For IBT, we Ô¨Ånd
fore the inference.                                                                           0
                                                      a set of classiÔ¨Åers such that i yiwixi > i yiwixi for all
                                                       0                                0      c
  As in the previous experiment, Figure 4 shows perfor- y 6= y (and that satisfy the constraints,P y ‚ààPC(Y )).
mance of two systems varied by the number of features. Un- As previously noted, when learning local classiÔ¨Åers inde-
like the previous experiment, the number of features in each pendently (LO and L+I), one can only guarantee convergence
experiment was determined by the frequency of occurrence. when each local problem is separable ‚Äì however, it is often
Less frequent features are pruned to make the task more difÔ¨Å- the case that global constraints render these problems insepa-
cult. The results are similar to the SRL task in that only when rable. Therefore, there is a lower bound, opt, on the optimal
the problem becomes difÔ¨Åcult IBT outperforms L+I.     error achievable. Since each component is a separate learning
                                                      problem, the generalization error is thus
6  Bound Prediction                                   Corollary 6.3 When H is the set of separating hyperplanes
                                                          d
In this section, we use standard VC-style generalization in IR ,
bounds from learning theory to gain intuition into when learn-
                                                                        32(d log((em/d)) + log(4/Œ¥))
ing locally (LO and L+I) may outperform learning globally    ‚â§ opt +                            .   (3)
(IBT) by comparing the expressivity and complexity of each            r             m
hypothesis space. When learning globally, it is possible to
                                                      Proof sketch: We show that N (m) ‚â§ (em/d)d  when H
learn concepts that may be difÔ¨Åcult to learn locally, since the                  H
                                                      is the class of threshold linear functions in d dimensions.
global constraints are not available to the local algorithms.
                                                      NH(m)   is precisely the maximum number of continuous
On the other hand, while the global hypothesis space is more                                   d
expressive, it has a substantially larger representation. here regions an arrangement of m halfspaces in IR , which is
                                                          d   m‚àí1                  d
we develop two bounds‚Äîboth for linear classiÔ¨Åers on a re- 2 i=1 i  ‚â§  2(e(m ‚àí 1)/d) . For m >  1, the result
stricted problem. The Ô¨Årst upper bounds the generalization holds.P See  [Anthony and Bartlett, 1999][Theorem 3.1] for
error for learning locally by assuming various degrees of sep- details.
arability. The second provides an improved generalization On the other hand, when learning collectively with IBT,
bound for globally learned classiÔ¨Åers by assuming separabil- examples consist of the full vector x ‚àà IRcd. In this set-
ity in the more expressive global hypothesis space.   ting, convergence is guaranteed (if, of course, such a function
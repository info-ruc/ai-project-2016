        PsychSim:      Modeling    Theory    of  Mind   with   Decision-Theoretic      Agents

                              David  V. Pynadath   and Stacy  C. Marsella
                    Information Sciences  Institute, University of Southern California


                         4676  Admiralty Way,  Marina  del Rey, CA  90292 USA
                                      Â 


                                       marsella,pynadath Â¡ @isi.edu


                    Abstract                          that people must balance in a social interaction. For exam-
                                                      ple, psychological research has identiï¬ed a range of goals that
    Agent-based modeling of human social behavior     motivate classroom bullies (e.g., peer approval, sadism, tan-
    is an increasingly important research area. A key gible rewards). All bullies share the same goals, but it is the
    factor in human social interaction is our beliefs relative priorities that they place on them that leads to the
    about others, a theory of mind. Whether we be-    variations in their behavior. Resolving the ambiguity among
    lieve a message depends not only on its content   equally possible, but unequally plausible or preferred, options
    but also on our model of the communicator. How    requires a quantitative model of uncertainty and preference.
    we act depends not only on the immediate effect   Unfortunately, more quantitative frameworks, like decision
    but also on how we believe others will react. In  theory and game theory, face their own difï¬culties in model-
    this paper, we discuss PsychSim, an implemented   ing human psychology. Game theoretic frameworks typically
    multiagent-based simulation tool for modeling in- rely on concepts of equilibria that people rarely achieve in an
    teractions and inï¬‚uence. While typical approaches unstructured social setting like a classroom. Decision theoret-
    to such modeling have used ï¬rst-order logic, Psych- ical frameworks typically rely on assumptions of rationality
    Sim agents have their own decision-theoretic model that people constantly violate.
    of the world, including beliefs about its environ-
    ment and recursive models of other agents. Using    We  have developed a social simulation tool, PsychSim
    these quantitative models of uncertainty and pref- [Marsella et al., 2004], that operationalizes existing psycho-
    erences, we have translated existing psychological logical theories as boundedly rational computations to gen-
    theories into a decision-theoretic semantics that al- erate more plausibly human behavior. PsychSim allows a
    low the agents to reason about degrees of believ- user to quickly construct a social scenario where a diverse
    ability in a novel way. We discuss PsychSimâ€™s un- set of entities, groups or individuals, interact and communi-
    derlying architecture and describe its application to cate. Each entity has its own preferences, relationships (e.g.,
    a school violence scenario for illustration.      friendship, hostility, authority) with other entities, private be-
                                                      liefs, and mental models about other entities. The simulation
                                                      tool generates the behavior for these entities and provides ex-
1  Introduction                                       planations of the result in terms of each entityâ€™s preferences
People interact within a rich social framework. To better and beliefs. The richness of the entity models allows one to
understand peopleâ€™s social interactions, researchers have in- explore the potential consequences of minor variations on the
creasingly relied on computational models [Liebrand et al., scenario. A user can play different roles by specifying actions
1998; Prietula et al., 1998]. Models of social interaction or messages for any entity to perform.
have also been used to create social training environments A central aspect of the PsychSim design is that agents
where the learner explores high-stress social interactions in have fully speciï¬ed decision-theoretic models of others.
the safety of a virtual world [Marsella et al., 2000]. A key Such quantitative recursive models give PsychSim a power-
factor in human social interaction is our beliefs about others, ful mechanism to model a range of factors in a principled
a theory of mind [Whiten, 1991]. Our decisions to act are way. For instance, we exploit this recursive modeling to al-
inï¬‚uenced by how we believe others will react. Whether we low agents to form complex attributions about others, enrich
believe a message depends not only on its content but also the messages between agents to include the beliefs and prefer-
on our model of the communicator. Giving its importance in ences of other agents, model the impact such recursive mod-
human social interaction, modeling theory of mind can play els have on an agentâ€™s own behavior, model the inï¬‚uence ob-
a key role in enriching social simulations.           servations of anotherâ€™s behavior have on the agentâ€™s model of
  Typical approaches to modeling theory of mind in a com- that other, and enrich the explanations provided to the user.
putational framework have relied on ï¬rst-order logic to rep- The decision-theoretic models in particular give our agents
resent beliefs and goals. However, such representations are the ability to judge degree of credibility of messages in a sub-
often insensitive to the distinctions among conï¬‚icting goals jective fashion that can consider the range of inï¬‚uences thatsway such judgments in humans.                        For example, the bullyâ€™s attack on the victim impacts the
  The rest of this paper describes PsychSimâ€™s underlying ar- power of the bully, the power of the victim, etc. The dis-
chitecture in more detail, using a school bully scenario for tribution over the bullyâ€™s and victimâ€™s changes in power is a
illustration. The agents represent different people and groups function of the relative powers of the twoâ€”e.g., the larger
in the school setting. The user can analyze the simulated the power gap that the bully enjoys over the victim, the more
behavior of the students to explore the causes and cures for likely the victim is to suffer a big loss in power.
school violence. One agent represents a bully, and another
represents the student who is the target of the bullyâ€™s vio- 2.2 Preferences
lence. A third agent represents the group of onlookers, who PsychSimâ€™s decision-theoretic framework represents an
encourage the bullyâ€™s exploits by, for example, laughing at the agentâ€™s incentives for behavior as a reward function that maps
victim as he is beaten up. A ï¬nal agent represents the classâ€™s the state of the world into a real-valued evaluation of beneï¬t
teacher trying to maintain control of the classroom, for exam- for the agent. We separate components of this reward function
ple by doling out punishment in response to the violence. into two types of subgoals. A goal of Minimize/maximize
                                                      feature(agent)    corresponds to a negative/positive re-
2  The  Agent  Models                                 ward proportional to the value of the given state feature. For
We  embed PsychSimâ€™s agents within a decision-theoretic example, an agent can have the goal of maximizing its own
framework for quantitative modeling of multiple agents. Each power. A goal of Minimize/maximize action(actor,
agent maintains its independent beliefs about the world, has object) corresponds to a negative/positive reward propor-
its own goals and it owns policies for achieving those goals. tional to the number of matching actions performed. For ex-
The PsychSim framework is an extension to the Com-MTDP ample, the teacher may have the goal of minimizing the num-
model [Pynadath and Tambe, 2002] of agent teamwork. To ber of times any student teases any other.
extend the Com-MTDP framework to social scenarios (where We can represent the overall preferences of an agent,


the agents are pursuing their own goals, rather than those of as well as the relative priority among them, as a vec-


                                                                     "                      "$# Â¡Â£Â¢


                                                                                             Â   Â 
a team), we designed novel agent models for handling belief tor of weights, Â  , so that the product, , quan-


update and policy application, as described in Section 2.3. tiï¬es the degree of satisfaction that the agent receives
                                                                                                       Â¡Â£Â¢

                                                      from the world, as represented by the state vector, Â  .
2.1  Model  of the World                              For  example, in the school violence simulation, the
Each agent model starts with a representation of its current bullyâ€™s reward function consists of goals of maximiz-
state and the Markovian process by which that state evolves ing power(bully), minimizing power(victim), and
over time in response to the actions performed.       maximizing laugh(onlookers,     victim).   By modi-
                                                      fying the weights on the different goals, we can alter the mo-
State                                                 tivation of the agent and, thus, its behavior in the simulation.
Each agent model includes several features representing
its â€œtrueâ€ state. This state consists of objective facts 2.3 Beliefs about Others
about the world, some of which may be hidden from the
                                                      As described by Sections 2.1 and 2.2, the overall decision
agent itself. For our example bully domain, we included
                                                      problem facing a single agent maps easily into a partially
such state features as power(agent), to represent the
                                                      observable Markov decision problem (POMDP) [Smallwood
strength of an agent.  trust(truster,trustee)
                                                      and Sondik, 1973]. Software agents can solve such a deci-
represents the  degree  of   trust that  the  agent
                                                      sion problem using existing algorithms to form their beliefs
truster   has in another agent trusteeâ€™s  messages.
                                                      and then determine the action that maximizes their reward
support(supporter,supportee)       is the strength of
                                                      given those beliefs. However, we do not expect people to
support that an agent supporter has for another agent

                                          Â¡Â£Â¢         conform to such optimality in their behavior. Thus, we have

supportee.   We represent the state as a vector, Â  , where
                                                      taken the POMDP algorithms as our starting point and mod-
each component corresponds to one of these state features
                       Â¤Â¦Â¥Â¨Â§
Â©Â§                    iï¬ed them in a psychologically motivated manner to capture
and has a value in the range .
                                                      more human-like behavior. This â€œbounded rationalityâ€ better
Actions                                               captures the reasoning of people in the real-world, as well as
Agents have a set of actions that they can choose to change the providing the additional beneï¬t of avoiding the computational
world. An action consists of an action type (e.g., punish), complexity incurred by an assumption of perfect rationality.
an agent performing the action (i.e., the actor), and possi-
bly another agent who is the object of the action. For exam- Nested Beliefs


ple, the action laugh(onlooker,  victim)  represents  The simulation agents have only a subjective view of the


                                                                                  %
                                                                                  Â¢


the laughter of the onlooker directed at the victim.  world, where they form beliefs, Â  , about what they think is


                                                                          Â¡&Â¢


                                                                                   '                   (
                                                      the state of the world, Â  . Agent â€™s beliefs about agent
World Dynamics

                                                      have the same structure as the real agent ( . Thus, our agent
The state of the world changes in response to the actions per- belief models follow a recursive structure, similar to previous


formed by the agents. We model these dynamics using a tran-
                            Â©


                          Â©                           work on game-theoretic agents [Gmytrasiewicz and Durfee,


                         Â¡  Â¡Â£


                           Â  Â 
sition probability function, Â  , to capture the possibly 1995]. Of course, the nesting of these agent models is poten-


uncertain effects of these actions on the subsequent state: tially unbounded. However, although inï¬nite nesting is re-


                        Â©             Â© Â©


       


           Â¢  Â¢  Â¢            


          Â¡      Â¡ Â¡   Â¡     !    Â¡  Â¡ 


                 Â  Â     Â  Â    Â    Â  Â  Â 
         Â                                     (1)   quired for modeling optimal behavior, people rarely use suchdeep models [Taylor et al., 1996]. In our school violence sce- Stereotypical Mental Models
nario, we found that 2-level nesting was sufï¬ciently rich to If we applied this full lookahead policy within the nested
generate the desired behavior. Thus, the agents model each models of the other agents, the computational complexity of
other as 1-level agents, who, in turn, model each other as 0- the top-level lookahead would quickly become infeasible as
level agents, who do not have any beliefs. Thus, there is an the number of agents grew. To simplify the agentsâ€™ reasoning,
inherent loss of precision (but with a gain in computational these mental models are realized as simpliï¬ed stereotypes of
efï¬ciency) as we move deeper into the belief structure. the richer lookahead behavior models of the agents them-
  For example, an agentâ€™s beliefs may include its subjec- selves. For our simulation model of a bullying scenario, we
tive view on states of the world: â€œThe bully believes that the have implemented mental models corresponding to attention-
teacher is weakâ€, â€œThe onlookers believe that the teacher sup- seeking, sadistic, dominance-seeking, etc. For example, a
ports the victimâ€, or â€œThe bully believes that he/she is power- model of an attention-seeking bully speciï¬es a high prior-
ful.â€ These beliefs may also include its subjective view on be- ity on increasing the approval (i.e., support) that the other
liefs of other agents: â€œThe teacher believes that the bully be- agents have for it, a dominance-seeking bully speciï¬es a high
lieves the teacher to be weak.â€ An agent may also have a sub- priority on increasing its power as paramount, and a bully
jective view of the preferences of other agents: â€œThe teacher agent speciï¬es a high priority on hurting others.
believes that the bully has a goal to increase his power.â€ It These simpliï¬ed mental models also include potentially er-
is important to note that we also separate an agentâ€™s subjec- roneous beliefs about the policies of other agents. Although
tive view of itself from the real agent. We can thus represent the real agents use lookahead exclusively when choosing their
errors that the agent has in its view of itself (e.g., the bully own actions (as described in Section 2.3), the agents believe
believes himself to be stronger than he actually is). that the other agents follow much more reactive policies as
  Actions affect the beliefs of agents in several ways. For part of their mental models of each other. PsychSim models


example, the bullyâ€™s attack may alter the beliefs that agents reactive policies as a table of â€œCondition  Actionâ€ rules. The
have about the state of the worldâ€”such as beliefs about the left-hand side conditions may trigger on an observation of
bullyâ€™s power. Each agent updates its beliefs according to some action or a belief of some agent (e.g., such as the bully
its subjective beliefs about the world dynamics. It may also believing himself as powerful). The conditions may also be
alter the beliefs about the bullyâ€™s preferences and policy. We more complicated combinations of these basic triggers (e.g.,
discuss the procedure of belief update in Section 2.4. a conjunction of conditions that matches when each and every


Policies of Behavior                                  individual condition matches).


                                %
                                 




                                Â                        The use of these more reactive policies in the mental mod-
                              
Each agentâ€™s policy is a function, Â  , that represents the
process by which it selects an action or message based on its els that agents have of each other achieves two desirable re-
beliefs. An agentâ€™s policy allows us to model critical psycho- sults. First, from a human modeling perspective, the agents
logical distinctions such as reactive vs. deliberative behavior. perform a shallower reasoning that provides a more accurate
We model each agentâ€™s real policy as a bounded lookahead model of the real-world entities they represent. Second, from
procedure that seeks to maximize expected reward simulat- a computational perspective, the direct action rules are cheap
ing the behavior of the other agents and the dynamics of the to execute, so the agents gain signiï¬cant efï¬ciency in their


world in response to the selected action/message. Each agent reasoning.


                              %


Â¡


                               Â¢ Â¥ 


                              Â 
                           !


 computes a quantitative value, Â¢Â¤Â£ , of each possible ac- 2.4 Modeling Inï¬‚uence and Belief Change


                    %


                    Â¢ Â¥


tion, , given its beliefs, Â  .                        Messages


                                      Â© Â©


    %       %         %       %   %          %


                           


          Â¥                                Â¥


                                   Â¢      Â¢ 


     Â¢      Â¢         Â¢   Â¢ 


     Â¥       Â¥Â¨Â§
Â©


        " #                                    


                                   Â¥          Â¥


            Â          Â        Â     Â 


    Â                                                  Messages are attempts by one agent to inï¬‚uence the beliefs of


 Â¢Â¦Â£    Â           Â¢                  Â Â¨ Â  
                

                                               another. Messages have four components: source, recipients,
                                                (2)   subject, and content. For example, the teacher (source) could


                                                      tell the bully (recipient) that the principal (subject of the mes-


                                      Â©




    %       %         %
                              %   %      %


                           


          Â¥


                                   Â¢  Â¢




     Â¢      Â¢         Â¢
                               Â¢ 


             Â¥Â¨Â§
Â©




        " #              
                                              


                                   Â¥      Â¥








    Â 
            Â          Â 
                              Â 
                                   Â 








  Â¢ 
         Â           Â¢ 
                              
                                       Â 


                                       Â         (3)   sage) will punish violence by the bully (content). Messages
                
                                               can refer to beliefs, preferences, policies, or any other aspect
                                                      of other agents. Thus, a message may make a claim about a

Thus, an agent ï¬rst uses the transition function,  , to project


                                                     state feature of the subject (â€œthe principal is powerfulâ€), the
the immediate effect of the action, , and then projects an- beliefs of the subject (â€œthe principal believes that he is pow-



other  steps into the future, weighing each state against its
                           Â¡


     "                                                erfulâ€), the preferences of the subject (â€œthe bully wants to

goals, Â  . At the ï¬rst step, agent uses its model of the poli-

                           Â¥                          increase his powerâ€), the policy of the subject (â€œif the bully
cies of all of the other agents, Â  , and, in subsequent steps, it thinks the victim is weak, he will pick on himâ€), or the stereo-
uses its model of the policies of all agents, including itself, Â  . typical model of the subject (â€œthe bully is selï¬shâ€).
Thus, the agent is seeking to maximize the expected reward
of its behavior as in a POMDP. However, PsychSimâ€™s agents Inï¬‚uence Factors
are only boundedly rational, given that they are constrained, A challenge in creating a social simulation is addressing how



both by the ï¬nite horizon,  , of their lookahead and the pos- groups or individuals inï¬‚uence each other, how they update


                          %
                          Â 

sible error in their belief state, . By varying  for different their beliefs and alter behavior based on any partial observa-
agents, we can model entities who display different degrees tion of, as well as messages from, others. Although many
of reactive vs. deliberative behavior in their thinking. psychological results and theories must inform the modelingof such inï¬‚uence (e.g., [Cialdini, 2001; Abelson et al., 1968; responds to:




                     ]                                                           Â¡


                                                                              Â¦Â¥  Â©  Â©   Â©


Petty and Cacioppo, 1986 ) they often suffer from two short-                  Â©


                                                                            %


                                                                             Â¢            Â¢Â¨Â§ 
Â©


                                                                                              


                                                                            Â 


                                                                                      Â¢Â¤Â¢Â£Â¢


                                                                               Â   Â       Â 


comings from a computational perspective. First, they iden-      consistency 


                                                                        Â¡


                                                                      Â¥  Â©  Â©   Â©


                                                                                       %


                                                                   


                                                                                Â¢Â¨Â§  Â¢


tify factors that affect inï¬‚uence but do not operationalize                          Â©


                                                                                       Â 


                                                                             Â¢Â¤Â¢Â£Â¢


                                                                      Â    Â      Â 


those factors. Second, they are rarely comprehensive and do                           


                                                                                      


                                                                  Â¨Â§ 


not address the details of how various factors relate to each     Â¢


                                                                                      Â©


                                                                                      


                                                                            %          %


                                                                               


                                                                                    


                                                                 Â©  Â©                 


                                                                            Â           Â 


                                                                         Â¢      Â 


other or can be composed. To provide a sufï¬cient basis for                Â£                           (4)


                                                                    Â¡


                                                                  
                                                                     
our computational models, our approach has been to distill           Â£
key psychological factors and map those factors into our sim-

ulation framework. Here, our decision-theoretic models are The value function, Â¢ , computed is with respect to the agent

helpful in quantifying the impact of factors in such a way that performing the action at time  . We are summing the value
they can be composed. Speciï¬cally, a survey of the social of the observed action to the acting agent, given the set of
psychology literature identiï¬ed the following key factors: beliefs under consideration. The higher the value, the more
                                                      likely that agent is to have chosen the observed action, and,
  Consistency: People expect, prefer, and are driven to main- thus, the higher the degree of consistency.
tain consistency, and avoid cognitive dissonance, between be- Self-interest is similar to consistency, in that the agent
liefs and behaviors.                                  compares two sets of beliefs, one which accepts the message
  Self-interest: The inferences we draw are biased by self- and one which rejects it. However, while consistency evalu-
interest (e.g., motivated inference) and how deeply we ana- ates the past, we compute self-interest by evaluating the fu-
lyze information in general is biased by self-interest. ture using Equation 3. An agent can perform an analogous
                                                      computation using its beliefs about the senderâ€™s preferences
  Speakerâ€™s Self-interest: If the sender of a message beneï¬ts to compute the senderâ€™s self-interest in sending the message.
greatly if the recipient believes it, there is often a tendency to Bias factors represent subjective views of the message
be more critical and for inï¬‚uence to fail.            sender that inï¬‚uence the receiverâ€™s acceptance/rejection of
  Trust, Likability, Afï¬nity: The relation to the source of the the message. We treat support (or afï¬nity) and trust as such
message, whether we trust, like or have some group afï¬nity a bias on message acceptance. Agents compute their support
for him, all impact whether we are inï¬‚uenced by the message. and trust levels as a running history of their past interactions.
                                                      In particular, one agent increases (decreases) its trust in an-
                                                      other, when the second sends a message that the ï¬rst decides
Computational Model of Inï¬‚uence                       to accept (reject). Similarly, an agent increases (decreases)
                                                      its support for another, when the second selects an action that
                                                      has a high (low) reward, with respect to the preferences of


To model such factors in the simulation, one could specify                                         
                                                      the ï¬rst. In other words, if an agent selects an action , then
them exogenously and make them explicit, user-speciï¬ed fac-
                                                      the other agents modify their support level for that agent by a



tors for a message. This tactic is often employed in social                %


                                                                        " #        "


                                                                           Â 
                                                                                   Â 


simulations where massive numbers of simpler, often iden- value proportional to Â  , where corresponds to the goals
                                                          %
tical, agents are used to explore emergent social properties. and Â  the new beliefs of the agent modifying its support.
However, providing each agent with quantitative models of Upon receiving any information (whether message or ob-
itself and, more importantly, of other agents gives us a pow- servation), an agent must consider all of these various factors
erful mechanism to model this range of factors in a principled in deciding whether to accept it and how to alter its beliefs
way. We model these factors by a few simple mechanisms in (including its mental models of the other agents). For a mes-
the simulation: consistency, self-interest, and bias. We can sage, the agent determines acceptance using a weighted sum
render each as a quantitative function of beliefs that allows of the ï¬ve components: consistency, self-interest, speaker


an agent to compare alternate candidate belief states (e.g., an self-interest, trust and support. Whenever an agent observes



             %       %


                     
                     Â 
agentâ€™s original Â  vs. the implied by a message).     an action by another, it checks whether the observation is con-
                                                      sistent with its current beliefs (including mental models). If
  Consistency is an evaluation of the degree to which a po- so, no belief change is necessary. If not, the agent evalu-
tential belief agreed with prior observations. In effect, the ates alternate mental models as possible new beliefs to adopt
agent asks itself, â€œIf this belief holds, would it better explain in light of this inconsistent behavior. Agents evaluate these
the past better than my current beliefs?â€. We use a Bayesian possible belief changes using the same weighted sum as for
deï¬nition of consistency based on the relative likelihood of messages.
past observations given the two candidate sets of beliefs (e.g., Each agentâ€™s decision-making procedure is sensitive to
my current beliefs with and without believing the message). these changes that its actions may trigger in the beliefs of oth-
An agent assesses the quality of the competing explanations ers. Each agent accounts for the othersâ€™ belief update when
by a re-simulation of the past history. In other words, it starts doing its lookahead, as Equations 2 and 3 project the future
at time 0 with the two worlds implied by the two candidate beliefs of the other agents in response to an agentâ€™s selected
sets of beliefs, projects each world forward up to the current action. Similar to work by [de Rosis et al., 2003] this mech-
point of time, and computes the probability of the observa- anism provides PsychSim agents with a potential incentive to


tion it received. In particular, the consistency of a sequence deceive, if doing so leads the other agents to perform actions


               Â¡


                Â©  Â©


                                             %


                  


                                             Â 


                    Â¢Â£Â¢Â¤Â¢
                 Â 
of observations, Â      , with a given belief state, , cor- that lead to a better state for the deceiving agent.  We see the computation of these factors as a toolkit for the models of the teacher: normal, where the teacher will punish
user to explore the systemâ€™s behavior under existing theories, the bully in response to an act of violence; severe, where the
which we can encode in PsychSim. For example, the elab- teacher will more harshly punish the bully than in the normal
oration likelihood model (ELM) [Petty and Cacioppo, 1986] model; and weak, where the teacher never punishes the bully.
argues that the way messages are processed differs according The relative priorities of these subgoals within the bullyâ€™s
to the relevance of the message to the receiver. High rele- overall reward function provide a large space of possible be-
vance or importance would lead to a deeper assessment of the havior. When creating a model of a speciï¬c bully, PsychSim
message, which is consistent with the self-interest calcula- uses a ï¬tting algorithm to automatically determine the appro-
tions our model performs. PsychSimâ€™s linear combination of priate weights for these goals to match observed behavior.
factors is roughly in keeping with ELM because self-interest For example, if the user wants the bully to initially attack a
values of high magnitude would tend to dominate.      victim and the teacher to threaten the bully with punishment,
                                                      then the user speciï¬es those behaviors and the model param-
3  PsychSim   in Operation                            eters are ï¬tted accordingly [Pynadath and Marsella, 2004].
                                                      This degree of automation signiï¬cantly simpliï¬es simulation
The research literature on childhood aggression provides in- setup. In this experiment, we selected three speciï¬c bully
teresting insight into the role that theory of mind plays in hu- models from the overall space: (1) dominance-seeking, (2)
man behavior. Investigations of bullying and victimization sadistic, and (3) attention-seeking, each corresponding to a
[Schwartz, 2000] have identiï¬ed four types of children; we goal weighting that favors the corresponding subgoal.
focus here on nonvictimized aggressors, those who display
proactive aggression due to positive outcome expectancies 3.2 Experimental Results
for aggression. Children develop expectations on the likely PsychSim allows one to explore multiple tactics for dealing
outcomes of aggression based on past experiences (e.g., did with a social issue and see the potential consequences. Here,
past acts of aggression lead to rewards or punishment). This we examine a decision point for the teacher after the bully has
section describes the results of our exploration of the space attacked the victim, followed by laughter by the rest of the
of different nonvictimized aggressors and the effectiveness of class. At this point, the teacher can punish the bully, punish
possible intervention strategies in dealing with them. the whole class (including the victim), or do nothing. We ex-
                                                      plore the impact of different types of proactive aggression by
3.1  Scenario Setup                                   varying the type of the bully, the teacherâ€™s decision to punish
The user sets up a simulation in PsychSim by selecting the bully, the whole class, or no one, and the mental models
generic agent models that will play the roles of the various that the bully has of the other students and the teacher.
groups or individuals to be simulated and specializing those A successful outcome is when the bully does not choose
models as needed. In our bullying scenario, we constructed to act out violently toward the victim the next time around.
generic bully models that compute outcome expectancies as By examining the outcomes under these combinations, we


the expected value of actions ( Â¢Â£ from Equation 2). Thus, can see the effects of intervention over the space of possible
when considering possible aggression, the agents consider classroom settings. Table 1 shows all of the outcomes, where
the immediate effect of an act of violence, as well as the we use the â€œ*â€ wildcard symbol to collapse rows where the


possible consequences, including the change in the beliefs outcome was the same. Similarly, a row with â€œ Â  severeâ€ in the
of the other agents. In our example scenario, a bully has Teacher row spans the cases where the bullyâ€™s mental model
three subgoals that provide incentives to perform an act of of the teacher is either normal or weak.
aggression: (1) to change the power dynamic in the class by We ï¬rst see that the PsychSim bully models meets our in-
making himself stronger, (2) to change the power dynamic tuitive expectations. For example, we see from Table 1 that
by weakening his victim, and (3) to earn the approval of his if the bully thinks that the teacher is too weak to ever punish,
peers (as demonstrated by their response of laughter at the then no immediate action by the teacher will change the bully
victim). Our bully agent models the ï¬rst incentive as a goal from picking on the victim. Thus, it is critical for the teacher
of maximizing power(bully)  and the second as minimiz- to avoid behavior that leads the bully to form such mental
ing power(victim),  both coupled with a belief that an act models. Similarly, if the bully is of the attention-seeking va-
of aggression will increase the former and decrease the latter. riety, then punishment directed at solely himself will not dis-
The third incentive seeks to maximize the laugh actions di- suade him, as he will still expect to gain peer approval. In
rected at the victim, so it must consider the actions that the such cases, the teacher is better off punishing the whole class.
other agents may take in response.                      We can see more interesting cases as we delve deeper. For
  For example, a bully motivated by the approval of his class- example, if we look at the case of a sadistic bully when the
mates would use his mental model of them to predict whether teacher punishes the whole class, we see that bully can be
they would laugh along with him. We implemented two pos- dissuaded only if he thinks that the other students will ap-
sible mental models of the bullyâ€™s classmates: encouraging, prove of his act of violence. This outcome may seem counter-
where the students will laugh at the victim, and scared, where intuitive at ï¬rst, but the sadistic bully is primarily concerned
the students will laugh only if the teacher did not punish them with causing suffering for the victim, and thus does not mind
for laughing last time. Similarly, the bully would use his men- being punished if the victim is punished as well. However, if
tal model of the teacher to predict whether he will be pun- the bully thinks that the rest of the class is encouraging, then
ished or not. We provide the bully with three possible mental the teacherâ€™s punishment of the whole class costs him peer
                      continuous time associative bandit problemsâˆ—          andrasÂ´  gyorgyÂ¨   levente kocsis    ivett szaboÂ´  csaba szepesvariÂ´                  automation research institute hungarian academy                              sciences machine learning research group                 gyaszitbmehu kocsissztakihu ivettgmailhu szcsabasztakihu               budapest university technology economics department stochastics                         university alberta department computing science                        abstract                          continuous values time instants decisions      paper consider extension multi place continuous values supercom      armed bandit problem generalized setting puter ï¬xed cost running whilst centreâ€™s income      decision maker receives side information based quality solutions delivered given      performs action chosen ï¬nite set time single task executed supercomputer      receives reward unlike standard bandit  admittedly assumption looks absurd ï¬rst sight      settings performing action takes random pe context example think results      riod time environment assumed sta extended general case number      tionary stochastic memoryless goal algorithms run simultaneously bounded      maximize average reward received unit  stant trouble decided stick      time maximize average rate return simplifying assumption      consider online learning problem      allocation rule decides based side information      decision maker initially does know available task just received algorithm use      environment learn  processing goal maximize return rate      trial error propose â€œupper conï¬dence   note criterion different maximizing total      boundâ€style algorithm exploits structure reward fact processing task takes time dur      problem show regret al ing tasks processed rate maximiza      gorithm relative optimal algorithm tion problem solved selecting algorithm      perfect knowledge problem grows  highest expected payoff tasks look difï¬cult      optimal logarithmic rate number decisions solve best thing drop      scales polynomially parameters sults payoff exchange learner does suffer      problem                                          loss processing possibly rewarding                                                        tasks note possible pres                                                        ence side information case problem    introduction                                       simplify usual multiarmed bandit problem  multiarmed bandit problems ï¬nd applications various needs ï¬nd best option highest reward rate  ï¬elds statistics control learning theory eco example illustrates learner aim quickly learn  nomics popular seminal paper good allocation strategy rate maximization solve  robbins  enjoy perpetual popular problems simultaneously predicting longterm val  ity                                                  ues available algorithms given information    version bandit problem consider mo task processed balancing exploration ex  tivated following example imagine sequence ploitation loss selecting inferior options  tasks arrive processing center regret kept minimum problem  single supercomputer each tasks number sider thought minimalistic example  alternative algorithms applied information learner faces problems simultaneously  tasks available used predict bandit problems continuous time studied ear  algorithms try processing time depends lier number authors kaspi mandel  task hand algorithm selected baum  karoui karatzas  references    âˆ—this research supported ministry econ earlier results concern construction op  omy transport hungary grant gvop timal allocation policies typically form gittins   hungarian national science foundation grant dexes given parametric form distributions  jÂ´anos bolyai research scholarship random variables involved contrast consider  hungarian academy sciences                        agnostic case particular parametric form assumed                                                    ijcai                                                     environment supposed stationary stochas  tic agnostic nonparametric case studied             Î´ixe  Î´ix  extensively discrete time case fact problem denote expected reward delay respectively op  ï¬rst considered robbins  introduced tion chosen presence sideinformation  certaintyequivalence rule forcing article exact protocol decision making follows  robbins showed rule asymptotically consistent cision making happens discrete trials let Ï„  sense frequency time instants best let Ï„t denote time beginning tth trial  arm selected converges surely recently beginning tth trial decision maker receives               agrawal   suggested number simple samplemean side information xt based value xt infor  based policies showed resulting policiesâ€™ regret mation received decision maker prior trials  decisions olog known al cision maker select option executing  location rule achieve regret lower cp log                                                        decision maker receives reward rt  rittxt suf  appropriate problem dependent constant cp lai rob                                                        fers delay Î´t  Î´ittxt time point  bins  agrawalsâ€™ policies unimprovable apart available decision maker select option  constant factors lately auer et al  strengthened                                                        Ï„t  Ï„t  Î´ittxt  results suggesting policies achieve logarithmic goal decision maker ï¬nd good allocation  regret uniformly time just asymptotically policy formally allocation policy maps possible histories  added beneï¬t policies simple index set gain average reward rate  implement                                            delivered allocation policy given    base algorithm algorithm ucb auer et                                                                                                                   al  agrawal  assume stationary                   t rt                                                                       Î»   lim sup         memoryless stochastic environment side informa                nâ†’âˆ    Î´t   tion iid process taking values ï¬nite set payoff                                                                                        delay sequences jointly distributed options rt reward sequence Î´t delay se  distribution depends side information quence experienced policy used optimal allo  precise assumptions listed section like cation policy maximizes gain note  ucb algorithm decides option choose based problem stated special case semimarkov decision  samplemeans corrected upper conï¬dence bounds problems puterman  theory semimarkov  case separate statistics kept option  cision problems furnishes necessary tools char  sideinformation pairs main result shows result acterize optimal allocation policies let deï¬ne optimal                                                        gain  ing policy achieves logarithmic regret uniformly time               âˆ—                                                                                  Î»  supÎ»    unimprovable apart constant factors                        paper organized follows deï¬ne problem                                      âˆ—      proposed algorithm section  main result policy said optimal satisï¬es Î»  Î»  logarithmic regret bound algorithmâ€™s performance follows generic theory exist determinis  presented section  conclusions drawn section  tic stationary policies optimal optimal action                                                        âˆˆxcan determined ordering options                                                        relative valuestherelative value option ob    algorithm                                      serving expected reward collected minus  problem previous section formalized fol expected reward gained during time takes  lows let denote number options available let collect reward  denote set possible values side information          âˆ—                  âˆ—                                                                       qi xrix âˆ’ Î´ixÎ»   assumed ï¬nite let xxxt bearan  dom sequence covariates representing side information intuitively clear policy selects  available time tth decision generated indepen options best relative values optimize  dently distribution supported  each deci gain fact follows theory semimarkov  sion point decision maker select option decision problems case stationary                    receives reward rt  rit txtwhere deterministic policy  xâ†’ais optimal  ritxt reward decision maker received obeys constraints  chosen option unlike classical bandit problems              âˆ—                    âˆ—                                                             ruxx âˆ’ Î´uxxÎ» maxrix âˆ’ Î´ixÎ»    collection reward takes random time op                        iâˆˆa  tion selected side information equals time                                                        simultaneously âˆˆx  Î´itx assume ï¬xed ritxÎ´itx                                                          total regret allocation policy deï¬ned  iid sequence independent xt                                                        loss suffered selecting optimal option each  sume ritx âˆˆ rminrmax Î´itx âˆˆ Î´minÎ´max                                                        time step interested expected regret  Î´min   expect boundedness assumptions                                                        regret deï¬nition uses optimal gain Î»âˆ—  relaxed Î´itx â‰¥  appropriate moment conditions                                                                                      Î´itx ritx let                                                                                                                                       âˆ—                                                                       rn  Î»     Î´t âˆ’    rt                                             rix   rix                                                                                                  ijcai                                                     value ï¬rst term maximum reward cts appropriate deterministic sequence se                                                                                                         collected during time ï¬rst decisions ex lected simultaneously policies âˆˆu Î»t  pected regret compares expected value                                                                        cttutvicinity Î» high probability se  expected value actual total payoffs received quence explicitly constructed during proof  follows allocation policy minimizes regret make sure depends known quantities  optimize rate return                     words Î»n optimal gain decision maker                          Î´itxand    single element problem guarantee high probability given data seen  reduces classical stochastic bandit problem far  stochastic bandit problems regret lower bounded                         ucb                                                          proposed allocation policy ut  selects op          seeking policies regret grows     ucb  olog                                              tions  ut xt rule  logarithmic rate                                                                                                                                         ucb                    âˆ’    idea underlying algorithm develop upper  ut    argmax  ritx Î´itxÎ»t Ë†cttixt                         âˆ—                                              iâˆˆa  estimates values qi appropriate conï¬dence  bounds just like auer et al  upper conï¬ similarly cts cË†ts appropriate deterministic  dence estimates selected ensure given sequence chosen later  px   options ultimately selected inï¬nitely  time suboptimal options selected mainresult  increasingly rarely                                  main result following bound expected regret    algorithm follows let consider tth deci theorem  let assumptions previous section hold                                   âˆ—                                                                   ucb  sion good estimate Î»t Î»  given ritÎ´itxtletrn nstep regret policy   base decision estimates relative      â‰¥         âˆ—                                                                                 âˆ’                                          values qi options given Î´ xÎ»                         ritx denotes average rewards during ï¬rst deci     âˆ—          Ï€                                                        rn â‰¤                   kx  kx  logn  sions time points side information              option selected Î´itx deï¬ned analogously                                                                                                                                                         t                                                      logn                                                                                                                                                                                        Î”ix       ritx                 xs  rs                     iÎ”i xâˆˆx                                                                     âˆ—        âˆ—                                                          Î´maxÎ» âˆ’  rmin                                                                                                  âˆ—       âˆ—                                                           Î”ixmaxqj   âˆ’ qi â‰¥ ik       Î´itx                xs  Î´s                 jâˆˆa                  tix                                                        positive constant given  proof  tix denotes number times option theorem  selected side information present trials proof follows similar lines theorem  auer           t                                et al  main difference                                                                                     âˆ—             tix    xt             handle estimation error Î»  prove theorem                                                    using series propositions                                                          ï¬rst proposition bounds expected regret terms    plan combine appropriate upper bounds rix number times suboptimal option chosen  lower bounds Î´ix based respective sample                                                        proposition  following bound holds expected  averages ritx Î´itx tix obtain upper es           âˆ—                                            regret arbitrary policy uu  timate qi order sample based                                                                                                                              estimate need appropriate lower estimate Î»âˆ—                                                                                  â‰¤          âˆ—             âˆˆuâˆ—  estimate deï¬ned follows                       rn      pxl       utx          let denote set stationary policies  uu        xâˆˆx                                              xâ†’apickanyu        âˆˆuletÎ»t    denote empirical                                                                   âˆ—             âˆ—           âˆ—  estimate gain policy                               xi âˆˆaqi  xmaxqj                      t                                                                  jâˆˆa                     uxs rs              Î»t   t                                  denotes set optimal options                          uxs Î´s                           âˆ—                âˆ—                                                                xmaxÎ´jxÎ»    âˆ’ rj                                                                              let tut denote number times option                                                        loss worst choice xfurtherbylâˆ—x â‰¤ lâˆ—  â€˜compatibleâ€™ policy selected                                                                                   t                                                        n                                                               â‰¤    âˆ—                  âˆˆuâˆ—               tut      uxs                  rn          px       utx                                                                       xâˆˆx                                                  âˆ—                                                     n  Î»t estimate Î» deï¬ned                             âˆ—              âˆˆuâˆ—                                                                              utx    xxt                  Î»t maxÎ»t  âˆ’ ctt                               xâˆˆx                        uâˆˆu                                                            ijcai                                                                                                 âˆ—  proof   let consider tth term Î´tÎ» âˆ’ rt proposition  assume following conditions sat                                          âˆ—  of expected regret   Î´tÎ» âˆ’ rt      isï¬ed             âˆ—                                                                      iâˆˆa Î´tÎ» âˆ’ rti   using  utxt                                                                                  Î»    â‰¥  Î»t âˆ’ ctt             ut depends past ft sigma algebra                                                                                             âˆ—       âˆ—                       ftâˆ’                                      â‰¤  Î´ Î´    measurable                  Î»       Î»t  cttuâˆ—                                                                  ï¬rst condition meant hold stationary          âˆ—                                                      âˆˆu    Î´tÎ» âˆ’ rti                             policies                   âˆ— âˆ’                                              âˆ— â‰¥   â‰¥   âˆ— âˆ’          Î´itxtÎ»  ritxt                            Î»    Î»t   Î»   cttuâˆ—                              âˆ—                                                                                Î´itxtÎ» âˆ’ ritxti  ftâˆ’xt                                       âˆ’                                                        proof  let policy maximizes Î»t cttut                               âˆ—                                                                      Î´itxtÎ» âˆ’ ritxtftâˆ’xt                                                                         holds  Î»t  Î»t âˆ’ ctt  â‰¤                             âˆ—                                                                               Î´ixtÎ» âˆ’ rixtftâˆ’xt   u    âˆ—                                                        Î»   â‰¤ Î»  proving upper bound Î»t hand                           âˆ—                                                         âˆ—         iÎ´ixtÎ» âˆ’ rixt                                       â‰¥    âˆ’                                                        choice  Î»t Î»t cttuâˆ—t                                                                               âˆ— âˆ’  using ut does depend xtweget  lower bounded Î» cttuâˆ—t using  proving                                                                                                                    âˆ—                                             lower bound Î»t     Î´tÎ» âˆ’ rt                                                         following proposition shows Î»t lower                                   âˆ—                              âˆ—             utxtiÎ´ixtÎ» âˆ’ rixt        bound Î» high probability           iâˆˆa                                                      proposition  let                         âˆ—                                                            âˆ’        pxqi xe utxi xt                                              iâˆˆa xâˆˆx                                                         logt                                                                    cts                          âˆ—                                                                    âˆ’        pxqi xe utxi              iâˆˆa xâˆˆx                                                                                                                                                                                                                                                    rmax âˆ’ rmin  rmaxÎ´max âˆ’ Î´min                                                     max                                                                                                            Î´min            Î´min     âˆ— âˆ’       âˆ’                âˆ—     Î´tÎ»   rt         px      qi  utxi                      xâˆˆx     iâˆˆu âˆ—x                                                                                                                            âˆ— âˆ’             âˆ—      â‰¤                                    âˆ—                              Î»t Î»    cttuâˆ—  Î»   Î»t                      âˆ’     px      qi xe utxi                                                              xâˆˆx     iâˆˆu âˆ—x                    proof according proposition   holds station                                                                                      âˆ—        âˆ—                                                                                       â‰¥   â‰¥   âˆ’  tt âˆ—                                   âˆ—                    ary policies  holds Î» Î» Î»     let wtixe utxi âˆˆux wtix                     âˆ—                   âˆ—                                                        order Î»t Î» âˆ’ ctt âˆ— Î»t Î» hold                                                                                 let Î¼ti x wti jâˆˆa wtj xthen conditions proposition  vio        â‰¥                        â‰¤  Î¼ti  wti jâˆˆa wtj   ï¬rst term lated using union bound                                                                                        expression upper bounded                 âˆ—                 âˆ—                                                         Î»t Î»  âˆ’ ctt âˆ—  Î»  Î»t                                                                                                                                 âˆ—                                                             âˆ—            vt  âˆ’     px   qi xÎ¼tix              â‰¤            âˆ’             âˆ—                                                                   Î»   Î»t   cttut    Î»   Î»t  cttut                    xâˆˆx                                         Î¼tixif optimal Î¼t deï¬nes optimal fix law total probability  stochastic policy bellmanâ€™s equation gives                                                                                                                                                                                          âˆ’                    âˆ’                                              Î»   Î»t  cttut       Î»   Î»t  ctstuts                                                                                    âˆ—                            âˆ—  Î´tÎ» âˆ’ rt â‰¤âˆ’       px       xe utxi                                                      deï¬ne                    xâˆˆx     iâˆˆu âˆ—x                                                               t                                                   âˆ—                                                                     â‰¤      pxl       utxi    rË†t         uxs rsr       pxruxx                  xâˆˆx           iâˆˆu âˆ—x                                              xâˆˆx                                                                                           âˆ—                âˆ—                                                                  pxl xe utx âˆˆu                                                                                        Î´Ë†t        uxs Î´sÎ´      pxÎ´uxx                  xâˆˆx                                                                                       xâˆˆx  summing expression gives advertised using elementary algebra                                                                                   bound                                                                                                                   Î»   Î»t âˆ’ ctstuts    statements used prove high prob                                                 âˆ—                              â‰¤   ctsÎ´min â‰¤ rË† âˆ’ tuts  ability Î»t good estimate Î»  follows                                                                                        âˆ—   âˆ—                                         âˆ—                               â‰¤   âˆ’ Ë†u  denotes arbitrary ï¬xed optimal policy Î»t  Î»t          ctsÎ´minrmax   Î´   Î´t tuts                                                     ijcai                                                                         exploiting rË†t Î´Ë†t martingale sequences expectations second terms bounded                                                                                                         sorting slight variant hoeffdingazuma bound proposition  ï¬rst term multiplied zts   devroye et al  bound  bounded    âˆ’                                                             summing and analogous argument                         âˆ—              âˆ—                                                         âˆ’                         âˆ—                                             zts  ritâˆ’x Î´itâˆ’xÎ» Ë†ctâˆ’s    Î»  Î»t  cttut  desired bound                                                                                                                            âˆ—        âˆ—       âˆ—                                                                        âˆ’ Î´  xÎ» âˆ’ ctsË†ctâˆ’s     ready prove main theorem                  tâˆ’      tâˆ’  proof superscript â€˜âˆ—â€™ quantity refers                   âˆ—               âˆ—                    expression equals fol  optimal policy  example rt xruâˆ—xtx lowing events hold   âˆ—                 âˆ—  Î´t xÎ´uâˆ—xtx ttuâˆ—xx tetc                                                        atss                                            ucb  proof theorem  proposition  applied shows    âˆ—       âˆ—     âˆ—   âˆ—     âˆ—    âˆ—              sufï¬ces ï¬xed âˆˆxand suboptimal choice rtâˆ’xâˆ’Î´tâˆ’xÎ» â‰¤r xâˆ’Î´ xÎ» âˆ’ctâˆ’szts        âˆ—  âˆˆux  derive olog upper bound ex  tss                                                 ucb          pected number times choice selected                  âˆ—             âˆ—                                                                            âˆ’          â‰¥     âˆ’                         side information need show ritâˆ’x Î´itâˆ’xÎ» rix Î´ixÎ» Ë†ctâˆ’s zts                                                                     âˆ—       âˆ—    âˆ—               âˆ—                                                           tss      âˆ’             âˆ’          ts                                                                Î´ xÎ» rx    Î´ xÎ» Ë†c                                                                              âˆ—                 ucb                                                     âˆ’            ut   xi xt   â‰¤  olog     ctâˆ’s Ë†ctâˆ’s Î´t ctâˆ’s let choices                                                    conï¬dence intervals deï¬ne                                                                                                                                                                       let qitxritx âˆ’ Î´itxÎ»t using deï¬nition             uts   log       ucb      ucb  ut   ifut   xi    holds qitxË†cttixt    âˆ—                                                                                               âˆš  qt xË†ctt âˆ—xt integer  deï¬ned cts proposition  cts  cuts                                                        deï¬ned deï¬ne cË†ts implicitly  n                                                                               ucb                                            through deï¬nition cts deï¬ned      ut  xi   â‰¤                                                        probability atss small let                                                                                                                                                                                ucb                                          maxrmax  âˆ’ rmin rmaxÎ´max âˆ’ Î´minÎ´min          ut   xi tix âˆ’  â‰¥ xxt                                                                                                                                                                                                                cts  auts  Î´maxcdeï¬ne               n                                      â‰¤               ucb             âˆ’    â‰¥                                                      ut   xi tix                                                                                                               cË†ts auts using deï¬nitions bound  write tth term sum follows    probabilities three events start atss                                      ucb                                                                     âˆ—      âˆ—                              âˆ’   â‰¥                               tss â‰¤     â‰¤      âˆ’           ut   xi tix                                   cts  rt xz                                                                                      âˆ—                                âˆ—                                         âˆ— â‰¤       âˆ’  âˆ—               qitâˆ’xË†ctt xtâˆ’ qtâˆ’xË†ctâˆ’t âˆ—xtâˆ’           ctsÎ»   Î´t Î´ xzts                                                                                                                                                                                                                                                      â‰¤ exp  âˆ’cts srmax âˆ’ rmin                     tix âˆ’  â‰¥                                                                                                                                            âˆ—                                                                                 âˆ’              max âˆ’  min                               âˆ—                                 exp    cts sÎ»  Î´    Î´                itâˆ’     tâˆ’s          tâˆ’s                xË†c     qtâˆ’xË†c                                  t    ssâˆˆht                                               used        xt  rt                                                        t                                                           xt  Î´t martingales                                                  abovementioned variant hoeffdingazuma                                                                                                                                                  inequality plugging deï¬nition cts     hts     â‰¤ â‰¤ âˆ’ â‰¤ â‰¤ âˆ’                                         âˆ’        âˆ’                                                        probability event atss bounded                      âˆ’         âˆ—    âˆ’  zts     tix           probability btss bounded way                                                                                                                                                 expression cË†ts cts  fix âˆˆ ht using deï¬nition qitx                                                          n                            âˆ—   qitâˆ’xË†ctâˆ’s qtâˆ’xË†ctâˆ’s                                atss btss                                                                      ssâˆˆht     â‰¤  ritâˆ’x âˆ’ Î´itâˆ’xÎ»tâˆ’ Ë†ctâˆ’s                                                                  n                                                                                                                           Ï€                    âˆ—        âˆ—                                â‰¤                           â‰¤                             rtâˆ’x âˆ’ Î´tâˆ’xÎ»tâˆ’ Ë†ctâˆ’s                                                                                                          ssâˆˆht                   âˆ—           âˆ—             â‰¥  tâˆ’ â‰¥    âˆ’                                                                          Î»    Î»      Î»    ctâˆ’tuâˆ— tâˆ’                                                                                                                     deï¬ne xa logt Î”ix                     âˆ—                     âˆ—                   âˆ’                                                                                            Î»tâˆ’ Î»    ctâˆ’tuâˆ— tâˆ’  Î»   Î»tâˆ’     ctss holds Î”ix  Ë†cts                                                     ijcai                                                     

                     learning inference constrained output                  vasin punyakanok           dan roth         wentau yih          dav zimak                                      department science                                university illinois urbanachampaign                         punyakan danr yih davzimakuiucedu                          abstract                          tional random ï¬elds lafferty et al  perceptronbased                                                        learning structured output collins  carreras      study learning structured output discrimi marquez  maxmargin markov networks      native framework values output vari allow incorporating markovian assumptions output      ables estimated local classiï¬ers  variables taskar et al       framework complex dependencies                                                          incorporating constraints during training lead solu      variables captured constraints dictate                                                        tions directly optimize true objective function      global labels inferred compare                                                        perform better nonetheless real world      strategies learning independent classiï¬ers                                                        applications using technique show signiï¬cant ad      inference based training observing behav                                                        vantages important discover      iors different conditions experiments theo                                                        tradeoffs using each schemes      retical justiï¬cation lead conclusion using      inference based learning superior lo   paper compare three learning schemes      cal classiï¬ers difï¬cult learn require ï¬rst classiï¬ers learned independently learning      examples discernible difference   lo second inference used maintain struc      observed                                  tural consistency learning learning plus inference                                                        li ï¬nally inference used learning pa                                                        rameters classiï¬er inference based training ibt    introduction                                       semantic role labeling srl observed punyakanok  making decisions real world problems involves assigning et al  carreras marquez  lo  values sets variables complex expressive cal classiï¬cation problems easy learn li outperforms  structure inï¬‚uence dictate assignments ibt using reduced feature space  possible example task identifying named enti problem longer locally separable ibt  ties sentence prediction governed constraints like come poor local classiï¬cations yield accurate global  â€œentities overlapâ€ example exists scene classiï¬cations  terpretation tasks predictions respect constraints section  provides formal deï¬nition problem  arise nature data task example section  compare three learning  â€œhumans arms legs headâ€       schemes using online perceptron algorithm applied    exist three fundamentally different solutions three settings collins  details three set  learning classiï¬ers structured output ï¬rst tings use linear representation li ibt  structure ignored local classiï¬ers learned used share decision function space conjectures  predict each output component separately sec relative performance different schemes pre  ond learning decoupled task maintaining struc sented section  despite fact ibt pow  tured output estimators used produce global erful technique section  provide experiment  consistent structural constraints shows li outperform ibt exist accu  learned each output variable separately discrimina rate local classiï¬ers depend structure  tive hmm conditional models punyakanok roth  examples learn complex structural depen  mccallum  et al  dynamic programming  dencies theoretically justiï¬ed section   based schemes used context sequential predictions  fall category class solutions  background  corporates dependencies variables learn  ing process directly induce estimators optimize structured output classiï¬cation problems ï¬‚avors  global performance measure traditionally solutions paper focus problems natural  generative recent developments pro split task smaller classiï¬cation tasks  duced discriminative models type including condi solve directly single task section  consider thesemantic rolelabeling problem input nat  learning  ural language features output position present ways learn scoring function pa  type semanticrole sentence problem rameters differing structurebased  learn set local functions â€œis ference process leveraged during training learning  phrase argument â€™runâ€™â€ global classiï¬er pre                                                        sists choosing function  âˆ— â†’ yâˆ— hy  dict semanticroles addition natural structural                                                        pothesis space typically data supplied set  constraints dictate example semantic roles                                                                   distribution  single verb overlap structural constraints                                                                                        âˆ— Ã— yâˆ— concepts general fo  linguistic constraints yield restricted output space cus online learning linear representations using variant  classiï¬ers operate                         perceptron algorithm collins     general given assignment  nx collec                                   âˆˆ                    learning local classiï¬ers learning standalone local  tion input variables        struc                                       nx              classiï¬ers straightforward setting  tured classiï¬cation problem involves identifying â€œbestâ€                                                        knowledge inference procedure used  assignment âˆˆ  yny collection output variables                                                        each example âˆˆ learning algorithm en         yn  consistent deï¬ned struc                                                     sure          ture structure thought constraining    yt                                                                                       figure online perceptronstyle algorithm  output space smaller space cyny  âŠ† yny          âˆ—      âˆ—                                                                                                                                           presented global constraints used har     â†’    constrains output space structurally peled et al  details section  experiments  consistent                                             learning global classiï¬ers seek train classiï¬ers    paper structured output classiï¬er function produce correct global classiï¬cation        nx       ny       â†’     uses global scoring function end key difference learning locally feed       nx    ny     Ã—   â†’  ir assign scores each possible ex inference process determines classiï¬ers  amplelabel pair given input hoped correct modify classiï¬ers inference  output achieves highest score consistent outputs procedure yield desired result collins               yË†  hx  argmax fx           carreras marquez  train according global                         yâˆˆcyny                      criterion algorithm presented online proce                                                        dure each step subset classiï¬ers  nx ny depend example hand addition dated according inference feedback figure  view global scoring function composition set details perceptronlike algorithm learning infer                                                nx  local scoring functions fyx tyâˆˆy  fy  Ã— ence feedback       ny â†’ ir each function represents score note practice common problems mod  conï¬dence output variable yt takes value      eled way local classiï¬ers dependent                                ny                      output input sort interaction                                                        incorporated directly algorithm learning global            fx     yny   fyt                               xt                     classiï¬er long appropriate inference process used                                                        addition provide fair comparison lo li    inference task determining optimal assign ibp setting care ensure  ment given assignment sequential structure learning algorithms appropriate task order  constraints polynomialtime algorithms viterbi remain focused problem training  cscl punyakanok roth  typically used inference feedback experiments analysis presented  efï¬cient inference general structure constraints concern local classiï¬ers interaction  generic search method beam search ap  plied recently integer programming shown  effective inference approach nlp applica  conjectures  tions roth yih  punyakanok et al   section investigate relative performance    paper consider classiï¬ers linear rep classiï¬er systems learned inference feed  resentation linear local classiï¬ers linear functions competing factors initially lo                                  dy  fyx  Î±  Â· Î¦ Î± âˆˆ ir   weight  cal classiï¬cation problems â€œeasyâ€ likely  vector Î¦yx âˆˆ irdy feature vector learning local classiï¬ers lo yield accu  easy show global scoring function rate classiï¬ers accurate model structural  written familiar form fx  Î± Â· Î¦x constraints additionally increase performance learning                                          yt                            plus inference li local problems  Î¦    Î¦ tiyty accumula  tion outputp variables features occurring class difï¬cult learn accurate model structure  Î±   Î±     Î±y concatenation Î±yâ€™s important overcome suboptimal lo  Î¦x  Î¦x     Î¦yx concatenation cal classiï¬ers despite existence global solution  Î¦yx yâ€™s global classiï¬er      local classiï¬cation problems increasingly difï¬                                                        cult unlikely structure based inference ï¬x poor            hx  yË†  argmax Î± Â· Î¦x            classiï¬ers learned locally case training                       yâˆˆcyny                        ference feedback ibt expected perform                                                      claim  ï¬xed number examples           algorithm onlinelocallearning                       xy     âˆ—    âˆ—                    local classiï¬cation tasks separable li               input    âˆˆ Ã—                        outperforms ibt               output fy   âˆˆ                           yâˆˆy                             task globally separable locally sepa                                            initialize Î±y âˆˆ irÎ¦  âˆˆ             rable ibt outperforms li sufï¬cient ex               repeat converge                        amples number correlates degree                 each âˆˆ dxy                  separability local classiï¬ers                         ny                                Î±y                        yË†t  argmaxy Â· Î¦              experiments                     yË†t  yt                                                  present experiments show relative performance                       Î±  Î±  Î¦                                                  learning plus inference li compares inference based                       Î±Ë†t  Î±Ë†t âˆ’ Î¦Ë†t                                                        training ibt quality local classiï¬ers                                                        training data varies               inference feedback                                                          synthetic data                                                        experiment each example set points          algorithm onlinegloballearning                                                                                    xy     âˆ—    âˆ—                   dimensional real space      xc âˆˆ ir Ã—              input   âˆˆ  Ã—                                         output fy   âˆˆ                           Ã— ir label sequence binary variable                          yâˆˆy                                                                                                         yc âˆˆ    labeled according              initialize Î± âˆˆ irÎ¦              repeat converge                               xy                           hx  argmax    yifixi âˆ’  âˆ’ yifixi               each âˆˆ                                                                                                             yâˆˆcy  xi                 yË†  argmax    ny Î± Â· Î¦x                           yâˆˆcy                                                                  yË†                         cy  subset   imposing random                                                                                Î±  Î±  Î¦x âˆ’ Î¦x yË†           straint fixi  wixi Î¸i each fi corresponds                                                          local classiï¬er yi  gixi  ifixi clearly dataset                inference feedback             generated hypothesis globally linearly separable                                                        vary difï¬culty local classiï¬cation generate ex                                                        amples various degree linear separability lo  figure  algorithms learning infer cal classiï¬ers controlling fraction Îº data  ence feedback key difference lies inference step hx  gx  gx     gcxcâ€”examples la  argmax inference learning locally trivial bels generated local classiï¬ers independently violate  prediction simply considering each la constraints gx âˆˆ cyc  bel locally learning globally uses global inference figure  compares performance different learning  argmaxyâˆˆcyny  predict global labels            strategies relative number training examples used                                                        experiments   true hypothesis picked ran                                                        dom cyc random subset half size    ï¬rst attempt formalize difï¬culty classiï¬ca yc training halted cycle complete errors  tion tasks deï¬ne separability learnability classi  cycles reached performance averaged  ï¬er âˆˆ globally separates data set iff exam  trials figure shows locally linearly separable case                                              ples âˆˆ fx  fx  âˆˆ  li outperforms ibt figure shows results  locally separates iff examples âˆˆ case difï¬cult local classiï¬cation tasksÎº                                                ny  fyt  fyx âˆˆ  yt âˆˆ  ibt outperforms li figure shows case  learning algorithm function data sets data totally locally linearly separableÎº    say globally locally learnable case li outperforms ibt number train  exists âˆˆ globally locally separates ing examples small cases inference helps    following simple relationships exist local  global learning  local separability implies global separa  realworld data  bility inverse true  local separability implies section present experiments realworld  local global learnability  global separability implies problems natural language processing â€“ semantic role  global learnability local learnability result labeling noun phrase identiï¬cation  clear exist learning algorithms learn global sep  arations given examples ibt outperform semanticrole labeling  li learning examples limited semantic role labeling srl believed important  cause expensive label learning task natural language understanding imme  algorithms simply scale examples diate applications tasks information extraction  ï¬xed number examples li outperform ibt                                                           total possible output labels cÂ· ï¬xes random                                                        fraction legitimate global labels                                                                                                                                                                                                                 accuracy                                                                                                                                      lo                                   li                                                        ibt                                                                                   lo                      training examples                                                                                                li                                                                                                ibt                                                                               Îº                                                                                                                                                                                                                             separability  features                                                      figure  results semanticrole labeling srl problem                                                        number features increases difï¬culty local classiï¬                                                        cation problem easier independently learned clas                                                     siï¬ers lo perform especially inference used                                                        learning li using inference during training ibt aid perfor                                                    mance learning problem difï¬cult features          accuracy                                         lo                                    li                  amloc                                       ibt              represents leaver represents thing left rep                                    resents benefactor amloc adjunct indicating lo                      training examples                cation action determines verb                                                          model problem  using classiï¬ers map                   Îº                                                   stituent candidates  different types                                                        fao  fa kingsbury palmer  carreras                                                       marquez  local multiclass decisions                                                        sufï¬cient structural constraints necessary ensure                                                     example arguments overlap embed each                                                        order include structural linguistic constraints                                                        use general inference procedure based integer linear                                                     programming punyakanok et al  use data pro              accuracy                                      vided conll shared task carreras marquez                                                                                                lo                 restrict focus sentences greater                                       li              ï¬ve arguments addition simplify problem                                       ibt              assume boundaries constituents given â€“ task                                             mainly assign argument types                      training examples                  experiments clearly show ibt outperforms lo                                                        cally learned lo li local classiï¬ers                    Îº                      separable difï¬cult learn difï¬culty local learn                                                        ing controlled varying number input features  figure  comparison different learning strategies various features linear classiï¬er expressive  degrees difï¬culties local classiï¬ers Îº   implies locally learn effectively li outperforms ibt  linearly separability higher Îº indicates harder local classiï¬cation features problem difï¬cult ibt outper                                                        forms li figure   question answering goal identify each verb noun phrase labeling  sentence constituents ï¬ll semantic role noun phrase identiï¬cation involves identiï¬cation  determine argument types agent patient phrases words participate syntactic relation  instrument adjuncts locative temporal ship speciï¬cally use standard base noun phrases  manner example given sentence â€œ left pearls np data set ramshaw marcus  taken  daughterinlaw willâ€ goal identify dif wall street journal corpus penn treebank marcus et  ferent arguments verb left yields output al       left  pearls daughterinlaw phrase identiï¬er consists classiï¬ers                                                     begin deï¬ning growth function measure                                                        effective size hypothesis space                                                        deï¬nition  growth function given hypothesis                                                        class consisting functions  â†’ growth func                                                        tion nhm counts maximum number ways label                                                      data set size                                                           nhm       sup    hx     hxm âˆˆ                                                                                                                                             xxmâˆˆx                                                          wellknown vcstyle generalization bound expresses                                                      expected error  best hypothesis hopt unseen data                                                        following theorem adapted anthony bartlett                                           li                                           ibt          theorem  directly write growth function                                                           bound                                                     separability  features               theorem  suppose set functions set                                                         set growth function nhm let hopt âˆˆ  figure  results noun phrase np identiï¬cation prob hypothesis minimizes sample error sample  lem                                                  size drawn unknown ï¬xed probability distri                                                        bution probability  âˆ’ Î´    detects beginning second detects end           logn   logÎ´                                                                                                        phrase outcome classiï¬ers com  â‰¤ opt                           bined way satisï¬es structural constraints constraints                      nonoverlapping using efï¬cient constraint satisfac simplicity ï¬rst setting sep  tion mechanism makes use conï¬dence clas arate function learned each ï¬xed number  siï¬ersâ€™ outcomes punyakanok roth          output variables section  each example                                                                                                           case li trains each classiï¬er independently components input      xc âˆˆ ir Ã—    Ã— ir                                                                                        during evaluation inference used output      yc âˆˆ     hand ibt incorporates inference training given dataset aim learn set linear scor                                                                                                   each sentence each word position processed clas ing functions fixi  wixi wi âˆˆ ir each  siï¬ers outcomes used inference process       lo li setting simple ï¬nd  infer ï¬nal prediction classiï¬ers updated set weight vectors each component satisfy  based ï¬nal prediction prediction yiwixi   examples âˆˆ ibt ï¬nd  fore inference                                                                                                                                   set classiï¬ers yiwixi  yiwixi                                                                                                  previous experiment figure  shows perfor  satisfy constraintsp âˆˆpcy   mance systems varied number features previously noted learning local classiï¬ers inde  like previous experiment number features each pendently lo li guarantee convergence  experiment determined frequency occurrence each local problem separable â€“  frequent features pruned make task difï¬ case global constraints render problems insepa  cult results similar srl task rable lower bound opt optimal  problem difï¬cult ibt outperforms li     error achievable each component separate learning                                                        problem generalization error    bound prediction                                   corollary  set separating hyperplanes                                                             section use standard vcstyle generalization ir   bounds learning theory gain intuition learn                                                                          logemd  logÎ´  ing locally lo li outperform learning globally    â‰¤ opt                                  ibt comparing expressivity complexity each                         hypothesis space learning globally possible                                                        proof sketch show â‰¤ emdd   learn concepts difï¬cult learn locally                                                                         class threshold linear functions dimensions  global constraints available local algorithms                                                        nhm   precisely maximum number continuous  hand global hypothesis space                                    expressive substantially larger representation regions arrangement halfspaces ir                                                               mâˆ’                   develop boundsâ€”both linear classiï¬ers   â‰¤  em âˆ’     result  stricted problem ï¬rst upper bounds generalization holdsp see  anthony bartlett theorem   error learning locally assuming various degrees sep details  arability second provides improved generalization hand learning collectively ibt  bound globally learned classiï¬ers assuming separabil examples consist vector âˆˆ ircd set  ity expressive global hypothesis space   ting convergence guaranteed course function

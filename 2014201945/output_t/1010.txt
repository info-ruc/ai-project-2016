                    realtime heuristic search priority queue            chris rayner katherine davison vadim bulitko kenneth anderson jieshan lu                                            university alberta                                     department computing science                                   edmonton alberta canada tg              raynerkdavisonbulitkoandersonjieshanualbertaca                        abstract                          updates neighboring state prioritizing heuris                                                        tic updates efï¬cient learning motivated obser      learning realtime search interleaves plan vations asynchronous dynamic programming barto et      ning acting allows agents learn mul al  states updated time new      tiple trials respond quickly algorithms state values depend order updates oc      require prior knowledge environment     cur judicious update ordering make individual updates      deployed preprocessing    effective second signiï¬cant update state      introduce prioritizedlrta plrta learn   affects neighbors giving priority neighbors      ing realtime search algorithm based prioritized focus computation worthwhile updates      sweeping plrta focuses learning important     rest paper organized follows ï¬rst      areas search space importance mally problem examine identify      state determined magnitude shortcomings related algorithms motivate ap      dates neighboring states empirical tests proach provide comprehensive description      pathplanning commercial game maps show     novel algorithm general properties justify      substantial learning speedup stateoftheart performance metrics conduct empirical evaluation      realtime search algorithms                      conclude considering possible extensions plrta      introduction                                          problem formulation  introduce prioritized learning realtime plrta focus  problems   deï¬ned      tuple  plrta prioritizes learning achieve signiï¬cant speedups ssgh ï¬nite set states  competing realtime search algorithms           set deterministic actions cause state transitions    realtime search algorithms interleave planning acting cs cost performing action âˆˆ state âˆˆ  generate actions userbounded time algorithms executing action state returns agent state  agentcentered koenig  require action said blocked blocked actions  priori knowledge map learn transition model discovered agentâ€™s visibility radius  interacting environment improve distance agent sense environment  solutions reï¬ning heuristic function multiple trials update transition model  algorithms three properties used path agent begins particular start state âˆˆ aims  planning games virtual reality trainers dini et reach goal state sg reaching goal state  al  robotics koenig simmons  each agent teleported start state commences  domains agents plan act potentially unknown new trial learning agent converged completes  environments identical tasks solved succes trial updating heuristic value state  sion agent opportunity improve performance action executed agent incurs cost associ  learning examples include commutetype tasks ated action general realvalued costs lower  resource collection patrolling                   bounded positive constant used assume    focus learning process learning takes state space safely explorable insomuch goal state  place online onsite critical minimize learning reachable state  time converging rapidly highquality solutions   agent deals initial uncertainty    build existing research present learning real action blocked particular state assuming  time search algorithm makes learning experience actions states unblocked belief known  efï¬cient prioritizing updates moore atkeson  freespace assumption koenig et al   states deemed important updated agent explores learn remember actions  states importance determined magnitude possible states plan accordingly                                                    ijcai                                                      related work                                         prioritizedlrtas    realtime agent situated given time single state   known current state current state changed                                                                 stateupdates  taking actions incurring execution cost agent repeat  reach goal current state ways  queuepop  agent plan sequence actions leading goal   act agent plan incompletely execute                                                                    stateupdatep  partial plan repeat reaches goal end  review search algorithms techniques             states updated queue  âˆ…    agent using local repair lra silver     â‡ neighbor sâ€™ lowest fs scs shs  plans complete path current state goal end  executes plan path optimal given agentâ€™s  current knowledge agent discover planned  path blocked point stop replan figure  plrta agent updates current state  updated world knowledge each plan generated states taken queue  search hart et al  time needed ï¬rst input parameter deï¬ned user agent takes single  replanning log num greedy repeats process reaching                                                        goal state   ber states algorithms dynamic stentz        lite koenig likhachev  efï¬ciently  correct current plan reproduce                                                          koenigâ€™s lrta koenig  updates heuristic val  reduce computation needed ï¬rst                                                        ues lss states each accelerate conver  each trial executed large ï¬rstmove delay nega                                                        gence process dijkstrastyle relaxation procedure  tively affects agentâ€™s responsiveness interactive environ                                                        uses produces highly informed heuristics process ex  ments games highspeed robotics                                                        pensive limits size lss used real    simplest form korfâ€™s learning realtime  time domains koenig likhachev   lrta  updates current state respect attempt reduce convergence execution cost pr  immediate neighbors refer version lrta lrts bulitko et al  builds hierarchy levels  lrtad initial heuristic nonoverestimating abstraction runs search algorithms each level                                         lrta converges optimally korf   search higher levels abstraction constrains lower  travel each trial during learning oscillate unpre level searches promising sections map reducing ex  dictably causing seemingly irrational behavior heuristic ploration lower levels result convergence travel  weighting learning separate upper bound reduces ï¬rst delay improved cost complex imple                      path length instability shimbo ishida  bulitko mentation additional computation required main            lee   result suboptimal solutions   tain abstraction hierarchy during exploration    deï¬ne local search space lss states different line research considers sophisticated  neighbors generated planning   date schemes realtime dynamic programming algorithms  lrtad looks current stateâ€™s immediate barto bradtke singh note â€œthe subset states  neighbors deeper lookahead gives agent costs backed changes stage stage  formation decide action korf  choice subsets determines precise nature  stance lrts bulitko lee  considers algorithmâ€  prioritized sweeping reinforce  states radius current state alternatively ment learning algorithm performs updates order pri  koenig uses lss deï¬ned partial search ority moore atkeson  state high priority  current state goal                 large potential change value function    updating state value each planning states potential update greater âˆˆ  stage result efï¬cient learning example added queue prioritized sweeping shown  physical backtracking helps state experience efï¬cient qlearning dynapi moore  updates close physical proximity agent sla atkeson  core inï¬‚uence algorithm  slat  shue zamani shue  et al   Î³trap bulitko  lrts bulitko lee   physically return previously visited states po  novel algorithm  tentially reducing number trials needed conver prioritizedlrta plrta combines ranked updates  gence possibility increasing travel cost al prioritized sweeping lrtaâ€™s realtime search  ternatively lrtak hernandezÂ´ meseguer sumptions deterministic environment nontrivial  uses mental backups decrease number initial heuristic section plrtaâ€™s algo  vergence trials techniques difï¬cult com rithmic details comment nature execution  bine recent study demonstrates fragile highly plrta agent planning phase acting phase  contextspeciï¬c effects combining physical mental interleaved agent reaches goal fig  backups sigmundarson bjornssonÂ¨           ure  during planning phase agent gains knowl                                                    ijcai                                                                                                                                                             stateupdates                                      hs  current estimated cost traveling                                                        closest goal state figure     ï¬nd neighbor s lowest fs scs shs    Î” â‡  fs s âˆ’ hs                                   algorithm properties    Î”                                         section make general observations key fea          â‡             hs   fs                                    tures make plrta different learning real      neighbors                       time search algorithms discuss plrtaâ€™s conver        addtoqueuen   Î”                              gence space time complexity      end    end                                              key features design                                                        unlike prioritized sweepingâ€™s  parameter restricts  figure  value state set lowest available potentially small updates entering queue plrta  cs shs cs s cost traveling s speciï¬es maximum queue size guarantees strict limit  hs estimates distance s goal value memory computational time used enabling  changes neighbors enqueued                algorithm process arbitrarily small updates                                                          plrta speciï¬es current state                                                                                                          addtoqueues   Î”s                                 updated plrta degenerates korfâ€™s lrtad korf                                                         size queue     sâˆˆ queue                                     plrta agent disallows duplicate entries queue      queuef ull                              retains contents queue acting phases        ï¬nd state âˆˆ queue smallest Î”r            design key difference plrta real                                                                                                     Î”r  Î”s                                 time search algorithms lrtak hernandezÂ´          queueremover                                meseguer koenigâ€™s lrta  koenig                                                                      queueinserts Î”s                             plrta agentâ€™s local search space nec        end                                          essarily contiguous dependent agentâ€™s current state                                                   property beneï¬cial change single stateâ€™s        queueinserts Î”s                              heuristic value affect heuristic values      end                                            potentially remote states empirically limiting far    end                                              dates propagate unexplored regions state space                                                        does signiï¬cantly impact plrtaâ€™s performance                                                          plrta algorithm present speciï¬es pri  figure  state inserted queue room oritized learning process greedy action selection  queue priority greater previ                                                      plrta modiï¬ed select actions way  ously enqueued state  state enqueued incorporates techniques algorithms  inserted second time queue                                                        creased lookahead speciï¬ed radius bulitko                                                        lee  heuristic weighting shimbo ishida   edge navigate world updating dis bulitko lee  preferentially taking actions  tance heuristics select states during acting phase agent through recently updated states koenig   agent simply uses greedy actionselection choose  phases         theoretical evaluation    beginning planning phase agent updates similar korfâ€™s lrta korf  plrta  current state considering immediate neighbors viewed special case barto et alâ€™s trialbased real  figure  current stateâ€™s value time dynamic programming rtdp following  changes stored variable Î” each cur orems outline theoretical guarantees trial  rent stateâ€™s neighbors slated entry queue based rtdp hold plrta explain plrtaâ€™s  priority Î” queue entry lowest prior time space complexity  ity removed figure  plrta requires initial world theorem  plrta converges optimal solution  model updates spread unseen states use freespace                                                        start state âˆˆ goal state sg âˆˆ initial  assumption                                           heuristic nonoverestimating    current stateâ€™s heuristic updated series pri  oritized updates begins states spec algorithm meets criteria set convergence  iï¬ed user taken queue barto et al barto et al  shown trial  dated using procedure figure  states based rtdp extension plrta converges op  queue updates remain queue timal policy undiscounted shortest path problems  used planning phase                   start state set goal states sg exists    having completed planning phase agent moves policy takes agent goal probability   acting phase agent takes single action moving theorem  plrtaâ€™s permove time complexity  neighboring state s minimumvalued fs s om Â· logq maximum number updates  cs shs cs s cost traveling s time step size queue                                                    ijcai                                                      primary source plrtaâ€™s permove time complex puter game use particular testbed enabled com  ity comes updates algorithm performs parison existing published data number states  speciï¬ed each updates potentially each map       sults queue insertions branching factor generated  problems each map resulting total  current state each insertions requires  unique path planning problems solved each  check state queued using hash  competing parameterizations learning realtime  table high priority search algorithms table   queued ologq using ordered balanced tree      agent incurs unit costs forâˆš moving states  theorem  plrtaâ€™s memory requirements space  cardinal direction costs  moving diagonally  complexity os size state space algorithms experimented use octile distance bu                                                                             plrta requires memory environmental  litko lee  initial heuristic  model states queue learning model state precise execution cost  priori unknown environment necessitates keeping track curred agent obstacles  constant number connections states goal sg maps initially unknown each  duplicate states disallowed maximum agents uncertainty map handled using  number states queue exceed  aforementioned freespace assumption visibility ra                                                        dius each algorithm set  limits each agent    performance metrics                                knows world begins planning                                                            compare plrta   ï¬ve  algorithms lra  realtime search algorithms used lrtad lrtsdÎ³t prlrts lra  sponse time user experience important base level lrtsdÎ³t ï¬rst ab  measure performance search algorithms using fol stract level lrts parameters handtuned  lowing metrics                                       low convergence execution cost size koenigâ€™s    firstmove lag time agent make ï¬rst adeï¬ned strict search space similar parameter  measure algorithmâ€™s ï¬rstmove lag terms lrtaâ€™s queue size compare koenigâ€™s lrta  number states touched ï¬rst trial using local search spaces size      agent converged solution                                                                line previous research realtime search enables                                           compare new results old results                                     suboptimality ï¬nal solution percentagewise          length ï¬nal path longer                                                                                               length optimal path                                                                                                       planning time unit distance traveled indicates      planning step realtime multiagent applica  tions measure upper bounded application    straints producing action each time step video                                                             game algorithmâ€™s planning time measured terms  number states touched unit distance traveled      memory consumed number heuristic values                 stored heuristic table measure does include   memory used store observed map algorithms   run use map representation    learning heuristic search algorithms typically learn  multiple trials use convergence execution cost measure                                                                                                                          total distance physically traveled agent during                         learning process measure terms distance                          traveled agent path converges distance  measured terms cost traveling state figure  convergence execution cost semilog averaged                                                         problems plotted optimal solution length                                           lrtad large convergence execution cost    note measures platform independent lrtaqueuesizeupdates convergence execu  report planning time number states touched tion cost comparable lra  algorithm state considered touched heuristic  value accessed algorithm linear correla each algorithmâ€™s performance tabulated compari  tion number states touched wall time son table  lra lrtad demonstrate ex  taken implementation                         tremes lra smallest convergence execution cost                                                        stores heuristic values ï¬rstmove lag    experimental results                               greatest algorithms plans way  ran search algorithms pathplanning problems ï¬ve goal lrtad largest convergence execution cost  different maps taken bestselling commercial com result simplistic update procedure ï¬rst                                                    ijcai                                                                   algorithm             execution  planning     lag      heuristic memory suboptimality                   lra                  Â±   Â±   Â±                                    lrtad             Â±   Â±   Â±     Â±                     lrtsd Î³      Â±   Â±   Â±   Â±      Â±           prlrtsdÎ³      Â±   Â±   Â±     Â±         Â±            koenigâ€™s lrtalss      Â±   Â±   Â±   Â±                    koenigâ€™s lrtalss      Â±   Â±   Â±   Â±                    koenigâ€™s lrtalss      Â±   Â±   Â±   Â±                    koenigâ€™s lrtalss      Â±   Â±   Â±   Â±                plrtaqueuesize updates  Â±   Â±   Â±   Â±                plrtaqueuesize updates  Â±   Â±   Â±    Â±                plrtaqueuesize updates  Â±   Â±   Â±    Â±                plrtaqueuesize updates  Â±   Â±   Â±    Â±              table  results  problems visibility radius  results lra lrta lrts prlrts taken  bulitko et al     lag planning costs extremely low each queue size ï¬xed maximum number updates fig  parameterization plrta ï¬rstmove lag comparable ure  demonstrates plrtaâ€™s parameters provide  lrtad convergence execution cost effective ways changing algorithm meet speciï¬c  lower algorithms use sophisticated abstraction rou time andor space requirements  tines prlrts    figure  shows average convergence execution cost  future work  algorithms  problems various lengths  lrtaâ€™s convergence execution cost similar lraâ€™s prioritized lrta simple effective algorithm invites  indicates heuristic learning plrta efï¬cient analysis experimentation randomized  expense learning heuristic function startlocations problems explore provide ad  scales similarly expense learning priori ditional insight like extend plrta  known map                                     include dynamic parameterization settings                                                        beneï¬cial use extra memory available                                                        lrta provides convenient way advantage free                                                        memory queue size dynamically adjusted                                                          plrta beneï¬t sophisticated action                                                        selection scheme purely greedy decisionmaking                                                        process present plrtaâ€™s simplicity makes easy                                                   experiment number recent realtime search tech                                                        niques improve convergence time                                                      state abstraction successfully applied realtime                                                        heuristic search bulitko et al  hybrid approach                                                    combines prioritized updates state abstraction likely                                                        produce search routine powerful ei                                                    ther method interesting direction extend                                                        plrta handle dynamic environments including fo                                                   cused exploration allowing heuristic values decrease     convergence  execution cost                                                                                conclusions                                                                                                         incremental search algorithms realtime search algo                                        queue size  rithms meet different requirements incremental search al        maximum number updates                       gorithms lra converge quickly suffer                                                        arbitrarily long delays responding realtime search  figure  impact queue size maximum number works strict permove computational limit  updates convergence execution cost                long online interactive learning process reduces applica    using set  problems used generate bility good solutions needed start  table  explore plrtaâ€™s parameter space exper plrta response time par fastest known  iment reveals queue size maximum number realtime search algorithms learning process  updates exhibit independence converges time scales mere map discov  affect performance increase maximum ery lra plrta agent learn twice fast  number updates ï¬xed queue size convergence actual map stateoftheart prlrts agent learns  execution cost decreases happens increase smaller abstract map                                                    ijcai                                                    

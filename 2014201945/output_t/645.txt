              value observation monitoring dynamic systems               eyal evendar                   sham kakade                    yishay mansour‚àó   information science    toyota technological institute     school science       university pennsylvania            chicago il usa                 tel aviv university      philadelphia pa  usa               shamtticorg                tel aviv  israel        evendarseasupennedu                                               mansourcstauacil                        abstract                           kanazawa  ‚Äî  share markov                                                        sumption naturally like provide conditions      consider fundamental problem monitor   monitoring possible modelling errors      ing tracking belief state dynamic sys present conditions dynam      tem model approximately correct ics transition states      initial belief state unknown observability true model      general setting model transition dynamics usually depends application      slightly misspeciÔ¨Åed monitoring observations depend user      sequently planning impossible errors   able obtain better observations adding sensors      accumulate time provide new      just accurate sensors paper main      characterization value observationwhich  quantifying observations useful      allows bound error accumulation        effects monitoring problem      value observation parameter gov   deÔ¨Åne proposed measure illus      erns information observation pro    trative example hmm value information      vides instance partially observable mdps vary parametric manner consider hmm       pomdp mdp     state observation reveals true state prob      unobservable markov decision process param   ability  ‚àí  probability  gives random state      eter  new parameter characterizes thought having noisy sensor intuitively      spectrum mdps unobservable mdps       parameter  varies zero state monitoring      pending information conveyed  harder      observations                                   introduce parameter characterizes infor                                                        mative observations helping disambiguate                                                        underlying hidden state coin parameter    introduction                                       value observation value observation criterion tries  real world applications require estimation quantify different belief states different                                                                                               known state given past observations goal main observation distributions formally  distance  tain track belief state distribution states tween belief states related observation dis  applications Ô¨Årst step tributions maintained multiplicative factor  challenging tasks learning planning value observation parameter  dynamics perfectly known approx paper use update rule variant  imate model available model initial state bayesian update perform bayesian update given  perfectly known state monitoring reduces bayesian inaccurate model add noise par  inference modelling error tran ticular mix resulting belief state uniform dis  sition model slightly incorrect belief states tribution adding noise crucial algorithm en  approximate model diverge true bayesian sures beliefs incorrectly overly conÔ¨Ådent  lief state implications divergence preventing belief state adapting fast  dire                                                 new informative information    popular dynamic models monitoring   main results show model approxi  unknown state hidden markov model hmm ra  mate modiÔ¨Åed bayesian updates guarantee  biner  juang  extensions partially observ true belief state belief state diverge ‚Äî assum  able markov decision process puterman  kalman fil ing value observation negligible speciÔ¨Å  ters kalman  dynamic bayesian networks dean cally show initial state approximately ac                                                        curate expected kldivergence belief    ‚àósupported grant isf bsf     state true belief state remains small show                                                    ijcai                                                    uninformative initial state arbitrary algorithm subsection  provides main monitoring  initial belief state converge belief state theorem subsection  proves theorem section   expected kldivergence true belief state small show extend results dynamic bayesian  remain finally extend networks  results setting considered boyen  koller   goal compactly represent belief state  preliminaries  precision rate convergence depends value                                                        hidden markov model hmm tuple ob  observation                                                        set states     natural setting inaccurate model                                                        transition probability form state state ob  underlying environment precisely markovian ex                                                        observations set observation distribution  ample transition model slightly inÔ¨Çu                                                        state belief state distribution states  enced extrinsic random variables given                                                        bi probability state sithe  extrinsic variables true transition model environ                                                        transition probabilities belief states deÔ¨Åned accord  ment slightly different model each time step                                                        ing hmm  transition observation probability using  case like model environment                                                        bayesian update  markovian cost introducing error                                                          belief state b¬∑ probability observing  fact transition model entirely markovian                                                        oobwhere  results apply setting encouraging                 sult cases markovian assumption           oob    oosbs  abstraction environment precise                   scription  related work work closely related observing observation belief state b¬∑  boyen koller  considered monitor dated belief state  ing hidden markov model setting environ                  oosbs                                                                       uo bs  ment exactly known agent wants com                        oob  pact factored representation belief state                                                                 exactly factored form main assumption uo deÔ¨Åned observation update operator  environment mixing rapidly error contract deÔ¨Åne transition update operator  geometric factor each time apply transition                                                                                                             matrix operator contrast interested monitoring      bs     sbs   approximate environment model                      s  work theirs assume form contraction                                                          denote bt belief state time time   beliefs tend closer truth bayesian                                                         discuss case initial belief state  updates ‚Äî through assumption value                                                         known case unknown observing  observation through assumption tran                                                        observation ot ‚àà ob inductive computation belief  sition matrix main advantage method                                                        state time  applications improve quality observa                                                                               ob   tions adding better sensors mix                   ot  ing assumption used boyan koller alter  able furthermore Ô¨Ånal section explicitly consider Ô¨Årst update belief state observation                                                                                             assumption setting show belief state date operator according observation andthenbythe  compactly maintained model approx transition update operator straightforward consider                                                                                        imate additional error accumulates maintain different update order distribution                                                                                          ing compact factored representation                states conditioned observing                                                                                      particle filtering doucet  different monitoring initial belief state   approach estimates current belief state  making clever sampling limit observes  approximate monitoring  true belief state major drawback method interested monitoring belief state case  case large variance requires samples model inaccurate  combination methods considered correct initial belief state let assume  ng et al                                     algorithm access transition matrix p observa                                                building work boyen  koller  tion distribution o error respect true                                 trajectory tree kearns et al   mcallester singh models algorithm‚Äôs goal accurately estimate   provides approximate planning algorithm similar                             ÀÜb  extensions using algorithm possible       belief state time  denote                                                          notational simplicity deÔ¨Åne eo‚àºb  eo‚àºo ¬∑b     outline outline paper follows sec                                                                                                     p clear context deÔ¨Åne  tion  provide notation deÔ¨Ånitions section                main section paper deals monitoring t wheno o clear                                                                                            ob  composed subsections subsection  describes context deÔ¨Åne uo uo uo uo                                                     ijcai                                                      main behavior                  belief state update                                                                                        present belief state update naive approach                     kl   ÀÜb                                                  just use approximate transition matrix pÀÜ ap                                                        proximate observation distribution oÀÜ problem  expectation taken respect observation se                                                        approach approximate belief state place neg  quences ot‚àí  drawn according true model                                                     ligible probability possible state mistake         ÀÜb                          belief states time  respect irreversible  observation sequences                            consider following update operator tÀú each states    order quantify accuracy state monitoring ‚àà  assume accuracy conditions approxi                                                                 tÀús‚àí  u tÀÜsu unis  mate model kldistance natural error measure   uni  assumptions make accuracy   uniform distribution intuitively update                                                                uÀú  model later reÔ¨Çected quality monitoring operator mixes uniform distribution weight                                                        u  keeps probability state  assumption  accuracy  given hmm   model    bounded away zero unfortunately mixture  ob oant o accurate model hmm     uniform distribution additional source inaccuracy  ob states ‚àà        belief state analysis                                                        account                                       klp  ¬∑sp ¬∑s ‚â§ t                  belief state update follows              kl  ¬∑s o ¬∑s ‚â§                                       ÀÜb    tÀúuÀÜ ÀÜb                                                                        ot                                                                        ÀÜbt previous belief state    deÔ¨Åne value observation parameter  deÔ¨Ånition  given observation distribution oletm  monitoring belief state  matrix entry oosthevalue subsection present main theorem relates               Œ≥                       mx             accuracy belief state main parameters  observation  deÔ¨Åned infxx                                                quality approximate model value observation                                                        weight uniform distribution    note value observation Œ≥                                                        theorem  time let ÀÜbt belief state updated ac  belief states                                                        cording equation  bt true belief state zt      b ‚àí   ‚â•o  ¬∑b  ‚àí ¬∑b   ‚â• Œ≥b ‚àí                                               klbtÀÜbt  Œ≥ value observation                                                                                            Ô¨Årst inequality follows simple algebra                zt ‚â§ zt   ‚àí Œ±zt     parameter Œ≥ plays critical rule analysis                     ‚àö              Œ≥                                                          t   u       Œ≥  o Œ±                         Œ≥            b ‚àí     o ¬∑b  ‚àí                   log                log  extreme                                                              u  ¬∑b                                                                 ÀÜ                   note deÔ¨Ånition similar def furthermore b ‚àí b ‚â§ Œ± times  inition dobrushin coefÔ¨Åcient supb p  ¬∑ ‚àí                                                                                                log ‚àö   ¬∑                                                                            u        widely used Ô¨Åltering literature           zt ‚â§                moral  consider examples                               Œ±      Œ≥       Œ≥                   let   consider  having support state initial belief states ÀÜb  Œ¥there                            b ‚àí                                                         state case     exists time œÑŒ¥ ‚â•  ‚â• œÑŒ¥      o ¬∑b  ‚àí ¬∑b                                                    fore             implies                              ‚àö                                                                                   log u  different observations states holds   zt ‚â§       Œ¥           Œ¥  states implies given observation          Œ±         Œ≥  uniquely recover state illustrate value observation following corollary completely speciÔ¨Åes algo  characterization pomdp terminology Œ≥ rithm providing choice u  weight uniform  fully observable mdp observation appear distribution                                                                                                      ÀÜ                positive probability states extreme corollary  assume b ‚àí b ‚â§ Œ± u   unobservable mdp value Œ≥ t                                                                         log  times   o¬∑b ‚àí o¬∑b belief states                                                                                                             ‚àö                                                                           log t    recall example introduction state      zt ‚â§           t  Œ≥ o  observation reveals true state probability ‚àí            Œ≥                                                                                 probability gives random state straight proof the choice wehave                   Œ≥    ‚àí                                    ‚àö               ‚àö               ‚àö  forward show   approaches                    Œ≥    ‚â§        Œ≥     value observation approaches                                                     show having value Œ≥ bounded away                                                                             log        zero sufÔ¨Åcient ensure guarantee monitor       log   log         ‚â§  log     ing quality improves Œ≥ increases         u         t          t  paper assume Œ≥                             completes proof                                                                           ijcai                                                                                                                          analysis                                       note zt positive supermartingale                                                                                                    z  start presenting propositions useful proving converges probability  random variable                                                                    z                        theorem proved later Ô¨Årst provides bound expectation cannot larger Œ±                                                                           error accumulation                             larger Œ± expectation timestep                                                                                                      z ‚â•  proposition  error accumulation belief states strictly expected value deÔ¨Ånition        ÀÜ                              ÀÜ         ÀÜ     zt regardless initial knowledge belief  bt bt updates bt  tuot bt bt  tÀúuot bt                                                    state monitoring accurate results error                                                                                                              Œ±                                                        ÀÜ                 ÀÜ   eot klbt   bt    ‚â§  klbtbtu  log  o                                                    error accumulation analysis                                                                    ‚àíklo¬∑bto¬∑ÀÜbt       subsection present series lemmas prove                                                        proposition  lemmas bound difference    proposition lower bounds term propo updates approximate true model  sition  term depends value obser start proving lemma  provided begin  vation enables ensure belief states ning subsection  diverge                                                                                           proposition  value observation let Œ≥ value lemma  belief states    observation belief states ‚â• Œº                                                                               kltb   tb  ‚â§ klb t  sthen                                                                                                                                                                                                                                     proof let deÔ¨Åne joint distributions ps                                 Œ≥klbb                                              kl   ¬∑b o ¬∑b  ‚â•                            bs ps spÀÜs bs                                                                     log Œº              proof speciÔ¨Åcally denote random ‚ÄôÔ¨Årst‚Äô state                                  ‚àö                     s random ‚Äônext‚Äô state chain rule                              ‚àíŒ≥   o  o                                                        relative entropy write    using propositions prove main theo                                                                                                       rem theorem                                       klppklbbes‚àºbklt        ¬∑st¬∑s                                         uÀú    proof theorem  fact mixes            ‚â§   klbbt  uniform distribution Œº  u  combining  propositions   recalling deÔ¨Ånition we line follows assumption                                                           let ss ss denote distributions  obtain                                                                                                                 Ô¨Årst state given state respectively             kl   ÀÜb      ‚â§                                                               ot      t‚àí                      chain rule conditional probabilities                                                                                                                                            klbtÀÜbt ‚àí Œ± klbtÀÜbt                 klppkltbtab                                                                                                                                                                                es‚àºtbklpss pss     taking expectation respect ot‚àí                                                                     ‚â•   kl  tb tb                                                                                                                                                                                   line follows positivity relative         zt    ‚â§   zt   ‚àí Œ±e  klbtÀÜbt                                                      entropy putting results leads claim                                                                       ‚â§   zt   ‚àí Œ±z                                                         lemma bounds effect mixing uniform  line follows convexity      distribution                                                                                                                                            lemma   belief states           klbtÀÜbt  ‚â•   klbtÀÜbt                                                             kltbtbÀú  ‚â§    ‚àí u kltbtbÀÜ u log  proves Ô¨Årst claim theorem    proceed case the initial belief state proof convexity                      ÀÜ                good sense b ‚àí b ‚â§ Œ± thenwehave                                                             kltb   tbÀú  ‚â§   ‚àí u kltb tbÀÜ                                       ‚àí Œ±z                                                 Œ±  function t                                kl   tb uni ¬∑               ‚àí   Œ±                      ‚â§                                               derivative   which positive  Œ±                                                                           ‚â§    ‚àí u kltb tbÀÜ   zt   mapped   theneveryzt ‚â§                                                                Œ±               Œ±                  Œ±                                      mapped smaller value zt remain                     log              Œ±     conclude subtle case unknown initial belief line uses fact relative entropy  state deÔ¨Åne following random variable        tween distribution uniform bounded                                                      log                                                                                               t         Œ±                     combining lemmas obtain following                zt                                Œ±                   lemma transition model                                                    ijcai                                                    lemma   belief states           proof proposition  using deÔ¨Ånitions updates                                                        previous lemmas                                                                                      kltbtbÀú  ‚â§ klbbt  u log                                                                 kl   ÀÜb                                                             ot‚àºbt         dealing transition model left deal                                                                                                                ÀÜ  observation model provide analog lemma        eot‚àºbt kltuot  bttÀúuot bt  regards observation model                                                                                                                                        ÀÜ                                                              ‚â§  eot‚àºbt kluot  btuot bt  t  u log  lemma   belief states                                                                                                                                                          ‚â§  klbtÀÜbto ‚àí klo¬∑bto¬∑ÀÜbt              kl   u        o‚àºo ¬∑b                                                                      t  u log                                                   ‚â§ klbbo  ‚àí  klo¬∑bo¬∑b      Ô¨Årst inequality lemma  second                                                        lemma  completes proof proposition     proof let Ô¨Åx observation owehave                                                                                           kl  u                             value observation proposition  analysis                   log                                   uobs             following technical lemma useful proof                                                                                                    os  ob  relates  norm kl divergence                                                                   log                 lemma   assume ÀÜbs Œºfor Œº                                     oosbsoob                                                                                                                                                   ob                                  ‚àí                       kl  bÀÜb ‚â§b ‚àí ÀÜb                             log   log                                      log Œº                                          oob                                                               oos             proof let set states greater ÀÜb                          uob slog                                                       sbs ‚â• ÀÜbsso                                     oos                                                                                                                                                  kl  bÀÜb              ‚â§           line uses fact ob o ob           log            log                                                                          ÀÜbs            ÀÜbs  constants respect                                                     s‚ààa                                                                                                 let expectations Ô¨Årst term                          bs             bs                                                                        bs ‚àí ÀÜbs log     ÀÜbslog                                                                                     ÀÜbs            ÀÜbs                                                                 s‚ààa                     s‚ààa                                                                       o‚àºb       log                                                                         bs                                 ‚â§   log     bs ‚àí ÀÜbs                                                                     Œº                                                                         s‚ààa                            oos                                                                          ob                                                            ‚àí ÀÜb                        ob   logb                                                                                                                    ÀÜbslog                                                                                       ÀÜb                                                                   s‚ààa                                 os         kl                                                                  log                                                                                                   ‚â§            ‚àí ÀÜb      ‚àí ÀÜb                                                                 log Œº                                                                                           s‚ààa             s‚ààa  step uses fact oos simi                                                                                 b ‚àí ÀÜb  larly term straightforward show           log Œº                                                                                                          os                      used concavity log function                                                          o‚àºb       log                                                                                                          s‚ààabs‚àíÀÜbs  b‚àíÀÜb  claim follows                           oos                                                                                                                         Œº                                                         os     os         using fact                   ob                             ready complete proof make                         ob    log                                   oos         use pinsker‚Äôs inequality relates kl divergence                                                                                                                                                           norm states distributions            es‚àºb  klo¬∑so¬∑s                                                                                                                                                                klpq ‚â•  p ‚àí q               second term                                                                                                                 proof proposition  pinsker‚Äôs inequality                   ob                                                    sumption       eo‚àºb  ‚àí log          klo¬∑b  o¬∑b                                              o ob                                                                          ‚àö                                                                                                                                                  o¬∑s ‚àí o¬∑s ‚â§ klo¬∑so¬∑s ‚â§  o  directly deÔ¨Ånition relative entropy lemma states ‚àà using triangle inequality  follows assumption                                                                                                                     ready prove proposition           o¬∑b‚àío¬∑ÀÜb ‚â§o¬∑b‚àío¬∑ÀÜbo¬∑ÀÜb‚àío¬∑ÀÜb                                                     ijcai                                                    

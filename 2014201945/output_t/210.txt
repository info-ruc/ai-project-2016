peripheralfoveal vision realtime object recognition tracking video           stephen gould joakim arfvidsson adrian kaehler benjamin sapp marius messner                  gary bradski paul baumstarck sukwon chung andrew ng                                            stanford university                                         stanford ca  usa                          abstract                            little changes visual stream                                                        frame expects possible identify      human object recognition physical envi  objects portions scene time using high      ronment far superior robotic resolution fovea tracking previously identiÔ¨Åed objects      vision believe reason    peripheral region result possible      this‚Äîone heretofore     use computationally expensive classiÔ¨Åcation algorithms      signiÔ¨Åcantly exploited artiÔ¨Åcial vision relatively limited portion scene fovea      literature‚Äîis humans use fovea Ô¨Åxate Ô¨Åxated accumulating successful classiÔ¨Åcations      near object obtaining high resolu series frames realtime      tion image object rendering easy rec great deal happened recent years area      ognize paper present novel method location identiÔ¨Åcation speciÔ¨Åc objects object classes      identifying tracking objects multiresolution images work concentrated      digital video partially cluttered environments single frames object taking signiÔ¨Åcant      method motivated biological vision sys proportion Ô¨Åeldofview allows accurate      tems uses learned ‚Äúattentive‚Äù map  robust object recognition implies wish      low resolution data stream direct high  able Ô¨Ånd small objects higher      resolution ‚Äúfovea‚Äù objects recognized image resolutions naive approach signiÔ¨Åcant      fovea tracked using peripheral vi computational cost going higher resolution      sion object recognition run     continuous video sequences standard technique      small foveal image achieves perfor simply treat each frame image run classiÔ¨Åca      mance realtime object recognition tracking tion algorithm frame      simpler systems              frame typically using overlap indicate object                                                        frame object frame    introduction                                       ing kalman Ô¨Ålter stabilize measurements time  human visual far outperforms robotic primary difÔ¨Åculty simple method presents  terms object recognition reasons tremendous effort misdirected vast ma  paper focus hypothesis‚Äî jority scene does contain objects  heretofore little exploited vi attempting locate kalman Ô¨Ålter used pre  sion literature‚Äîthat division retina foveal dict new location object way  peripheral regions key importance improving detect appearance new objects enter  formance vision systems continuous video scene approached camera motion  sequences brieÔ¨Çy density photoreceptor rod cone solution propose introduce peripheralfoveal  cells varies retina small central fovea model attention directed small portion  high density color sensitive cone cells responsible visual Ô¨Åeld propose using lowresolution wideangle  detailed vision surrounding periphery contain video camera peripheral vision pantiltzoom ptz  ing signiÔ¨Åcantly lower density cones large num camera foveal vision ptz allows high resolu  ber monochromatic rod cells responsible tion small portion scene inter  things detecting motion estimates equivalent ested given time refer image scene  number ‚Äúpixels‚Äù human eye vary based supplied lowresolution wideangle camera pe  spatial acuity  degrees edelman weiss  ripheral view image supplied pantiltzoom                                              √ó  fahle poggio  appears order   consider example typical coffee mug distance Ô¨Åve  pixels indepth treatment human visual meters appearing standard  √ó  resolution ‚ó¶ Ô¨Åeldof  ception refer reader excellent text view camera mm tall coffee mug reduced mere   books literature example wandell  pixels high rendering extremely difÔ¨Åcult recognize                                                    ijcai                                                    camera foveal view simply fovea            outlines related work section  present probabilis    use attentive model determine regions tic framework attention model directs foveal  peripheral view wish perform object classi gaze experimental results sample hdv video stream  Ô¨Åcation attentive model learned labeled data real dualcamera hardware presented sec  interpreted map indicating probability tion  video streams typical ofÔ¨Åce environment  particular pixel unidentiÔ¨Åed object contain distractors objects various types  fovea repeatedly directed choosing region previously trained classiÔ¨Åers show  examine based expected reduction uncer performance attention driven signiÔ¨Åcantly  tainty location objects scene identiÔ¨Åca better naive scanning approaches  tion objects foveal view performed using  stateoftheart object classiÔ¨Åcation technologies  related work  example viola jones  serre et al   brubaker et al                               early computational architecture explaining visual    ptz camera used realworld robotic applications attention proposed koch ullman    modeled study peak magniÔ¨Åcation using model scene analyzed produce multiple fea  highdeÔ¨Ånition video hdv camera ‚Äúfoveal‚Äù ture maps combined form saliency map  gion selected video stream synthetically extract single saliency map used bias attention regions  ing small region hdv image advantage highest activity researchers example hu  second method input data exactly reproducible et al  privitera stark  itti et al  able evaluate different foveal camera motions suggested adjustments improvements koch ull  recorded video stream figure  shows robot man‚Äôs model review various techniques presented  mounted different camera setups         itti koch                                                           number systems inspired physiological mod                                                        els available technologies proposed Ô¨Ånd                                                        ing objects scene based idea visual attention                                                        example tagare et al  propose maximumlikelihood                                                        decision strategy Ô¨Ånding known object image                                                          recently active vision systems proposed                                                        robotic platforms instead viewing static image                                                        world systems actively change Ô¨Åeldofview                                                        obtain accurate results humanoid                                                        tects follows single known object using peripheral                                                        foveal vision presented ude et al  sim                                                        ilar hardware theirs proposed bjorkman¬®                                                        kragic  task object recognition pose esti                                                        mation orabona et al  attention driven sys                                                        tem described directs visual exploration                                                        salient object static scene                                                          analysis relationship corresponding                                                        points peripheral foveal views presented ude                                                        et al  describes physically control                                                        foveal gaze rigidly connected binocular cameras                                                             visual attention model  figure  stair platform left includes lowresolution periph  eral camera highresolution ptz camera topright alter visual comprises separate video cameras  native setup hdv camera replacing ptz bottomright Ô¨Åxed wideangle camera provides continuous low  experiments mount cameras standard tripod instead resolution video stream constitutes robot‚Äôs peripheral  using robotic platform                        view scene controllable pantiltzoom ptz cam                                                        era provides robot‚Äôs foveal view ptz camera    robot stair stanford artiÔ¨Åcial intelli commanded focus region peripheral  gence robot project longterm goal build view obtain detailed highresolution image area  ing intelligent homeofÔ¨Åce assistant carry tasks scene outlined conduct ex  cleaning room dinner party Ô¨Ånding periments recorded highresolution video streams allow  fetching items home ofÔ¨Åce ability repeatability comparing different algorithms  visually scan environment quickly identify objects figure  shows example peripheral foveal view  key elements needed robot accomplish typical ofÔ¨Åce scene attention selects  tasks                                           foveal window peripheral view corresponding    rest paper organized follows section  region highresolution video stream used                                                    ijcai                                                    figure  illustration peripheral middle foveal right views scene attentive map showing regions high  left takes approximately  seconds ptz camera new location acquire image    classiÔ¨Åcation attentive map generated fea objects  tures extracted peripheral view used determine                                                                                       Œæ            Œæ  direct foveal gaze discuss          tracked          unidentiÔ¨Åed                                                                 ‚ààt    primary goal identify track ob                 ok‚ààt  jects time particular like minimize Ô¨Årst summation objects tracked   uncertainty location identiÔ¨Åable objects second summation objects scene  scene computationally efÔ¨Åcient way identiÔ¨Åed  tention select regions scene tracked  informative understanding robot‚Äôs visual envi know total number objects  ronment                                              scene cannot directly compute entropy    able track previously identiÔ¨Åed objects                    hŒækt                                                        unidentiÔ¨Åed objects ok‚ààt       instead learn  consecutive frames using peripheral vision probability ok Ô¨Ånding previouslyunknown ob  classify new objects appear highresolution ject given foveal region scene based features        fovea  uncertainty tracked object‚Äôs position grows extracted peripheral view description  time directing fovea expected position model section  detect new ob  object reclassifying allows update estimate ject terms rightmost sum eq   location alternatively directing fovea different reduced expected reduction entropy taking  scene allows Ô¨Ånd new objects action Ô¨Åxating region fis  fovea instantaneously attention                needs periodically decide following actions Œîha  ok     Œækt                                                                              unidentiÔ¨Åed              conÔ¨Årmation tracked object Ô¨Åxating fovea                         ‚àí htrackedŒækt         predicted location object conÔ¨Årm                                                        term       Œækt constant reÔ¨Çects      presence update estimate position                unidentiÔ¨Åed                                                        uncertainty state untracked objects  search unidentiÔ¨Åed objects moving fovea htrackedŒækt entropy associated kalman      new scene running object clas Ô¨Ålter attached object detected      siÔ¨Åers region                          section                                                           objects tracked peripheral vision uncertainty    decision takes approximately   location grows reduce uncertainty   seconds‚Äîlimited speed ptz camera‚Äîfor                                                       observing object‚Äôs position through reclassiÔ¨Åcation  fovea acquire image new region area expected location use kalman Ô¨Ålter  during time track identiÔ¨Åed objects using pe track object easily compute reduction  ripheral vision fovea position search                                                        entropy taking action object ok ‚ààt  new tracked objects scanning scales shifts                                                                           foveal view standard practice state Œîha    ln Œ£kt‚àíln Œ£kt      oftheart object classiÔ¨Åers                                                        Œ£kt Œ£kt covariance matrices    formally let Œækt denote state kth object                                                                          sociated kalman Ô¨Ålter th object   time  assume independence objects reclassifying object respectively  scene uncertainty simply sum entropy terms                                                           experiments estimated term assuming largevariance    experiments single highresolution video stream distribution peripheral view possible object locations  simulate time required fovea delaying image practice algorithm‚Äôs performance appeared insensitive  selected hdv camera required number frames parameter                                                    ijcai                                                      formalism taking action estimation object‚Äôs state occlusion ob  duce uncertainty tracked object‚Äôs position ject case assume lost track  taking action reduce uncertainty object  unidentiÔ¨Åed objects assume equal costs each action objects recognized foveal view  choose action maximizes ex tracked peripheral view need transform coor  pected reduction entropy deÔ¨Åned eq   dinates views using wellknown stereo    tracking models calibration technique zhang  compute ex                                                        trinsic parameters ptz camera respect    object tracking                                  wideangle camera given objects far away rel  track identiÔ¨Åed objects using kalman Ô¨Ålter ative baseline cameras  assume independence objects associate separate disparity corresponding pixels objects  kalman Ô¨Ålter each object accurate dynamic model each view small corrected local correlation  objects outside current scope approach provides adequate accuracy controlling  use simplifying assumptions track each object‚Äôs coordi fovea Ô¨Ånding corresponding location objects  nates image plane state kth tracked tween views  object                                               finally entropy tracked object‚Äôs state required                                                        deciding actions state Œæt gaus                                                    Œæk xk   yk  xÀô yÀôk              sian random vector differential entropy                                                                                          represents ycoordinates yvelocity    htrackedŒækt   lnœÄe Œ£kt     object                                                              Œ£ ‚àà r√ó    each frame perform kalman Ô¨Ålter motion update         covariance matrix associated                                                                                       step using current estimate object‚Äôs state position estimate th object time   velocity update step                   ‚é°               ‚é§                      model                    Œît                                                                 choose foveal region examine action                   ‚é¢Œît          ‚é•        Œæ                     Œæ tŒ∑            need way estimate probability detecting                 ‚é£          ‚é¶                                                                   previously unknown object region scene                                                                                      deÔ¨Åne ‚Äúinterest model‚Äù rapidly identi                                                        Ô¨Åes pixels high probability containing objects  Œ∑m ‚àºn  Œ£m motion model noise Œît  duration timestep                      classify useful consequence deÔ¨Ånition    compute optical Ô¨Çow vectors peripheral view model automatically encodes biological phe  generated lucas kanade  sparse optical nomena saliency inhibition return‚Äîthe processes  Ô¨Çow algorithm Ô¨Çow vectors measure ve regions high visual stimuli selected fur                                                        ther investigation recently attended regions  locity each tracked object zvt averaging optical                                                                                                       Ô¨Çow object‚Äôs bounding box perform prevented attended klein   kalman Ô¨Ålter observation update assuming velocity obser detailed review  vation measurement model                                approach each pixel peripheral view                                                        estimate probability belonging unidentiÔ¨Åed ob                                                    ject build map regions scene             zvt              ŒæktŒ∑v                                                             density high map atten                                                        tion determines direct fovea achieve  Œ∑v ‚àºn  Œ£v velocity measurement model maximum beneÔ¨Åt described  noise                                                  formally deÔ¨Åne pixel interesting    object appears foveal view tak unknown classiÔ¨Åable object classiÔ¨Åable  ing action classiÔ¨Åcation returns estimate means object belongs object classes  zpt object‚Äôs position use perform cor classiÔ¨Åcation trained recognize  responding kalman Ô¨Ålter observation update greatly reduce model interestingness yt pixel periph  uncertainty location accumulated during tracking eral view xt time using dynamic bayesian network  position measurement observation model given dbn fragment shown figure                                                                                                                       th pixel ij     pixel interesting time             zpt              ŒæktŒ∑p             each pixel associated                                                                                                                                               vector observed features œÜijxt ‚àà   Œ∑p ‚àºn  Œ£p position measurement model                                                           resize image ptz camera size  noise                                                appear peripheral view compute crosscorrelation    incorporate position measurement model resized ptz image peripheral image  special case able reclassify object actual location fovea location maximum cross  object expected appear foveal view correlation small area expected location periph  example misclassiÔ¨Åcation error poor eral view                                                    ijcai                                                        yijt                                     procedure hand label single training video auto      yijt                                       matically generate data learning model given    yijt                                       speciÔ¨Åc combination classiÔ¨Åers foveal movement                                                        policies         yijt                                        adapt parameters probabilistic models       yijt                                        maximize likelihood training data described                                 yijt     yijt                                        model trained  frame video                                                        sequence  seconds  frames second figure         yijt                                     shows example learned map      yijt                                       algorithm automatically selected mugs inter    yijt                                       esting region                                             ijxt    figure  fragment dynamic bayesian network modeling  tentive      belief state entire frame time  yt  xxt exact inference  graphical model intractable apply approximate infer  ence estimate probability space constraints preclude  discussion brieÔ¨Çy applied assumed density fil                                                        figure  learned righthand panel shows proba  teringthe boyenkoller  algorithm approximate bility each pixel peripheral image left  distribution using a factored representation individ  ual pixels yt ‚âà ij yij experiments  inference algorithm appeared perform    model pixel depends  experimental results  pixel‚Äôs motion compensated neighbor evaluate performance visual attention  hood ni previous timestep features ex measuring percentage times classiÔ¨Åable object  tracted current frame parameterizations appearing scene correctly identiÔ¨Åed count  yijt  ynijt ‚àí  yij  œÜij xt number falsepositives tracked frame  given logistic functions learned parameters compare attention driven method directing fovea  use bayes rule compute œÜijxt  yijt needed three naive approaches  dbn belief update using model Ô¨Åxing foveal gaze center view  map estimate probability Ô¨Ånding object  given foveal region ok computing mean ii linearly scanning scene topleft  probability pixel foveal region inter right  esting                                              iii randomly moving fovea scene    features œÜij used predict pixel ex                                                          classiÔ¨Åers trained image patches roughly  tracted local image patch include harris corner                                                         √ó  pixels depending object class trained  features horizontal vertical edge density saturation                                                        each object class use   positive  color values duration pixel tracked                                                        training examples   negative examples set  object weighted decay number times fovea                                                        negative examples contained examples objects  previously Ô¨Åxated region containing pixel                                                        random images extract subset fea    learning model                      tures serre et al  images learn                                                        boosted decision tree classiÔ¨Åer each object  recall deÔ¨Åne pixel interesting                                                        good performance comparable stateoftheart sys  unclassiÔ¨Åed object order generate training data                                                        tems recognizing variety objects image patch  learn parameters model Ô¨Årst                                                        size chosen each object achieve good classi  hand label classiÔ¨Åable objects lowresolution training                                                        Ô¨Åcation accuracy large prevent  video sequence begins recognize                                                        classifying small objects scene  track objects pixels associated objects                                                            conduct  experiments using recorded high  longer interesting deÔ¨Ånition generate                                                        deÔ¨Ånition video streams Ô¨Årst assuming perfect classiÔ¨Å  training data annotating interesting pixels                                                        cation falsepositives falsenegatives  marked interesting hand labeled training video                                                        time fovea Ô¨Åxates object correctly classify  objects currently tracked using                                                        object second using actual trained stateofthe    envisage signiÔ¨Åcantly better estimates ex art classiÔ¨Åers addition different fovea control algo  ample using logistic regression recalibrate probabilities rithms compare method performing ob  algorithm‚Äôs performance appeared fairly insensitive choice ject classiÔ¨Åcation frames lowresolution                                                    ijcai                                                    

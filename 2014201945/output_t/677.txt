                                 transfer learning doing            krueger tim oates tom armstrong                paul cohen carole beal           university maryland baltimore county         usc information sciences institute                  csee  hilltop circle                        admiralty way                     baltimore md                        marina del rey ca              wkruegoatesarmcsumbcedu                    cohencbealisiedu                        abstract                          learner learns ï¬nite state machines uses current ma                                                        chine generate      develop related themes learning proce      experiments paper involve sequence three      dures knowledge transfer paper intro   games ï¬rst game child adult each      duces methods learning procedures stacks cards cards faceup      transferring previouslylearned knowledge cards facedown letâ€™s denote      slightly different task demonstrate experi stacks owner adult child      ment transfer accelerates learning          faceup facedown                                                        stacks au ad cu cd each player ï¬‚ip                                                        card facedown stack    introduction                                       faceup stack each player does fast  procedures interesting reasons infants exer ignore playerâ€™s actions purposes  cise procedures called â€œcircular reactionsâ€ piaget game      birth gradually develop complexity adding                                                                                    Â  Â¡ Â¢ Â£                                                                        Â¤ Â¥ Â¦ Â§ Â¨ Â£ Â¥ Â© Â¨ Â¡                                                                                                  Â¡ Â¢ Â£      new elements eventually incorporate objects                          Â                                                                           Â£ Â¥ Â© Â¨ Â¡           fantâ€™s environment piaget believed infants learn                                                                         Â¡ Â¢ Â£                 Â¢ Â© Â¨ Â£ Â¥ Â© Â¨          world executing procedures older students           Â       literature expertnovice differences                                                                          Â¢ Â© Â¨ Â£ Â¥ Â© Â¨ Â¡       Â  Â¡ Â¢ Â£                                                                                   Â¥ Â¦ Â§ Â¨ Â£ Â¥ Â© Â¨              summarized single phrase novices know â€œhowâ€ ex                    Â¤                                                                                    Â¥ Â© Â¨         perts know â€œwhyâ€ novices run statistical tests                  Â£  understand appropriate follow  recipes understand underlying chemistry gas figure  state machine game  yields perfect play  tronomy    advantages learning factlike knowledge  second game players turns ï¬‚ipping  alongside procedures useful work proce moving cards shown figure  nodes  dures doesnâ€™t completely understand left specify constraints child observes  means learning grounded activity gradual action currently taken  life agent exercising procedures learner adult lowerleft state machine adult  produces occasional failures context needs currently ï¬‚ipping card face  gradually learn new procedures nonprocedural stack fliptopad happens  knowledge includes facts reasons action executed child wait  â€œunderstandingâ€ colloquially conditioning vari adult does fliptopad child does wait  ables affect probabilities procedures suc time leads state adult does  ceed social environments human help movetopad topau results  learner correct missteps procedure goes com child waiting adult executes wait action  pletely wrong minimizes creditassignment prob constraint upperright state child ï¬‚ips card  lem                                                  facedown stack adult continues wait    intention machine learn sequence lowerright state child does movetopcd  increasinglydifï¬cult games starting extremely easy topcu time later adult ï¬‚ips card  ones games twoperson card games player facedown stack cycle repeats  makes mistakes competent player offers game just like second game  corrections necessary convenience play player turns card color card  ers learner child adult correct play matches card atop playerâ€™s faceup stack  games modeled ï¬nite state machines players say â€œsquawkâ€  learning state machines                           experiments                                                        figure  shows machines intermediate steps                                                        path learning turn taking game ma  goal learn procedures speciï¬cally perfectplay chine single state child wait  state machines described previous movecd cu flipcd edges labeled  section useful distinction drawn learning counts  number times transition taken  state machine learning state machine given related number times transition resulted machine  state machine interested second case does yield perfect play state split ob  present kind transfer learning servable feature reduces entropy distribution  begin discussion learning methods negative feedback feedback received  learning state machines novo bayesian model just  merging bmm  stolcke  wellknown method  learning hmms state splitting ss learns  hmms splitting merging states    training data approaches sequence ob  servations movetopcd topcu sym  bol squawk special symbol bmm ss  algorithms rely indicate child  allowed perfect play incorrect play  generated learnerâ€™s incorrect machine active  learning regime passive learning requires training data figure  machines produced ss learning turn  includes mistakes adult admonitions cor taking game  rections purpose build simulators child  adult play                                             machine figure  shows result split                                                        ting feature pruning away transitions al    bmm topdown approach initial hmm ways cause machine correctly captures fact  constructed state observation obser adult corrects child legal action wait  vations greedily merged maximize posterior likeli adult repairs incorrect action result  hood data using description length prior hmms yes residual feedback nondeterminism exists  incremental sense new observations added state errors action ordering ï¬‚ipping twice  during merging process ss bottomup approach row state split  starts state matches observations second set experiments child chose actions ran  peatedly splits states observable features world domly set known actions model devel  effort accurately predict negative feedback oped using bmm guide action selection ini  teacher features chosen minimize entropy tially child frequently choose incor  distribution feedback positive negative states rect action learning early model tedious    regardless hmm learned bmm   timeconsuming requires heavy exploration second  ss used action selection game play game simple turntaking game easy learn  parse new observations interested learning  simulation time steps required learn opti  series related increasingly difï¬cult games requires mal model game starting scratch  effort total learning difï¬cult game using model bias model learned game  novo example easier learn three games  time steps required achieve optimal model  sequence using machine learned game bias complex game game  model  learning game   learn play squawk used bias learning game  additional  prior machine serve bias                        time steps needed learn game  making total                                                         time steps game  took total half long    using bmm learn new game biased exist learn game  learned intermediate step  ing hmm new states transitions added new learning process  observations old obsolete state transitions  moved instead data collected acknowledgments  new game probabilities obsolete state transitions  longer traversed tend zero accept work supported darpa contract number   able want quickly reï¬ne model work  project learning doing  new game harnessing information possible  previous experience achieve preserve model references  structure eliminate bias old probability parameters stolcke  andreas stolcke bayesian learning  moving game bmm terminol  probabilistic language models phd thesis university  ogy means reset viterbi counts uniform california berkeley   small starting learn new game

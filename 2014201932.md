#一、图像处理
##实验内容
使用caffe框架训练和测试自己的图片
##实验数据
在一篇博客中找到了一份数据集，共有500张图片，分为大巴车、恐龙、大象、鲜花和马五个类，每个类100张。每类选出20张作为测试，其余80张作为训练。因此最终训练图片400张，测试图片100张，共5类。


![Paste_Image.png](http://upload-images.jianshu.io/upload_images/4026972-9e7afdaee9fec3d0.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

##数据处理
利用caffe自带的接口将图片转化为lmdb格式。

    #!/usr/bin/env sh
    MY=examples/myfile
    echo "Create train lmdb.."
    rm -rf $MY/img_train_lmdb
    build/tools/convert_imageset \
    --shuffle \
    --resize_height=256 \
    --resize_width=256 \
    /home/cuzibl/caffe/data/re/ \
    $MY/train.txt \
    $MY/img_train_lmdb
    echo "Create test lmdb.."
    rm -rf $MY/img_test_lmdb
    build/tools/convert_imageset \
    --shuffle \
    --resize_width=256 \
    --resize_height=256 \
    /home/cuzibl/caffe/data/re/ \
    $MY/test.txt \
    $MY/img_test_lmdb
    echo "All Done.."


![](http://upload-images.jianshu.io/upload_images/4026972-7ffe8e0ba9fb4c92.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

##计算图片均值
利用caffe程序提供的计算均值的文件compute_image_mean.cpp来计算图片均值，用以提高训练的速度和精度。
    #sudo build/tools/compute_image_mean examples/myfile/img_train_lmdb examples/myfile/mean.binaryproto

##创建模型并修改配置文件
使用caffe自带的caffenet模型，将models/bvlc_reference_caffenet/文件夹下的solver.prototxt和train_val.prototxt复制到myfile文件夹内，并修改部分参数。


![Paste_Image.png](http://upload-images.jianshu.io/upload_images/4026972-5eb50bbed2050df7.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

![Paste_Image.png](http://upload-images.jianshu.io/upload_images/4026972-2a733ddb4b7725db.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)
##训练和测试
    #sudo build/tools/caffe train -solver examples/myfile/solver.prototxt

##运行结果
accuracy=0.94

![4026972-438b8f1bad5ee976.png](http://upload-images.jianshu.io/upload_images/4026972-5a3e1621ee1fbf27.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

***
#二、文本处理
##实验内容
真假论文识别
##实验数据
真论文：ijcai，将其中100篇挑出作为测试数据
假论文：1000篇假论文
均为txt格式，一篇论文对应一个txt文件
##实验环境及工具
ubuntu14.04
python 2.7
collections、libsvm
##数据处理
1、数据清洗。去除所有符号、数字、和停用单词。


![Paste_Image.png](http://upload-images.jianshu.io/upload_images/4026972-411a0aad93cfde09.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

2、建立字典，统计词频。调用collection.OrderedDict()，对每一篇论文建立有序字典，将前三百个出现次数最多的词出现的次数记录下来。
![](http://upload-images.jianshu.io/upload_images/4026972-0df5120e1edf5dcc.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

##训练和测试
1、调用svm_problem(label,value_set)函数将数据转化为标准svm输入格式
调用svm_train(prob,param)进行训练
2、调用svm_predict(label,data_set,model)函数进行测试
![](http://upload-images.jianshu.io/upload_images/4026972-21b6b368859391be.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)
